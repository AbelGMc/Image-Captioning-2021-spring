Hugginface transformers not installed; please visit https://github.com/huggingface/transformers
meshed-memory-transformer not installed; please run `pip install git+https://github.com/ruotianluo/meshed-memory-transformer.git`
Warning: coco-caption not available
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2032520771026611
Cider scores: 0.0003974496049553251
Read data: 1.272885799407959
Cider scores: 0.00031465890544677517
Read data: 0.2723703384399414
Cider scores: 0.0003907735310098968
Read data: 0.27219557762145996
Cider scores: 0.00028706233176638816
Read data: 0.27443575859069824
Cider scores: 0.0003054171353920972
Read data: 0.2749922275543213
Cider scores: 0.0006250874058199223
Read data: 0.2761995792388916
Cider scores: 0.0005287404993973875
Read data: 0.27593517303466797
Cider scores: 0.0001832491623313271
Read data: 0.2771618366241455
Cider scores: 0.0001325871733825355
Read data: 0.27724742889404297
Cider scores: 0.0006390648778555014
Read data: 0.3343172073364258
Cider scores: 0.00045546429882131913
Read data: 0.2745938301086426
Cider scores: 0.000334635965596963
Read data: 0.27637195587158203
Cider scores: 0.00036416739174385706
Read data: 0.273867130279541
Cider scores: 0.0003801360174970193
Read data: 0.2752969264984131
Cider scores: 0.0005391711447022542
Read data: 0.2626645565032959
Cider scores: 0.00022402128677865437
Read data: 0.2635481357574463
Cider scores: 0.0004336632968340239
Read data: 0.26496434211730957
Cider scores: 0.00029306175112537664
Read data: 0.26770758628845215
Cider scores: 0.00023554969824404897
Read data: 0.2683537006378174
Cider scores: 0.0002747603526718356
Average cider score on test set: 0.000
End calculating cider score on TEST data set
===============================================
Read data: 0.26610827445983887
iter 0 (epoch 0), train_loss = 7.869, time/batch = 0.021
Read data: 0.00010728836059570312
iter 1 (epoch 0), train_loss = 7.840, time/batch = 0.016
Read data: 7.62939453125e-05
iter 2 (epoch 0), train_loss = 7.817, time/batch = 0.021
Read data: 9.894371032714844e-05
iter 3 (epoch 0), train_loss = 7.776, time/batch = 0.021
Read data: 0.0002040863037109375
iter 4 (epoch 0), train_loss = 7.769, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 5 (epoch 0), train_loss = 7.739, time/batch = 0.021
Read data: 7.62939453125e-05
iter 6 (epoch 0), train_loss = 7.667, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 7 (epoch 0), train_loss = 7.663, time/batch = 0.020
Read data: 8.034706115722656e-05
iter 8 (epoch 0), train_loss = 7.627, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 9 (epoch 0), train_loss = 7.606, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 10 (epoch 0), train_loss = 7.537, time/batch = 0.019
Read data: 0.00010037422180175781
iter 11 (epoch 0), train_loss = 7.538, time/batch = 0.027
Read data: 7.510185241699219e-05
iter 12 (epoch 0), train_loss = 7.505, time/batch = 0.029
Read data: 0.0001621246337890625
iter 13 (epoch 0), train_loss = 7.445, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 14 (epoch 0), train_loss = 7.393, time/batch = 0.020
Read data: 0.0001723766326904297
iter 15 (epoch 0), train_loss = 7.434, time/batch = 0.025
Read data: 0.00012445449829101562
iter 16 (epoch 0), train_loss = 7.313, time/batch = 0.018
Read data: 8.940696716308594e-05
iter 17 (epoch 0), train_loss = 7.252, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 18 (epoch 0), train_loss = 7.220, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 19 (epoch 0), train_loss = 7.154, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 20 (epoch 0), train_loss = 7.101, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 21 (epoch 0), train_loss = 7.032, time/batch = 0.019
Read data: 8.58306884765625e-05
iter 22 (epoch 0), train_loss = 7.014, time/batch = 0.021
Read data: 8.296966552734375e-05
iter 23 (epoch 0), train_loss = 7.041, time/batch = 0.020
Read data: 0.00019216537475585938
iter 24 (epoch 0), train_loss = 6.952, time/batch = 0.030
Read data: 0.00017213821411132812
iter 25 (epoch 0), train_loss = 6.874, time/batch = 0.019
Read data: 8.487701416015625e-05
iter 26 (epoch 0), train_loss = 6.891, time/batch = 0.021
Read data: 6.437301635742188e-05
iter 27 (epoch 0), train_loss = 6.817, time/batch = 0.020
Read data: 8.392333984375e-05
iter 28 (epoch 0), train_loss = 6.681, time/batch = 0.022
Read data: 0.00010251998901367188
iter 29 (epoch 0), train_loss = 6.714, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 30 (epoch 0), train_loss = 6.647, time/batch = 0.021
Read data: 5.698204040527344e-05
iter 31 (epoch 0), train_loss = 6.674, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 32 (epoch 0), train_loss = 6.636, time/batch = 0.025
Read data: 0.00505375862121582
iter 33 (epoch 0), train_loss = 6.511, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 34 (epoch 0), train_loss = 6.512, time/batch = 0.019
Read data: 5.507469177246094e-05
iter 35 (epoch 0), train_loss = 6.415, time/batch = 0.020
Read data: 0.00011992454528808594
iter 36 (epoch 0), train_loss = 6.618, time/batch = 0.022
Read data: 0.011243820190429688
iter 37 (epoch 0), train_loss = 6.372, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 38 (epoch 0), train_loss = 6.237, time/batch = 0.021
Read data: 5.602836608886719e-05
iter 39 (epoch 0), train_loss = 6.337, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 40 (epoch 0), train_loss = 6.291, time/batch = 0.028
Read data: 0.00014448165893554688
iter 41 (epoch 0), train_loss = 6.326, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 42 (epoch 0), train_loss = 6.232, time/batch = 0.019
Read data: 5.6743621826171875e-05
iter 43 (epoch 0), train_loss = 6.302, time/batch = 0.021
Read data: 0.0046770572662353516
iter 44 (epoch 0), train_loss = 6.093, time/batch = 0.020
Read data: 0.009117364883422852
iter 45 (epoch 0), train_loss = 6.148, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 46 (epoch 0), train_loss = 6.189, time/batch = 0.022
Read data: 5.841255187988281e-05
iter 47 (epoch 0), train_loss = 6.038, time/batch = 0.019
Read data: 0.005200862884521484
iter 48 (epoch 0), train_loss = 6.067, time/batch = 0.019
Read data: 0.0038232803344726562
iter 49 (epoch 0), train_loss = 6.070, time/batch = 0.023
Read data: 0.000171661376953125
iter 50 (epoch 0), train_loss = 5.925, time/batch = 0.019
Read data: 5.364418029785156e-05
iter 51 (epoch 0), train_loss = 6.009, time/batch = 0.024
Read data: 0.00988626480102539
iter 52 (epoch 0), train_loss = 5.960, time/batch = 0.020
Read data: 8.034706115722656e-05
iter 53 (epoch 0), train_loss = 5.892, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 54 (epoch 0), train_loss = 5.859, time/batch = 0.019
Read data: 5.5789947509765625e-05
iter 55 (epoch 0), train_loss = 5.910, time/batch = 0.027
Read data: 0.01267099380493164
iter 56 (epoch 0), train_loss = 5.890, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 57 (epoch 0), train_loss = 5.891, time/batch = 0.034
Read data: 8.869171142578125e-05
iter 58 (epoch 0), train_loss = 5.908, time/batch = 0.024
Read data: 5.936622619628906e-05
iter 59 (epoch 0), train_loss = 5.713, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 60 (epoch 0), train_loss = 5.749, time/batch = 0.026
Read data: 0.0001366138458251953
iter 61 (epoch 0), train_loss = 5.603, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 62 (epoch 0), train_loss = 5.549, time/batch = 0.019
Read data: 5.5789947509765625e-05
iter 63 (epoch 0), train_loss = 5.553, time/batch = 0.026
Read data: 0.0036041736602783203
iter 64 (epoch 0), train_loss = 5.716, time/batch = 0.020
Read data: 0.00012874603271484375
iter 65 (epoch 0), train_loss = 5.709, time/batch = 0.020
Read data: 8.845329284667969e-05
iter 66 (epoch 0), train_loss = 5.625, time/batch = 0.022
Read data: 5.507469177246094e-05
iter 67 (epoch 0), train_loss = 5.529, time/batch = 0.018
Read data: 0.020190954208374023
iter 68 (epoch 0), train_loss = 5.534, time/batch = 0.025
Read data: 0.0001418590545654297
iter 69 (epoch 0), train_loss = 5.812, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 70 (epoch 0), train_loss = 5.652, time/batch = 0.024
Read data: 6.151199340820312e-05
iter 71 (epoch 0), train_loss = 5.604, time/batch = 0.027
Read data: 0.008441686630249023
iter 72 (epoch 0), train_loss = 5.367, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 73 (epoch 0), train_loss = 5.434, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 74 (epoch 0), train_loss = 5.447, time/batch = 0.024
Read data: 6.151199340820312e-05
iter 75 (epoch 0), train_loss = 5.418, time/batch = 0.022
Read data: 0.0047304630279541016
iter 76 (epoch 0), train_loss = 5.435, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 77 (epoch 0), train_loss = 5.453, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 78 (epoch 0), train_loss = 5.395, time/batch = 0.019
Read data: 5.650520324707031e-05
iter 79 (epoch 0), train_loss = 5.606, time/batch = 0.025
Read data: 0.015253782272338867
iter 80 (epoch 0), train_loss = 5.378, time/batch = 0.026
Read data: 7.224082946777344e-05
iter 81 (epoch 0), train_loss = 5.426, time/batch = 0.026
Read data: 9.417533874511719e-05
iter 82 (epoch 0), train_loss = 5.289, time/batch = 0.023
Read data: 7.486343383789062e-05
iter 83 (epoch 0), train_loss = 5.215, time/batch = 0.022
Read data: 0.0034494400024414062
iter 84 (epoch 0), train_loss = 5.211, time/batch = 0.021
Read data: 0.00011301040649414062
iter 85 (epoch 0), train_loss = 5.504, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 86 (epoch 0), train_loss = 5.454, time/batch = 0.021
Read data: 6.031990051269531e-05
iter 87 (epoch 0), train_loss = 5.203, time/batch = 0.022
Read data: 0.01284933090209961
iter 88 (epoch 0), train_loss = 5.017, time/batch = 0.020
Read data: 0.00012755393981933594
iter 89 (epoch 0), train_loss = 5.296, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 90 (epoch 0), train_loss = 5.135, time/batch = 0.030
Read data: 6.532669067382812e-05
iter 91 (epoch 0), train_loss = 4.945, time/batch = 0.022
Read data: 0.005097150802612305
iter 92 (epoch 0), train_loss = 5.172, time/batch = 0.022
Read data: 7.62939453125e-05
iter 93 (epoch 0), train_loss = 5.158, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 94 (epoch 0), train_loss = 5.256, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 95 (epoch 0), train_loss = 5.092, time/batch = 0.022
Read data: 0.006268501281738281
iter 96 (epoch 0), train_loss = 5.069, time/batch = 0.023
Read data: 7.081031799316406e-05
iter 97 (epoch 0), train_loss = 5.180, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 98 (epoch 0), train_loss = 5.234, time/batch = 0.023
Read data: 6.699562072753906e-05
iter 99 (epoch 0), train_loss = 4.963, time/batch = 0.018
Read data: 0.011040449142456055
iter 100 (epoch 0), train_loss = 5.205, time/batch = 0.024
Read data: 0.00014019012451171875
iter 101 (epoch 0), train_loss = 4.985, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 102 (epoch 0), train_loss = 4.901, time/batch = 0.025
Read data: 7.05718994140625e-05
iter 103 (epoch 0), train_loss = 5.147, time/batch = 0.020
Read data: 0.006674766540527344
iter 104 (epoch 0), train_loss = 4.962, time/batch = 0.024
Read data: 7.104873657226562e-05
iter 105 (epoch 0), train_loss = 5.113, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 106 (epoch 0), train_loss = 5.003, time/batch = 0.020
Read data: 7.033348083496094e-05
iter 107 (epoch 0), train_loss = 4.810, time/batch = 0.022
Read data: 0.002608060836791992
iter 108 (epoch 0), train_loss = 4.933, time/batch = 0.021
Read data: 6.67572021484375e-05
iter 109 (epoch 0), train_loss = 4.912, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 110 (epoch 0), train_loss = 4.921, time/batch = 0.024
Read data: 7.462501525878906e-05
iter 111 (epoch 0), train_loss = 5.200, time/batch = 0.023
Read data: 0.014429330825805664
iter 112 (epoch 0), train_loss = 5.119, time/batch = 0.022
Read data: 7.128715515136719e-05
iter 113 (epoch 0), train_loss = 4.918, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 114 (epoch 0), train_loss = 4.787, time/batch = 0.024
Read data: 6.985664367675781e-05
iter 115 (epoch 0), train_loss = 4.927, time/batch = 0.025
Read data: 0.0038187503814697266
iter 116 (epoch 0), train_loss = 4.837, time/batch = 0.018
Read data: 6.747245788574219e-05
iter 117 (epoch 0), train_loss = 4.983, time/batch = 0.020
Read data: 0.010543346405029297
iter 118 (epoch 0), train_loss = 4.945, time/batch = 0.023
Read data: 7.224082946777344e-05
iter 119 (epoch 0), train_loss = 4.929, time/batch = 0.021
Read data: 0.006760120391845703
iter 120 (epoch 0), train_loss = 4.898, time/batch = 0.022
Read data: 7.224082946777344e-05
iter 121 (epoch 0), train_loss = 5.118, time/batch = 0.025
Read data: 0.005003213882446289
iter 122 (epoch 0), train_loss = 4.988, time/batch = 0.020
Read data: 6.771087646484375e-05
iter 123 (epoch 0), train_loss = 4.776, time/batch = 0.018
Read data: 0.009865999221801758
iter 124 (epoch 0), train_loss = 4.741, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 125 (epoch 0), train_loss = 4.799, time/batch = 0.033
Read data: 0.00011372566223144531
iter 126 (epoch 0), train_loss = 4.849, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 127 (epoch 0), train_loss = 4.801, time/batch = 0.022
Read data: 0.006742238998413086
iter 128 (epoch 0), train_loss = 4.714, time/batch = 0.027
Read data: 0.00012111663818359375
iter 129 (epoch 0), train_loss = 4.772, time/batch = 0.030
Read data: 0.00011324882507324219
iter 130 (epoch 0), train_loss = 4.954, time/batch = 0.022
Read data: 9.655952453613281e-05
iter 131 (epoch 0), train_loss = 4.851, time/batch = 0.024
Read data: 0.0065765380859375
iter 132 (epoch 0), train_loss = 4.860, time/batch = 0.024
Read data: 0.00011157989501953125
iter 133 (epoch 0), train_loss = 4.785, time/batch = 0.027
Read data: 0.00012063980102539062
iter 134 (epoch 0), train_loss = 4.939, time/batch = 0.033
Read data: 7.104873657226562e-05
iter 135 (epoch 0), train_loss = 4.793, time/batch = 0.026
Read data: 0.00021839141845703125
iter 136 (epoch 0), train_loss = 4.718, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 137 (epoch 0), train_loss = 4.827, time/batch = 0.022
Read data: 0.000110626220703125
iter 138 (epoch 0), train_loss = 4.639, time/batch = 0.022
Read data: 7.128715515136719e-05
iter 139 (epoch 0), train_loss = 4.642, time/batch = 0.022
Read data: 0.013773441314697266
iter 140 (epoch 0), train_loss = 4.748, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 141 (epoch 0), train_loss = 4.555, time/batch = 0.024
Read data: 0.00010919570922851562
iter 142 (epoch 0), train_loss = 4.807, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 143 (epoch 0), train_loss = 4.651, time/batch = 0.031
Read data: 0.007352352142333984
iter 144 (epoch 0), train_loss = 4.589, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 145 (epoch 0), train_loss = 4.734, time/batch = 0.026
Read data: 0.00010895729064941406
iter 146 (epoch 0), train_loss = 4.851, time/batch = 0.026
Read data: 0.0001399517059326172
iter 147 (epoch 0), train_loss = 4.532, time/batch = 0.038
Read data: 0.0001895427703857422
iter 148 (epoch 0), train_loss = 4.886, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 149 (epoch 0), train_loss = 4.520, time/batch = 0.022
Read data: 0.00022292137145996094
iter 150 (epoch 0), train_loss = 4.865, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 151 (epoch 0), train_loss = 4.630, time/batch = 0.024
Read data: 0.0001246929168701172
iter 152 (epoch 0), train_loss = 4.614, time/batch = 0.023
Read data: 0.0001125335693359375
iter 153 (epoch 0), train_loss = 4.848, time/batch = 0.038
Read data: 0.0001418590545654297
iter 154 (epoch 0), train_loss = 4.606, time/batch = 0.024
Read data: 6.461143493652344e-05
iter 155 (epoch 0), train_loss = 4.655, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 156 (epoch 0), train_loss = 4.514, time/batch = 0.025
Read data: 6.365776062011719e-05
iter 157 (epoch 0), train_loss = 4.660, time/batch = 0.024
Read data: 7.033348083496094e-05
iter 158 (epoch 0), train_loss = 4.517, time/batch = 0.023
Read data: 7.534027099609375e-05
iter 159 (epoch 0), train_loss = 4.663, time/batch = 0.029
Read data: 9.655952453613281e-05
iter 160 (epoch 0), train_loss = 4.791, time/batch = 0.031
Read data: 6.866455078125e-05
iter 161 (epoch 0), train_loss = 4.642, time/batch = 0.018
Read data: 7.224082946777344e-05
iter 162 (epoch 0), train_loss = 4.681, time/batch = 0.024
Read data: 0.00010800361633300781
iter 163 (epoch 0), train_loss = 4.571, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 164 (epoch 0), train_loss = 4.687, time/batch = 0.021
Read data: 5.936622619628906e-05
iter 165 (epoch 0), train_loss = 4.839, time/batch = 0.023
Read data: 7.390975952148438e-05
iter 166 (epoch 0), train_loss = 4.878, time/batch = 0.038
Read data: 9.1552734375e-05
iter 167 (epoch 0), train_loss = 4.853, time/batch = 0.020
Read data: 0.00010037422180175781
iter 168 (epoch 0), train_loss = 4.761, time/batch = 0.027
Read data: 6.604194641113281e-05
iter 169 (epoch 0), train_loss = 4.613, time/batch = 0.022
Read data: 0.00014066696166992188
iter 170 (epoch 0), train_loss = 4.487, time/batch = 0.023
Read data: 0.0001373291015625
iter 171 (epoch 0), train_loss = 4.741, time/batch = 0.024
Read data: 0.00013113021850585938
iter 172 (epoch 0), train_loss = 4.487, time/batch = 0.017
Read data: 5.888938903808594e-05
iter 173 (epoch 0), train_loss = 4.497, time/batch = 0.024
Read data: 7.367134094238281e-05
iter 174 (epoch 0), train_loss = 4.610, time/batch = 0.025
Read data: 0.00020956993103027344
iter 175 (epoch 0), train_loss = 4.439, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 176 (epoch 0), train_loss = 4.454, time/batch = 0.029
Read data: 0.00010228157043457031
iter 177 (epoch 0), train_loss = 4.664, time/batch = 0.032
Read data: 6.723403930664062e-05
iter 178 (epoch 0), train_loss = 4.591, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 179 (epoch 0), train_loss = 4.539, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 180 (epoch 0), train_loss = 4.442, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 181 (epoch 0), train_loss = 4.494, time/batch = 0.020
Read data: 0.000110626220703125
iter 182 (epoch 0), train_loss = 4.853, time/batch = 0.027
Read data: 0.0001633167266845703
iter 183 (epoch 0), train_loss = 4.625, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 184 (epoch 0), train_loss = 4.421, time/batch = 0.019
Read data: 7.200241088867188e-05
iter 185 (epoch 0), train_loss = 4.449, time/batch = 0.022
Read data: 7.104873657226562e-05
iter 186 (epoch 0), train_loss = 4.351, time/batch = 0.024
Read data: 0.00011968612670898438
iter 187 (epoch 0), train_loss = 4.472, time/batch = 0.030
Read data: 8.96453857421875e-05
iter 188 (epoch 0), train_loss = 4.741, time/batch = 0.021
Read data: 6.914138793945312e-05
iter 189 (epoch 0), train_loss = 4.417, time/batch = 0.022
Read data: 7.05718994140625e-05
iter 190 (epoch 0), train_loss = 4.798, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 191 (epoch 0), train_loss = 4.931, time/batch = 0.034
Read data: 9.322166442871094e-05
iter 192 (epoch 0), train_loss = 4.724, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 193 (epoch 0), train_loss = 4.416, time/batch = 0.022
Read data: 7.653236389160156e-05
iter 194 (epoch 0), train_loss = 4.467, time/batch = 0.024
Read data: 0.00012421607971191406
iter 195 (epoch 0), train_loss = 4.421, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 196 (epoch 0), train_loss = 4.900, time/batch = 0.021
Read data: 6.866455078125e-05
iter 197 (epoch 0), train_loss = 4.476, time/batch = 0.025
Read data: 7.224082946777344e-05
iter 198 (epoch 0), train_loss = 4.480, time/batch = 0.021
Read data: 6.699562072753906e-05
iter 199 (epoch 0), train_loss = 4.411, time/batch = 0.020
Read data: 0.006155490875244141
iter 200 (epoch 0), train_loss = 4.608, time/batch = 0.019
Read data: 5.602836608886719e-05
iter 201 (epoch 0), train_loss = 4.722, time/batch = 0.024
Read data: 6.937980651855469e-05
iter 202 (epoch 0), train_loss = 4.470, time/batch = 0.022
Read data: 6.961822509765625e-05
iter 203 (epoch 0), train_loss = 4.831, time/batch = 0.022
Read data: 0.008816719055175781
iter 204 (epoch 0), train_loss = 4.483, time/batch = 0.019
Read data: 5.5789947509765625e-05
iter 205 (epoch 0), train_loss = 4.489, time/batch = 0.021
Read data: 6.818771362304688e-05
iter 206 (epoch 0), train_loss = 4.889, time/batch = 0.026
Read data: 6.747245788574219e-05
iter 207 (epoch 0), train_loss = 4.311, time/batch = 0.023
Read data: 0.007043361663818359
iter 208 (epoch 0), train_loss = 4.597, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 209 (epoch 0), train_loss = 4.533, time/batch = 0.020
Read data: 7.009506225585938e-05
iter 210 (epoch 0), train_loss = 4.373, time/batch = 0.020
Read data: 7.104873657226562e-05
iter 211 (epoch 0), train_loss = 4.466, time/batch = 0.021
Read data: 0.018095016479492188
iter 212 (epoch 0), train_loss = 4.547, time/batch = 0.018
Read data: 5.507469177246094e-05
iter 213 (epoch 0), train_loss = 4.235, time/batch = 0.019
Read data: 6.651878356933594e-05
iter 214 (epoch 0), train_loss = 4.717, time/batch = 0.025
Read data: 6.723403930664062e-05
iter 215 (epoch 0), train_loss = 5.018, time/batch = 0.030
Read data: 0.008068561553955078
iter 216 (epoch 0), train_loss = 4.418, time/batch = 0.021
Read data: 5.817413330078125e-05
iter 217 (epoch 0), train_loss = 4.512, time/batch = 0.022
Read data: 7.176399230957031e-05
iter 218 (epoch 0), train_loss = 4.721, time/batch = 0.023
Read data: 6.937980651855469e-05
iter 219 (epoch 0), train_loss = 4.797, time/batch = 0.027
Read data: 0.008012056350708008
iter 220 (epoch 0), train_loss = 4.456, time/batch = 0.023
Read data: 6.008148193359375e-05
iter 221 (epoch 0), train_loss = 4.480, time/batch = 0.023
Read data: 7.534027099609375e-05
iter 222 (epoch 0), train_loss = 4.372, time/batch = 0.021
Read data: 6.818771362304688e-05
iter 223 (epoch 0), train_loss = 4.747, time/batch = 0.023
Read data: 0.01113128662109375
iter 224 (epoch 0), train_loss = 4.601, time/batch = 0.020
Read data: 0.000202178955078125
iter 225 (epoch 0), train_loss = 4.508, time/batch = 0.020
Read data: 7.557868957519531e-05
iter 226 (epoch 0), train_loss = 4.702, time/batch = 0.023
Read data: 6.961822509765625e-05
iter 227 (epoch 0), train_loss = 4.716, time/batch = 0.026
Read data: 0.008462667465209961
iter 228 (epoch 0), train_loss = 4.330, time/batch = 0.018
Read data: 5.507469177246094e-05
iter 229 (epoch 0), train_loss = 4.398, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 230 (epoch 0), train_loss = 4.593, time/batch = 0.020
Read data: 7.05718994140625e-05
iter 231 (epoch 0), train_loss = 4.399, time/batch = 0.024
Read data: 0.011740446090698242
iter 232 (epoch 0), train_loss = 4.593, time/batch = 0.026
Read data: 5.841255187988281e-05
iter 233 (epoch 0), train_loss = 4.514, time/batch = 0.031
Read data: 6.604194641113281e-05
iter 234 (epoch 0), train_loss = 4.439, time/batch = 0.020
Read data: 7.677078247070312e-05
iter 235 (epoch 0), train_loss = 4.672, time/batch = 0.029
Read data: 9.036064147949219e-05
iter 236 (epoch 0), train_loss = 4.771, time/batch = 0.023
Read data: 6.175041198730469e-05
iter 237 (epoch 0), train_loss = 4.739, time/batch = 0.023
Read data: 7.152557373046875e-05
iter 238 (epoch 0), train_loss = 4.436, time/batch = 0.026
Read data: 7.295608520507812e-05
iter 239 (epoch 0), train_loss = 4.682, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 240 (epoch 0), train_loss = 4.283, time/batch = 0.018
Read data: 7.915496826171875e-05
iter 241 (epoch 0), train_loss = 4.499, time/batch = 0.028
Read data: 7.510185241699219e-05
iter 242 (epoch 0), train_loss = 4.500, time/batch = 0.023
Read data: 7.319450378417969e-05
iter 243 (epoch 0), train_loss = 4.435, time/batch = 0.024
Read data: 0.0015294551849365234
iter 244 (epoch 0), train_loss = 3.996, time/batch = 0.019
Read data: 5.459785461425781e-05
iter 245 (epoch 0), train_loss = 4.417, time/batch = 0.020
Read data: 6.794929504394531e-05
iter 246 (epoch 0), train_loss = 4.339, time/batch = 0.021
Read data: 7.224082946777344e-05
iter 247 (epoch 0), train_loss = 4.456, time/batch = 0.021
Read data: 0.014537334442138672
iter 248 (epoch 0), train_loss = 4.462, time/batch = 0.024
Read data: 0.0001246929168701172
iter 249 (epoch 0), train_loss = 4.490, time/batch = 0.019
Read data: 0.00033545494079589844
iter 250 (epoch 0), train_loss = 4.576, time/batch = 0.019
Read data: 6.747245788574219e-05
iter 251 (epoch 0), train_loss = 4.330, time/batch = 0.023
Read data: 0.013333559036254883
iter 252 (epoch 0), train_loss = 4.650, time/batch = 0.019
Read data: 5.745887756347656e-05
iter 253 (epoch 0), train_loss = 4.495, time/batch = 0.020
Read data: 8.606910705566406e-05
iter 254 (epoch 0), train_loss = 4.214, time/batch = 0.020
Read data: 6.532669067382812e-05
iter 255 (epoch 0), train_loss = 4.476, time/batch = 0.020
Read data: 0.01564955711364746
iter 256 (epoch 0), train_loss = 4.372, time/batch = 0.019
Read data: 5.793571472167969e-05
iter 257 (epoch 0), train_loss = 4.527, time/batch = 0.023
Read data: 7.081031799316406e-05
iter 258 (epoch 0), train_loss = 4.616, time/batch = 0.020
Read data: 7.462501525878906e-05
iter 259 (epoch 0), train_loss = 4.151, time/batch = 0.018
Read data: 0.018404006958007812
iter 260 (epoch 0), train_loss = 4.587, time/batch = 0.025
Read data: 0.0001201629638671875
iter 261 (epoch 0), train_loss = 4.324, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 262 (epoch 0), train_loss = 4.227, time/batch = 0.020
Read data: 6.723403930664062e-05
iter 263 (epoch 0), train_loss = 4.317, time/batch = 0.024
Read data: 0.00851750373840332
iter 264 (epoch 0), train_loss = 4.409, time/batch = 0.028
Read data: 5.6743621826171875e-05
iter 265 (epoch 0), train_loss = 4.464, time/batch = 0.028
Read data: 6.437301635742188e-05
iter 266 (epoch 0), train_loss = 4.380, time/batch = 0.021
Read data: 7.295608520507812e-05
iter 267 (epoch 0), train_loss = 4.290, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 268 (epoch 0), train_loss = 4.319, time/batch = 0.019
Read data: 5.555152893066406e-05
iter 269 (epoch 0), train_loss = 4.576, time/batch = 0.031
Read data: 0.00011754035949707031
iter 270 (epoch 0), train_loss = 4.271, time/batch = 0.028
Read data: 6.842613220214844e-05
iter 271 (epoch 0), train_loss = 4.454, time/batch = 0.022
Read data: 9.989738464355469e-05
iter 272 (epoch 0), train_loss = 4.231, time/batch = 0.026
Read data: 6.151199340820312e-05
iter 273 (epoch 0), train_loss = 4.304, time/batch = 0.023
Read data: 0.0001423358917236328
iter 274 (epoch 0), train_loss = 4.222, time/batch = 0.023
Read data: 0.0002117156982421875
iter 275 (epoch 0), train_loss = 4.492, time/batch = 0.022
Read data: 0.003105640411376953
iter 276 (epoch 0), train_loss = 4.607, time/batch = 0.023
Read data: 5.841255187988281e-05
iter 277 (epoch 0), train_loss = 4.607, time/batch = 0.021
Read data: 7.200241088867188e-05
iter 278 (epoch 0), train_loss = 4.424, time/batch = 0.020
Read data: 9.1552734375e-05
iter 279 (epoch 0), train_loss = 4.530, time/batch = 0.029
Read data: 0.0030298233032226562
iter 280 (epoch 0), train_loss = 4.256, time/batch = 0.019
Read data: 5.412101745605469e-05
iter 281 (epoch 0), train_loss = 4.519, time/batch = 0.023
Read data: 7.462501525878906e-05
iter 282 (epoch 0), train_loss = 4.400, time/batch = 0.021
Read data: 7.390975952148438e-05
iter 283 (epoch 0), train_loss = 4.220, time/batch = 0.023
Read data: 0.01168966293334961
iter 284 (epoch 0), train_loss = 4.517, time/batch = 0.019
Read data: 5.602836608886719e-05
iter 285 (epoch 0), train_loss = 4.441, time/batch = 0.027
Read data: 6.866455078125e-05
iter 286 (epoch 0), train_loss = 4.611, time/batch = 0.023
Read data: 0.00010728836059570312
iter 287 (epoch 0), train_loss = 4.088, time/batch = 0.021
Read data: 0.008275747299194336
iter 288 (epoch 0), train_loss = 4.364, time/batch = 0.019
Read data: 5.936622619628906e-05
iter 289 (epoch 0), train_loss = 4.304, time/batch = 0.018
Read data: 6.747245788574219e-05
iter 290 (epoch 0), train_loss = 4.322, time/batch = 0.023
Read data: 7.2479248046875e-05
iter 291 (epoch 0), train_loss = 4.462, time/batch = 0.024
Read data: 0.011214971542358398
iter 292 (epoch 0), train_loss = 4.335, time/batch = 0.019
Read data: 5.984306335449219e-05
iter 293 (epoch 0), train_loss = 4.172, time/batch = 0.025
Read data: 6.818771362304688e-05
iter 294 (epoch 0), train_loss = 4.393, time/batch = 0.026
Read data: 6.4849853515625e-05
iter 295 (epoch 0), train_loss = 4.629, time/batch = 0.029
Read data: 0.001560211181640625
iter 296 (epoch 0), train_loss = 4.520, time/batch = 0.023
Read data: 5.9604644775390625e-05
iter 297 (epoch 0), train_loss = 4.391, time/batch = 0.022
Read data: 7.152557373046875e-05
iter 298 (epoch 0), train_loss = 4.253, time/batch = 0.021
Read data: 7.009506225585938e-05
iter 299 (epoch 0), train_loss = 4.249, time/batch = 0.019
Read data: 0.012435674667358398
iter 300 (epoch 0), train_loss = 4.636, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 301 (epoch 0), train_loss = 4.301, time/batch = 0.020
Read data: 7.009506225585938e-05
iter 302 (epoch 0), train_loss = 4.286, time/batch = 0.025
Read data: 0.00012040138244628906
iter 303 (epoch 0), train_loss = 4.727, time/batch = 0.025
Read data: 0.0027472972869873047
iter 304 (epoch 0), train_loss = 4.220, time/batch = 0.021
Read data: 5.841255187988281e-05
iter 305 (epoch 0), train_loss = 4.406, time/batch = 0.024
Read data: 6.532669067382812e-05
iter 306 (epoch 0), train_loss = 4.161, time/batch = 0.020
Read data: 7.534027099609375e-05
iter 307 (epoch 0), train_loss = 4.069, time/batch = 0.023
Read data: 0.010478019714355469
iter 308 (epoch 0), train_loss = 4.086, time/batch = 0.019
Read data: 5.817413330078125e-05
iter 309 (epoch 0), train_loss = 4.342, time/batch = 0.018
Read data: 7.43865966796875e-05
iter 310 (epoch 0), train_loss = 4.290, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 311 (epoch 0), train_loss = 4.637, time/batch = 0.025
Read data: 0.01150059700012207
iter 312 (epoch 0), train_loss = 4.099, time/batch = 0.021
Read data: 5.5789947509765625e-05
iter 313 (epoch 0), train_loss = 4.484, time/batch = 0.029
Read data: 6.937980651855469e-05
iter 314 (epoch 0), train_loss = 4.493, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 315 (epoch 0), train_loss = 4.190, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 316 (epoch 0), train_loss = 4.590, time/batch = 0.032
Read data: 6.341934204101562e-05
iter 317 (epoch 0), train_loss = 4.067, time/batch = 0.020
Read data: 6.914138793945312e-05
iter 318 (epoch 0), train_loss = 4.084, time/batch = 0.023
Read data: 7.653236389160156e-05
iter 319 (epoch 0), train_loss = 4.693, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 320 (epoch 0), train_loss = 4.515, time/batch = 0.021
Read data: 5.7220458984375e-05
iter 321 (epoch 0), train_loss = 4.354, time/batch = 0.021
Read data: 6.556510925292969e-05
iter 322 (epoch 0), train_loss = 4.334, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 323 (epoch 0), train_loss = 4.403, time/batch = 0.023
Read data: 0.010553598403930664
iter 324 (epoch 0), train_loss = 4.578, time/batch = 0.022
Read data: 0.00018787384033203125
iter 325 (epoch 0), train_loss = 4.256, time/batch = 0.022
Read data: 6.866455078125e-05
iter 326 (epoch 0), train_loss = 4.341, time/batch = 0.019
Read data: 9.894371032714844e-05
iter 327 (epoch 0), train_loss = 4.319, time/batch = 0.023
Read data: 0.009648799896240234
iter 328 (epoch 0), train_loss = 4.186, time/batch = 0.022
Read data: 5.626678466796875e-05
iter 329 (epoch 0), train_loss = 4.445, time/batch = 0.024
Read data: 6.771087646484375e-05
iter 330 (epoch 0), train_loss = 4.161, time/batch = 0.020
Read data: 0.00013518333435058594
iter 331 (epoch 0), train_loss = 4.221, time/batch = 0.024
Read data: 0.0069980621337890625
iter 332 (epoch 0), train_loss = 4.349, time/batch = 0.025
Read data: 5.555152893066406e-05
iter 333 (epoch 0), train_loss = 4.524, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 334 (epoch 0), train_loss = 4.242, time/batch = 0.022
Read data: 7.748603820800781e-05
iter 335 (epoch 0), train_loss = 4.442, time/batch = 0.026
Read data: 0.00016236305236816406
iter 336 (epoch 0), train_loss = 4.297, time/batch = 0.021
Read data: 6.580352783203125e-05
iter 337 (epoch 0), train_loss = 4.394, time/batch = 0.022
Read data: 9.870529174804688e-05
iter 338 (epoch 0), train_loss = 4.375, time/batch = 0.023
Read data: 7.486343383789062e-05
iter 339 (epoch 0), train_loss = 4.130, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 340 (epoch 0), train_loss = 4.276, time/batch = 0.018
Read data: 5.7697296142578125e-05
iter 341 (epoch 0), train_loss = 4.198, time/batch = 0.021
Read data: 7.343292236328125e-05
iter 342 (epoch 0), train_loss = 4.277, time/batch = 0.022
Read data: 0.00010132789611816406
iter 343 (epoch 0), train_loss = 4.189, time/batch = 0.023
Read data: 0.014147043228149414
iter 344 (epoch 0), train_loss = 3.947, time/batch = 0.021
Read data: 5.698204040527344e-05
iter 345 (epoch 0), train_loss = 4.355, time/batch = 0.018
Read data: 7.224082946777344e-05
iter 346 (epoch 0), train_loss = 3.998, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 347 (epoch 0), train_loss = 4.398, time/batch = 0.020
Read data: 0.015155792236328125
iter 348 (epoch 0), train_loss = 4.534, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 349 (epoch 0), train_loss = 3.958, time/batch = 0.023
Read data: 0.00021505355834960938
iter 350 (epoch 0), train_loss = 3.984, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 351 (epoch 0), train_loss = 4.135, time/batch = 0.031
Read data: 9.632110595703125e-05
iter 352 (epoch 0), train_loss = 4.523, time/batch = 0.021
Read data: 0.00011444091796875
iter 353 (epoch 0), train_loss = 4.373, time/batch = 0.020
Read data: 7.319450378417969e-05
iter 354 (epoch 0), train_loss = 4.354, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 355 (epoch 0), train_loss = 3.964, time/batch = 0.028
Read data: 0.00016188621520996094
iter 356 (epoch 0), train_loss = 3.968, time/batch = 0.018
Read data: 5.984306335449219e-05
iter 357 (epoch 0), train_loss = 4.139, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 358 (epoch 0), train_loss = 4.515, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 359 (epoch 0), train_loss = 4.023, time/batch = 0.028
Read data: 0.00012731552124023438
iter 360 (epoch 0), train_loss = 4.227, time/batch = 0.024
Read data: 0.0001068115234375
iter 361 (epoch 0), train_loss = 4.101, time/batch = 0.022
Read data: 7.748603820800781e-05
iter 362 (epoch 0), train_loss = 3.832, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 363 (epoch 0), train_loss = 4.359, time/batch = 0.024
Read data: 0.0044062137603759766
iter 364 (epoch 0), train_loss = 4.344, time/batch = 0.025
Read data: 6.508827209472656e-05
iter 365 (epoch 0), train_loss = 4.350, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 366 (epoch 0), train_loss = 4.110, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 367 (epoch 0), train_loss = 4.304, time/batch = 0.023
Read data: 0.0036170482635498047
iter 368 (epoch 0), train_loss = 4.249, time/batch = 0.021
Read data: 0.00011444091796875
iter 369 (epoch 0), train_loss = 4.116, time/batch = 0.016
Read data: 7.390975952148438e-05
iter 370 (epoch 0), train_loss = 4.019, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 371 (epoch 0), train_loss = 4.287, time/batch = 0.021
Read data: 0.014611244201660156
iter 372 (epoch 0), train_loss = 4.210, time/batch = 0.022
Read data: 0.00011110305786132812
iter 373 (epoch 0), train_loss = 4.477, time/batch = 0.021
Read data: 7.581710815429688e-05
iter 374 (epoch 0), train_loss = 4.129, time/batch = 0.025
Read data: 7.414817810058594e-05
iter 375 (epoch 0), train_loss = 4.519, time/batch = 0.023
Read data: 0.0026760101318359375
iter 376 (epoch 0), train_loss = 4.330, time/batch = 0.022
Read data: 0.00012373924255371094
iter 377 (epoch 0), train_loss = 4.127, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 378 (epoch 0), train_loss = 4.479, time/batch = 0.035
Read data: 6.747245788574219e-05
iter 379 (epoch 0), train_loss = 4.221, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 380 (epoch 0), train_loss = 4.038, time/batch = 0.021
Read data: 7.319450378417969e-05
iter 381 (epoch 0), train_loss = 4.370, time/batch = 0.022
Read data: 0.00010156631469726562
iter 382 (epoch 0), train_loss = 4.149, time/batch = 0.029
Read data: 7.414817810058594e-05
iter 383 (epoch 0), train_loss = 4.198, time/batch = 0.024
Read data: 0.00010228157043457031
iter 384 (epoch 0), train_loss = 4.122, time/batch = 0.022
Read data: 0.00015354156494140625
iter 385 (epoch 0), train_loss = 4.207, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 386 (epoch 0), train_loss = 4.418, time/batch = 0.020
Read data: 7.62939453125e-05
iter 387 (epoch 0), train_loss = 4.280, time/batch = 0.028
Read data: 0.00010418891906738281
iter 388 (epoch 0), train_loss = 4.191, time/batch = 0.024
Read data: 0.00012063980102539062
iter 389 (epoch 0), train_loss = 4.674, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 390 (epoch 0), train_loss = 4.483, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 391 (epoch 0), train_loss = 3.872, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 392 (epoch 0), train_loss = 4.301, time/batch = 0.023
Read data: 7.224082946777344e-05
iter 393 (epoch 0), train_loss = 4.215, time/batch = 0.019
Read data: 9.489059448242188e-05
iter 394 (epoch 0), train_loss = 4.421, time/batch = 0.023
Read data: 0.0001385211944580078
iter 395 (epoch 0), train_loss = 4.190, time/batch = 0.026
Read data: 0.005597352981567383
iter 396 (epoch 0), train_loss = 4.259, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 397 (epoch 0), train_loss = 4.267, time/batch = 0.022
Read data: 0.00012540817260742188
iter 398 (epoch 0), train_loss = 4.078, time/batch = 0.022
Read data: 7.200241088867188e-05
iter 399 (epoch 0), train_loss = 4.284, time/batch = 0.023
Read data: 0.006948947906494141
iter 400 (epoch 0), train_loss = 4.476, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 401 (epoch 0), train_loss = 4.129, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 402 (epoch 0), train_loss = 4.406, time/batch = 0.023
Read data: 7.176399230957031e-05
iter 403 (epoch 0), train_loss = 3.946, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 404 (epoch 0), train_loss = 4.139, time/batch = 0.019
Read data: 5.5789947509765625e-05
iter 405 (epoch 0), train_loss = 4.300, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 406 (epoch 0), train_loss = 3.870, time/batch = 0.021
Read data: 6.985664367675781e-05
iter 407 (epoch 0), train_loss = 4.275, time/batch = 0.020
Read data: 0.012356758117675781
iter 408 (epoch 0), train_loss = 4.181, time/batch = 0.019
Read data: 5.698204040527344e-05
iter 409 (epoch 0), train_loss = 4.459, time/batch = 0.028
Read data: 9.489059448242188e-05
iter 410 (epoch 0), train_loss = 4.289, time/batch = 0.026
Read data: 7.319450378417969e-05
iter 411 (epoch 0), train_loss = 4.219, time/batch = 0.022
Read data: 0.00663447380065918
iter 412 (epoch 0), train_loss = 4.476, time/batch = 0.021
Read data: 7.724761962890625e-05
iter 413 (epoch 0), train_loss = 4.277, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 414 (epoch 0), train_loss = 4.029, time/batch = 0.019
Read data: 7.05718994140625e-05
iter 415 (epoch 0), train_loss = 4.412, time/batch = 0.020
Read data: 0.007898092269897461
iter 416 (epoch 0), train_loss = 4.049, time/batch = 0.021
Read data: 5.9604644775390625e-05
iter 417 (epoch 0), train_loss = 4.574, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 418 (epoch 0), train_loss = 4.031, time/batch = 0.018
Read data: 7.271766662597656e-05
iter 419 (epoch 0), train_loss = 4.103, time/batch = 0.021
Read data: 0.009814977645874023
iter 420 (epoch 0), train_loss = 4.131, time/batch = 0.023
Read data: 6.222724914550781e-05
iter 421 (epoch 0), train_loss = 3.719, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 422 (epoch 0), train_loss = 4.201, time/batch = 0.021
Read data: 7.081031799316406e-05
iter 423 (epoch 0), train_loss = 4.112, time/batch = 0.027
Read data: 0.00013828277587890625
iter 424 (epoch 0), train_loss = 4.352, time/batch = 0.021
Read data: 0.00029158592224121094
iter 425 (epoch 0), train_loss = 4.225, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 426 (epoch 0), train_loss = 4.275, time/batch = 0.024
Read data: 7.128715515136719e-05
iter 427 (epoch 0), train_loss = 4.182, time/batch = 0.026
Read data: 0.0030803680419921875
iter 428 (epoch 0), train_loss = 4.323, time/batch = 0.021
Read data: 9.489059448242188e-05
iter 429 (epoch 0), train_loss = 4.233, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 430 (epoch 0), train_loss = 4.053, time/batch = 0.021
Read data: 7.200241088867188e-05
iter 431 (epoch 0), train_loss = 3.895, time/batch = 0.021
Read data: 0.006044864654541016
iter 432 (epoch 0), train_loss = 4.167, time/batch = 0.021
Read data: 5.936622619628906e-05
iter 433 (epoch 0), train_loss = 3.792, time/batch = 0.025
Read data: 0.00011587142944335938
iter 434 (epoch 0), train_loss = 3.946, time/batch = 0.022
Read data: 7.033348083496094e-05
iter 435 (epoch 0), train_loss = 4.062, time/batch = 0.025
Read data: 0.002870798110961914
iter 436 (epoch 0), train_loss = 3.936, time/batch = 0.018
Read data: 5.793571472167969e-05
iter 437 (epoch 0), train_loss = 4.005, time/batch = 0.024
Read data: 0.003531217575073242
iter 438 (epoch 0), train_loss = 4.094, time/batch = 0.026
Read data: 7.462501525878906e-05
iter 439 (epoch 0), train_loss = 4.057, time/batch = 0.026
Read data: 0.0016798973083496094
iter 440 (epoch 0), train_loss = 4.096, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 441 (epoch 0), train_loss = 4.180, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 442 (epoch 0), train_loss = 3.848, time/batch = 0.024
Read data: 6.961822509765625e-05
iter 443 (epoch 0), train_loss = 3.843, time/batch = 0.026
Read data: 0.0026330947875976562
iter 444 (epoch 0), train_loss = 4.106, time/batch = 0.019
Read data: 5.745887756347656e-05
iter 445 (epoch 0), train_loss = 4.139, time/batch = 0.020
Read data: 0.0072307586669921875
iter 446 (epoch 0), train_loss = 4.256, time/batch = 0.024
Read data: 7.081031799316406e-05
iter 447 (epoch 0), train_loss = 4.454, time/batch = 0.028
Read data: 0.0001227855682373047
iter 448 (epoch 0), train_loss = 4.177, time/batch = 0.021
Read data: 5.793571472167969e-05
iter 449 (epoch 0), train_loss = 4.224, time/batch = 0.029
Read data: 0.0002415180206298828
iter 450 (epoch 0), train_loss = 4.500, time/batch = 0.023
Read data: 0.00012254714965820312
iter 451 (epoch 0), train_loss = 4.022, time/batch = 0.026
Read data: 0.00015473365783691406
iter 452 (epoch 0), train_loss = 3.951, time/batch = 0.024
Read data: 5.817413330078125e-05
iter 453 (epoch 0), train_loss = 4.170, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 454 (epoch 0), train_loss = 4.264, time/batch = 0.021
Read data: 6.866455078125e-05
iter 455 (epoch 0), train_loss = 3.998, time/batch = 0.025
Read data: 0.00016236305236816406
iter 456 (epoch 0), train_loss = 3.998, time/batch = 0.021
Read data: 6.222724914550781e-05
iter 457 (epoch 0), train_loss = 3.976, time/batch = 0.022
Read data: 0.00571751594543457
iter 458 (epoch 0), train_loss = 4.118, time/batch = 0.023
Read data: 7.486343383789062e-05
iter 459 (epoch 0), train_loss = 4.037, time/batch = 0.025
Read data: 0.00012350082397460938
iter 460 (epoch 0), train_loss = 3.971, time/batch = 0.019
Read data: 5.7697296142578125e-05
iter 461 (epoch 0), train_loss = 3.820, time/batch = 0.020
Read data: 0.008947372436523438
iter 462 (epoch 0), train_loss = 4.071, time/batch = 0.024
Read data: 0.00014352798461914062
iter 463 (epoch 0), train_loss = 3.872, time/batch = 0.028
Read data: 0.00012922286987304688
iter 464 (epoch 0), train_loss = 4.080, time/batch = 0.021
Read data: 5.6743621826171875e-05
iter 465 (epoch 0), train_loss = 4.376, time/batch = 0.027
Read data: 0.00010204315185546875
iter 466 (epoch 0), train_loss = 3.930, time/batch = 0.025
Read data: 0.00012755393981933594
iter 467 (epoch 0), train_loss = 3.943, time/batch = 0.025
Read data: 0.00012540817260742188
iter 468 (epoch 0), train_loss = 3.969, time/batch = 0.018
Read data: 5.555152893066406e-05
iter 469 (epoch 0), train_loss = 4.120, time/batch = 0.020
Read data: 0.014432430267333984
iter 470 (epoch 0), train_loss = 3.943, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 471 (epoch 0), train_loss = 3.984, time/batch = 0.023
Read data: 0.00012302398681640625
iter 472 (epoch 0), train_loss = 4.227, time/batch = 0.022
Read data: 5.7220458984375e-05
iter 473 (epoch 0), train_loss = 4.214, time/batch = 0.024
Read data: 0.0059549808502197266
iter 474 (epoch 0), train_loss = 3.800, time/batch = 0.023
Read data: 0.00031685829162597656
iter 475 (epoch 0), train_loss = 3.843, time/batch = 0.025
Read data: 0.00012302398681640625
iter 476 (epoch 0), train_loss = 3.874, time/batch = 0.022
Read data: 5.888938903808594e-05
iter 477 (epoch 0), train_loss = 3.854, time/batch = 0.025
Read data: 0.002825021743774414
iter 478 (epoch 0), train_loss = 4.095, time/batch = 0.018
Read data: 5.7220458984375e-05
iter 479 (epoch 0), train_loss = 4.515, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 480 (epoch 0), train_loss = 3.962, time/batch = 0.019
Read data: 6.031990051269531e-05
iter 481 (epoch 0), train_loss = 3.816, time/batch = 0.020
Read data: 0.01671886444091797
iter 482 (epoch 0), train_loss = 4.192, time/batch = 0.018
Read data: 5.650520324707031e-05
iter 483 (epoch 0), train_loss = 3.749, time/batch = 0.022
Read data: 0.003017425537109375
iter 484 (epoch 0), train_loss = 3.987, time/batch = 0.019
Read data: 6.031990051269531e-05
iter 485 (epoch 0), train_loss = 3.704, time/batch = 0.020
Read data: 0.01595473289489746
iter 486 (epoch 0), train_loss = 3.774, time/batch = 0.023
Read data: 0.00010466575622558594
iter 487 (epoch 0), train_loss = 3.951, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 488 (epoch 0), train_loss = 4.131, time/batch = 0.023
Read data: 5.9604644775390625e-05
iter 489 (epoch 0), train_loss = 3.929, time/batch = 0.023
Read data: 0.0026972293853759766
iter 490 (epoch 0), train_loss = 3.920, time/batch = 0.016
Read data: 9.489059448242188e-05
iter 491 (epoch 0), train_loss = 4.224, time/batch = 0.029
Read data: 0.00016117095947265625
iter 492 (epoch 0), train_loss = 4.327, time/batch = 0.024
Read data: 5.888938903808594e-05
iter 493 (epoch 0), train_loss = 3.903, time/batch = 0.020
Read data: 0.012176513671875
iter 494 (epoch 0), train_loss = 4.535, time/batch = 0.022
Read data: 0.00010585784912109375
iter 495 (epoch 0), train_loss = 3.977, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 496 (epoch 0), train_loss = 3.935, time/batch = 0.021
Read data: 0.00010085105895996094
iter 497 (epoch 0), train_loss = 4.005, time/batch = 0.023
Read data: 0.008382797241210938
iter 498 (epoch 0), train_loss = 4.051, time/batch = 0.020
Read data: 6.151199340820312e-05
iter 499 (epoch 0), train_loss = 4.003, time/batch = 0.030
Read data: 0.0002315044403076172
iter 500 (epoch 0), train_loss = 4.204, time/batch = 0.019
Read data: 0.00010037422180175781
iter 501 (epoch 0), train_loss = 3.666, time/batch = 0.023
Read data: 0.003953456878662109
iter 502 (epoch 0), train_loss = 3.548, time/batch = 0.018
Read data: 0.00010228157043457031
iter 503 (epoch 0), train_loss = 4.453, time/batch = 0.027
Read data: 0.00015473365783691406
iter 504 (epoch 0), train_loss = 4.320, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 505 (epoch 0), train_loss = 4.157, time/batch = 0.023
Read data: 0.007152080535888672
iter 506 (epoch 0), train_loss = 3.973, time/batch = 0.020
Read data: 6.985664367675781e-05
iter 507 (epoch 0), train_loss = 4.214, time/batch = 0.032
Read data: 8.940696716308594e-05
iter 508 (epoch 0), train_loss = 3.886, time/batch = 0.019
Read data: 0.00010228157043457031
iter 509 (epoch 0), train_loss = 3.916, time/batch = 0.022
Read data: 0.005540609359741211
iter 510 (epoch 0), train_loss = 4.314, time/batch = 0.027
Read data: 6.771087646484375e-05
iter 511 (epoch 0), train_loss = 4.128, time/batch = 0.024
Read data: 0.00016117095947265625
iter 512 (epoch 0), train_loss = 3.914, time/batch = 0.033
Read data: 0.00012111663818359375
iter 513 (epoch 0), train_loss = 4.231, time/batch = 0.020
Read data: 9.489059448242188e-05
iter 514 (epoch 0), train_loss = 4.011, time/batch = 0.020
Read data: 7.748603820800781e-05
iter 515 (epoch 0), train_loss = 4.109, time/batch = 0.024
Read data: 0.00011873245239257812
iter 516 (epoch 0), train_loss = 4.124, time/batch = 0.019
Read data: 5.793571472167969e-05
iter 517 (epoch 0), train_loss = 4.120, time/batch = 0.027
Read data: 0.003032684326171875
iter 518 (epoch 0), train_loss = 4.152, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 519 (epoch 0), train_loss = 3.680, time/batch = 0.024
Read data: 0.0001304149627685547
iter 520 (epoch 0), train_loss = 4.097, time/batch = 0.021
Read data: 5.555152893066406e-05
iter 521 (epoch 0), train_loss = 4.132, time/batch = 0.027
Read data: 0.001401662826538086
iter 522 (epoch 0), train_loss = 4.268, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 523 (epoch 0), train_loss = 3.697, time/batch = 0.021
Read data: 0.0030422210693359375
iter 524 (epoch 0), train_loss = 3.876, time/batch = 0.019
Read data: 0.00019502639770507812
iter 525 (epoch 0), train_loss = 4.116, time/batch = 0.022
Read data: 0.009830474853515625
iter 526 (epoch 0), train_loss = 4.170, time/batch = 0.018
Read data: 6.127357482910156e-05
iter 527 (epoch 0), train_loss = 3.915, time/batch = 0.027
Read data: 0.002354145050048828
iter 528 (epoch 0), train_loss = 4.004, time/batch = 0.019
Read data: 5.626678466796875e-05
iter 529 (epoch 0), train_loss = 4.230, time/batch = 0.022
Read data: 0.010020732879638672
iter 530 (epoch 0), train_loss = 4.087, time/batch = 0.020
Read data: 6.175041198730469e-05
iter 531 (epoch 0), train_loss = 4.063, time/batch = 0.021
Read data: 0.005674600601196289
iter 532 (epoch 0), train_loss = 4.006, time/batch = 0.019
Read data: 6.0558319091796875e-05
iter 533 (epoch 0), train_loss = 4.327, time/batch = 0.021
Read data: 0.007961034774780273
iter 534 (epoch 0), train_loss = 4.006, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 535 (epoch 0), train_loss = 4.245, time/batch = 0.033
Read data: 9.393692016601562e-05
iter 536 (epoch 0), train_loss = 4.117, time/batch = 0.019
Read data: 6.4849853515625e-05
iter 537 (epoch 0), train_loss = 3.903, time/batch = 0.022
Read data: 9.965896606445312e-05
iter 538 (epoch 0), train_loss = 4.016, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 539 (epoch 0), train_loss = 3.886, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 540 (epoch 0), train_loss = 4.173, time/batch = 0.022
Read data: 5.6743621826171875e-05
iter 541 (epoch 0), train_loss = 3.948, time/batch = 0.027
Read data: 0.00011801719665527344
iter 542 (epoch 0), train_loss = 3.880, time/batch = 0.021
Read data: 7.510185241699219e-05
iter 543 (epoch 0), train_loss = 3.801, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 544 (epoch 0), train_loss = 3.685, time/batch = 0.021
Read data: 5.984306335449219e-05
iter 545 (epoch 0), train_loss = 3.996, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 546 (epoch 0), train_loss = 4.041, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 547 (epoch 0), train_loss = 3.659, time/batch = 0.022
Read data: 9.751319885253906e-05
iter 548 (epoch 0), train_loss = 4.460, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 549 (epoch 0), train_loss = 3.966, time/batch = 0.024
Read data: 0.00022721290588378906
iter 550 (epoch 0), train_loss = 4.166, time/batch = 0.021
Read data: 7.62939453125e-05
iter 551 (epoch 0), train_loss = 4.011, time/batch = 0.024
Read data: 0.002040386199951172
iter 552 (epoch 0), train_loss = 4.240, time/batch = 0.021
Read data: 5.7697296142578125e-05
iter 553 (epoch 0), train_loss = 3.610, time/batch = 0.025
Read data: 0.0015208721160888672
iter 554 (epoch 0), train_loss = 3.961, time/batch = 0.022
Read data: 0.0001049041748046875
iter 555 (epoch 0), train_loss = 3.997, time/batch = 0.024
Read data: 0.0035016536712646484
iter 556 (epoch 0), train_loss = 4.166, time/batch = 0.027
Read data: 0.00013589859008789062
iter 557 (epoch 0), train_loss = 3.793, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 558 (epoch 0), train_loss = 3.889, time/batch = 0.021
Read data: 0.00010228157043457031
iter 559 (epoch 0), train_loss = 3.901, time/batch = 0.024
Read data: 0.002827167510986328
iter 560 (epoch 0), train_loss = 3.984, time/batch = 0.027
Read data: 5.7697296142578125e-05
iter 561 (epoch 0), train_loss = 4.157, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 562 (epoch 0), train_loss = 4.007, time/batch = 0.018
Read data: 6.866455078125e-05
iter 563 (epoch 0), train_loss = 4.326, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 564 (epoch 0), train_loss = 4.128, time/batch = 0.022
Read data: 5.6743621826171875e-05
iter 565 (epoch 0), train_loss = 3.731, time/batch = 0.025
Read data: 0.0031545162200927734
iter 566 (epoch 0), train_loss = 3.779, time/batch = 0.019
Read data: 5.626678466796875e-05
iter 567 (epoch 0), train_loss = 4.085, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 568 (epoch 0), train_loss = 4.149, time/batch = 0.019
Read data: 6.222724914550781e-05
iter 569 (epoch 0), train_loss = 3.924, time/batch = 0.021
Read data: 0.007280588150024414
iter 570 (epoch 0), train_loss = 4.074, time/batch = 0.036
Read data: 7.62939453125e-05
iter 571 (epoch 0), train_loss = 3.863, time/batch = 0.024
Read data: 0.00012350082397460938
iter 572 (epoch 0), train_loss = 4.064, time/batch = 0.029
Read data: 6.127357482910156e-05
iter 573 (epoch 0), train_loss = 4.232, time/batch = 0.032
Read data: 8.845329284667969e-05
iter 574 (epoch 0), train_loss = 4.084, time/batch = 0.026
Read data: 0.00015878677368164062
iter 575 (epoch 0), train_loss = 3.815, time/batch = 0.019
Read data: 8.869171142578125e-05
iter 576 (epoch 0), train_loss = 3.508, time/batch = 0.020
Read data: 6.29425048828125e-05
iter 577 (epoch 0), train_loss = 4.344, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 578 (epoch 0), train_loss = 3.682, time/batch = 0.019
Read data: 5.91278076171875e-05
iter 579 (epoch 0), train_loss = 3.986, time/batch = 0.029
Read data: 8.392333984375e-05
iter 580 (epoch 0), train_loss = 4.051, time/batch = 0.019
Read data: 0.00013184547424316406
iter 581 (epoch 0), train_loss = 4.042, time/batch = 0.019
Read data: 0.0016634464263916016
iter 582 (epoch 0), train_loss = 3.926, time/batch = 0.021
Read data: 5.555152893066406e-05
iter 583 (epoch 0), train_loss = 4.125, time/batch = 0.020
Read data: 0.00010347366333007812
iter 584 (epoch 0), train_loss = 4.168, time/batch = 0.024
Read data: 7.414817810058594e-05
iter 585 (epoch 0), train_loss = 3.965, time/batch = 0.021
Read data: 0.00577545166015625
iter 586 (epoch 0), train_loss = 3.780, time/batch = 0.031
Read data: 0.00012803077697753906
iter 587 (epoch 0), train_loss = 4.101, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 588 (epoch 0), train_loss = 3.847, time/batch = 0.018
Read data: 7.200241088867188e-05
iter 589 (epoch 0), train_loss = 4.120, time/batch = 0.028
Read data: 0.002844095230102539
iter 590 (epoch 0), train_loss = 4.246, time/batch = 0.024
Read data: 5.6743621826171875e-05
iter 591 (epoch 0), train_loss = 3.895, time/batch = 0.022
Read data: 0.0009217262268066406
iter 592 (epoch 0), train_loss = 3.775, time/batch = 0.021
Read data: 6.794929504394531e-05
iter 593 (epoch 0), train_loss = 3.631, time/batch = 0.021
Read data: 0.015210866928100586
iter 594 (epoch 0), train_loss = 3.778, time/batch = 0.021
Read data: 5.888938903808594e-05
iter 595 (epoch 0), train_loss = 3.856, time/batch = 0.020
Read data: 8.940696716308594e-05
iter 596 (epoch 0), train_loss = 3.852, time/batch = 0.019
Read data: 6.723403930664062e-05
iter 597 (epoch 0), train_loss = 3.713, time/batch = 0.026
Read data: 0.009720563888549805
iter 598 (epoch 0), train_loss = 4.147, time/batch = 0.023
Read data: 0.0001251697540283203
iter 599 (epoch 0), train_loss = 3.940, time/batch = 0.024
Read data: 0.0002295970916748047
iter 600 (epoch 0), train_loss = 3.878, time/batch = 0.025
Read data: 7.43865966796875e-05
iter 601 (epoch 1), train_loss = 3.859, time/batch = 0.024
Read data: 0.002469301223754883
iter 602 (epoch 1), train_loss = 4.023, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 603 (epoch 1), train_loss = 3.941, time/batch = 0.026
Read data: 0.0001499652862548828
iter 604 (epoch 1), train_loss = 4.137, time/batch = 0.024
Read data: 6.985664367675781e-05
iter 605 (epoch 1), train_loss = 4.131, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 606 (epoch 1), train_loss = 3.949, time/batch = 0.021
Read data: 5.7220458984375e-05
iter 607 (epoch 1), train_loss = 3.839, time/batch = 0.026
Read data: 0.00011086463928222656
iter 608 (epoch 1), train_loss = 3.942, time/batch = 0.021
Read data: 6.937980651855469e-05
iter 609 (epoch 1), train_loss = 3.803, time/batch = 0.023
Read data: 0.011530876159667969
iter 610 (epoch 1), train_loss = 3.982, time/batch = 0.029
Read data: 6.628036499023438e-05
iter 611 (epoch 1), train_loss = 4.016, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 612 (epoch 1), train_loss = 3.740, time/batch = 0.018
Read data: 0.00010824203491210938
iter 613 (epoch 1), train_loss = 3.796, time/batch = 0.025
Read data: 0.013983726501464844
iter 614 (epoch 1), train_loss = 4.109, time/batch = 0.020
Read data: 6.771087646484375e-05
iter 615 (epoch 1), train_loss = 4.236, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 616 (epoch 1), train_loss = 3.633, time/batch = 0.026
Read data: 7.390975952148438e-05
iter 617 (epoch 1), train_loss = 3.646, time/batch = 0.029
Read data: 0.010243892669677734
iter 618 (epoch 1), train_loss = 3.520, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 619 (epoch 1), train_loss = 4.067, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 620 (epoch 1), train_loss = 3.688, time/batch = 0.021
Read data: 6.341934204101562e-05
iter 621 (epoch 1), train_loss = 4.079, time/batch = 0.020
Read data: 0.017294645309448242
iter 622 (epoch 1), train_loss = 3.885, time/batch = 0.023
Read data: 6.628036499023438e-05
iter 623 (epoch 1), train_loss = 4.268, time/batch = 0.022
Read data: 7.224082946777344e-05
iter 624 (epoch 1), train_loss = 3.818, time/batch = 0.021
Read data: 0.00018167495727539062
iter 625 (epoch 1), train_loss = 4.033, time/batch = 0.022
Read data: 0.014073848724365234
iter 626 (epoch 1), train_loss = 3.960, time/batch = 0.023
Read data: 6.4849853515625e-05
iter 627 (epoch 1), train_loss = 4.187, time/batch = 0.019
Read data: 6.961822509765625e-05
iter 628 (epoch 1), train_loss = 3.871, time/batch = 0.023
Read data: 0.0001087188720703125
iter 629 (epoch 1), train_loss = 4.389, time/batch = 0.025
Read data: 0.010317087173461914
iter 630 (epoch 1), train_loss = 4.114, time/batch = 0.028
Read data: 6.818771362304688e-05
iter 631 (epoch 1), train_loss = 3.886, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 632 (epoch 1), train_loss = 3.705, time/batch = 0.020
Read data: 7.772445678710938e-05
iter 633 (epoch 1), train_loss = 3.950, time/batch = 0.024
Read data: 0.007056713104248047
iter 634 (epoch 1), train_loss = 4.118, time/batch = 0.027
Read data: 7.414817810058594e-05
iter 635 (epoch 1), train_loss = 4.359, time/batch = 0.022
Read data: 7.176399230957031e-05
iter 636 (epoch 1), train_loss = 3.863, time/batch = 0.022
Read data: 7.486343383789062e-05
iter 637 (epoch 1), train_loss = 3.869, time/batch = 0.023
Read data: 0.008962392807006836
iter 638 (epoch 1), train_loss = 3.790, time/batch = 0.018
Read data: 5.8650970458984375e-05
iter 639 (epoch 1), train_loss = 3.796, time/batch = 0.018
Read data: 7.128715515136719e-05
iter 640 (epoch 1), train_loss = 3.657, time/batch = 0.023
Read data: 0.00010514259338378906
iter 641 (epoch 1), train_loss = 3.924, time/batch = 0.025
Read data: 0.023006200790405273
iter 642 (epoch 1), train_loss = 4.137, time/batch = 0.018
Read data: 6.079673767089844e-05
iter 643 (epoch 1), train_loss = 4.182, time/batch = 0.024
Read data: 7.200241088867188e-05
iter 644 (epoch 1), train_loss = 3.071, time/batch = 0.020
Read data: 7.343292236328125e-05
iter 645 (epoch 1), train_loss = 3.790, time/batch = 0.019
Read data: 0.029348134994506836
iter 646 (epoch 1), train_loss = 3.837, time/batch = 0.030
Read data: 7.104873657226562e-05
iter 647 (epoch 1), train_loss = 4.066, time/batch = 0.024
Read data: 7.319450378417969e-05
iter 648 (epoch 1), train_loss = 3.880, time/batch = 0.021
Read data: 8.416175842285156e-05
iter 649 (epoch 1), train_loss = 3.732, time/batch = 0.022
Read data: 0.004038810729980469
iter 650 (epoch 1), train_loss = 3.666, time/batch = 0.021
Read data: 5.91278076171875e-05
iter 651 (epoch 1), train_loss = 3.990, time/batch = 0.026
Read data: 7.2479248046875e-05
iter 652 (epoch 1), train_loss = 4.281, time/batch = 0.022
Read data: 7.62939453125e-05
iter 653 (epoch 1), train_loss = 4.364, time/batch = 0.025
Read data: 0.008237838745117188
iter 654 (epoch 1), train_loss = 3.846, time/batch = 0.018
Read data: 7.319450378417969e-05
iter 655 (epoch 1), train_loss = 3.769, time/batch = 0.020
Read data: 7.390975952148438e-05
iter 656 (epoch 1), train_loss = 3.847, time/batch = 0.020
Read data: 7.414817810058594e-05
iter 657 (epoch 1), train_loss = 4.196, time/batch = 0.023
Read data: 0.02065277099609375
iter 658 (epoch 1), train_loss = 3.982, time/batch = 0.021
Read data: 6.413459777832031e-05
iter 659 (epoch 1), train_loss = 3.700, time/batch = 0.023
Read data: 6.580352783203125e-05
iter 660 (epoch 1), train_loss = 3.985, time/batch = 0.026
Read data: 7.367134094238281e-05
iter 661 (epoch 1), train_loss = 3.998, time/batch = 0.029
Read data: 0.0021953582763671875
iter 662 (epoch 1), train_loss = 3.735, time/batch = 0.022
Read data: 6.508827209472656e-05
iter 663 (epoch 1), train_loss = 3.681, time/batch = 0.021
Read data: 7.200241088867188e-05
iter 664 (epoch 1), train_loss = 3.631, time/batch = 0.022
Read data: 7.414817810058594e-05
iter 665 (epoch 1), train_loss = 3.878, time/batch = 0.022
Read data: 0.016991615295410156
iter 666 (epoch 1), train_loss = 3.700, time/batch = 0.023
Read data: 7.224082946777344e-05
iter 667 (epoch 1), train_loss = 3.726, time/batch = 0.021
Read data: 6.842613220214844e-05
iter 668 (epoch 1), train_loss = 3.556, time/batch = 0.020
Read data: 7.534027099609375e-05
iter 669 (epoch 1), train_loss = 4.119, time/batch = 0.022
Read data: 0.015976905822753906
iter 670 (epoch 1), train_loss = 3.888, time/batch = 0.025
Read data: 6.508827209472656e-05
iter 671 (epoch 1), train_loss = 4.284, time/batch = 0.020
Read data: 6.67572021484375e-05
iter 672 (epoch 1), train_loss = 3.744, time/batch = 0.022
Read data: 6.580352783203125e-05
iter 673 (epoch 1), train_loss = 3.606, time/batch = 0.021
Read data: 0.018854856491088867
iter 674 (epoch 1), train_loss = 3.765, time/batch = 0.020
Read data: 0.00017380714416503906
iter 675 (epoch 1), train_loss = 3.535, time/batch = 0.020
Read data: 7.43865966796875e-05
iter 676 (epoch 1), train_loss = 3.625, time/batch = 0.025
Read data: 6.67572021484375e-05
iter 677 (epoch 1), train_loss = 4.130, time/batch = 0.032
Read data: 0.009458780288696289
iter 678 (epoch 1), train_loss = 4.034, time/batch = 0.020
Read data: 6.747245788574219e-05
iter 679 (epoch 1), train_loss = 3.757, time/batch = 0.021
Read data: 6.699562072753906e-05
iter 680 (epoch 1), train_loss = 3.669, time/batch = 0.021
Read data: 6.604194641113281e-05
iter 681 (epoch 1), train_loss = 3.663, time/batch = 0.017
Read data: 0.019766807556152344
iter 682 (epoch 1), train_loss = 3.772, time/batch = 0.018
Read data: 9.322166442871094e-05
iter 683 (epoch 1), train_loss = 3.740, time/batch = 0.022
Read data: 7.605552673339844e-05
iter 684 (epoch 1), train_loss = 3.780, time/batch = 0.024
Read data: 6.604194641113281e-05
iter 685 (epoch 1), train_loss = 3.642, time/batch = 0.019
Read data: 0.020104646682739258
iter 686 (epoch 1), train_loss = 3.635, time/batch = 0.023
Read data: 6.961822509765625e-05
iter 687 (epoch 1), train_loss = 3.728, time/batch = 0.023
Read data: 6.747245788574219e-05
iter 688 (epoch 1), train_loss = 4.441, time/batch = 0.024
Read data: 6.532669067382812e-05
iter 689 (epoch 1), train_loss = 3.778, time/batch = 0.021
Read data: 0.010875940322875977
iter 690 (epoch 1), train_loss = 3.712, time/batch = 0.023
Read data: 6.532669067382812e-05
iter 691 (epoch 1), train_loss = 3.697, time/batch = 0.022
Read data: 6.508827209472656e-05
iter 692 (epoch 1), train_loss = 3.781, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 693 (epoch 1), train_loss = 4.048, time/batch = 0.019
Read data: 0.018364429473876953
iter 694 (epoch 1), train_loss = 3.667, time/batch = 0.019
Read data: 9.298324584960938e-05
iter 695 (epoch 1), train_loss = 3.829, time/batch = 0.027
Read data: 6.67572021484375e-05
iter 696 (epoch 1), train_loss = 3.987, time/batch = 0.021
Read data: 6.651878356933594e-05
iter 697 (epoch 1), train_loss = 4.321, time/batch = 0.020
Read data: 0.015985727310180664
iter 698 (epoch 1), train_loss = 3.724, time/batch = 0.022
Read data: 6.556510925292969e-05
iter 699 (epoch 1), train_loss = 3.746, time/batch = 0.021
Read data: 0.0001704692840576172
iter 700 (epoch 1), train_loss = 3.798, time/batch = 0.029
Read data: 6.794929504394531e-05
iter 701 (epoch 1), train_loss = 3.860, time/batch = 0.018
Read data: 0.01213526725769043
iter 702 (epoch 1), train_loss = 3.975, time/batch = 0.020
Read data: 6.461143493652344e-05
iter 703 (epoch 1), train_loss = 3.837, time/batch = 0.024
Read data: 6.580352783203125e-05
iter 704 (epoch 1), train_loss = 3.775, time/batch = 0.021
Read data: 7.390975952148438e-05
iter 705 (epoch 1), train_loss = 4.138, time/batch = 0.027
Read data: 0.009023904800415039
iter 706 (epoch 1), train_loss = 3.833, time/batch = 0.021
Read data: 6.341934204101562e-05
iter 707 (epoch 1), train_loss = 4.091, time/batch = 0.020
Read data: 7.772445678710938e-05
iter 708 (epoch 1), train_loss = 3.795, time/batch = 0.020
Read data: 7.581710815429688e-05
iter 709 (epoch 1), train_loss = 4.145, time/batch = 0.025
Read data: 0.016936302185058594
iter 710 (epoch 1), train_loss = 3.605, time/batch = 0.018
Read data: 7.510185241699219e-05
iter 711 (epoch 1), train_loss = 4.079, time/batch = 0.024
Read data: 6.604194641113281e-05
iter 712 (epoch 1), train_loss = 3.762, time/batch = 0.021
Read data: 7.653236389160156e-05
iter 713 (epoch 1), train_loss = 3.535, time/batch = 0.020
Read data: 0.019360780715942383
iter 714 (epoch 1), train_loss = 3.653, time/batch = 0.020
Read data: 6.842613220214844e-05
iter 715 (epoch 1), train_loss = 3.773, time/batch = 0.021
Read data: 7.152557373046875e-05
iter 716 (epoch 1), train_loss = 3.644, time/batch = 0.020
Read data: 7.2479248046875e-05
iter 717 (epoch 1), train_loss = 3.845, time/batch = 0.033
Read data: 0.009554862976074219
iter 718 (epoch 1), train_loss = 3.785, time/batch = 0.028
Read data: 6.556510925292969e-05
iter 719 (epoch 1), train_loss = 3.787, time/batch = 0.022
Read data: 7.081031799316406e-05
iter 720 (epoch 1), train_loss = 3.670, time/batch = 0.025
Read data: 6.699562072753906e-05
iter 721 (epoch 1), train_loss = 3.698, time/batch = 0.021
Read data: 0.0083465576171875
iter 722 (epoch 1), train_loss = 4.154, time/batch = 0.022
Read data: 7.82012939453125e-05
iter 723 (epoch 1), train_loss = 3.924, time/batch = 0.021
Read data: 0.00011467933654785156
iter 724 (epoch 1), train_loss = 3.609, time/batch = 0.023
Read data: 0.0001723766326904297
iter 725 (epoch 1), train_loss = 3.581, time/batch = 0.026
Read data: 0.0075032711029052734
iter 726 (epoch 1), train_loss = 3.637, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 727 (epoch 1), train_loss = 3.672, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 728 (epoch 1), train_loss = 4.021, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 729 (epoch 1), train_loss = 3.767, time/batch = 0.024
Read data: 0.010164260864257812
iter 730 (epoch 1), train_loss = 3.810, time/batch = 0.023
Read data: 6.580352783203125e-05
iter 731 (epoch 1), train_loss = 3.649, time/batch = 0.021
Read data: 6.532669067382812e-05
iter 732 (epoch 1), train_loss = 4.065, time/batch = 0.021
Read data: 7.653236389160156e-05
iter 733 (epoch 1), train_loss = 3.631, time/batch = 0.018
Read data: 0.018963336944580078
iter 734 (epoch 1), train_loss = 3.503, time/batch = 0.018
Read data: 5.91278076171875e-05
iter 735 (epoch 1), train_loss = 3.684, time/batch = 0.026
Read data: 6.651878356933594e-05
iter 736 (epoch 1), train_loss = 4.140, time/batch = 0.021
Read data: 6.818771362304688e-05
iter 737 (epoch 1), train_loss = 3.525, time/batch = 0.018
Read data: 0.02534174919128418
iter 738 (epoch 1), train_loss = 3.638, time/batch = 0.024
Read data: 0.00010204315185546875
iter 739 (epoch 1), train_loss = 4.265, time/batch = 0.020
Read data: 6.628036499023438e-05
iter 740 (epoch 1), train_loss = 3.754, time/batch = 0.022
Read data: 6.628036499023438e-05
iter 741 (epoch 1), train_loss = 3.797, time/batch = 0.019
Read data: 0.017091989517211914
iter 742 (epoch 1), train_loss = 4.232, time/batch = 0.024
Read data: 6.580352783203125e-05
iter 743 (epoch 1), train_loss = 3.706, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 744 (epoch 1), train_loss = 3.688, time/batch = 0.024
Read data: 6.508827209472656e-05
iter 745 (epoch 1), train_loss = 3.645, time/batch = 0.018
Read data: 0.015534639358520508
iter 746 (epoch 1), train_loss = 3.790, time/batch = 0.022
Read data: 6.532669067382812e-05
iter 747 (epoch 1), train_loss = 3.633, time/batch = 0.021
Read data: 6.532669067382812e-05
iter 748 (epoch 1), train_loss = 3.930, time/batch = 0.018
Read data: 7.510185241699219e-05
iter 749 (epoch 1), train_loss = 3.892, time/batch = 0.018
Read data: 0.025029420852661133
iter 750 (epoch 1), train_loss = 4.184, time/batch = 0.021
Read data: 7.581710815429688e-05
iter 751 (epoch 1), train_loss = 3.991, time/batch = 0.025
Read data: 7.200241088867188e-05
iter 752 (epoch 1), train_loss = 4.121, time/batch = 0.024
Read data: 6.580352783203125e-05
iter 753 (epoch 1), train_loss = 3.972, time/batch = 0.026
Read data: 0.012958765029907227
iter 754 (epoch 1), train_loss = 3.949, time/batch = 0.022
Read data: 9.751319885253906e-05
iter 755 (epoch 1), train_loss = 4.038, time/batch = 0.020
Read data: 6.67572021484375e-05
iter 756 (epoch 1), train_loss = 3.711, time/batch = 0.021
Read data: 7.510185241699219e-05
iter 757 (epoch 1), train_loss = 3.811, time/batch = 0.025
Read data: 0.016448974609375
iter 758 (epoch 1), train_loss = 3.507, time/batch = 0.021
Read data: 6.651878356933594e-05
iter 759 (epoch 1), train_loss = 3.795, time/batch = 0.022
Read data: 6.4849853515625e-05
iter 760 (epoch 1), train_loss = 3.845, time/batch = 0.020
Read data: 6.437301635742188e-05
iter 761 (epoch 1), train_loss = 3.377, time/batch = 0.016
Read data: 0.02779531478881836
iter 762 (epoch 1), train_loss = 3.807, time/batch = 0.023
Read data: 0.00011301040649414062
iter 763 (epoch 1), train_loss = 3.636, time/batch = 0.029
Read data: 7.009506225585938e-05
iter 764 (epoch 1), train_loss = 4.034, time/batch = 0.021
Read data: 6.794929504394531e-05
iter 765 (epoch 1), train_loss = 3.636, time/batch = 0.019
Read data: 0.018726587295532227
iter 766 (epoch 1), train_loss = 3.603, time/batch = 0.021
Read data: 6.67572021484375e-05
iter 767 (epoch 1), train_loss = 3.882, time/batch = 0.023
Read data: 6.532669067382812e-05
iter 768 (epoch 1), train_loss = 4.002, time/batch = 0.023
Read data: 6.747245788574219e-05
iter 769 (epoch 1), train_loss = 4.125, time/batch = 0.018
Read data: 0.011393547058105469
iter 770 (epoch 1), train_loss = 3.690, time/batch = 0.029
Read data: 6.580352783203125e-05
iter 771 (epoch 1), train_loss = 3.680, time/batch = 0.023
Read data: 6.699562072753906e-05
iter 772 (epoch 1), train_loss = 3.963, time/batch = 0.024
Read data: 6.341934204101562e-05
iter 773 (epoch 1), train_loss = 3.804, time/batch = 0.023
Read data: 0.0029463768005371094
iter 774 (epoch 1), train_loss = 3.838, time/batch = 0.018
Read data: 0.0001728534698486328
iter 775 (epoch 1), train_loss = 3.564, time/batch = 0.022
Read data: 7.343292236328125e-05
iter 776 (epoch 1), train_loss = 3.887, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 777 (epoch 1), train_loss = 4.126, time/batch = 0.030
Read data: 0.002071380615234375
iter 778 (epoch 1), train_loss = 3.909, time/batch = 0.032
Read data: 6.413459777832031e-05
iter 779 (epoch 1), train_loss = 3.520, time/batch = 0.021
Read data: 6.628036499023438e-05
iter 780 (epoch 1), train_loss = 4.104, time/batch = 0.023
Read data: 6.67572021484375e-05
iter 781 (epoch 1), train_loss = 3.994, time/batch = 0.020
Read data: 0.001882791519165039
iter 782 (epoch 1), train_loss = 3.755, time/batch = 0.018
Read data: 5.650520324707031e-05
iter 783 (epoch 1), train_loss = 3.901, time/batch = 0.020
Read data: 6.937980651855469e-05
iter 784 (epoch 1), train_loss = 3.728, time/batch = 0.023
Read data: 6.771087646484375e-05
iter 785 (epoch 1), train_loss = 3.775, time/batch = 0.023
Read data: 0.013393402099609375
iter 786 (epoch 1), train_loss = 3.363, time/batch = 0.021
Read data: 5.888938903808594e-05
iter 787 (epoch 1), train_loss = 3.650, time/batch = 0.023
Read data: 7.152557373046875e-05
iter 788 (epoch 1), train_loss = 4.049, time/batch = 0.023
Read data: 6.723403930664062e-05
iter 789 (epoch 1), train_loss = 3.475, time/batch = 0.025
Read data: 0.005156278610229492
iter 790 (epoch 1), train_loss = 3.905, time/batch = 0.021
Read data: 6.079673767089844e-05
iter 791 (epoch 1), train_loss = 3.566, time/batch = 0.024
Read data: 7.05718994140625e-05
iter 792 (epoch 1), train_loss = 4.021, time/batch = 0.020
Read data: 6.985664367675781e-05
iter 793 (epoch 1), train_loss = 4.043, time/batch = 0.026
Read data: 0.0033707618713378906
iter 794 (epoch 1), train_loss = 3.767, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 795 (epoch 1), train_loss = 3.632, time/batch = 0.017
Read data: 6.961822509765625e-05
iter 796 (epoch 1), train_loss = 3.605, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 797 (epoch 1), train_loss = 3.502, time/batch = 0.019
Read data: 0.020198345184326172
iter 798 (epoch 1), train_loss = 3.545, time/batch = 0.021
Read data: 5.745887756347656e-05
iter 799 (epoch 1), train_loss = 3.503, time/batch = 0.021
Read data: 0.00016260147094726562
iter 800 (epoch 1), train_loss = 3.732, time/batch = 0.021
Read data: 7.081031799316406e-05
iter 801 (epoch 1), train_loss = 3.728, time/batch = 0.020
Read data: 0.014095067977905273
iter 802 (epoch 1), train_loss = 3.448, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 803 (epoch 1), train_loss = 3.564, time/batch = 0.022
Read data: 7.224082946777344e-05
iter 804 (epoch 1), train_loss = 3.866, time/batch = 0.023
Read data: 7.033348083496094e-05
iter 805 (epoch 1), train_loss = 3.710, time/batch = 0.019
Read data: 0.012404918670654297
iter 806 (epoch 1), train_loss = 3.849, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 807 (epoch 1), train_loss = 3.763, time/batch = 0.018
Read data: 6.914138793945312e-05
iter 808 (epoch 1), train_loss = 4.132, time/batch = 0.026
Read data: 0.00011992454528808594
iter 809 (epoch 1), train_loss = 3.911, time/batch = 0.020
Read data: 0.010019063949584961
iter 810 (epoch 1), train_loss = 3.787, time/batch = 0.020
Read data: 6.508827209472656e-05
iter 811 (epoch 1), train_loss = 3.797, time/batch = 0.023
Read data: 7.081031799316406e-05
iter 812 (epoch 1), train_loss = 3.799, time/batch = 0.020
Read data: 6.651878356933594e-05
iter 813 (epoch 1), train_loss = 4.003, time/batch = 0.020
Read data: 0.01607489585876465
iter 814 (epoch 1), train_loss = 3.861, time/batch = 0.019
Read data: 5.7220458984375e-05
iter 815 (epoch 1), train_loss = 4.137, time/batch = 0.024
Read data: 7.200241088867188e-05
iter 816 (epoch 1), train_loss = 4.081, time/batch = 0.021
Read data: 6.842613220214844e-05
iter 817 (epoch 1), train_loss = 3.772, time/batch = 0.025
Read data: 0.010671615600585938
iter 818 (epoch 1), train_loss = 3.719, time/batch = 0.020
Read data: 8.273124694824219e-05
iter 819 (epoch 1), train_loss = 3.265, time/batch = 0.019
Read data: 6.914138793945312e-05
iter 820 (epoch 1), train_loss = 4.114, time/batch = 0.021
Read data: 6.937980651855469e-05
iter 821 (epoch 1), train_loss = 4.021, time/batch = 0.019
Read data: 0.023021221160888672
iter 822 (epoch 1), train_loss = 3.804, time/batch = 0.024
Read data: 6.866455078125e-05
iter 823 (epoch 1), train_loss = 3.779, time/batch = 0.026
Read data: 6.818771362304688e-05
iter 824 (epoch 1), train_loss = 3.668, time/batch = 0.018
Read data: 0.00017547607421875
iter 825 (epoch 1), train_loss = 3.564, time/batch = 0.021
Read data: 0.007048130035400391
iter 826 (epoch 1), train_loss = 3.792, time/batch = 0.021
Read data: 5.841255187988281e-05
iter 827 (epoch 1), train_loss = 3.655, time/batch = 0.022
Read data: 6.818771362304688e-05
iter 828 (epoch 1), train_loss = 4.073, time/batch = 0.020
Read data: 7.295608520507812e-05
iter 829 (epoch 1), train_loss = 3.574, time/batch = 0.018
Read data: 0.014395475387573242
iter 830 (epoch 1), train_loss = 4.036, time/batch = 0.024
Read data: 6.0558319091796875e-05
iter 831 (epoch 1), train_loss = 3.876, time/batch = 0.024
Read data: 6.890296936035156e-05
iter 832 (epoch 1), train_loss = 4.129, time/batch = 0.021
Read data: 0.00012922286987304688
iter 833 (epoch 1), train_loss = 3.878, time/batch = 0.023
Read data: 0.007852792739868164
iter 834 (epoch 1), train_loss = 3.747, time/batch = 0.021
Read data: 0.00012922286987304688
iter 835 (epoch 1), train_loss = 3.581, time/batch = 0.020
Read data: 6.914138793945312e-05
iter 836 (epoch 1), train_loss = 4.019, time/batch = 0.022
Read data: 6.890296936035156e-05
iter 837 (epoch 1), train_loss = 3.364, time/batch = 0.025
Read data: 0.009325742721557617
iter 838 (epoch 1), train_loss = 3.777, time/batch = 0.027
Read data: 0.00012969970703125
iter 839 (epoch 1), train_loss = 3.698, time/batch = 0.019
Read data: 6.699562072753906e-05
iter 840 (epoch 1), train_loss = 3.621, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 841 (epoch 1), train_loss = 3.711, time/batch = 0.023
Read data: 0.00822591781616211
iter 842 (epoch 1), train_loss = 3.669, time/batch = 0.023
Read data: 5.841255187988281e-05
iter 843 (epoch 1), train_loss = 4.114, time/batch = 0.034
Read data: 9.632110595703125e-05
iter 844 (epoch 1), train_loss = 3.516, time/batch = 0.024
Read data: 6.365776062011719e-05
iter 845 (epoch 1), train_loss = 3.267, time/batch = 0.020
Read data: 9.322166442871094e-05
iter 846 (epoch 1), train_loss = 3.728, time/batch = 0.021
Read data: 0.00012946128845214844
iter 847 (epoch 1), train_loss = 3.578, time/batch = 0.021
Read data: 6.985664367675781e-05
iter 848 (epoch 1), train_loss = 4.016, time/batch = 0.020
Read data: 6.842613220214844e-05
iter 849 (epoch 1), train_loss = 3.554, time/batch = 0.024
Read data: 0.011726856231689453
iter 850 (epoch 1), train_loss = 3.978, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 851 (epoch 1), train_loss = 3.779, time/batch = 0.023
Read data: 7.390975952148438e-05
iter 852 (epoch 1), train_loss = 3.724, time/batch = 0.023
Read data: 7.510185241699219e-05
iter 853 (epoch 1), train_loss = 4.020, time/batch = 0.025
Read data: 0.005767345428466797
iter 854 (epoch 1), train_loss = 4.220, time/batch = 0.025
Read data: 0.00013303756713867188
iter 855 (epoch 1), train_loss = 3.648, time/batch = 0.022
Read data: 7.295608520507812e-05
iter 856 (epoch 1), train_loss = 3.620, time/batch = 0.022
Read data: 7.271766662597656e-05
iter 857 (epoch 1), train_loss = 3.531, time/batch = 0.023
Read data: 0.008199691772460938
iter 858 (epoch 1), train_loss = 4.086, time/batch = 0.020
Read data: 5.7220458984375e-05
iter 859 (epoch 1), train_loss = 3.568, time/batch = 0.022
Read data: 7.510185241699219e-05
iter 860 (epoch 1), train_loss = 3.684, time/batch = 0.023
Read data: 7.271766662597656e-05
iter 861 (epoch 1), train_loss = 3.530, time/batch = 0.028
Read data: 0.0043182373046875
iter 862 (epoch 1), train_loss = 3.666, time/batch = 0.027
Read data: 6.341934204101562e-05
iter 863 (epoch 1), train_loss = 3.865, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 864 (epoch 1), train_loss = 3.805, time/batch = 0.026
Read data: 6.508827209472656e-05
iter 865 (epoch 1), train_loss = 3.965, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 866 (epoch 1), train_loss = 3.774, time/batch = 0.028
Read data: 7.390975952148438e-05
iter 867 (epoch 1), train_loss = 3.609, time/batch = 0.024
Read data: 0.0001289844512939453
iter 868 (epoch 1), train_loss = 3.738, time/batch = 0.021
Read data: 7.295608520507812e-05
iter 869 (epoch 1), train_loss = 3.225, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 870 (epoch 1), train_loss = 3.964, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 871 (epoch 1), train_loss = 4.083, time/batch = 0.020
Read data: 0.00012373924255371094
iter 872 (epoch 1), train_loss = 3.904, time/batch = 0.021
Read data: 6.699562072753906e-05
iter 873 (epoch 1), train_loss = 3.955, time/batch = 0.020
Read data: 0.012516975402832031
iter 874 (epoch 1), train_loss = 3.532, time/batch = 0.024
Read data: 0.00019431114196777344
iter 875 (epoch 1), train_loss = 3.618, time/batch = 0.024
Read data: 7.414817810058594e-05
iter 876 (epoch 1), train_loss = 3.671, time/batch = 0.028
Read data: 0.00012540817260742188
iter 877 (epoch 1), train_loss = 3.709, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 878 (epoch 1), train_loss = 3.349, time/batch = 0.019
Read data: 5.6743621826171875e-05
iter 879 (epoch 1), train_loss = 3.895, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 880 (epoch 1), train_loss = 3.453, time/batch = 0.020
Read data: 7.033348083496094e-05
iter 881 (epoch 1), train_loss = 3.623, time/batch = 0.022
Read data: 0.010202646255493164
iter 882 (epoch 1), train_loss = 3.400, time/batch = 0.021
Read data: 5.435943603515625e-05
iter 883 (epoch 1), train_loss = 3.943, time/batch = 0.027
Read data: 6.771087646484375e-05
iter 884 (epoch 1), train_loss = 3.728, time/batch = 0.035
Read data: 9.703636169433594e-05
iter 885 (epoch 1), train_loss = 3.708, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 886 (epoch 1), train_loss = 3.480, time/batch = 0.021
Read data: 8.320808410644531e-05
iter 887 (epoch 1), train_loss = 3.272, time/batch = 0.020
Read data: 0.00012111663818359375
iter 888 (epoch 1), train_loss = 3.501, time/batch = 0.031
Read data: 0.00016498565673828125
iter 889 (epoch 1), train_loss = 3.575, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 890 (epoch 1), train_loss = 3.660, time/batch = 0.024
Read data: 5.841255187988281e-05
iter 891 (epoch 1), train_loss = 4.194, time/batch = 0.030
Read data: 6.67572021484375e-05
iter 892 (epoch 1), train_loss = 3.801, time/batch = 0.023
Read data: 0.0001251697540283203
iter 893 (epoch 1), train_loss = 3.651, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 894 (epoch 1), train_loss = 3.549, time/batch = 0.018
Read data: 5.984306335449219e-05
iter 895 (epoch 1), train_loss = 4.019, time/batch = 0.021
Read data: 6.985664367675781e-05
iter 896 (epoch 1), train_loss = 3.710, time/batch = 0.018
Read data: 0.00013446807861328125
iter 897 (epoch 1), train_loss = 3.641, time/batch = 0.024
Read data: 9.799003601074219e-05
iter 898 (epoch 1), train_loss = 3.666, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 899 (epoch 1), train_loss = 3.813, time/batch = 0.022
Read data: 0.00016117095947265625
iter 900 (epoch 1), train_loss = 3.773, time/batch = 0.019
Read data: 9.608268737792969e-05
iter 901 (epoch 1), train_loss = 3.608, time/batch = 0.033
Read data: 8.940696716308594e-05
iter 902 (epoch 1), train_loss = 2.961, time/batch = 0.021
Read data: 5.888938903808594e-05
iter 903 (epoch 1), train_loss = 3.403, time/batch = 0.023
Read data: 6.651878356933594e-05
iter 904 (epoch 1), train_loss = 3.720, time/batch = 0.026
Read data: 7.033348083496094e-05
iter 905 (epoch 1), train_loss = 3.988, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 906 (epoch 1), train_loss = 3.812, time/batch = 0.021
Read data: 0.00010728836059570312
iter 907 (epoch 1), train_loss = 4.017, time/batch = 0.021
Read data: 6.794929504394531e-05
iter 908 (epoch 1), train_loss = 4.063, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 909 (epoch 1), train_loss = 4.035, time/batch = 0.035
Read data: 0.00017952919006347656
iter 910 (epoch 1), train_loss = 3.929, time/batch = 0.023
Read data: 7.295608520507812e-05
iter 911 (epoch 1), train_loss = 3.575, time/batch = 0.023
Read data: 6.985664367675781e-05
iter 912 (epoch 1), train_loss = 3.603, time/batch = 0.023
Read data: 0.00011873245239257812
iter 913 (epoch 1), train_loss = 3.757, time/batch = 0.018
Read data: 0.009539604187011719
iter 914 (epoch 1), train_loss = 3.528, time/batch = 0.020
Read data: 7.557868957519531e-05
iter 915 (epoch 1), train_loss = 3.609, time/batch = 0.021
Read data: 7.653236389160156e-05
iter 916 (epoch 1), train_loss = 3.574, time/batch = 0.019
Read data: 0.00012302398681640625
iter 917 (epoch 1), train_loss = 3.701, time/batch = 0.020
Read data: 0.022910118103027344
iter 918 (epoch 1), train_loss = 3.641, time/batch = 0.021
Read data: 5.7220458984375e-05
iter 919 (epoch 1), train_loss = 4.060, time/batch = 0.029
Read data: 7.295608520507812e-05
iter 920 (epoch 1), train_loss = 3.324, time/batch = 0.026
Read data: 6.937980651855469e-05
iter 921 (epoch 1), train_loss = 3.844, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 922 (epoch 1), train_loss = 3.802, time/batch = 0.023
Read data: 6.890296936035156e-05
iter 923 (epoch 1), train_loss = 3.872, time/batch = 0.025
Read data: 7.081031799316406e-05
iter 924 (epoch 1), train_loss = 3.892, time/batch = 0.020
Read data: 0.00015878677368164062
iter 925 (epoch 1), train_loss = 3.677, time/batch = 0.023
Read data: 0.007959842681884766
iter 926 (epoch 1), train_loss = 3.677, time/batch = 0.023
Read data: 6.270408630371094e-05
iter 927 (epoch 1), train_loss = 3.979, time/batch = 0.025
Read data: 7.128715515136719e-05
iter 928 (epoch 1), train_loss = 4.080, time/batch = 0.021
Read data: 7.009506225585938e-05
iter 929 (epoch 1), train_loss = 3.295, time/batch = 0.020
Read data: 0.009832143783569336
iter 930 (epoch 1), train_loss = 3.645, time/batch = 0.020
Read data: 6.0558319091796875e-05
iter 931 (epoch 1), train_loss = 2.919, time/batch = 0.024
Read data: 7.176399230957031e-05
iter 932 (epoch 1), train_loss = 3.736, time/batch = 0.023
Read data: 6.937980651855469e-05
iter 933 (epoch 1), train_loss = 4.052, time/batch = 0.030
Read data: 0.0030028820037841797
iter 934 (epoch 1), train_loss = 3.932, time/batch = 0.023
Read data: 6.842613220214844e-05
iter 935 (epoch 1), train_loss = 3.499, time/batch = 0.021
Read data: 7.033348083496094e-05
iter 936 (epoch 1), train_loss = 3.704, time/batch = 0.021
Read data: 6.532669067382812e-05
iter 937 (epoch 1), train_loss = 3.248, time/batch = 0.018
Read data: 0.012235403060913086
iter 938 (epoch 1), train_loss = 3.671, time/batch = 0.023
Read data: 6.103515625e-05
iter 939 (epoch 1), train_loss = 3.152, time/batch = 0.026
Read data: 0.00011658668518066406
iter 940 (epoch 1), train_loss = 3.965, time/batch = 0.033
Read data: 0.00011992454528808594
iter 941 (epoch 1), train_loss = 3.990, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 942 (epoch 1), train_loss = 3.526, time/batch = 0.018
Read data: 9.5367431640625e-05
iter 943 (epoch 1), train_loss = 3.306, time/batch = 0.025
Read data: 0.00010585784912109375
iter 944 (epoch 1), train_loss = 3.933, time/batch = 0.026
Read data: 6.914138793945312e-05
iter 945 (epoch 1), train_loss = 3.890, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 946 (epoch 1), train_loss = 4.076, time/batch = 0.028
Read data: 6.341934204101562e-05
iter 947 (epoch 1), train_loss = 3.427, time/batch = 0.018
Read data: 0.00014328956604003906
iter 948 (epoch 1), train_loss = 3.614, time/batch = 0.027
Read data: 7.319450378417969e-05
iter 949 (epoch 1), train_loss = 3.795, time/batch = 0.024
Read data: 0.00028896331787109375
iter 950 (epoch 1), train_loss = 3.638, time/batch = 0.023
Read data: 7.367134094238281e-05
iter 951 (epoch 1), train_loss = 3.832, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 952 (epoch 1), train_loss = 3.716, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 953 (epoch 1), train_loss = 3.945, time/batch = 0.023
Read data: 0.0033636093139648438
iter 954 (epoch 1), train_loss = 3.614, time/batch = 0.020
Read data: 6.651878356933594e-05
iter 955 (epoch 1), train_loss = 3.754, time/batch = 0.028
Read data: 0.00011873245239257812
iter 956 (epoch 1), train_loss = 3.379, time/batch = 0.022
Read data: 6.842613220214844e-05
iter 957 (epoch 1), train_loss = 3.600, time/batch = 0.028
Read data: 0.002425670623779297
iter 958 (epoch 1), train_loss = 3.595, time/batch = 0.021
Read data: 5.9604644775390625e-05
iter 959 (epoch 1), train_loss = 3.724, time/batch = 0.029
Read data: 7.081031799316406e-05
iter 960 (epoch 1), train_loss = 3.734, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 961 (epoch 1), train_loss = 3.586, time/batch = 0.019
Read data: 0.005575656890869141
iter 962 (epoch 1), train_loss = 3.419, time/batch = 0.027
Read data: 0.00014209747314453125
iter 963 (epoch 1), train_loss = 4.059, time/batch = 0.018
Read data: 7.534027099609375e-05
iter 964 (epoch 1), train_loss = 3.455, time/batch = 0.024
Read data: 6.961822509765625e-05
iter 965 (epoch 1), train_loss = 3.816, time/batch = 0.022
Read data: 0.010573148727416992
iter 966 (epoch 1), train_loss = 3.646, time/batch = 0.023
Read data: 0.0001366138458251953
iter 967 (epoch 1), train_loss = 3.593, time/batch = 0.020
Read data: 8.20159912109375e-05
iter 968 (epoch 1), train_loss = 3.603, time/batch = 0.025
Read data: 7.390975952148438e-05
iter 969 (epoch 1), train_loss = 3.801, time/batch = 0.025
Read data: 0.009752988815307617
iter 970 (epoch 1), train_loss = 3.735, time/batch = 0.028
Read data: 6.699562072753906e-05
iter 971 (epoch 1), train_loss = 3.540, time/batch = 0.029
Read data: 6.842613220214844e-05
iter 972 (epoch 1), train_loss = 3.597, time/batch = 0.023
Read data: 0.00020360946655273438
iter 973 (epoch 1), train_loss = 3.612, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 974 (epoch 1), train_loss = 3.340, time/batch = 0.023
Read data: 7.62939453125e-05
iter 975 (epoch 1), train_loss = 3.504, time/batch = 0.022
Read data: 7.295608520507812e-05
iter 976 (epoch 1), train_loss = 3.244, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 977 (epoch 1), train_loss = 3.388, time/batch = 0.021
Read data: 0.0025687217712402344
iter 978 (epoch 1), train_loss = 3.705, time/batch = 0.019
Read data: 5.3882598876953125e-05
iter 979 (epoch 1), train_loss = 3.769, time/batch = 0.018
Read data: 8.440017700195312e-05
iter 980 (epoch 1), train_loss = 3.533, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 981 (epoch 1), train_loss = 3.820, time/batch = 0.024
Read data: 0.01660633087158203
iter 982 (epoch 1), train_loss = 3.773, time/batch = 0.024
Read data: 5.555152893066406e-05
iter 983 (epoch 1), train_loss = 3.760, time/batch = 0.021
Read data: 6.699562072753906e-05
iter 984 (epoch 1), train_loss = 3.400, time/batch = 0.023
Read data: 7.009506225585938e-05
iter 985 (epoch 1), train_loss = 3.488, time/batch = 0.023
Read data: 0.007218599319458008
iter 986 (epoch 1), train_loss = 3.774, time/batch = 0.019
Read data: 5.555152893066406e-05
iter 987 (epoch 1), train_loss = 3.813, time/batch = 0.024
Read data: 0.00011491775512695312
iter 988 (epoch 1), train_loss = 4.054, time/batch = 0.034
Read data: 0.00012803077697753906
iter 989 (epoch 1), train_loss = 3.811, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 990 (epoch 1), train_loss = 4.121, time/batch = 0.023
Read data: 6.031990051269531e-05
iter 991 (epoch 1), train_loss = 3.679, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 992 (epoch 1), train_loss = 3.947, time/batch = 0.020
Read data: 6.937980651855469e-05
iter 993 (epoch 1), train_loss = 3.726, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 994 (epoch 1), train_loss = 3.358, time/batch = 0.021
Read data: 6.413459777832031e-05
iter 995 (epoch 1), train_loss = 3.751, time/batch = 0.023
Read data: 7.700920104980469e-05
iter 996 (epoch 1), train_loss = 3.716, time/batch = 0.023
Read data: 7.009506225585938e-05
iter 997 (epoch 1), train_loss = 3.697, time/batch = 0.026
Read data: 0.0031528472900390625
iter 998 (epoch 1), train_loss = 3.690, time/batch = 0.023
Read data: 5.8650970458984375e-05
iter 999 (epoch 1), train_loss = 3.357, time/batch = 0.022
image 976:    
image 5399:    
image 6910:     
image 660:     
image 6372:    
image 616:    
image 2678:    
image 2375:    
image 2494:    
image 6381:    
evaluating validation preformance... 10/1000 (3.620545)
image 2798:    
image 5884:    
image 2067:     
image 3600:    
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:    
image 6718:    
evaluating validation preformance... 20/1000 (3.327507)
image 6903:     
image 3301:    
image 2019:    
image 5535:    
image 7680:    
image 5527:     
image 2568:    
image 160:     
image 8085:     
image 7670:     
evaluating validation preformance... 30/1000 (3.540780)
image 4604:    
image 5745:    
image 5288:    
image 1562:     
image 7807:     
image 3572:    
image 6763:    
image 4318:    
image 1744:    
image 1684:    
evaluating validation preformance... 40/1000 (3.697219)
image 2938:    
image 5183:     
image 2380:    
image 6973:     
image 5629:    
image 7130:    
image 1679:    
image 7194:     
image 2022:     
image 2850:    
evaluating validation preformance... 50/1000 (3.461405)
image 4940:     
image 4905:    
image 469:     
image 102:    
image 6009:    
image 4271:    
image 6329:    
image 1729:    
image 4444:    
image 6070:    
evaluating validation preformance... 60/1000 (3.682546)
image 4389:     
image 4281:     
image 4504:    
image 6146:    
image 5767:    
image 3160:     
image 7146:     
image 4433:    
image 2973:    
image 5641:    
evaluating validation preformance... 70/1000 (3.551324)
image 3258:    
image 6895:     
image 5296:    
image 4623:    
image 2588:    
image 4656:    
image 663:    
image 2322:    
image 2260:     
image 2242:     
evaluating validation preformance... 80/1000 (3.662730)
image 3276:     
image 3812:     
image 1400:    
image 3443:     
image 5027:    
image 7251:     
image 7305:     
image 1480:     
image 4806:     
image 766:    
evaluating validation preformance... 90/1000 (3.105311)
image 6124:    
image 5415:    
image 369:    
image 5747:    
image 1003:    
image 6612:    
image 7701:    
image 7379:     
image 1165:     
image 6553:     
evaluating validation preformance... 100/1000 (3.920545)
image 2800:    
image 7249:    
image 3211:    
image 686:     
image 3986:    
image 2518:    
image 7399:    
image 1832:    
image 3666:    
image 150:     
evaluating validation preformance... 110/1000 (3.731331)
image 1122:    
image 509:    
image 4091:    
image 5761:    
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:     
image 5302:    
evaluating validation preformance... 120/1000 (3.373752)
image 3477:     
image 1212:    
image 3809:    
image 4329:    
image 3500:    
image 4913:     
image 4589:     
image 5863:    
image 1642:    
image 6166:     
evaluating validation preformance... 130/1000 (3.784653)
image 6214:    
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:    
image 8068:    
image 4450:    
image 1524:    
image 2867:    
evaluating validation preformance... 140/1000 (3.556383)
image 1738:     
image 1455:    
image 4198:    
image 2180:    
image 4436:     
image 197:    
image 519:    
image 8070:    
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.846690)
image 1865:     
image 3830:    
image 360:     
image 5097:    
image 4455:    
image 1153:    
image 1248:     
image 7688:     
image 820:    
image 7993:     
evaluating validation preformance... 160/1000 (3.693177)
image 4297:    
image 3315:    
image 1107:    
image 2051:    
image 4713:     
image 8036:    
image 5662:    
image 2095:    
image 3679:    
image 3426:    
evaluating validation preformance... 170/1000 (3.494504)
image 7922:    
image 2353:    
image 4580:    
image 5905:     
image 6488:    
image 3000:    
image 1806:    
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (3.524933)
image 2313:     
image 6289:    
image 8084:    
image 2696:     
image 5830:     
image 6240:     
image 4541:    
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (3.575146)
image 5372:     
image 7529:    
image 875:    
image 2107:     
image 8015:    
image 6565:    
image 6174:     
image 6894:    
image 4164:    
image 7049:    
evaluating validation preformance... 200/1000 (3.304323)
image 5159:    
image 1199:    
image 2456:    
image 3402:    
image 7631:    
image 3562:    
image 405:    
image 2532:    
image 2844:    
image 4023:    
evaluating validation preformance... 210/1000 (3.539405)
image 2599:    
image 822:    
image 3926:    
image 6942:    
image 1942:    
image 618:    
image 1725:    
image 1089:     
image 864:    
image 7345:    
evaluating validation preformance... 220/1000 (3.642838)
image 4024:    
image 1894:    
image 7297:     
image 1796:    
image 7075:    
image 2258:    
image 5122:     
image 5586:    
image 4483:     
image 6582:    
evaluating validation preformance... 230/1000 (3.554714)
image 1917:    
image 5844:     
image 1661:    
image 1510:    
image 4630:    
image 6741:    
image 1020:     
image 5967:    
image 8014:    
image 5594:    
evaluating validation preformance... 240/1000 (3.331089)
image 7143:    
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:    
image 890:    
image 778:    
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (3.668690)
image 3028:    
image 3141:     
image 7137:     
image 3444:    
image 2049:    
image 550:    
image 3367:     
image 4907:    
image 6173:    
image 3082:    
evaluating validation preformance... 260/1000 (3.400409)
image 492:    
image 5429:    
image 6968:    
image 2672:     
image 6920:    
image 6211:    
image 3326:     
image 1870:    
image 4511:    
image 7380:     
evaluating validation preformance... 270/1000 (3.755206)
image 833:    
image 5483:    
image 2476:     
image 5930:    
image 59:    
image 5007:    
image 2884:    
image 486:    
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (3.467717)
image 2481:    
image 1860:    
image 1464:    
image 4488:    
image 7299:    
image 5006:    
image 7828:    
image 7372:    
image 2058:    
image 2130:    
evaluating validation preformance... 290/1000 (3.547386)
image 6835:    
image 4698:     
image 7212:    
image 5933:     
image 2431:    
image 7277:     
image 2088:     
image 3340:     
image 3579:    
image 6928:    
evaluating validation preformance... 300/1000 (3.309626)
image 2805:    
image 4374:    
image 25:    
image 7702:    
image 256:    
image 7362:     
image 2148:    
image 1974:     
image 6050:    
image 6156:    
evaluating validation preformance... 310/1000 (3.869319)
image 3553:    
image 5971:    
image 122:     
image 3212:     
image 7223:    
image 7007:    
image 6064:    
image 7358:    
image 5096:     
image 6423:    
evaluating validation preformance... 320/1000 (3.398491)
image 489:    
image 5316:    
image 2613:     
image 7935:    
image 7768:    
image 7894:     
image 6267:     
image 2203:    
image 5727:    
image 1159:     
evaluating validation preformance... 330/1000 (3.624419)
image 5179:    
image 3754:    
image 2911:    
image 6979:     
image 5449:     
image 2198:    
image 2535:    
image 2601:    
image 4524:    
image 3972:    
evaluating validation preformance... 340/1000 (3.395875)
image 4542:     
image 1878:     
image 5329:     
image 4139:    
image 6018:    
image 1206:    
image 5385:    
image 2794:     
image 7785:    
image 2085:     
evaluating validation preformance... 350/1000 (3.605708)
image 6881:    
image 942:    
image 2775:    
image 3311:    
image 4587:     
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:     
evaluating validation preformance... 360/1000 (2.908157)
image 2905:    
image 7814:    
image 56:    
image 5034:    
image 7946:    
image 3470:    
image 4655:    
image 818:     
image 6607:    
image 4866:    
evaluating validation preformance... 370/1000 (3.588703)
image 4351:     
image 1054:    
image 129:    
image 2849:    
image 725:    
image 2573:    
image 6766:     
image 5754:    
image 1955:    
image 7569:    
evaluating validation preformance... 380/1000 (3.741388)
image 2458:    
image 1084:    
image 4835:    
image 867:    
image 723:    
image 6255:    
image 5255:     
image 3598:    
image 2997:    
image 60:    
evaluating validation preformance... 390/1000 (3.793021)
image 828:    
image 2733:    
image 791:     
image 5408:    
image 7842:    
image 1117:     
image 5817:     
image 1231:    
image 1630:    
image 6886:    
evaluating validation preformance... 400/1000 (3.370258)
image 2627:    
image 7172:    
image 1991:    
image 7413:    
image 2105:    
image 3919:    
image 7980:    
image 670:    
image 2325:    
image 7546:     
evaluating validation preformance... 410/1000 (3.264073)
image 4359:    
image 2372:    
image 4472:     
image 6810:    
image 1592:    
image 7864:     
image 4286:    
image 6688:    
image 5697:    
image 7020:    
evaluating validation preformance... 420/1000 (3.203721)
image 30:    
image 5540:     
image 2445:     
image 5896:     
image 7607:    
image 1426:     
image 6977:     
image 877:    
image 2408:    
image 7706:    
evaluating validation preformance... 430/1000 (3.748647)
image 385:    
image 6938:    
image 2381:     
image 5796:    
image 4010:    
image 3452:    
image 2023:    
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (3.699497)
image 1731:     
image 978:     
image 6033:     
image 5080:    
image 7804:    
image 439:    
image 4790:     
image 5855:    
image 4245:     
image 973:    
evaluating validation preformance... 450/1000 (3.324072)
image 2241:    
image 2651:    
image 2315:    
image 4784:    
image 5160:    
image 2466:    
image 975:    
image 3818:     
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (3.932077)
image 7979:    
image 1618:    
image 7608:    
image 6393:     
image 5100:    
image 4480:    
image 1440:    
image 5886:    
image 5995:    
image 1900:     
evaluating validation preformance... 470/1000 (4.111265)
image 4503:    
image 7112:    
image 3480:    
image 7533:    
image 5050:     
image 6862:    
image 7450:    
image 841:    
image 1118:    
image 6114:     
evaluating validation preformance... 480/1000 (3.794891)
image 358:    
image 4663:     
image 5541:    
image 4485:    
image 2727:     
image 1040:    
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (4.196733)
image 2044:    
image 4349:     
image 3855:     
image 1846:    
image 3724:    
image 606:     
image 6577:     
image 6820:     
image 1485:    
image 5744:    
evaluating validation preformance... 500/1000 (3.497793)
image 1797:    
image 4670:    
image 4846:    
image 5907:    
image 3321:     
image 1700:    
image 438:    
image 5980:     
image 408:    
image 5403:    
evaluating validation preformance... 510/1000 (4.019462)
image 3246:     
image 4424:    
image 41:    
image 459:     
image 1072:     
image 5650:    
image 2597:    
image 5416:    
image 2744:    
image 5979:    
evaluating validation preformance... 520/1000 (3.628335)
image 6806:    
image 6464:    
image 1872:    
image 1575:    
image 3045:     
image 303:    
image 5552:     
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (3.331234)
image 5619:    
image 4391:    
image 891:    
image 3072:    
image 7781:     
image 6163:    
image 7376:     
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (3.646060)
image 5292:     
image 2901:    
image 3568:    
image 690:     
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:    
image 1961:     
evaluating validation preformance... 550/1000 (3.570463)
image 5439:    
image 7981:    
image 6012:    
image 4732:    
image 6630:    
image 994:    
image 5079:    
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (3.732225)
image 6056:    
image 6419:    
image 275:     
image 7441:    
image 7893:    
image 3623:    
image 7232:     
image 4778:    
image 1007:    
image 3387:    
evaluating validation preformance... 570/1000 (3.787841)
image 7936:    
image 5433:    
image 5691:     
image 1628:     
image 4501:    
image 1247:    
image 315:    
image 317:    
image 329:    
image 3267:     
evaluating validation preformance... 580/1000 (3.277066)
image 2135:     
image 3865:    
image 7837:    
image 1172:    
image 4651:    
image 73:    
image 1500:    
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (3.603155)
image 4420:     
image 1734:     
image 7239:    
image 7447:    
image 8009:    
image 4510:     
image 7495:    
image 2530:    
image 4597:     
image 3381:    
evaluating validation preformance... 600/1000 (3.606603)
image 353:    
image 1095:     
image 3583:     
image 3264:    
image 5668:    
image 7189:    
image 6573:     
image 3253:     
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (3.750946)
image 69:    
image 3465:    
image 6179:    
image 552:    
image 511:    
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (3.758058)
image 6575:     
image 5695:    
image 7418:    
image 1948:    
image 4012:    
image 6981:    
image 989:     
image 2847:    
image 4456:    
image 2351:    
evaluating validation preformance... 630/1000 (3.325373)
image 8074:    
image 1904:    
image 7917:     
image 2394:    
image 4406:    
image 883:     
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (3.507342)
image 5313:    
image 2377:    
image 6058:    
image 4661:    
image 2955:    
image 3333:    
image 7124:    
image 4278:     
image 953:    
image 4037:    
evaluating validation preformance... 650/1000 (3.672247)
image 8065:    
image 3577:    
image 3254:     
image 4562:     
image 5462:    
image 2824:     
image 1639:    
image 1475:    
image 3991:    
image 1023:    
evaluating validation preformance... 660/1000 (3.646102)
image 5701:     
image 1709:     
image 4811:     
image 622:    
image 5997:    
image 1608:     
image 4119:     
image 1619:     
image 5652:     
image 1972:    
evaluating validation preformance... 670/1000 (3.696026)
image 7877:    
image 6761:    
image 6880:    
image 4914:    
image 4522:    
image 2311:    
image 7587:    
image 4848:    
image 6722:    
image 7784:     
evaluating validation preformance... 680/1000 (4.037613)
image 1445:    
image 6841:    
image 2896:    
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (3.807349)
image 6860:    
image 576:     
image 6580:    
image 1497:     
image 3360:    
image 4939:    
image 6225:    
image 3669:    
image 980:    
image 5362:     
evaluating validation preformance... 700/1000 (3.795682)
image 5343:     
image 68:    
image 3184:    
image 5637:     
image 2041:    
image 650:    
image 4911:    
image 34:    
image 7801:     
image 1129:    
evaluating validation preformance... 710/1000 (3.413098)
image 7368:    
image 709:       
image 3197:     
image 5214:    
image 445:     
image 3428:    
image 268:    
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (3.486640)
image 5729:     
image 6395:     
image 516:     
image 1026:    
image 2972:     
image 3005:    
image 1241:     
image 2743:     
image 3665:    
image 1290:    
evaluating validation preformance... 730/1000 (3.311358)
image 2527:    
image 6266:    
image 4161:    
image 1139:     
image 3781:    
image 6081:     
image 997:    
image 5092:    
image 7789:    
image 2504:     
evaluating validation preformance... 740/1000 (3.264542)
image 2239:    
image 120:     
image 4902:     
image 3796:    
image 3355:    
image 1787:    
image 5365:     
image 2674:     
image 4735:    
image 6197:    
evaluating validation preformance... 750/1000 (3.910406)
image 3279:    
image 6380:    
image 2663:    
image 3815:    
image 512:     
image 5899:    
image 6078:    
image 4808:     
image 3780:    
image 7174:    
evaluating validation preformance... 760/1000 (3.696107)
image 4582:     
image 5484:    
image 3049:     
image 4641:     
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:    
image 3449:     
evaluating validation preformance... 770/1000 (3.186861)
image 6220:    
image 6238:    
image 4534:    
image 2732:    
image 7003:    
image 1739:    
image 5503:     
image 2329:    
image 1201:    
image 5956:    
evaluating validation preformance... 780/1000 (3.710088)
image 6867:    
image 5525:    
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:    
image 3312:    
image 7824:     
image 2032:    
evaluating validation preformance... 790/1000 (4.221540)
image 5047:     
image 325:    
image 7626:    
image 4552:    
image 983:     
image 8052:     
image 1585:     
image 4336:     
image 1728:    
image 6725:    
evaluating validation preformance... 800/1000 (3.220572)
image 7288:     
image 7302:     
image 3055:    
image 5250:    
image 1158:     
image 290:     
image 159:    
image 4345:    
image 2217:    
image 3169:    
evaluating validation preformance... 810/1000 (3.562088)
image 614:    
image 7295:    
image 4110:    
image 5402:     
image 3060:    
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:     
evaluating validation preformance... 820/1000 (3.129617)
image 7204:     
image 4428:    
image 7825:     
image 5890:     
image 4334:    
image 5514:    
image 7147:    
image 6348:    
image 580:    
image 2531:    
evaluating validation preformance... 830/1000 (3.396007)
image 5107:     
image 3973:    
image 4233:    
image 3593:     
image 5872:    
image 2074:     
image 5805:    
image 5683:    
image 1489:     
image 6117:    
evaluating validation preformance... 840/1000 (3.334310)
image 7592:    
image 1798:    
image 3567:    
image 5090:     
image 6440:    
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (3.910714)
image 4404:     
image 5501:    
image 5765:    
image 1838:     
image 4354:    
image 336:     
image 3596:     
image 1921:     
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (3.815071)
image 4254:     
image 6842:    
image 1644:    
image 7371:     
image 4638:    
image 4031:    
image 2702:    
image 4927:     
image 3222:    
image 4002:    
evaluating validation preformance... 870/1000 (3.346808)
image 4934:    
image 6487:    
image 4217:    
image 6355:    
image 2793:    
image 7201:     
image 5681:     
image 1824:     
image 2098:    
image 28:     
evaluating validation preformance... 880/1000 (3.436555)
image 5460:     
image 3671:    
image 3602:    
image 3473:    
image 2048:    
image 1379:    
image 419:    
image 2314:     
image 6244:    
image 4530:    
evaluating validation preformance... 890/1000 (3.789179)
image 7485:    
image 6102:    
image 1001:     
image 7167:    
image 4168:    
image 187:    
image 7798:    
image 4813:    
image 7753:    
image 210:     
evaluating validation preformance... 900/1000 (4.186206)
image 5664:    
image 4985:    
image 4082:     
image 6291:    
image 5573:    
image 1405:    
image 4431:     
image 2801:    
image 2398:     
image 7205:    
evaluating validation preformance... 910/1000 (3.281105)
image 1368:    
image 1925:     
image 5870:    
image 4915:    
image 3879:    
image 1002:     
image 4605:    
image 6475:    
image 3748:    
image 844:    
evaluating validation preformance... 920/1000 (3.508122)
image 7152:     
image 4559:    
image 7233:     
image 1341:    
image 5337:    
image 3189:    
image 6274:     
image 7102:     
image 5532:    
image 2516:    
evaluating validation preformance... 930/1000 (3.402164)
image 5636:     
image 7799:    
image 6025:    
image 6907:    
image 2507:    
image 7014:    
image 5566:    
image 5161:    
image 652:    
image 4412:     
evaluating validation preformance... 940/1000 (3.644274)
image 5860:    
image 3275:    
image 1935:    
image 3520:    
image 5452:    
image 2446:    
image 5984:    
image 5804:    
image 6691:     
image 6530:    
evaluating validation preformance... 950/1000 (3.867714)
image 1081:    
image 1179:    
image 4316:    
image 3588:    
image 1085:     
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:     
evaluating validation preformance... 960/1000 (3.754083)
image 4935:    
image 1930:    
image 6850:     
image 5310:    
image 177:    
image 94:    
image 529:    
image 4632:     
image 3766:     
image 374:     
evaluating validation preformance... 970/1000 (3.462213)
image 5688:    
image 5448:     
image 5871:    
image 7516:    
image 3734:    
image 2921:     
image 7800:    
image 3999:    
image 6317:    
image 5931:    
evaluating validation preformance... 980/1000 (3.747783)
image 7352:    
image 5113:    
image 7822:    
image 4858:    
image 658:    
image 2982:    
image 5843:    
image 1822:    
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (3.486479)
image 5789:     
image 5606:     
image 6107:    
image 7976:     
image 3890:    
image 5901:    
image 1163:     
image 2483:    
image 2591:    
image 7615:    
evaluating validation preformance... 1000/1000 (3.511416)
average loss on validation: 3.589
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3431673049926758
Cider scores: 0.21505231418315493
Read data: 0.29320693016052246
Cider scores: 0.25956025747503864
Read data: 0.25701165199279785
Cider scores: 0.19332857535367917
Read data: 0.2219395637512207
Cider scores: 0.21263415253727103
Read data: 0.19568562507629395
Cider scores: 0.20090341941519885
Read data: 0.1719968318939209
Cider scores: 0.23054208820637134
Read data: 0.20766639709472656
Cider scores: 0.21986106734715302
Read data: 0.17674970626831055
Cider scores: 0.2098962810846743
Read data: 0.16982722282409668
Cider scores: 0.22640722559314194
Read data: 0.1936025619506836
Cider scores: 0.2757498751507482
Read data: 0.23833775520324707
Cider scores: 0.20562443592706076
Read data: 0.17896556854248047
Cider scores: 0.2702569044913816
Read data: 0.1795945167541504
Cider scores: 0.2761688558687106
Read data: 0.17353105545043945
Cider scores: 0.23814207452455183
Read data: 0.18018364906311035
Cider scores: 0.2189077295195775
Read data: 0.16779565811157227
Cider scores: 0.23420430745222282
Read data: 0.1672358512878418
Cider scores: 0.20874490254046266
Read data: 0.16188621520996094
Cider scores: 0.3013376460160637
Read data: 0.16263508796691895
Cider scores: 0.19821492000521385
Read data: 0.16060566902160645
Cider scores: 0.31957662788030405
Average cider score on test set: 0.236
End calculating cider score on TEST data set
===============================================
Read data: 0.16726112365722656
iter 1000 (epoch 1), train_loss = 3.650, time/batch = 0.021
Read data: 8.153915405273438e-05
iter 1001 (epoch 1), train_loss = 3.604, time/batch = 0.028
Read data: 0.00011515617370605469
iter 1002 (epoch 1), train_loss = 3.357, time/batch = 0.019
Read data: 0.00010585784912109375
iter 1003 (epoch 1), train_loss = 3.172, time/batch = 0.018
Read data: 0.0001761913299560547
iter 1004 (epoch 1), train_loss = 3.907, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 1005 (epoch 1), train_loss = 3.698, time/batch = 0.025
Read data: 0.00011014938354492188
iter 1006 (epoch 1), train_loss = 3.378, time/batch = 0.018
Read data: 7.367134094238281e-05
iter 1007 (epoch 1), train_loss = 3.791, time/batch = 0.020
Read data: 9.107589721679688e-05
iter 1008 (epoch 1), train_loss = 3.816, time/batch = 0.021
Read data: 0.000171661376953125
iter 1009 (epoch 1), train_loss = 3.618, time/batch = 0.025
Read data: 0.00017762184143066406
iter 1010 (epoch 1), train_loss = 3.828, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 1011 (epoch 1), train_loss = 3.493, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 1012 (epoch 1), train_loss = 4.038, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 1013 (epoch 1), train_loss = 3.482, time/batch = 0.021
Read data: 0.0001628398895263672
iter 1014 (epoch 1), train_loss = 3.366, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 1015 (epoch 1), train_loss = 3.624, time/batch = 0.027
Read data: 0.000156402587890625
iter 1016 (epoch 1), train_loss = 3.340, time/batch = 0.025
Read data: 0.00015306472778320312
iter 1017 (epoch 1), train_loss = 3.055, time/batch = 0.019
Read data: 9.393692016601562e-05
iter 1018 (epoch 1), train_loss = 3.488, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 1019 (epoch 1), train_loss = 3.598, time/batch = 0.027
Read data: 0.00016164779663085938
iter 1020 (epoch 1), train_loss = 3.816, time/batch = 0.021
Read data: 0.00011873245239257812
iter 1021 (epoch 1), train_loss = 3.771, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 1022 (epoch 1), train_loss = 3.594, time/batch = 0.025
Read data: 0.0001385211944580078
iter 1023 (epoch 1), train_loss = 3.242, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 1024 (epoch 1), train_loss = 3.439, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 1025 (epoch 1), train_loss = 3.932, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 1026 (epoch 1), train_loss = 3.682, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 1027 (epoch 1), train_loss = 3.291, time/batch = 0.031
Read data: 7.772445678710938e-05
iter 1028 (epoch 1), train_loss = 3.869, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 1029 (epoch 1), train_loss = 3.500, time/batch = 0.024
Read data: 0.00016379356384277344
iter 1030 (epoch 1), train_loss = 3.757, time/batch = 0.018
Read data: 8.320808410644531e-05
iter 1031 (epoch 1), train_loss = 3.559, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 1032 (epoch 1), train_loss = 3.642, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 1033 (epoch 1), train_loss = 3.730, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 1034 (epoch 1), train_loss = 3.472, time/batch = 0.021
Read data: 8.130073547363281e-05
iter 1035 (epoch 1), train_loss = 3.314, time/batch = 0.020
Read data: 8.440017700195312e-05
iter 1036 (epoch 1), train_loss = 3.751, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 1037 (epoch 1), train_loss = 3.865, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 1038 (epoch 1), train_loss = 3.740, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 1039 (epoch 1), train_loss = 3.499, time/batch = 0.026
Read data: 0.000247955322265625
iter 1040 (epoch 1), train_loss = 3.378, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 1041 (epoch 1), train_loss = 3.857, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 1042 (epoch 1), train_loss = 3.781, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 1043 (epoch 1), train_loss = 3.512, time/batch = 0.020
Read data: 0.0001285076141357422
iter 1044 (epoch 1), train_loss = 3.294, time/batch = 0.028
Read data: 0.00014829635620117188
iter 1045 (epoch 1), train_loss = 3.615, time/batch = 0.020
Read data: 7.891654968261719e-05
iter 1046 (epoch 1), train_loss = 3.123, time/batch = 0.020
Read data: 8.893013000488281e-05
iter 1047 (epoch 1), train_loss = 3.584, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 1048 (epoch 1), train_loss = 3.810, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 1049 (epoch 1), train_loss = 3.652, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 1050 (epoch 1), train_loss = 3.378, time/batch = 0.021
Read data: 7.748603820800781e-05
iter 1051 (epoch 1), train_loss = 3.787, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 1052 (epoch 1), train_loss = 3.585, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 1053 (epoch 1), train_loss = 3.537, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 1054 (epoch 1), train_loss = 3.763, time/batch = 0.021
Read data: 6.699562072753906e-05
iter 1055 (epoch 1), train_loss = 3.325, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 1056 (epoch 1), train_loss = 3.359, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 1057 (epoch 1), train_loss = 3.898, time/batch = 0.023
Read data: 0.0001773834228515625
iter 1058 (epoch 1), train_loss = 3.278, time/batch = 0.020
Read data: 0.0001392364501953125
iter 1059 (epoch 1), train_loss = 3.456, time/batch = 0.019
Read data: 8.630752563476562e-05
iter 1060 (epoch 1), train_loss = 3.427, time/batch = 0.020
Read data: 9.107589721679688e-05
iter 1061 (epoch 1), train_loss = 3.917, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 1062 (epoch 1), train_loss = 3.804, time/batch = 0.022
Read data: 0.00011539459228515625
iter 1063 (epoch 1), train_loss = 3.660, time/batch = 0.033
Read data: 8.487701416015625e-05
iter 1064 (epoch 1), train_loss = 3.648, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 1065 (epoch 1), train_loss = 3.859, time/batch = 0.028
Read data: 0.00016880035400390625
iter 1066 (epoch 1), train_loss = 3.761, time/batch = 0.025
Read data: 7.390975952148438e-05
iter 1067 (epoch 1), train_loss = 3.521, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 1068 (epoch 1), train_loss = 3.723, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 1069 (epoch 1), train_loss = 4.149, time/batch = 0.023
Read data: 0.00013303756713867188
iter 1070 (epoch 1), train_loss = 3.148, time/batch = 0.020
Read data: 7.05718994140625e-05
iter 1071 (epoch 1), train_loss = 3.460, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 1072 (epoch 1), train_loss = 3.799, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 1073 (epoch 1), train_loss = 3.484, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 1074 (epoch 1), train_loss = 3.730, time/batch = 0.018
Read data: 0.0001983642578125
iter 1075 (epoch 1), train_loss = 3.625, time/batch = 0.028
Read data: 0.00016355514526367188
iter 1076 (epoch 1), train_loss = 3.884, time/batch = 0.022
Read data: 0.0001461505889892578
iter 1077 (epoch 1), train_loss = 3.384, time/batch = 0.019
Read data: 0.010529756546020508
iter 1078 (epoch 1), train_loss = 3.621, time/batch = 0.018
Read data: 7.534027099609375e-05
iter 1079 (epoch 1), train_loss = 3.454, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 1080 (epoch 1), train_loss = 4.003, time/batch = 0.035
Read data: 0.00015997886657714844
iter 1081 (epoch 1), train_loss = 3.738, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 1082 (epoch 1), train_loss = 3.595, time/batch = 0.020
Read data: 6.651878356933594e-05
iter 1083 (epoch 1), train_loss = 3.552, time/batch = 0.020
Read data: 8.940696716308594e-05
iter 1084 (epoch 1), train_loss = 3.436, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 1085 (epoch 1), train_loss = 3.588, time/batch = 0.022
Read data: 0.008520126342773438
iter 1086 (epoch 1), train_loss = 3.456, time/batch = 0.021
Read data: 0.00011372566223144531
iter 1087 (epoch 1), train_loss = 3.278, time/batch = 0.018
Read data: 8.821487426757812e-05
iter 1088 (epoch 1), train_loss = 3.457, time/batch = 0.025
Read data: 0.00017523765563964844
iter 1089 (epoch 1), train_loss = 3.243, time/batch = 0.020
Read data: 0.013251304626464844
iter 1090 (epoch 1), train_loss = 3.778, time/batch = 0.023
Read data: 7.176399230957031e-05
iter 1091 (epoch 1), train_loss = 3.632, time/batch = 0.020
Read data: 8.749961853027344e-05
iter 1092 (epoch 1), train_loss = 3.615, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 1093 (epoch 1), train_loss = 3.555, time/batch = 0.026
Read data: 0.0025606155395507812
iter 1094 (epoch 1), train_loss = 3.448, time/batch = 0.028
Read data: 0.0001201629638671875
iter 1095 (epoch 1), train_loss = 3.612, time/batch = 0.018
Read data: 9.679794311523438e-05
iter 1096 (epoch 1), train_loss = 3.772, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 1097 (epoch 1), train_loss = 3.951, time/batch = 0.027
Read data: 0.0022106170654296875
iter 1098 (epoch 1), train_loss = 3.539, time/batch = 0.025
Read data: 6.723403930664062e-05
iter 1099 (epoch 1), train_loss = 3.390, time/batch = 0.020
Read data: 0.0001418590545654297
iter 1100 (epoch 1), train_loss = 3.648, time/batch = 0.026
Read data: 0.00014472007751464844
iter 1101 (epoch 1), train_loss = 3.701, time/batch = 0.027
Read data: 0.0031452178955078125
iter 1102 (epoch 1), train_loss = 3.778, time/batch = 0.026
Read data: 6.818771362304688e-05
iter 1103 (epoch 1), train_loss = 3.487, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 1104 (epoch 1), train_loss = 3.651, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 1105 (epoch 1), train_loss = 3.470, time/batch = 0.030
Read data: 0.00012803077697753906
iter 1106 (epoch 1), train_loss = 3.793, time/batch = 0.030
Read data: 7.581710815429688e-05
iter 1107 (epoch 1), train_loss = 3.619, time/batch = 0.026
Read data: 0.0001621246337890625
iter 1108 (epoch 1), train_loss = 3.668, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 1109 (epoch 1), train_loss = 3.323, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 1110 (epoch 1), train_loss = 3.595, time/batch = 0.021
Read data: 0.00018978118896484375
iter 1111 (epoch 1), train_loss = 3.745, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 1112 (epoch 1), train_loss = 3.480, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 1113 (epoch 1), train_loss = 3.357, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 1114 (epoch 1), train_loss = 3.560, time/batch = 0.021
Read data: 0.0001270771026611328
iter 1115 (epoch 1), train_loss = 3.370, time/batch = 0.023
Read data: 0.0001010894775390625
iter 1116 (epoch 1), train_loss = 2.981, time/batch = 0.021
Read data: 0.00018644332885742188
iter 1117 (epoch 1), train_loss = 3.423, time/batch = 0.024
Read data: 0.00010633468627929688
iter 1118 (epoch 1), train_loss = 3.476, time/batch = 0.020
Read data: 7.104873657226562e-05
iter 1119 (epoch 1), train_loss = 3.712, time/batch = 0.023
Read data: 0.000125885009765625
iter 1120 (epoch 1), train_loss = 3.446, time/batch = 0.023
Read data: 0.00013589859008789062
iter 1121 (epoch 1), train_loss = 3.115, time/batch = 0.019
Read data: 0.011481285095214844
iter 1122 (epoch 1), train_loss = 3.560, time/batch = 0.022
Read data: 0.00010967254638671875
iter 1123 (epoch 1), train_loss = 3.629, time/batch = 0.028
Read data: 0.00012302398681640625
iter 1124 (epoch 1), train_loss = 3.660, time/batch = 0.021
Read data: 0.0001304149627685547
iter 1125 (epoch 1), train_loss = 3.214, time/batch = 0.021
Read data: 0.0046579837799072266
iter 1126 (epoch 1), train_loss = 3.775, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 1127 (epoch 1), train_loss = 3.744, time/batch = 0.023
Read data: 0.00011873245239257812
iter 1128 (epoch 1), train_loss = 3.574, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 1129 (epoch 1), train_loss = 3.768, time/batch = 0.024
Read data: 0.0001361370086669922
iter 1130 (epoch 1), train_loss = 4.181, time/batch = 0.022
Read data: 6.937980651855469e-05
iter 1131 (epoch 1), train_loss = 4.103, time/batch = 0.020
Read data: 0.000110626220703125
iter 1132 (epoch 1), train_loss = 3.543, time/batch = 0.019
Read data: 0.000152587890625
iter 1133 (epoch 1), train_loss = 3.204, time/batch = 0.022
Read data: 0.01490330696105957
iter 1134 (epoch 1), train_loss = 3.637, time/batch = 0.025
Read data: 6.842613220214844e-05
iter 1135 (epoch 1), train_loss = 3.439, time/batch = 0.025
Read data: 0.00015306472778320312
iter 1136 (epoch 1), train_loss = 3.505, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 1137 (epoch 1), train_loss = 3.505, time/batch = 0.024
Read data: 0.00017595291137695312
iter 1138 (epoch 1), train_loss = 3.814, time/batch = 0.026
Read data: 7.390975952148438e-05
iter 1139 (epoch 1), train_loss = 3.283, time/batch = 0.023
Read data: 0.00011968612670898438
iter 1140 (epoch 1), train_loss = 3.736, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 1141 (epoch 1), train_loss = 3.863, time/batch = 0.021
Read data: 0.0020101070404052734
iter 1142 (epoch 1), train_loss = 3.720, time/batch = 0.031
Read data: 7.009506225585938e-05
iter 1143 (epoch 1), train_loss = 3.163, time/batch = 0.022
Read data: 0.00014853477478027344
iter 1144 (epoch 1), train_loss = 3.532, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 1145 (epoch 1), train_loss = 3.431, time/batch = 0.023
Read data: 0.00015592575073242188
iter 1146 (epoch 1), train_loss = 3.826, time/batch = 0.025
Read data: 0.00014448165893554688
iter 1147 (epoch 1), train_loss = 3.868, time/batch = 0.020
Read data: 9.655952453613281e-05
iter 1148 (epoch 1), train_loss = 3.044, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 1149 (epoch 1), train_loss = 3.653, time/batch = 0.020
Read data: 0.008423805236816406
iter 1150 (epoch 1), train_loss = 3.334, time/batch = 0.019
Read data: 7.677078247070312e-05
iter 1151 (epoch 1), train_loss = 3.260, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 1152 (epoch 1), train_loss = 3.799, time/batch = 0.017
Read data: 0.00012254714965820312
iter 1153 (epoch 1), train_loss = 3.935, time/batch = 0.023
Read data: 0.014517068862915039
iter 1154 (epoch 1), train_loss = 3.492, time/batch = 0.024
Read data: 0.00010395050048828125
iter 1155 (epoch 1), train_loss = 3.534, time/batch = 0.021
Read data: 8.845329284667969e-05
iter 1156 (epoch 1), train_loss = 3.858, time/batch = 0.024
Read data: 0.00010395050048828125
iter 1157 (epoch 1), train_loss = 3.663, time/batch = 0.021
Read data: 0.006292819976806641
iter 1158 (epoch 1), train_loss = 3.805, time/batch = 0.024
Read data: 0.00010824203491210938
iter 1159 (epoch 1), train_loss = 3.630, time/batch = 0.026
Read data: 9.417533874511719e-05
iter 1160 (epoch 1), train_loss = 3.541, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 1161 (epoch 1), train_loss = 3.964, time/batch = 0.021
Read data: 9.369850158691406e-05
iter 1162 (epoch 1), train_loss = 3.444, time/batch = 0.022
Read data: 6.794929504394531e-05
iter 1163 (epoch 1), train_loss = 3.786, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 1164 (epoch 1), train_loss = 3.457, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 1165 (epoch 1), train_loss = 3.500, time/batch = 0.031
Read data: 0.0001575946807861328
iter 1166 (epoch 1), train_loss = 3.156, time/batch = 0.022
Read data: 0.00014090538024902344
iter 1167 (epoch 1), train_loss = 3.729, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 1168 (epoch 1), train_loss = 3.690, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 1169 (epoch 1), train_loss = 3.755, time/batch = 0.024
Read data: 0.00015401840209960938
iter 1170 (epoch 1), train_loss = 3.344, time/batch = 0.019
Read data: 7.939338684082031e-05
iter 1171 (epoch 1), train_loss = 3.554, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 1172 (epoch 1), train_loss = 3.702, time/batch = 0.023
Read data: 9.918212890625e-05
iter 1173 (epoch 1), train_loss = 3.320, time/batch = 0.020
Read data: 0.010800600051879883
iter 1174 (epoch 1), train_loss = 3.709, time/batch = 0.023
Read data: 7.200241088867188e-05
iter 1175 (epoch 1), train_loss = 3.046, time/batch = 0.020
Read data: 0.00010657310485839844
iter 1176 (epoch 1), train_loss = 3.362, time/batch = 0.023
Read data: 0.00010633468627929688
iter 1177 (epoch 1), train_loss = 3.690, time/batch = 0.029
Read data: 0.005484819412231445
iter 1178 (epoch 1), train_loss = 3.665, time/batch = 0.023
Read data: 0.0001087188720703125
iter 1179 (epoch 1), train_loss = 3.544, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 1180 (epoch 1), train_loss = 3.892, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 1181 (epoch 1), train_loss = 3.722, time/batch = 0.020
Read data: 0.006952762603759766
iter 1182 (epoch 1), train_loss = 3.387, time/batch = 0.020
Read data: 8.893013000488281e-05
iter 1183 (epoch 1), train_loss = 3.659, time/batch = 0.019
Read data: 0.00012969970703125
iter 1184 (epoch 1), train_loss = 3.621, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 1185 (epoch 1), train_loss = 3.271, time/batch = 0.022
Read data: 0.01596808433532715
iter 1186 (epoch 1), train_loss = 3.290, time/batch = 0.021
Read data: 7.62939453125e-05
iter 1187 (epoch 1), train_loss = 3.433, time/batch = 0.018
Read data: 0.0001418590545654297
iter 1188 (epoch 1), train_loss = 3.547, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 1189 (epoch 1), train_loss = 3.780, time/batch = 0.022
Read data: 0.020214080810546875
iter 1190 (epoch 1), train_loss = 3.749, time/batch = 0.022
Read data: 6.866455078125e-05
iter 1191 (epoch 1), train_loss = 3.705, time/batch = 0.026
Read data: 0.0009524822235107422
iter 1192 (epoch 1), train_loss = 3.347, time/batch = 0.020
Read data: 8.940696716308594e-05
iter 1193 (epoch 1), train_loss = 3.224, time/batch = 0.019
Read data: 0.012061595916748047
iter 1194 (epoch 1), train_loss = 3.551, time/batch = 0.020
Read data: 7.581710815429688e-05
iter 1195 (epoch 1), train_loss = 3.554, time/batch = 0.018
Read data: 8.225440979003906e-05
iter 1196 (epoch 1), train_loss = 3.201, time/batch = 0.024
Read data: 0.00015664100646972656
iter 1197 (epoch 1), train_loss = 3.574, time/batch = 0.020
Read data: 0.021426677703857422
iter 1198 (epoch 1), train_loss = 3.584, time/batch = 0.023
Read data: 7.390975952148438e-05
iter 1199 (epoch 1), train_loss = 3.781, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 1200 (epoch 1), train_loss = 3.894, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 1201 (epoch 2), train_loss = 2.969, time/batch = 0.020
Read data: 0.002918243408203125
iter 1202 (epoch 2), train_loss = 3.673, time/batch = 0.027
Read data: 0.00010943412780761719
iter 1203 (epoch 2), train_loss = 3.122, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 1204 (epoch 2), train_loss = 3.439, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 1205 (epoch 2), train_loss = 3.483, time/batch = 0.024
Read data: 0.0032045841217041016
iter 1206 (epoch 2), train_loss = 3.573, time/batch = 0.030
Read data: 6.794929504394531e-05
iter 1207 (epoch 2), train_loss = 3.682, time/batch = 0.021
Read data: 0.00011658668518066406
iter 1208 (epoch 2), train_loss = 3.271, time/batch = 0.021
Read data: 8.225440979003906e-05
iter 1209 (epoch 2), train_loss = 3.567, time/batch = 0.020
Read data: 0.009494543075561523
iter 1210 (epoch 2), train_loss = 3.484, time/batch = 0.025
Read data: 6.508827209472656e-05
iter 1211 (epoch 2), train_loss = 3.064, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 1212 (epoch 2), train_loss = 3.538, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 1213 (epoch 2), train_loss = 3.372, time/batch = 0.020
Read data: 0.004114389419555664
iter 1214 (epoch 2), train_loss = 2.805, time/batch = 0.024
Read data: 6.771087646484375e-05
iter 1215 (epoch 2), train_loss = 3.475, time/batch = 0.021
Read data: 8.225440979003906e-05
iter 1216 (epoch 2), train_loss = 3.217, time/batch = 0.022
Read data: 9.655952453613281e-05
iter 1217 (epoch 2), train_loss = 3.322, time/batch = 0.021
Read data: 0.009447574615478516
iter 1218 (epoch 2), train_loss = 3.501, time/batch = 0.035
Read data: 0.00013113021850585938
iter 1219 (epoch 2), train_loss = 3.766, time/batch = 0.020
Read data: 8.368492126464844e-05
iter 1220 (epoch 2), train_loss = 3.279, time/batch = 0.021
Read data: 8.130073547363281e-05
iter 1221 (epoch 2), train_loss = 3.415, time/batch = 0.021
Read data: 0.011989593505859375
iter 1222 (epoch 2), train_loss = 3.388, time/batch = 0.029
Read data: 7.176399230957031e-05
iter 1223 (epoch 2), train_loss = 3.303, time/batch = 0.031
Read data: 0.00010037422180175781
iter 1224 (epoch 2), train_loss = 3.783, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 1225 (epoch 2), train_loss = 3.138, time/batch = 0.022
Read data: 0.00018715858459472656
iter 1226 (epoch 2), train_loss = 3.347, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 1227 (epoch 2), train_loss = 3.482, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 1228 (epoch 2), train_loss = 3.482, time/batch = 0.019
Read data: 8.559226989746094e-05
iter 1229 (epoch 2), train_loss = 3.548, time/batch = 0.021
Read data: 0.014492034912109375
iter 1230 (epoch 2), train_loss = 3.722, time/batch = 0.028
Read data: 7.081031799316406e-05
iter 1231 (epoch 2), train_loss = 3.656, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 1232 (epoch 2), train_loss = 3.266, time/batch = 0.019
Read data: 8.249282836914062e-05
iter 1233 (epoch 2), train_loss = 3.335, time/batch = 0.020
Read data: 0.012824773788452148
iter 1234 (epoch 2), train_loss = 3.690, time/batch = 0.024
Read data: 0.00010347366333007812
iter 1235 (epoch 2), train_loss = 3.319, time/batch = 0.023
Read data: 6.818771362304688e-05
iter 1236 (epoch 2), train_loss = 3.287, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 1237 (epoch 2), train_loss = 3.486, time/batch = 0.026
Read data: 0.0033111572265625
iter 1238 (epoch 2), train_loss = 3.770, time/batch = 0.028
Read data: 6.699562072753906e-05
iter 1239 (epoch 2), train_loss = 3.263, time/batch = 0.021
Read data: 6.961822509765625e-05
iter 1240 (epoch 2), train_loss = 3.563, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 1241 (epoch 2), train_loss = 3.525, time/batch = 0.025
Read data: 0.00019240379333496094
iter 1242 (epoch 2), train_loss = 3.043, time/batch = 0.027
Read data: 7.2479248046875e-05
iter 1243 (epoch 2), train_loss = 3.567, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 1244 (epoch 2), train_loss = 3.653, time/batch = 0.025
Read data: 0.00014543533325195312
iter 1245 (epoch 2), train_loss = 3.519, time/batch = 0.026
Read data: 0.000171661376953125
iter 1246 (epoch 2), train_loss = 3.623, time/batch = 0.020
Read data: 7.295608520507812e-05
iter 1247 (epoch 2), train_loss = 3.340, time/batch = 0.020
Read data: 8.416175842285156e-05
iter 1248 (epoch 2), train_loss = 3.579, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 1249 (epoch 2), train_loss = 3.896, time/batch = 0.021
Read data: 0.010983705520629883
iter 1250 (epoch 2), train_loss = 3.527, time/batch = 0.030
Read data: 6.914138793945312e-05
iter 1251 (epoch 2), train_loss = 3.700, time/batch = 0.025
Read data: 6.699562072753906e-05
iter 1252 (epoch 2), train_loss = 3.463, time/batch = 0.019
Read data: 0.00016164779663085938
iter 1253 (epoch 2), train_loss = 3.434, time/batch = 0.024
Read data: 0.0018393993377685547
iter 1254 (epoch 2), train_loss = 3.800, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 1255 (epoch 2), train_loss = 3.587, time/batch = 0.024
Read data: 6.67572021484375e-05
iter 1256 (epoch 2), train_loss = 3.090, time/batch = 0.021
Read data: 0.00013518333435058594
iter 1257 (epoch 2), train_loss = 3.504, time/batch = 0.033
Read data: 0.003052234649658203
iter 1258 (epoch 2), train_loss = 3.736, time/batch = 0.022
Read data: 0.00011110305786132812
iter 1259 (epoch 2), train_loss = 3.475, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 1260 (epoch 2), train_loss = 3.517, time/batch = 0.023
Read data: 7.486343383789062e-05
iter 1261 (epoch 2), train_loss = 3.584, time/batch = 0.035
Read data: 8.916854858398438e-05
iter 1262 (epoch 2), train_loss = 3.743, time/batch = 0.026
Read data: 6.580352783203125e-05
iter 1263 (epoch 2), train_loss = 3.156, time/batch = 0.019
Read data: 6.771087646484375e-05
iter 1264 (epoch 2), train_loss = 3.501, time/batch = 0.019
Read data: 7.772445678710938e-05
iter 1265 (epoch 2), train_loss = 3.054, time/batch = 0.023
Read data: 0.012892007827758789
iter 1266 (epoch 2), train_loss = 3.173, time/batch = 0.018
Read data: 6.008148193359375e-05
iter 1267 (epoch 2), train_loss = 3.850, time/batch = 0.023
Read data: 7.009506225585938e-05
iter 1268 (epoch 2), train_loss = 3.662, time/batch = 0.019
Read data: 7.319450378417969e-05
iter 1269 (epoch 2), train_loss = 3.165, time/batch = 0.021
Read data: 0.019227266311645508
iter 1270 (epoch 2), train_loss = 3.158, time/batch = 0.027
Read data: 6.175041198730469e-05
iter 1271 (epoch 2), train_loss = 3.329, time/batch = 0.019
Read data: 7.414817810058594e-05
iter 1272 (epoch 2), train_loss = 3.553, time/batch = 0.021
Read data: 0.00011491775512695312
iter 1273 (epoch 2), train_loss = 3.294, time/batch = 0.030
Read data: 0.0028715133666992188
iter 1274 (epoch 2), train_loss = 3.595, time/batch = 0.023
Read data: 0.00020360946655273438
iter 1275 (epoch 2), train_loss = 3.298, time/batch = 0.021
Read data: 7.367134094238281e-05
iter 1276 (epoch 2), train_loss = 3.778, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 1277 (epoch 2), train_loss = 3.156, time/batch = 0.024
Read data: 0.011419057846069336
iter 1278 (epoch 2), train_loss = 3.591, time/batch = 0.028
Read data: 6.461143493652344e-05
iter 1279 (epoch 2), train_loss = 3.647, time/batch = 0.021
Read data: 7.43865966796875e-05
iter 1280 (epoch 2), train_loss = 3.821, time/batch = 0.029
Read data: 0.0001227855682373047
iter 1281 (epoch 2), train_loss = 3.982, time/batch = 0.025
Read data: 9.655952453613281e-05
iter 1282 (epoch 2), train_loss = 3.592, time/batch = 0.019
Read data: 5.9604644775390625e-05
iter 1283 (epoch 2), train_loss = 3.287, time/batch = 0.027
Read data: 7.081031799316406e-05
iter 1284 (epoch 2), train_loss = 3.141, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 1285 (epoch 2), train_loss = 2.957, time/batch = 0.023
Read data: 0.0048329830169677734
iter 1286 (epoch 2), train_loss = 3.992, time/batch = 0.020
Read data: 5.817413330078125e-05
iter 1287 (epoch 2), train_loss = 3.472, time/batch = 0.026
Read data: 7.033348083496094e-05
iter 1288 (epoch 2), train_loss = 3.542, time/batch = 0.023
Read data: 0.00015592575073242188
iter 1289 (epoch 2), train_loss = 3.237, time/batch = 0.026
Read data: 0.004994392395019531
iter 1290 (epoch 2), train_loss = 3.469, time/batch = 0.023
Read data: 5.936622619628906e-05
iter 1291 (epoch 2), train_loss = 3.396, time/batch = 0.021
Read data: 6.866455078125e-05
iter 1292 (epoch 2), train_loss = 3.601, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 1293 (epoch 2), train_loss = 3.605, time/batch = 0.028
Read data: 0.0066127777099609375
iter 1294 (epoch 2), train_loss = 3.615, time/batch = 0.026
Read data: 6.723403930664062e-05
iter 1295 (epoch 2), train_loss = 3.360, time/batch = 0.021
Read data: 6.67572021484375e-05
iter 1296 (epoch 2), train_loss = 3.232, time/batch = 0.025
Read data: 6.866455078125e-05
iter 1297 (epoch 2), train_loss = 3.712, time/batch = 0.024
Read data: 0.006520509719848633
iter 1298 (epoch 2), train_loss = 3.287, time/batch = 0.020
Read data: 5.793571472167969e-05
iter 1299 (epoch 2), train_loss = 3.255, time/batch = 0.025
Read data: 6.771087646484375e-05
iter 1300 (epoch 2), train_loss = 3.725, time/batch = 0.020
Read data: 0.0002276897430419922
iter 1301 (epoch 2), train_loss = 3.608, time/batch = 0.022
Read data: 0.015419483184814453
iter 1302 (epoch 2), train_loss = 3.826, time/batch = 0.026
Read data: 6.365776062011719e-05
iter 1303 (epoch 2), train_loss = 3.530, time/batch = 0.021
Read data: 6.985664367675781e-05
iter 1304 (epoch 2), train_loss = 3.468, time/batch = 0.023
Read data: 7.033348083496094e-05
iter 1305 (epoch 2), train_loss = 3.373, time/batch = 0.022
Read data: 0.011237859725952148
iter 1306 (epoch 2), train_loss = 3.418, time/batch = 0.021
Read data: 5.841255187988281e-05
iter 1307 (epoch 2), train_loss = 3.506, time/batch = 0.028
Read data: 0.00010275840759277344
iter 1308 (epoch 2), train_loss = 3.764, time/batch = 0.019
Read data: 0.00010991096496582031
iter 1309 (epoch 2), train_loss = 3.562, time/batch = 0.023
Read data: 0.01325678825378418
iter 1310 (epoch 2), train_loss = 3.693, time/batch = 0.024
Read data: 0.000125885009765625
iter 1311 (epoch 2), train_loss = 3.718, time/batch = 0.023
Read data: 0.00012040138244628906
iter 1312 (epoch 2), train_loss = 3.762, time/batch = 0.027
Read data: 6.556510925292969e-05
iter 1313 (epoch 2), train_loss = 2.899, time/batch = 0.023
Read data: 0.0053174495697021484
iter 1314 (epoch 2), train_loss = 3.462, time/batch = 0.027
Read data: 0.00012826919555664062
iter 1315 (epoch 2), train_loss = 3.440, time/batch = 0.021
Read data: 0.0001304149627685547
iter 1316 (epoch 2), train_loss = 3.414, time/batch = 0.028
Read data: 6.341934204101562e-05
iter 1317 (epoch 2), train_loss = 3.314, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 1318 (epoch 2), train_loss = 3.516, time/batch = 0.024
Read data: 0.0001308917999267578
iter 1319 (epoch 2), train_loss = 3.086, time/batch = 0.019
Read data: 7.534027099609375e-05
iter 1320 (epoch 2), train_loss = 3.474, time/batch = 0.022
Read data: 7.176399230957031e-05
iter 1321 (epoch 2), train_loss = 3.468, time/batch = 0.023
Read data: 0.011584997177124023
iter 1322 (epoch 2), train_loss = 3.496, time/batch = 0.022
Read data: 5.698204040527344e-05
iter 1323 (epoch 2), train_loss = 3.440, time/batch = 0.025
Read data: 6.508827209472656e-05
iter 1324 (epoch 2), train_loss = 3.122, time/batch = 0.023
Read data: 6.961822509765625e-05
iter 1325 (epoch 2), train_loss = 3.274, time/batch = 0.021
Read data: 0.010274410247802734
iter 1326 (epoch 2), train_loss = 3.394, time/batch = 0.028
Read data: 6.818771362304688e-05
iter 1327 (epoch 2), train_loss = 3.414, time/batch = 0.026
Read data: 6.699562072753906e-05
iter 1328 (epoch 2), train_loss = 3.300, time/batch = 0.021
Read data: 6.389617919921875e-05
iter 1329 (epoch 2), train_loss = 3.149, time/batch = 0.018
Read data: 0.00735926628112793
iter 1330 (epoch 2), train_loss = 3.577, time/batch = 0.023
Read data: 5.745887756347656e-05
iter 1331 (epoch 2), train_loss = 3.266, time/batch = 0.021
Read data: 0.00015664100646972656
iter 1332 (epoch 2), train_loss = 3.634, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 1333 (epoch 2), train_loss = 3.532, time/batch = 0.027
Read data: 0.0032269954681396484
iter 1334 (epoch 2), train_loss = 3.972, time/batch = 0.030
Read data: 7.486343383789062e-05
iter 1335 (epoch 2), train_loss = 3.460, time/batch = 0.021
Read data: 0.00012159347534179688
iter 1336 (epoch 2), train_loss = 3.904, time/batch = 0.025
Read data: 6.29425048828125e-05
iter 1337 (epoch 2), train_loss = 3.738, time/batch = 0.028
Read data: 9.489059448242188e-05
iter 1338 (epoch 2), train_loss = 3.296, time/batch = 0.022
Read data: 5.507469177246094e-05
iter 1339 (epoch 2), train_loss = 3.404, time/batch = 0.028
Read data: 6.67572021484375e-05
iter 1340 (epoch 2), train_loss = 3.260, time/batch = 0.022
Read data: 0.00012373924255371094
iter 1341 (epoch 2), train_loss = 3.411, time/batch = 0.023
Read data: 0.004728078842163086
iter 1342 (epoch 2), train_loss = 3.384, time/batch = 0.025
Read data: 6.031990051269531e-05
iter 1343 (epoch 2), train_loss = 3.625, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 1344 (epoch 2), train_loss = 2.948, time/batch = 0.023
Read data: 0.00012302398681640625
iter 1345 (epoch 2), train_loss = 3.316, time/batch = 0.022
Read data: 0.003981590270996094
iter 1346 (epoch 2), train_loss = 3.241, time/batch = 0.024
Read data: 5.91278076171875e-05
iter 1347 (epoch 2), train_loss = 3.600, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 1348 (epoch 2), train_loss = 3.857, time/batch = 0.026
Read data: 6.413459777832031e-05
iter 1349 (epoch 2), train_loss = 2.835, time/batch = 0.021
Read data: 0.002307415008544922
iter 1350 (epoch 2), train_loss = 3.484, time/batch = 0.032
Read data: 6.67572021484375e-05
iter 1351 (epoch 2), train_loss = 3.104, time/batch = 0.026
Read data: 6.747245788574219e-05
iter 1352 (epoch 2), train_loss = 3.123, time/batch = 0.021
Read data: 6.556510925292969e-05
iter 1353 (epoch 2), train_loss = 3.843, time/batch = 0.021
Read data: 0.0016818046569824219
iter 1354 (epoch 2), train_loss = 3.516, time/batch = 0.019
Read data: 7.462501525878906e-05
iter 1355 (epoch 2), train_loss = 3.581, time/batch = 0.020
Read data: 6.818771362304688e-05
iter 1356 (epoch 2), train_loss = 3.194, time/batch = 0.023
Read data: 0.0001304149627685547
iter 1357 (epoch 2), train_loss = 3.012, time/batch = 0.023
Read data: 0.018171310424804688
iter 1358 (epoch 2), train_loss = 3.590, time/batch = 0.023
Read data: 5.9604644775390625e-05
iter 1359 (epoch 2), train_loss = 3.299, time/batch = 0.023
Read data: 0.00012826919555664062
iter 1360 (epoch 2), train_loss = 3.785, time/batch = 0.036
Read data: 0.00010657310485839844
iter 1361 (epoch 2), train_loss = 3.404, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 1362 (epoch 2), train_loss = 3.179, time/batch = 0.022
Read data: 6.604194641113281e-05
iter 1363 (epoch 2), train_loss = 3.298, time/batch = 0.023
Read data: 0.00012946128845214844
iter 1364 (epoch 2), train_loss = 4.261, time/batch = 0.023
Read data: 7.414817810058594e-05
iter 1365 (epoch 2), train_loss = 3.529, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 1366 (epoch 2), train_loss = 3.253, time/batch = 0.026
Read data: 5.7697296142578125e-05
iter 1367 (epoch 2), train_loss = 3.278, time/batch = 0.023
Read data: 7.295608520507812e-05
iter 1368 (epoch 2), train_loss = 3.562, time/batch = 0.028
Read data: 0.0001239776611328125
iter 1369 (epoch 2), train_loss = 3.801, time/batch = 0.022
Read data: 9.846687316894531e-05
iter 1370 (epoch 2), train_loss = 3.565, time/batch = 0.018
Read data: 5.340576171875e-05
iter 1371 (epoch 2), train_loss = 3.591, time/batch = 0.029
Read data: 0.00012135505676269531
iter 1372 (epoch 2), train_loss = 3.670, time/batch = 0.023
Read data: 0.00011420249938964844
iter 1373 (epoch 2), train_loss = 3.549, time/batch = 0.018
Read data: 0.011799097061157227
iter 1374 (epoch 2), train_loss = 3.457, time/batch = 0.019
Read data: 5.173683166503906e-05
iter 1375 (epoch 2), train_loss = 3.359, time/batch = 0.023
Read data: 7.081031799316406e-05
iter 1376 (epoch 2), train_loss = 4.095, time/batch = 0.034
Read data: 0.00017547607421875
iter 1377 (epoch 2), train_loss = 4.140, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 1378 (epoch 2), train_loss = 3.443, time/batch = 0.022
Read data: 5.602836608886719e-05
iter 1379 (epoch 2), train_loss = 3.474, time/batch = 0.023
Read data: 0.00012731552124023438
iter 1380 (epoch 2), train_loss = 3.190, time/batch = 0.025
Read data: 7.081031799316406e-05
iter 1381 (epoch 2), train_loss = 3.852, time/batch = 0.031
Read data: 0.0030889511108398438
iter 1382 (epoch 2), train_loss = 3.293, time/batch = 0.019
Read data: 5.53131103515625e-05
iter 1383 (epoch 2), train_loss = 3.459, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 1384 (epoch 2), train_loss = 3.166, time/batch = 0.025
Read data: 7.104873657226562e-05
iter 1385 (epoch 2), train_loss = 3.549, time/batch = 0.023
Read data: 0.011854887008666992
iter 1386 (epoch 2), train_loss = 3.166, time/batch = 0.019
Read data: 5.650520324707031e-05
iter 1387 (epoch 2), train_loss = 3.662, time/batch = 0.021
Read data: 0.0001354217529296875
iter 1388 (epoch 2), train_loss = 3.366, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 1389 (epoch 2), train_loss = 3.755, time/batch = 0.027
Read data: 0.01032257080078125
iter 1390 (epoch 2), train_loss = 3.397, time/batch = 0.018
Read data: 5.459785461425781e-05
iter 1391 (epoch 2), train_loss = 3.302, time/batch = 0.027
Read data: 0.00012135505676269531
iter 1392 (epoch 2), train_loss = 3.411, time/batch = 0.024
Read data: 0.00013303756713867188
iter 1393 (epoch 2), train_loss = 3.764, time/batch = 0.022
Read data: 0.011399507522583008
iter 1394 (epoch 2), train_loss = 3.702, time/batch = 0.025
Read data: 5.6743621826171875e-05
iter 1395 (epoch 2), train_loss = 3.585, time/batch = 0.026
Read data: 6.890296936035156e-05
iter 1396 (epoch 2), train_loss = 3.493, time/batch = 0.021
Read data: 6.437301635742188e-05
iter 1397 (epoch 2), train_loss = 3.435, time/batch = 0.020
Read data: 0.00816202163696289
iter 1398 (epoch 2), train_loss = 3.294, time/batch = 0.032
Read data: 6.270408630371094e-05
iter 1399 (epoch 2), train_loss = 3.416, time/batch = 0.021
Read data: 0.0017039775848388672
iter 1400 (epoch 2), train_loss = 3.411, time/batch = 0.021
Read data: 0.0001251697540283203
iter 1401 (epoch 2), train_loss = 3.377, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 1402 (epoch 2), train_loss = 3.761, time/batch = 0.031
Read data: 5.507469177246094e-05
iter 1403 (epoch 2), train_loss = 3.334, time/batch = 0.024
Read data: 0.00012445449829101562
iter 1404 (epoch 2), train_loss = 3.451, time/batch = 0.022
Read data: 0.00012683868408203125
iter 1405 (epoch 2), train_loss = 3.327, time/batch = 0.019
Read data: 0.004378080368041992
iter 1406 (epoch 2), train_loss = 3.515, time/batch = 0.024
Read data: 5.650520324707031e-05
iter 1407 (epoch 2), train_loss = 2.914, time/batch = 0.026
Read data: 0.00012683868408203125
iter 1408 (epoch 2), train_loss = 3.443, time/batch = 0.029
Read data: 6.699562072753906e-05
iter 1409 (epoch 2), train_loss = 3.253, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 1410 (epoch 2), train_loss = 3.206, time/batch = 0.023
Read data: 6.532669067382812e-05
iter 1411 (epoch 2), train_loss = 3.490, time/batch = 0.022
Read data: 7.05718994140625e-05
iter 1412 (epoch 2), train_loss = 3.327, time/batch = 0.021
Read data: 0.00013303756713867188
iter 1413 (epoch 2), train_loss = 3.634, time/batch = 0.032
Read data: 9.489059448242188e-05
iter 1414 (epoch 2), train_loss = 3.493, time/batch = 0.023
Read data: 5.936622619628906e-05
iter 1415 (epoch 2), train_loss = 3.800, time/batch = 0.029
Read data: 7.033348083496094e-05
iter 1416 (epoch 2), train_loss = 4.097, time/batch = 0.028
Read data: 0.00015044212341308594
iter 1417 (epoch 2), train_loss = 3.555, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 1418 (epoch 2), train_loss = 3.536, time/batch = 0.023
Read data: 5.793571472167969e-05
iter 1419 (epoch 2), train_loss = 3.499, time/batch = 0.035
Read data: 6.842613220214844e-05
iter 1420 (epoch 2), train_loss = 2.998, time/batch = 0.023
Read data: 0.00011801719665527344
iter 1421 (epoch 2), train_loss = 3.748, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 1422 (epoch 2), train_loss = 3.607, time/batch = 0.025
Read data: 6.604194641113281e-05
iter 1423 (epoch 2), train_loss = 3.170, time/batch = 0.022
Read data: 7.104873657226562e-05
iter 1424 (epoch 2), train_loss = 3.656, time/batch = 0.026
Read data: 0.00024318695068359375
iter 1425 (epoch 2), train_loss = 3.746, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 1426 (epoch 2), train_loss = 3.331, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 1427 (epoch 2), train_loss = 3.793, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 1428 (epoch 2), train_loss = 3.621, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 1429 (epoch 2), train_loss = 3.407, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 1430 (epoch 2), train_loss = 3.937, time/batch = 0.025
Read data: 7.390975952148438e-05
iter 1431 (epoch 2), train_loss = 3.295, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 1432 (epoch 2), train_loss = 3.565, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 1433 (epoch 2), train_loss = 2.870, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 1434 (epoch 2), train_loss = 3.622, time/batch = 0.025
Read data: 6.604194641113281e-05
iter 1435 (epoch 2), train_loss = 3.369, time/batch = 0.027
Read data: 0.00010085105895996094
iter 1436 (epoch 2), train_loss = 3.485, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 1437 (epoch 2), train_loss = 3.291, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 1438 (epoch 2), train_loss = 3.485, time/batch = 0.026
Read data: 6.890296936035156e-05
iter 1439 (epoch 2), train_loss = 3.636, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 1440 (epoch 2), train_loss = 3.078, time/batch = 0.023
Read data: 0.00010991096496582031
iter 1441 (epoch 2), train_loss = 3.015, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 1442 (epoch 2), train_loss = 3.506, time/batch = 0.030
Read data: 6.532669067382812e-05
iter 1443 (epoch 2), train_loss = 3.609, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 1444 (epoch 2), train_loss = 3.239, time/batch = 0.028
Read data: 0.00011754035949707031
iter 1445 (epoch 2), train_loss = 3.781, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 1446 (epoch 2), train_loss = 3.518, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 1447 (epoch 2), train_loss = 3.177, time/batch = 0.023
Read data: 8.392333984375e-05
iter 1448 (epoch 2), train_loss = 3.978, time/batch = 0.024
Read data: 0.0001285076141357422
iter 1449 (epoch 2), train_loss = 3.016, time/batch = 0.025
Read data: 0.0002288818359375
iter 1450 (epoch 2), train_loss = 3.760, time/batch = 0.026
Read data: 7.128715515136719e-05
iter 1451 (epoch 2), train_loss = 3.559, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 1452 (epoch 2), train_loss = 3.747, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 1453 (epoch 2), train_loss = 3.682, time/batch = 0.025
Read data: 0.00014328956604003906
iter 1454 (epoch 2), train_loss = 2.958, time/batch = 0.027
Read data: 0.00010371208190917969
iter 1455 (epoch 2), train_loss = 3.046, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 1456 (epoch 2), train_loss = 3.203, time/batch = 0.024
Read data: 7.367134094238281e-05
iter 1457 (epoch 2), train_loss = 3.470, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 1458 (epoch 2), train_loss = 3.069, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 1459 (epoch 2), train_loss = 3.742, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 1460 (epoch 2), train_loss = 4.013, time/batch = 0.021
Read data: 7.724761962890625e-05
iter 1461 (epoch 2), train_loss = 3.288, time/batch = 0.020
Read data: 0.0001304149627685547
iter 1462 (epoch 2), train_loss = 3.408, time/batch = 0.022
Read data: 7.05718994140625e-05
iter 1463 (epoch 2), train_loss = 3.287, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 1464 (epoch 2), train_loss = 3.622, time/batch = 0.031
Read data: 0.00017023086547851562
iter 1465 (epoch 2), train_loss = 3.507, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 1466 (epoch 2), train_loss = 3.492, time/batch = 0.025
Read data: 6.914138793945312e-05
iter 1467 (epoch 2), train_loss = 3.347, time/batch = 0.023
Read data: 0.00015211105346679688
iter 1468 (epoch 2), train_loss = 3.172, time/batch = 0.022
Read data: 0.00015234947204589844
iter 1469 (epoch 2), train_loss = 3.514, time/batch = 0.021
Read data: 0.00012254714965820312
iter 1470 (epoch 2), train_loss = 3.420, time/batch = 0.026
Read data: 6.890296936035156e-05
iter 1471 (epoch 2), train_loss = 3.184, time/batch = 0.020
Read data: 9.202957153320312e-05
iter 1472 (epoch 2), train_loss = 3.230, time/batch = 0.028
Read data: 0.00012254714965820312
iter 1473 (epoch 2), train_loss = 3.483, time/batch = 0.021
Read data: 0.00017261505126953125
iter 1474 (epoch 2), train_loss = 3.426, time/batch = 0.021
Read data: 6.413459777832031e-05
iter 1475 (epoch 2), train_loss = 3.313, time/batch = 0.018
Read data: 0.0001418590545654297
iter 1476 (epoch 2), train_loss = 3.139, time/batch = 0.021
Read data: 0.00012135505676269531
iter 1477 (epoch 2), train_loss = 3.630, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 1478 (epoch 2), train_loss = 3.404, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 1479 (epoch 2), train_loss = 3.150, time/batch = 0.028
Read data: 9.655952453613281e-05
iter 1480 (epoch 2), train_loss = 3.379, time/batch = 0.022
Read data: 0.00014066696166992188
iter 1481 (epoch 2), train_loss = 3.496, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 1482 (epoch 2), train_loss = 3.942, time/batch = 0.031
Read data: 6.580352783203125e-05
iter 1483 (epoch 2), train_loss = 3.393, time/batch = 0.021
Read data: 8.96453857421875e-05
iter 1484 (epoch 2), train_loss = 3.209, time/batch = 0.024
Read data: 0.00013685226440429688
iter 1485 (epoch 2), train_loss = 3.151, time/batch = 0.020
Read data: 8.845329284667969e-05
iter 1486 (epoch 2), train_loss = 3.867, time/batch = 0.027
Read data: 0.0001404285430908203
iter 1487 (epoch 2), train_loss = 3.023, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 1488 (epoch 2), train_loss = 3.205, time/batch = 0.025
Read data: 0.0001468658447265625
iter 1489 (epoch 2), train_loss = 3.812, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 1490 (epoch 2), train_loss = 4.252, time/batch = 0.031
Read data: 7.128715515136719e-05
iter 1491 (epoch 2), train_loss = 3.198, time/batch = 0.019
Read data: 8.940696716308594e-05
iter 1492 (epoch 2), train_loss = 3.039, time/batch = 0.025
Read data: 0.00014090538024902344
iter 1493 (epoch 2), train_loss = 3.095, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 1494 (epoch 2), train_loss = 3.170, time/batch = 0.018
Read data: 0.00010704994201660156
iter 1495 (epoch 2), train_loss = 3.537, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 1496 (epoch 2), train_loss = 3.381, time/batch = 0.020
Read data: 6.580352783203125e-05
iter 1497 (epoch 2), train_loss = 3.901, time/batch = 0.031
Read data: 8.96453857421875e-05
iter 1498 (epoch 2), train_loss = 3.321, time/batch = 0.036
Read data: 8.893013000488281e-05
iter 1499 (epoch 2), train_loss = 3.585, time/batch = 0.019
Read data: 8.654594421386719e-05
iter 1500 (epoch 2), train_loss = 3.372, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 1501 (epoch 2), train_loss = 3.057, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 1502 (epoch 2), train_loss = 3.286, time/batch = 0.035
Read data: 6.818771362304688e-05
iter 1503 (epoch 2), train_loss = 3.199, time/batch = 0.024
Read data: 0.00013756752014160156
iter 1504 (epoch 2), train_loss = 3.426, time/batch = 0.031
Read data: 0.0001220703125
iter 1505 (epoch 2), train_loss = 3.256, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 1506 (epoch 2), train_loss = 3.691, time/batch = 0.026
Read data: 6.794929504394531e-05
iter 1507 (epoch 2), train_loss = 3.275, time/batch = 0.019
Read data: 8.821487426757812e-05
iter 1508 (epoch 2), train_loss = 3.622, time/batch = 0.026
Read data: 0.0001239776611328125
iter 1509 (epoch 2), train_loss = 3.747, time/batch = 0.018
Read data: 9.1552734375e-05
iter 1510 (epoch 2), train_loss = 3.596, time/batch = 0.024
Read data: 7.62939453125e-05
iter 1511 (epoch 2), train_loss = 2.828, time/batch = 0.019
Read data: 8.821487426757812e-05
iter 1512 (epoch 2), train_loss = 3.304, time/batch = 0.019
Read data: 5.817413330078125e-05
iter 1513 (epoch 2), train_loss = 2.766, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 1514 (epoch 2), train_loss = 3.481, time/batch = 0.021
Read data: 9.775161743164062e-05
iter 1515 (epoch 2), train_loss = 3.186, time/batch = 0.027
Read data: 0.00015664100646972656
iter 1516 (epoch 2), train_loss = 3.194, time/batch = 0.024
Read data: 0.00013446807861328125
iter 1517 (epoch 2), train_loss = 3.347, time/batch = 0.023
Read data: 0.0035228729248046875
iter 1518 (epoch 2), train_loss = 3.412, time/batch = 0.020
Read data: 0.00011467933654785156
iter 1519 (epoch 2), train_loss = 3.408, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 1520 (epoch 2), train_loss = 3.580, time/batch = 0.018
Read data: 0.00010585784912109375
iter 1521 (epoch 2), train_loss = 3.416, time/batch = 0.017
Read data: 0.017166614532470703
iter 1522 (epoch 2), train_loss = 3.478, time/batch = 0.026
Read data: 0.00010967254638671875
iter 1523 (epoch 2), train_loss = 3.493, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 1524 (epoch 2), train_loss = 3.540, time/batch = 0.024
Read data: 0.00013399124145507812
iter 1525 (epoch 2), train_loss = 3.619, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 1526 (epoch 2), train_loss = 3.502, time/batch = 0.019
Read data: 7.891654968261719e-05
iter 1527 (epoch 2), train_loss = 3.878, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 1528 (epoch 2), train_loss = 3.451, time/batch = 0.021
Read data: 0.00011038780212402344
iter 1529 (epoch 2), train_loss = 3.571, time/batch = 0.027
Read data: 0.0034122467041015625
iter 1530 (epoch 2), train_loss = 3.440, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 1531 (epoch 2), train_loss = 3.779, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 1532 (epoch 2), train_loss = 3.208, time/batch = 0.018
Read data: 0.00011014938354492188
iter 1533 (epoch 2), train_loss = 3.346, time/batch = 0.029
Read data: 0.008348226547241211
iter 1534 (epoch 2), train_loss = 3.544, time/batch = 0.026
Read data: 7.62939453125e-05
iter 1535 (epoch 2), train_loss = 3.168, time/batch = 0.018
Read data: 8.988380432128906e-05
iter 1536 (epoch 2), train_loss = 3.605, time/batch = 0.019
Read data: 5.4836273193359375e-05
iter 1537 (epoch 2), train_loss = 3.518, time/batch = 0.028
Read data: 0.00990748405456543
iter 1538 (epoch 2), train_loss = 3.196, time/batch = 0.024
Read data: 6.723403930664062e-05
iter 1539 (epoch 2), train_loss = 3.707, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 1540 (epoch 2), train_loss = 3.221, time/batch = 0.020
Read data: 0.000141143798828125
iter 1541 (epoch 2), train_loss = 3.381, time/batch = 0.022
Read data: 0.006202220916748047
iter 1542 (epoch 2), train_loss = 3.091, time/batch = 0.027
Read data: 6.961822509765625e-05
iter 1543 (epoch 2), train_loss = 3.395, time/batch = 0.019
Read data: 8.702278137207031e-05
iter 1544 (epoch 2), train_loss = 3.421, time/batch = 0.021
Read data: 0.00015115737915039062
iter 1545 (epoch 2), train_loss = 3.008, time/batch = 0.021
Read data: 0.008697509765625
iter 1546 (epoch 2), train_loss = 3.361, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 1547 (epoch 2), train_loss = 3.289, time/batch = 0.019
Read data: 9.608268737792969e-05
iter 1548 (epoch 2), train_loss = 3.538, time/batch = 0.022
Read data: 0.00011968612670898438
iter 1549 (epoch 2), train_loss = 3.653, time/batch = 0.026
Read data: 0.00715184211730957
iter 1550 (epoch 2), train_loss = 3.546, time/batch = 0.025
Read data: 7.009506225585938e-05
iter 1551 (epoch 2), train_loss = 3.280, time/batch = 0.022
Read data: 9.822845458984375e-05
iter 1552 (epoch 2), train_loss = 3.155, time/batch = 0.020
Read data: 0.00011181831359863281
iter 1553 (epoch 2), train_loss = 3.291, time/batch = 0.025
Read data: 0.008038043975830078
iter 1554 (epoch 2), train_loss = 2.993, time/batch = 0.022
Read data: 7.128715515136719e-05
iter 1555 (epoch 2), train_loss = 3.276, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 1556 (epoch 2), train_loss = 3.252, time/batch = 0.021
Read data: 6.67572021484375e-05
iter 1557 (epoch 2), train_loss = 3.618, time/batch = 0.022
Read data: 0.012664794921875
iter 1558 (epoch 2), train_loss = 3.582, time/batch = 0.026
Read data: 6.985664367675781e-05
iter 1559 (epoch 2), train_loss = 3.310, time/batch = 0.018
Read data: 8.869171142578125e-05
iter 1560 (epoch 2), train_loss = 3.617, time/batch = 0.021
Read data: 0.00011014938354492188
iter 1561 (epoch 2), train_loss = 3.543, time/batch = 0.032
Read data: 0.000186920166015625
iter 1562 (epoch 2), train_loss = 3.485, time/batch = 0.031
Read data: 7.104873657226562e-05
iter 1563 (epoch 2), train_loss = 3.160, time/batch = 0.018
Read data: 8.797645568847656e-05
iter 1564 (epoch 2), train_loss = 3.672, time/batch = 0.024
Read data: 0.0001285076141357422
iter 1565 (epoch 2), train_loss = 4.071, time/batch = 0.020
Read data: 0.0034546852111816406
iter 1566 (epoch 2), train_loss = 3.072, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 1567 (epoch 2), train_loss = 3.635, time/batch = 0.019
Read data: 8.678436279296875e-05
iter 1568 (epoch 2), train_loss = 3.507, time/batch = 0.020
Read data: 6.771087646484375e-05
iter 1569 (epoch 2), train_loss = 3.255, time/batch = 0.022
Read data: 0.012286663055419922
iter 1570 (epoch 2), train_loss = 3.163, time/batch = 0.028
Read data: 6.651878356933594e-05
iter 1571 (epoch 2), train_loss = 3.760, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 1572 (epoch 2), train_loss = 3.873, time/batch = 0.025
Read data: 0.0001232624053955078
iter 1573 (epoch 2), train_loss = 3.389, time/batch = 0.027
Read data: 0.00017714500427246094
iter 1574 (epoch 2), train_loss = 3.349, time/batch = 0.021
Read data: 0.0001850128173828125
iter 1575 (epoch 2), train_loss = 3.117, time/batch = 0.019
Read data: 9.655952453613281e-05
iter 1576 (epoch 2), train_loss = 3.153, time/batch = 0.021
Read data: 0.00011515617370605469
iter 1577 (epoch 2), train_loss = 3.445, time/batch = 0.023
Read data: 0.011125802993774414
iter 1578 (epoch 2), train_loss = 3.361, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 1579 (epoch 2), train_loss = 3.243, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 1580 (epoch 2), train_loss = 3.245, time/batch = 0.020
Read data: 0.0001418590545654297
iter 1581 (epoch 2), train_loss = 3.566, time/batch = 0.021
Read data: 0.005839109420776367
iter 1582 (epoch 2), train_loss = 3.222, time/batch = 0.021
Read data: 9.369850158691406e-05
iter 1583 (epoch 2), train_loss = 3.678, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 1584 (epoch 2), train_loss = 3.441, time/batch = 0.021
Read data: 7.009506225585938e-05
iter 1585 (epoch 2), train_loss = 3.726, time/batch = 0.029
Read data: 0.0029358863830566406
iter 1586 (epoch 2), train_loss = 3.672, time/batch = 0.022
Read data: 0.00010561943054199219
iter 1587 (epoch 2), train_loss = 3.320, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 1588 (epoch 2), train_loss = 3.720, time/batch = 0.023
Read data: 0.00011491775512695312
iter 1589 (epoch 2), train_loss = 3.393, time/batch = 0.024
Read data: 0.0031816959381103516
iter 1590 (epoch 2), train_loss = 3.317, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 1591 (epoch 2), train_loss = 3.360, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 1592 (epoch 2), train_loss = 3.269, time/batch = 0.025
Read data: 0.0001544952392578125
iter 1593 (epoch 2), train_loss = 3.301, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 1594 (epoch 2), train_loss = 3.203, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 1595 (epoch 2), train_loss = 3.283, time/batch = 0.028
Read data: 8.392333984375e-05
iter 1596 (epoch 2), train_loss = 3.463, time/batch = 0.019
Read data: 0.00014209747314453125
iter 1597 (epoch 2), train_loss = 3.201, time/batch = 0.022
Read data: 0.004828929901123047
iter 1598 (epoch 2), train_loss = 3.649, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 1599 (epoch 2), train_loss = 3.573, time/batch = 0.019
Read data: 0.00017762184143066406
iter 1600 (epoch 2), train_loss = 3.727, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 1601 (epoch 2), train_loss = 3.541, time/batch = 0.024
Read data: 0.009735107421875
iter 1602 (epoch 2), train_loss = 3.422, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 1603 (epoch 2), train_loss = 3.214, time/batch = 0.018
Read data: 8.20159912109375e-05
iter 1604 (epoch 2), train_loss = 3.140, time/batch = 0.025
Read data: 0.00014090538024902344
iter 1605 (epoch 2), train_loss = 3.560, time/batch = 0.022
Read data: 0.007378101348876953
iter 1606 (epoch 2), train_loss = 3.714, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 1607 (epoch 2), train_loss = 3.597, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 1608 (epoch 2), train_loss = 3.482, time/batch = 0.025
Read data: 0.0001633167266845703
iter 1609 (epoch 2), train_loss = 3.510, time/batch = 0.024
Read data: 0.003945350646972656
iter 1610 (epoch 2), train_loss = 3.517, time/batch = 0.030
Read data: 7.05718994140625e-05
iter 1611 (epoch 2), train_loss = 3.388, time/batch = 0.023
Read data: 0.00012302398681640625
iter 1612 (epoch 2), train_loss = 3.205, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 1613 (epoch 2), train_loss = 3.475, time/batch = 0.030
Read data: 0.00014138221740722656
iter 1614 (epoch 2), train_loss = 3.191, time/batch = 0.027
Read data: 7.271766662597656e-05
iter 1615 (epoch 2), train_loss = 3.342, time/batch = 0.016
Read data: 8.296966552734375e-05
iter 1616 (epoch 2), train_loss = 3.246, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 1617 (epoch 2), train_loss = 3.732, time/batch = 0.020
Read data: 0.012875080108642578
iter 1618 (epoch 2), train_loss = 3.332, time/batch = 0.027
Read data: 6.747245788574219e-05
iter 1619 (epoch 2), train_loss = 3.441, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 1620 (epoch 2), train_loss = 3.387, time/batch = 0.023
Read data: 0.00013685226440429688
iter 1621 (epoch 2), train_loss = 4.027, time/batch = 0.020
Read data: 0.005332231521606445
iter 1622 (epoch 2), train_loss = 3.483, time/batch = 0.024
Read data: 7.176399230957031e-05
iter 1623 (epoch 2), train_loss = 3.262, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 1624 (epoch 2), train_loss = 3.010, time/batch = 0.023
Read data: 0.00021958351135253906
iter 1625 (epoch 2), train_loss = 2.748, time/batch = 0.020
Read data: 0.011770248413085938
iter 1626 (epoch 2), train_loss = 3.519, time/batch = 0.027
Read data: 6.937980651855469e-05
iter 1627 (epoch 2), train_loss = 2.833, time/batch = 0.022
Read data: 9.894371032714844e-05
iter 1628 (epoch 2), train_loss = 3.325, time/batch = 0.024
Read data: 0.0001678466796875
iter 1629 (epoch 2), train_loss = 3.658, time/batch = 0.026
Read data: 0.0035848617553710938
iter 1630 (epoch 2), train_loss = 3.254, time/batch = 0.023
Read data: 7.176399230957031e-05
iter 1631 (epoch 2), train_loss = 3.355, time/batch = 0.024
Read data: 7.033348083496094e-05
iter 1632 (epoch 2), train_loss = 3.273, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 1633 (epoch 2), train_loss = 3.062, time/batch = 0.026
Read data: 0.0029478073120117188
iter 1634 (epoch 2), train_loss = 3.009, time/batch = 0.021
Read data: 7.176399230957031e-05
iter 1635 (epoch 2), train_loss = 3.111, time/batch = 0.019
Read data: 8.606910705566406e-05
iter 1636 (epoch 2), train_loss = 3.339, time/batch = 0.018
Read data: 0.00014281272888183594
iter 1637 (epoch 2), train_loss = 3.934, time/batch = 0.030
Read data: 0.008519649505615234
iter 1638 (epoch 2), train_loss = 3.548, time/batch = 0.025
Read data: 7.104873657226562e-05
iter 1639 (epoch 2), train_loss = 3.099, time/batch = 0.022
Read data: 7.319450378417969e-05
iter 1640 (epoch 2), train_loss = 3.826, time/batch = 0.027
Read data: 0.00013399124145507812
iter 1641 (epoch 2), train_loss = 3.454, time/batch = 0.026
Read data: 0.0021522045135498047
iter 1642 (epoch 2), train_loss = 3.458, time/batch = 0.023
Read data: 6.771087646484375e-05
iter 1643 (epoch 2), train_loss = 2.908, time/batch = 0.027
Read data: 6.961822509765625e-05
iter 1644 (epoch 2), train_loss = 3.639, time/batch = 0.019
Read data: 0.000164031982421875
iter 1645 (epoch 2), train_loss = 3.377, time/batch = 0.029
Read data: 9.441375732421875e-05
iter 1646 (epoch 2), train_loss = 2.866, time/batch = 0.021
Read data: 6.890296936035156e-05
iter 1647 (epoch 2), train_loss = 3.671, time/batch = 0.024
Read data: 6.699562072753906e-05
iter 1648 (epoch 2), train_loss = 3.404, time/batch = 0.027
Read data: 0.000171661376953125
iter 1649 (epoch 2), train_loss = 3.498, time/batch = 0.023
Read data: 0.009485244750976562
iter 1650 (epoch 2), train_loss = 3.312, time/batch = 0.020
Read data: 5.555152893066406e-05
iter 1651 (epoch 2), train_loss = 3.345, time/batch = 0.026
Read data: 7.009506225585938e-05
iter 1652 (epoch 2), train_loss = 3.350, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 1653 (epoch 2), train_loss = 3.507, time/batch = 0.028
Read data: 0.003414154052734375
iter 1654 (epoch 2), train_loss = 3.623, time/batch = 0.024
Read data: 6.866455078125e-05
iter 1655 (epoch 2), train_loss = 3.270, time/batch = 0.018
Read data: 7.009506225585938e-05
iter 1656 (epoch 2), train_loss = 3.276, time/batch = 0.025
Read data: 0.00011420249938964844
iter 1657 (epoch 2), train_loss = 3.538, time/batch = 0.022
Read data: 0.0037992000579833984
iter 1658 (epoch 2), train_loss = 3.134, time/batch = 0.028
Read data: 7.581710815429688e-05
iter 1659 (epoch 2), train_loss = 3.086, time/batch = 0.025
Read data: 6.723403930664062e-05
iter 1660 (epoch 2), train_loss = 3.320, time/batch = 0.024
Read data: 0.00016069412231445312
iter 1661 (epoch 2), train_loss = 3.660, time/batch = 0.025
Read data: 0.0001010894775390625
iter 1662 (epoch 2), train_loss = 3.347, time/batch = 0.022
Read data: 7.271766662597656e-05
iter 1663 (epoch 2), train_loss = 3.079, time/batch = 0.020
Read data: 7.152557373046875e-05
iter 1664 (epoch 2), train_loss = 3.450, time/batch = 0.018
Read data: 0.00012636184692382812
iter 1665 (epoch 2), train_loss = 3.215, time/batch = 0.020
Read data: 0.013839960098266602
iter 1666 (epoch 2), train_loss = 3.506, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 1667 (epoch 2), train_loss = 3.531, time/batch = 0.031
Read data: 7.128715515136719e-05
iter 1668 (epoch 2), train_loss = 3.396, time/batch = 0.021
Read data: 0.00010037422180175781
iter 1669 (epoch 2), train_loss = 3.256, time/batch = 0.022
Read data: 0.005159139633178711
iter 1670 (epoch 2), train_loss = 3.742, time/batch = 0.034
Read data: 6.723403930664062e-05
iter 1671 (epoch 2), train_loss = 3.215, time/batch = 0.019
Read data: 6.985664367675781e-05
iter 1672 (epoch 2), train_loss = 3.180, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 1673 (epoch 2), train_loss = 3.641, time/batch = 0.030
Read data: 8.988380432128906e-05
iter 1674 (epoch 2), train_loss = 3.575, time/batch = 0.023
Read data: 0.00016546249389648438
iter 1675 (epoch 2), train_loss = 3.603, time/batch = 0.023
Read data: 6.890296936035156e-05
iter 1676 (epoch 2), train_loss = 3.343, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 1677 (epoch 2), train_loss = 3.246, time/batch = 0.026
Read data: 0.00010824203491210938
iter 1678 (epoch 2), train_loss = 3.214, time/batch = 0.024
Read data: 7.367134094238281e-05
iter 1679 (epoch 2), train_loss = 3.293, time/batch = 0.023
Read data: 0.00011897087097167969
iter 1680 (epoch 2), train_loss = 3.137, time/batch = 0.023
Read data: 0.00013875961303710938
iter 1681 (epoch 2), train_loss = 3.352, time/batch = 0.030
Read data: 0.00011324882507324219
iter 1682 (epoch 2), train_loss = 3.015, time/batch = 0.028
Read data: 6.723403930664062e-05
iter 1683 (epoch 2), train_loss = 3.560, time/batch = 0.035
Read data: 6.413459777832031e-05
iter 1684 (epoch 2), train_loss = 3.378, time/batch = 0.021
Read data: 9.322166442871094e-05
iter 1685 (epoch 2), train_loss = 3.876, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 1686 (epoch 2), train_loss = 3.067, time/batch = 0.018
Read data: 7.343292236328125e-05
iter 1687 (epoch 2), train_loss = 3.470, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 1688 (epoch 2), train_loss = 3.027, time/batch = 0.020
Read data: 9.036064147949219e-05
iter 1689 (epoch 2), train_loss = 3.326, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 1690 (epoch 2), train_loss = 3.556, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 1691 (epoch 2), train_loss = 3.448, time/batch = 0.021
Read data: 6.914138793945312e-05
iter 1692 (epoch 2), train_loss = 2.799, time/batch = 0.021
Read data: 0.0001480579376220703
iter 1693 (epoch 2), train_loss = 2.723, time/batch = 0.018
Read data: 0.011843204498291016
iter 1694 (epoch 2), train_loss = 3.344, time/batch = 0.030
Read data: 7.319450378417969e-05
iter 1695 (epoch 2), train_loss = 3.666, time/batch = 0.020
Read data: 7.05718994140625e-05
iter 1696 (epoch 2), train_loss = 3.357, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 1697 (epoch 2), train_loss = 3.508, time/batch = 0.023
Read data: 0.0026869773864746094
iter 1698 (epoch 2), train_loss = 3.702, time/batch = 0.024
Read data: 0.00017333030700683594
iter 1699 (epoch 2), train_loss = 3.438, time/batch = 0.035
Read data: 0.00012826919555664062
iter 1700 (epoch 2), train_loss = 3.130, time/batch = 0.020
Read data: 0.00014090538024902344
iter 1701 (epoch 2), train_loss = 3.454, time/batch = 0.022
Read data: 0.0001690387725830078
iter 1702 (epoch 2), train_loss = 3.159, time/batch = 0.022
Read data: 9.584426879882812e-05
iter 1703 (epoch 2), train_loss = 3.376, time/batch = 0.025
Read data: 6.890296936035156e-05
iter 1704 (epoch 2), train_loss = 3.383, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 1705 (epoch 2), train_loss = 3.172, time/batch = 0.024
Read data: 0.00013589859008789062
iter 1706 (epoch 2), train_loss = 3.874, time/batch = 0.024
Read data: 0.00012683868408203125
iter 1707 (epoch 2), train_loss = 3.418, time/batch = 0.025
Read data: 7.462501525878906e-05
iter 1708 (epoch 2), train_loss = 3.260, time/batch = 0.025
Read data: 0.00013017654418945312
iter 1709 (epoch 2), train_loss = 3.161, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 1710 (epoch 2), train_loss = 3.539, time/batch = 0.027
Read data: 0.00011420249938964844
iter 1711 (epoch 2), train_loss = 3.338, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 1712 (epoch 2), train_loss = 3.715, time/batch = 0.024
Read data: 0.000133514404296875
iter 1713 (epoch 2), train_loss = 3.287, time/batch = 0.024
Read data: 0.00014257431030273438
iter 1714 (epoch 2), train_loss = 3.190, time/batch = 0.024
Read data: 0.00013685226440429688
iter 1715 (epoch 2), train_loss = 3.459, time/batch = 0.022
Read data: 6.961822509765625e-05
iter 1716 (epoch 2), train_loss = 3.246, time/batch = 0.019
Read data: 0.0001430511474609375
iter 1717 (epoch 2), train_loss = 3.456, time/batch = 0.033
Read data: 0.00014448165893554688
iter 1718 (epoch 2), train_loss = 3.619, time/batch = 0.022
Read data: 6.985664367675781e-05
iter 1719 (epoch 2), train_loss = 3.215, time/batch = 0.024
Read data: 7.176399230957031e-05
iter 1720 (epoch 2), train_loss = 3.745, time/batch = 0.024
Read data: 0.0001316070556640625
iter 1721 (epoch 2), train_loss = 3.486, time/batch = 0.021
Read data: 0.006067037582397461
iter 1722 (epoch 2), train_loss = 4.034, time/batch = 0.030
Read data: 7.462501525878906e-05
iter 1723 (epoch 2), train_loss = 3.601, time/batch = 0.025
Read data: 0.000125885009765625
iter 1724 (epoch 2), train_loss = 3.062, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 1725 (epoch 2), train_loss = 2.931, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 1726 (epoch 2), train_loss = 3.473, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 1727 (epoch 2), train_loss = 3.114, time/batch = 0.019
Read data: 7.152557373046875e-05
iter 1728 (epoch 2), train_loss = 3.073, time/batch = 0.021
Read data: 0.00012636184692382812
iter 1729 (epoch 2), train_loss = 3.293, time/batch = 0.021
Read data: 0.0064885616302490234
iter 1730 (epoch 2), train_loss = 3.415, time/batch = 0.033
Read data: 7.081031799316406e-05
iter 1731 (epoch 2), train_loss = 3.220, time/batch = 0.025
Read data: 0.00015783309936523438
iter 1732 (epoch 2), train_loss = 3.373, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 1733 (epoch 2), train_loss = 3.707, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 1734 (epoch 2), train_loss = 3.395, time/batch = 0.025
Read data: 7.295608520507812e-05
iter 1735 (epoch 2), train_loss = 3.644, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 1736 (epoch 2), train_loss = 3.460, time/batch = 0.023
Read data: 0.0001418590545654297
iter 1737 (epoch 2), train_loss = 2.976, time/batch = 0.024
Read data: 0.00010919570922851562
iter 1738 (epoch 2), train_loss = 3.717, time/batch = 0.022
Read data: 7.271766662597656e-05
iter 1739 (epoch 2), train_loss = 3.366, time/batch = 0.024
Read data: 0.00011348724365234375
iter 1740 (epoch 2), train_loss = 3.341, time/batch = 0.022
Read data: 0.00013399124145507812
iter 1741 (epoch 2), train_loss = 3.154, time/batch = 0.023
Read data: 0.00541996955871582
iter 1742 (epoch 2), train_loss = 3.521, time/batch = 0.026
Read data: 7.486343383789062e-05
iter 1743 (epoch 2), train_loss = 2.956, time/batch = 0.027
Read data: 7.367134094238281e-05
iter 1744 (epoch 2), train_loss = 3.364, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 1745 (epoch 2), train_loss = 2.945, time/batch = 0.022
Read data: 0.00011134147644042969
iter 1746 (epoch 2), train_loss = 3.588, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 1747 (epoch 2), train_loss = 3.512, time/batch = 0.025
Read data: 7.224082946777344e-05
iter 1748 (epoch 2), train_loss = 3.495, time/batch = 0.023
Read data: 0.00014066696166992188
iter 1749 (epoch 2), train_loss = 3.648, time/batch = 0.021
Read data: 0.00019288063049316406
iter 1750 (epoch 2), train_loss = 2.881, time/batch = 0.021
Read data: 6.937980651855469e-05
iter 1751 (epoch 2), train_loss = 3.394, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 1752 (epoch 2), train_loss = 3.344, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 1753 (epoch 2), train_loss = 3.384, time/batch = 0.033
Read data: 9.560585021972656e-05
iter 1754 (epoch 2), train_loss = 3.384, time/batch = 0.021
Read data: 7.414817810058594e-05
iter 1755 (epoch 2), train_loss = 3.426, time/batch = 0.025
Read data: 0.00011873245239257812
iter 1756 (epoch 2), train_loss = 3.090, time/batch = 0.022
Read data: 0.0001266002655029297
iter 1757 (epoch 2), train_loss = 2.883, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 1758 (epoch 2), train_loss = 3.185, time/batch = 0.025
Read data: 7.462501525878906e-05
iter 1759 (epoch 2), train_loss = 3.323, time/batch = 0.029
Read data: 0.0001361370086669922
iter 1760 (epoch 2), train_loss = 3.019, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 1761 (epoch 2), train_loss = 3.225, time/batch = 0.020
Read data: 9.393692016601562e-05
iter 1762 (epoch 2), train_loss = 3.002, time/batch = 0.025
Read data: 7.367134094238281e-05
iter 1763 (epoch 2), train_loss = 3.542, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 1764 (epoch 2), train_loss = 3.219, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 1765 (epoch 2), train_loss = 3.708, time/batch = 0.021
Read data: 0.0038034915924072266
iter 1766 (epoch 2), train_loss = 3.459, time/batch = 0.025
Read data: 7.486343383789062e-05
iter 1767 (epoch 2), train_loss = 3.095, time/batch = 0.023
Read data: 6.890296936035156e-05
iter 1768 (epoch 2), train_loss = 3.213, time/batch = 0.022
Read data: 0.00013303756713867188
iter 1769 (epoch 2), train_loss = 3.230, time/batch = 0.021
Read data: 0.005873680114746094
iter 1770 (epoch 2), train_loss = 3.581, time/batch = 0.025
Read data: 7.390975952148438e-05
iter 1771 (epoch 2), train_loss = 3.482, time/batch = 0.025
Read data: 6.842613220214844e-05
iter 1772 (epoch 2), train_loss = 3.278, time/batch = 0.026
Read data: 0.00016760826110839844
iter 1773 (epoch 2), train_loss = 3.207, time/batch = 0.024
Read data: 0.0001010894775390625
iter 1774 (epoch 2), train_loss = 3.151, time/batch = 0.027
Read data: 7.367134094238281e-05
iter 1775 (epoch 2), train_loss = 3.113, time/batch = 0.020
Read data: 7.367134094238281e-05
iter 1776 (epoch 2), train_loss = 3.402, time/batch = 0.027
Read data: 0.0001373291015625
iter 1777 (epoch 2), train_loss = 3.493, time/batch = 0.024
Read data: 0.00015592575073242188
iter 1778 (epoch 2), train_loss = 3.592, time/batch = 0.021
Read data: 7.677078247070312e-05
iter 1779 (epoch 2), train_loss = 3.389, time/batch = 0.025
Read data: 6.794929504394531e-05
iter 1780 (epoch 2), train_loss = 3.465, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 1781 (epoch 2), train_loss = 3.280, time/batch = 0.020
Read data: 0.006008148193359375
iter 1782 (epoch 2), train_loss = 3.953, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 1783 (epoch 2), train_loss = 3.173, time/batch = 0.022
Read data: 7.176399230957031e-05
iter 1784 (epoch 2), train_loss = 3.087, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 1785 (epoch 2), train_loss = 3.260, time/batch = 0.023
Read data: 0.003710031509399414
iter 1786 (epoch 2), train_loss = 3.071, time/batch = 0.023
Read data: 7.462501525878906e-05
iter 1787 (epoch 2), train_loss = 3.545, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 1788 (epoch 2), train_loss = 3.276, time/batch = 0.029
Read data: 0.00014257431030273438
iter 1789 (epoch 2), train_loss = 3.238, time/batch = 0.018
Read data: 0.0062482357025146484
iter 1790 (epoch 2), train_loss = 3.470, time/batch = 0.026
Read data: 0.0001125335693359375
iter 1791 (epoch 2), train_loss = 3.698, time/batch = 0.021
Read data: 0.0009057521820068359
iter 1792 (epoch 2), train_loss = 3.132, time/batch = 0.022
Read data: 0.00013136863708496094
iter 1793 (epoch 2), train_loss = 3.159, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 1794 (epoch 2), train_loss = 3.323, time/batch = 0.021
Read data: 6.67572021484375e-05
iter 1795 (epoch 2), train_loss = 3.123, time/batch = 0.024
Read data: 6.961822509765625e-05
iter 1796 (epoch 2), train_loss = 3.712, time/batch = 0.024
Read data: 0.00017404556274414062
iter 1797 (epoch 2), train_loss = 2.929, time/batch = 0.019
Read data: 0.008507728576660156
iter 1798 (epoch 2), train_loss = 3.155, time/batch = 0.022
Read data: 6.842613220214844e-05
iter 1799 (epoch 2), train_loss = 3.426, time/batch = 0.038
Read data: 0.0001609325408935547
iter 1800 (epoch 2), train_loss = 3.109, time/batch = 0.019
Read data: 0.0001361370086669922
iter 1801 (epoch 3), train_loss = 3.332, time/batch = 0.024
Read data: 0.0001957416534423828
iter 1802 (epoch 3), train_loss = 3.468, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 1803 (epoch 3), train_loss = 3.350, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 1804 (epoch 3), train_loss = 3.426, time/batch = 0.021
Read data: 0.00012874603271484375
iter 1805 (epoch 3), train_loss = 3.011, time/batch = 0.020
Read data: 0.007253170013427734
iter 1806 (epoch 3), train_loss = 2.915, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 1807 (epoch 3), train_loss = 3.350, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 1808 (epoch 3), train_loss = 3.671, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 1809 (epoch 3), train_loss = 3.581, time/batch = 0.022
Read data: 0.0019693374633789062
iter 1810 (epoch 3), train_loss = 2.823, time/batch = 0.019
Read data: 8.797645568847656e-05
iter 1811 (epoch 3), train_loss = 3.493, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 1812 (epoch 3), train_loss = 3.108, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 1813 (epoch 3), train_loss = 3.042, time/batch = 0.018
Read data: 0.00903463363647461
iter 1814 (epoch 3), train_loss = 3.167, time/batch = 0.029
Read data: 7.62939453125e-05
iter 1815 (epoch 3), train_loss = 3.386, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 1816 (epoch 3), train_loss = 3.586, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 1817 (epoch 3), train_loss = 3.419, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 1818 (epoch 3), train_loss = 2.917, time/batch = 0.026
Read data: 7.390975952148438e-05
iter 1819 (epoch 3), train_loss = 3.315, time/batch = 0.027
Read data: 7.200241088867188e-05
iter 1820 (epoch 3), train_loss = 3.682, time/batch = 0.023
Read data: 0.00017023086547851562
iter 1821 (epoch 3), train_loss = 3.231, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 1822 (epoch 3), train_loss = 3.797, time/batch = 0.021
Read data: 0.00014829635620117188
iter 1823 (epoch 3), train_loss = 3.265, time/batch = 0.024
Read data: 7.224082946777344e-05
iter 1824 (epoch 3), train_loss = 3.111, time/batch = 0.028
Read data: 0.0001289844512939453
iter 1825 (epoch 3), train_loss = 3.226, time/batch = 0.020
Read data: 0.0023124217987060547
iter 1826 (epoch 3), train_loss = 3.320, time/batch = 0.024
Read data: 5.5789947509765625e-05
iter 1827 (epoch 3), train_loss = 3.011, time/batch = 0.024
Read data: 7.367134094238281e-05
iter 1828 (epoch 3), train_loss = 2.924, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 1829 (epoch 3), train_loss = 3.718, time/batch = 0.023
Read data: 0.001960277557373047
iter 1830 (epoch 3), train_loss = 3.469, time/batch = 0.019
Read data: 0.00013208389282226562
iter 1831 (epoch 3), train_loss = 3.492, time/batch = 0.026
Read data: 6.604194641113281e-05
iter 1832 (epoch 3), train_loss = 3.259, time/batch = 0.023
Read data: 0.00013065338134765625
iter 1833 (epoch 3), train_loss = 3.174, time/batch = 0.021
Read data: 0.008481264114379883
iter 1834 (epoch 3), train_loss = 3.314, time/batch = 0.020
Read data: 8.559226989746094e-05
iter 1835 (epoch 3), train_loss = 3.296, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 1836 (epoch 3), train_loss = 3.012, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 1837 (epoch 3), train_loss = 3.395, time/batch = 0.025
Read data: 0.008059024810791016
iter 1838 (epoch 3), train_loss = 3.462, time/batch = 0.021
Read data: 0.00010895729064941406
iter 1839 (epoch 3), train_loss = 3.508, time/batch = 0.022
Read data: 7.271766662597656e-05
iter 1840 (epoch 3), train_loss = 3.278, time/batch = 0.023
Read data: 0.00014019012451171875
iter 1841 (epoch 3), train_loss = 3.121, time/batch = 0.023
Read data: 0.007297039031982422
iter 1842 (epoch 3), train_loss = 3.128, time/batch = 0.021
Read data: 5.412101745605469e-05
iter 1843 (epoch 3), train_loss = 3.093, time/batch = 0.021
Read data: 7.557868957519531e-05
iter 1844 (epoch 3), train_loss = 3.259, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 1845 (epoch 3), train_loss = 3.250, time/batch = 0.025
Read data: 0.006485700607299805
iter 1846 (epoch 3), train_loss = 3.198, time/batch = 0.019
Read data: 5.269050598144531e-05
iter 1847 (epoch 3), train_loss = 2.968, time/batch = 0.022
Read data: 0.00010442733764648438
iter 1848 (epoch 3), train_loss = 3.113, time/batch = 0.029
Read data: 0.0001430511474609375
iter 1849 (epoch 3), train_loss = 3.045, time/batch = 0.019
Read data: 0.009956598281860352
iter 1850 (epoch 3), train_loss = 3.367, time/batch = 0.021
Read data: 5.3882598876953125e-05
iter 1851 (epoch 3), train_loss = 2.843, time/batch = 0.022
Read data: 7.367134094238281e-05
iter 1852 (epoch 3), train_loss = 3.176, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 1853 (epoch 3), train_loss = 3.536, time/batch = 0.025
Read data: 0.0034422874450683594
iter 1854 (epoch 3), train_loss = 3.459, time/batch = 0.019
Read data: 5.340576171875e-05
iter 1855 (epoch 3), train_loss = 3.851, time/batch = 0.021
Read data: 7.104873657226562e-05
iter 1856 (epoch 3), train_loss = 3.074, time/batch = 0.023
Read data: 0.0001316070556640625
iter 1857 (epoch 3), train_loss = 3.351, time/batch = 0.022
Read data: 0.011785030364990234
iter 1858 (epoch 3), train_loss = 3.307, time/batch = 0.019
Read data: 5.602836608886719e-05
iter 1859 (epoch 3), train_loss = 3.260, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 1860 (epoch 3), train_loss = 3.305, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 1861 (epoch 3), train_loss = 3.970, time/batch = 0.030
Read data: 0.003564596176147461
iter 1862 (epoch 3), train_loss = 3.263, time/batch = 0.023
Read data: 5.5789947509765625e-05
iter 1863 (epoch 3), train_loss = 3.120, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 1864 (epoch 3), train_loss = 3.170, time/batch = 0.021
Read data: 8.821487426757812e-05
iter 1865 (epoch 3), train_loss = 3.202, time/batch = 0.022
Read data: 0.0024940967559814453
iter 1866 (epoch 3), train_loss = 2.999, time/batch = 0.021
Read data: 5.555152893066406e-05
iter 1867 (epoch 3), train_loss = 3.390, time/batch = 0.021
Read data: 7.271766662597656e-05
iter 1868 (epoch 3), train_loss = 3.674, time/batch = 0.024
Read data: 0.00011348724365234375
iter 1869 (epoch 3), train_loss = 3.099, time/batch = 0.019
Read data: 0.012723684310913086
iter 1870 (epoch 3), train_loss = 3.263, time/batch = 0.022
Read data: 5.8650970458984375e-05
iter 1871 (epoch 3), train_loss = 3.466, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 1872 (epoch 3), train_loss = 3.588, time/batch = 0.027
Read data: 0.00019741058349609375
iter 1873 (epoch 3), train_loss = 3.250, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 1874 (epoch 3), train_loss = 2.924, time/batch = 0.021
Read data: 5.3882598876953125e-05
iter 1875 (epoch 3), train_loss = 3.278, time/batch = 0.023
Read data: 0.00010132789611816406
iter 1876 (epoch 3), train_loss = 3.089, time/batch = 0.028
Read data: 0.00013685226440429688
iter 1877 (epoch 3), train_loss = 3.389, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 1878 (epoch 3), train_loss = 3.296, time/batch = 0.021
Read data: 5.507469177246094e-05
iter 1879 (epoch 3), train_loss = 3.421, time/batch = 0.022
Read data: 0.0001583099365234375
iter 1880 (epoch 3), train_loss = 3.244, time/batch = 0.025
Read data: 0.00017261505126953125
iter 1881 (epoch 3), train_loss = 3.211, time/batch = 0.025
Read data: 0.00010180473327636719
iter 1882 (epoch 3), train_loss = 2.962, time/batch = 0.019
Read data: 5.53131103515625e-05
iter 1883 (epoch 3), train_loss = 3.200, time/batch = 0.026
Read data: 7.343292236328125e-05
iter 1884 (epoch 3), train_loss = 3.672, time/batch = 0.033
Read data: 0.00015616416931152344
iter 1885 (epoch 3), train_loss = 3.500, time/batch = 0.034
Read data: 8.96453857421875e-05
iter 1886 (epoch 3), train_loss = 3.390, time/batch = 0.021
Read data: 5.459785461425781e-05
iter 1887 (epoch 3), train_loss = 3.344, time/batch = 0.020
Read data: 9.250640869140625e-05
iter 1888 (epoch 3), train_loss = 2.617, time/batch = 0.027
Read data: 0.00011563301086425781
iter 1889 (epoch 3), train_loss = 3.388, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 1890 (epoch 3), train_loss = 3.191, time/batch = 0.022
Read data: 5.4836273193359375e-05
iter 1891 (epoch 3), train_loss = 2.968, time/batch = 0.031
Read data: 0.00018930435180664062
iter 1892 (epoch 3), train_loss = 3.824, time/batch = 0.021
Read data: 0.00011491775512695312
iter 1893 (epoch 3), train_loss = 3.183, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 1894 (epoch 3), train_loss = 2.882, time/batch = 0.022
Read data: 5.626678466796875e-05
iter 1895 (epoch 3), train_loss = 3.108, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 1896 (epoch 3), train_loss = 3.610, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 1897 (epoch 3), train_loss = 3.349, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 1898 (epoch 3), train_loss = 3.345, time/batch = 0.019
Read data: 5.602836608886719e-05
iter 1899 (epoch 3), train_loss = 3.550, time/batch = 0.021
Read data: 0.00010728836059570312
iter 1900 (epoch 3), train_loss = 3.333, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 1901 (epoch 3), train_loss = 3.260, time/batch = 0.024
Read data: 0.008025407791137695
iter 1902 (epoch 3), train_loss = 3.075, time/batch = 0.022
Read data: 6.437301635742188e-05
iter 1903 (epoch 3), train_loss = 3.801, time/batch = 0.034
Read data: 0.00014591217041015625
iter 1904 (epoch 3), train_loss = 2.983, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 1905 (epoch 3), train_loss = 3.206, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 1906 (epoch 3), train_loss = 2.991, time/batch = 0.024
Read data: 6.580352783203125e-05
iter 1907 (epoch 3), train_loss = 3.330, time/batch = 0.024
Read data: 0.0001327991485595703
iter 1908 (epoch 3), train_loss = 2.866, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 1909 (epoch 3), train_loss = 3.141, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 1910 (epoch 3), train_loss = 3.309, time/batch = 0.019
Read data: 5.459785461425781e-05
iter 1911 (epoch 3), train_loss = 3.287, time/batch = 0.018
Read data: 7.43865966796875e-05
iter 1912 (epoch 3), train_loss = 3.407, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 1913 (epoch 3), train_loss = 2.842, time/batch = 0.018
Read data: 0.01537942886352539
iter 1914 (epoch 3), train_loss = 3.057, time/batch = 0.019
Read data: 5.7697296142578125e-05
iter 1915 (epoch 3), train_loss = 3.216, time/batch = 0.018
Read data: 7.748603820800781e-05
iter 1916 (epoch 3), train_loss = 3.413, time/batch = 0.026
Read data: 0.0001590251922607422
iter 1917 (epoch 3), train_loss = 3.145, time/batch = 0.021
Read data: 0.016211986541748047
iter 1918 (epoch 3), train_loss = 3.371, time/batch = 0.019
Read data: 5.9604644775390625e-05
iter 1919 (epoch 3), train_loss = 3.106, time/batch = 0.020
Read data: 7.271766662597656e-05
iter 1920 (epoch 3), train_loss = 3.275, time/batch = 0.025
Read data: 0.00013208389282226562
iter 1921 (epoch 3), train_loss = 3.271, time/batch = 0.021
Read data: 0.015903711318969727
iter 1922 (epoch 3), train_loss = 3.564, time/batch = 0.022
Read data: 5.626678466796875e-05
iter 1923 (epoch 3), train_loss = 3.217, time/batch = 0.032
Read data: 7.224082946777344e-05
iter 1924 (epoch 3), train_loss = 3.514, time/batch = 0.026
Read data: 0.00022459030151367188
iter 1925 (epoch 3), train_loss = 3.122, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 1926 (epoch 3), train_loss = 3.071, time/batch = 0.019
Read data: 5.340576171875e-05
iter 1927 (epoch 3), train_loss = 3.627, time/batch = 0.022
Read data: 0.0001277923583984375
iter 1928 (epoch 3), train_loss = 3.126, time/batch = 0.022
Read data: 0.000156402587890625
iter 1929 (epoch 3), train_loss = 3.016, time/batch = 0.019
Read data: 0.016429901123046875
iter 1930 (epoch 3), train_loss = 3.797, time/batch = 0.018
Read data: 5.5789947509765625e-05
iter 1931 (epoch 3), train_loss = 3.265, time/batch = 0.018
Read data: 7.581710815429688e-05
iter 1932 (epoch 3), train_loss = 3.531, time/batch = 0.029
Read data: 0.0001666545867919922
iter 1933 (epoch 3), train_loss = 3.061, time/batch = 0.020
Read data: 0.013184309005737305
iter 1934 (epoch 3), train_loss = 3.542, time/batch = 0.021
Read data: 5.459785461425781e-05
iter 1935 (epoch 3), train_loss = 3.308, time/batch = 0.022
Read data: 0.00011897087097167969
iter 1936 (epoch 3), train_loss = 3.566, time/batch = 0.024
Read data: 0.00013184547424316406
iter 1937 (epoch 3), train_loss = 3.568, time/batch = 0.020
Read data: 0.012282371520996094
iter 1938 (epoch 3), train_loss = 3.595, time/batch = 0.026
Read data: 6.341934204101562e-05
iter 1939 (epoch 3), train_loss = 2.860, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 1940 (epoch 3), train_loss = 3.085, time/batch = 0.023
Read data: 0.00016617774963378906
iter 1941 (epoch 3), train_loss = 3.292, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 1942 (epoch 3), train_loss = 3.127, time/batch = 0.020
Read data: 6.318092346191406e-05
iter 1943 (epoch 3), train_loss = 3.452, time/batch = 0.026
Read data: 0.00013685226440429688
iter 1944 (epoch 3), train_loss = 3.327, time/batch = 0.024
Read data: 0.000133514404296875
iter 1945 (epoch 3), train_loss = 3.157, time/batch = 0.020
Read data: 0.007114887237548828
iter 1946 (epoch 3), train_loss = 3.204, time/batch = 0.020
Read data: 5.698204040527344e-05
iter 1947 (epoch 3), train_loss = 3.231, time/batch = 0.023
Read data: 7.200241088867188e-05
iter 1948 (epoch 3), train_loss = 3.052, time/batch = 0.024
Read data: 0.00014162063598632812
iter 1949 (epoch 3), train_loss = 3.242, time/batch = 0.022
Read data: 0.0085906982421875
iter 1950 (epoch 3), train_loss = 3.355, time/batch = 0.018
Read data: 5.841255187988281e-05
iter 1951 (epoch 3), train_loss = 3.571, time/batch = 0.023
Read data: 6.866455078125e-05
iter 1952 (epoch 3), train_loss = 3.225, time/batch = 0.026
Read data: 0.0001354217529296875
iter 1953 (epoch 3), train_loss = 3.059, time/batch = 0.023
Read data: 0.0082855224609375
iter 1954 (epoch 3), train_loss = 3.512, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 1955 (epoch 3), train_loss = 2.672, time/batch = 0.021
Read data: 7.43865966796875e-05
iter 1956 (epoch 3), train_loss = 3.260, time/batch = 0.023
Read data: 0.00013375282287597656
iter 1957 (epoch 3), train_loss = 3.046, time/batch = 0.029
Read data: 8.749961853027344e-05
iter 1958 (epoch 3), train_loss = 3.254, time/batch = 0.021
Read data: 6.031990051269531e-05
iter 1959 (epoch 3), train_loss = 3.037, time/batch = 0.025
Read data: 7.271766662597656e-05
iter 1960 (epoch 3), train_loss = 3.351, time/batch = 0.029
Read data: 0.00016832351684570312
iter 1961 (epoch 3), train_loss = 3.086, time/batch = 0.019
Read data: 0.0029523372650146484
iter 1962 (epoch 3), train_loss = 3.335, time/batch = 0.021
Read data: 6.222724914550781e-05
iter 1963 (epoch 3), train_loss = 3.159, time/batch = 0.024
Read data: 0.00014448165893554688
iter 1964 (epoch 3), train_loss = 3.117, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 1965 (epoch 3), train_loss = 3.608, time/batch = 0.032
Read data: 9.417533874511719e-05
iter 1966 (epoch 3), train_loss = 3.109, time/batch = 0.020
Read data: 5.888938903808594e-05
iter 1967 (epoch 3), train_loss = 3.127, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 1968 (epoch 3), train_loss = 3.572, time/batch = 0.022
Read data: 0.00016570091247558594
iter 1969 (epoch 3), train_loss = 3.204, time/batch = 0.023
Read data: 0.007097721099853516
iter 1970 (epoch 3), train_loss = 3.359, time/batch = 0.020
Read data: 5.7697296142578125e-05
iter 1971 (epoch 3), train_loss = 3.427, time/batch = 0.023
Read data: 7.581710815429688e-05
iter 1972 (epoch 3), train_loss = 3.328, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 1973 (epoch 3), train_loss = 3.216, time/batch = 0.025
Read data: 0.00944209098815918
iter 1974 (epoch 3), train_loss = 3.180, time/batch = 0.022
Read data: 0.00017189979553222656
iter 1975 (epoch 3), train_loss = 3.605, time/batch = 0.025
Read data: 7.271766662597656e-05
iter 1976 (epoch 3), train_loss = 3.652, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 1977 (epoch 3), train_loss = 2.824, time/batch = 0.022
Read data: 0.008760213851928711
iter 1978 (epoch 3), train_loss = 3.086, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 1979 (epoch 3), train_loss = 3.186, time/batch = 0.020
Read data: 8.082389831542969e-05
iter 1980 (epoch 3), train_loss = 3.223, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 1981 (epoch 3), train_loss = 2.910, time/batch = 0.019
Read data: 0.006060123443603516
iter 1982 (epoch 3), train_loss = 3.332, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 1983 (epoch 3), train_loss = 3.246, time/batch = 0.021
Read data: 7.319450378417969e-05
iter 1984 (epoch 3), train_loss = 3.078, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 1985 (epoch 3), train_loss = 3.345, time/batch = 0.022
Read data: 0.01153254508972168
iter 1986 (epoch 3), train_loss = 2.996, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 1987 (epoch 3), train_loss = 3.426, time/batch = 0.025
Read data: 6.842613220214844e-05
iter 1988 (epoch 3), train_loss = 3.056, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 1989 (epoch 3), train_loss = 3.227, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 1990 (epoch 3), train_loss = 3.524, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 1991 (epoch 3), train_loss = 3.475, time/batch = 0.023
Read data: 7.605552673339844e-05
iter 1992 (epoch 3), train_loss = 3.405, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 1993 (epoch 3), train_loss = 2.907, time/batch = 0.026
Read data: 0.00019693374633789062
iter 1994 (epoch 3), train_loss = 2.574, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 1995 (epoch 3), train_loss = 2.974, time/batch = 0.026
Read data: 7.43865966796875e-05
iter 1996 (epoch 3), train_loss = 3.384, time/batch = 0.022
Read data: 8.320808410644531e-05
iter 1997 (epoch 3), train_loss = 3.041, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 1998 (epoch 3), train_loss = 3.022, time/batch = 0.023
Read data: 0.004613637924194336
iter 1999 (epoch 3), train_loss = 2.998, time/batch = 0.022
image 976:     
image 5399:     
image 6910:     
image 660:     
image 6372:     
image 616:    
image 2678:     
image 2375:    
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (3.289053)
image 2798:     
image 5884:    
image 2067:    
image 3600:    
image 3617:     
image 1697:     
image 6767:     
image 6023:    
image 6550:     
image 6718:     
evaluating validation preformance... 20/1000 (2.861333)
image 6903:     
image 3301:    
image 2019:     
image 5535:     
image 7680:     
image 5527:     
image 2568:     
image 160:    
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (3.217172)
image 4604:     
image 5745:     
image 5288:    
image 1562:     
image 7807:      
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.362823)
image 2938:    
image 5183:     
image 2380:      
image 6973:    
image 5629:     
image 7130:     
image 1679:    
image 7194:    
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (3.130543)
image 4940:      
image 4905:     
image 469:     
image 102:     
image 6009:    
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (3.387397)
image 4389:    
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:      
image 4433:    
image 2973:     
image 5641:    
evaluating validation preformance... 70/1000 (3.179571)
image 3258:     
image 6895:     
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:     
image 2242:     
evaluating validation preformance... 80/1000 (3.277303)
image 3276:     
image 3812:    
image 1400:     
image 3443:    
image 5027:     
image 7251:     
image 7305:    
image 1480:     
image 4806:     
image 766:    
evaluating validation preformance... 90/1000 (2.649153)
image 6124:     
image 5415:     
image 369:     
image 5747:     
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:     
image 6553:     
evaluating validation preformance... 100/1000 (3.568799)
image 2800:    
image 7249:     
image 3211:     
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:    
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (3.414917)
image 1122:     
image 509:    
image 4091:     
image 5761:     
image 16:     
image 231:    
image 6505:    
image 1450:    
image 3979:     
image 5302:     
evaluating validation preformance... 120/1000 (2.998821)
image 3477:     
image 1212:     
image 3809:     
image 4329:    
image 3500:     
image 4913:    
image 4589:     
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (3.444095)
image 6214:     
image 429:     
image 7743:     
image 3657:     
image 4535:     
image 5542:     
image 8068:     
image 4450:    
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (3.240568)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:     
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.506055)
image 1865:      
image 3830:    
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:     
image 820:     
image 7993:      
evaluating validation preformance... 160/1000 (3.363157)
image 4297:    
image 3315:     
image 1107:     
image 2051:     
image 4713:     
image 8036:     
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (3.138543)
image 7922:     
image 2353:     
image 4580:    
image 5905:      
image 6488:    
image 3000:     
image 1806:    
image 7761:     
image 3014:     
image 3687:    
evaluating validation preformance... 180/1000 (3.151102)
image 2313:      
image 6289:     
image 8084:    
image 2696:     
image 5830:     
image 6240:     
image 4541:     
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (3.156490)
image 5372:     
image 7529:     
image 875:     
image 2107:     
image 8015:    
image 6565:     
image 6174:     
image 6894:     
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.940501)
image 5159:     
image 1199:     
image 2456:     
image 3402:    
image 7631:     
image 3562:     
image 405:     
image 2532:     
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (3.178998)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:     
image 618:     
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (3.290650)
image 4024:     
image 1894:     
image 7297:      
image 1796:    
image 7075:    
image 2258:    
image 5122:     
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (3.120409)
image 1917:     
image 5844:      
image 1661:    
image 1510:    
image 4630:    
image 6741:    
image 1020:     
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.871443)
image 7143:     
image 6019:    
image 885:    
image 2802:     
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (3.254106)
image 3028:     
image 3141:     
image 7137:     
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:    
image 6173:     
image 3082:    
evaluating validation preformance... 260/1000 (3.043983)
image 492:    
image 5429:     
image 6968:    
image 2672:     
image 6920:     
image 6211:     
image 3326:     
image 1870:     
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.414754)
image 833:     
image 5483:    
image 2476:     
image 5930:     
image 59:    
image 5007:    
image 2884:    
image 486:    
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (3.158939)
image 2481:     
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:     
image 2130:     
evaluating validation preformance... 290/1000 (3.242710)
image 6835:    
image 4698:     
image 7212:     
image 5933:    
image 2431:     
image 7277:      
image 2088:      
image 3340:     
image 3579:     
image 6928:    
evaluating validation preformance... 300/1000 (2.852782)
image 2805:    
image 4374:     
image 25:    
image 7702:     
image 256:     
image 7362:    
image 2148:     
image 1974:     
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (3.496029)
image 3553:     
image 5971:     
image 122:    
image 3212:     
image 7223:    
image 7007:     
image 6064:    UNK
image 7358:     
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (3.004164)
image 489:     
image 5316:     
image 2613:     
image 7935:    UNK
image 7768:     
image 7894:     
image 6267:     
image 2203:     
image 5727:     
image 1159:     
evaluating validation preformance... 330/1000 (3.317262)
image 5179:    
image 3754:    
image 2911:     
image 6979:      
image 5449:    
image 2198:     
image 2535:     
image 2601:     
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (3.031851)
image 4542:     
image 1878:     
image 5329:     
image 4139:     
image 6018:    
image 1206:     
image 5385:    
image 2794:     
image 7785:    
image 2085:     
evaluating validation preformance... 350/1000 (3.234870)
image 6881:     
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:    
image 5241:     
image 6606:     
image 2387:    
image 3342:     
evaluating validation preformance... 360/1000 (2.509497)
image 2905:     
image 7814:     
image 56:     
image 5034:     
image 7946:    
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (3.218432)
image 4351:     
image 1054:    
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (3.406797)
image 2458:     
image 1084:     
image 4835:    
image 867:     
image 723:     
image 6255:     
image 5255:     
image 3598:     
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (3.450835)
image 828:     
image 2733:    
image 791:      
image 5408:     
image 7842:     
image 1117:     
image 5817:     
image 1231:     
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.947098)
image 2627:     
image 7172:     
image 1991:    
image 7413:     
image 2105:    
image 3919:     
image 7980:     
image 670:     
image 2325:     
image 7546:     
evaluating validation preformance... 410/1000 (2.863946)
image 4359:     
image 2372:    
image 4472:     
image 6810:     
image 1592:     
image 7864:     
image 4286:     
image 6688:     
image 5697:    
image 7020:    
evaluating validation preformance... 420/1000 (2.824101)
image 30:     
image 5540:     
image 2445:     
image 5896:     
image 7607:    
image 1426:     
image 6977:    
image 877:    
image 2408:     
image 7706:    
evaluating validation preformance... 430/1000 (3.394785)
image 385:     
image 6938:     
image 2381:     
image 5796:    
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:    
image 4092:     
evaluating validation preformance... 440/1000 (3.326996)
image 1731:     
image 978:      
image 6033:     
image 5080:     
image 7804:     
image 439:     
image 4790:     
image 5855:     
image 4245:     
image 973:     
evaluating validation preformance... 450/1000 (2.881682)
image 2241:     
image 2651:     
image 2315:     
image 4784:     
image 5160:     
image 2466:     
image 975:     
image 3818:    
image 6995:    
image 3682:     
evaluating validation preformance... 460/1000 (3.563320)
image 7979:     
image 1618:     
image 7608:    
image 6393:     
image 5100:     
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:     
evaluating validation preformance... 470/1000 (3.807894)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:      
image 6862:     
image 7450:    
image 841:    
image 1118:     
image 6114:      
evaluating validation preformance... 480/1000 (3.530572)
image 358:     
image 4663:     
image 5541:    
image 4485:     
image 2727:      
image 1040:     
image 3823:     
image 1595:     
image 4757:    
image 205:     
evaluating validation preformance... 490/1000 (3.926257)
image 2044:     
image 4349:     
image 3855:     
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:     
evaluating validation preformance... 500/1000 (3.169659)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:     
image 1700:     
image 438:     
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.634185)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:     
image 5650:     
image 2597:    
image 5416:     
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (3.282816)
image 6806:     
image 6464:     
image 1872:     
image 1575:    
image 3045:     
image 303:    
image 5552:     
image 4628:    
image 1314:    
image 6335:     
evaluating validation preformance... 530/1000 (2.981938)
image 5619:     
image 4391:    
image 891:     
image 3072:     
image 7781:     
image 6163:    
image 7376:      
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (3.223880)
image 5292:     
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:     
image 4696:     
image 1183:     
image 1961:      
evaluating validation preformance... 550/1000 (3.288035)
image 5439:     
image 7981:     
image 6012:    
image 4732:     
image 6630:    
image 994:     
image 5079:     
image 6169:    
image 4340:     
image 2134:     
evaluating validation preformance... 560/1000 (3.345380)
image 6056:     
image 6419:     
image 275:    
image 7441:     
image 7893:     
image 3623:    
image 7232:     
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (3.397103)
image 7936:     
image 5433:    
image 5691:     
image 1628:     
image 4501:     
image 1247:     
image 315:     
image 317:     
image 329:    
image 3267:    
evaluating validation preformance... 580/1000 (2.969651)
image 2135:     
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (3.238589)
image 4420:    
image 1734:      
image 7239:     
image 7447:     
image 8009:    
image 4510:     
image 7495:     
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (3.305381)
image 353:     
image 1095:    
image 3583:     
image 3264:     
image 5668:     
image 7189:    
image 6573:     
image 3253:    
image 1773:    
image 4823:     
evaluating validation preformance... 610/1000 (3.374343)
image 69:     
image 3465:    
image 6179:     
image 552:    
image 511:    
image 761:     
image 5742:    
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (3.313522)
image 6575:     
image 5695:    
image 7418:     
image 1948:     
image 4012:     
image 6981:     
image 989:     
image 2847:     
image 4456:     
image 2351:     
evaluating validation preformance... 630/1000 (2.973439)
image 8074:    
image 1904:    
image 7917:     
image 2394:     
image 4406:     
image 883:     
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (3.135455)
image 5313:     
image 2377:     
image 6058:     
image 4661:     
image 2955:    
image 3333:     
image 7124:     
image 4278:     
image 953:     
image 4037:     
evaluating validation preformance... 650/1000 (3.261482)
image 8065:     
image 3577:     
image 3254:     
image 4562:     
image 5462:     
image 2824:     
image 1639:     
image 1475:     
image 3991:     
image 1023:    
evaluating validation preformance... 660/1000 (3.289880)
image 5701:     
image 1709:     
image 4811:     
image 622:     
image 5997:     
image 1608:     
image 4119:     
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (3.447605)
image 7877:     
image 6761:     
image 6880:     
image 4914:     
image 4522:     
image 2311:    
image 7587:     
image 4848:    
image 6722:     
image 7784:      
evaluating validation preformance... 680/1000 (3.765731)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:     
image 1257:     
image 6405:     
image 6504:     
evaluating validation preformance... 690/1000 (3.496092)
image 6860:    
image 576:      
image 6580:     
image 1497:    
image 3360:    
image 4939:     
image 6225:     
image 3669:     
image 980:     
image 5362:     
evaluating validation preformance... 700/1000 (3.504038)
image 5343:     
image 68:     
image 3184:    
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:     
image 7801:     
image 1129:     
evaluating validation preformance... 710/1000 (3.050992)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:     
image 3428:     
image 268:     
image 2328:    
image 4627:     
image 1586:      
evaluating validation preformance... 720/1000 (3.141807)
image 5729:     
image 6395:     
image 516:      
image 1026:     
image 2972:     
image 3005:     
image 1241:     
image 2743:     
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.916382)
image 2527:    
image 6266:     
image 4161:    
image 1139:     
image 3781:     
image 6081:     
image 997:    
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.979869)
image 2239:    UNK
image 120:    
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (3.493831)
image 3279:     
image 6380:     
image 2663:    
image 3815:     
image 512:     
image 5899:     
image 6078:     
image 4808:     
image 3780:     
image 7174:     
evaluating validation preformance... 760/1000 (3.493185)
image 4582:     
image 5484:     
image 3049:    
image 4641:     
image 8028:     
image 4739:     
image 2452:     
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.817605)
image 6220:     
image 6238:     
image 4534:     
image 2732:     
image 7003:     
image 1739:     
image 5503:     
image 2329:    
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (3.384103)
image 6867:     
image 5525:     
image 4746:     
image 5531:     
image 5425:     
image 6978:     
image 3450:     
image 3312:     
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.884460)
image 5047:     
image 325:     
image 7626:     
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:     
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.807847)
image 7288:      
image 7302:     
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (3.102302)
image 614:     
image 7295:     
image 4110:     
image 5402:     
image 3060:     
image 1317:     
image 3339:     
image 1052:     
image 3701:     
image 4194:      
evaluating validation preformance... 820/1000 (2.720272)
image 7204:     
image 4428:     
image 7825:      
image 5890:     
image 4334:    UNK
image 5514:     
image 7147:    
image 6348:    
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (3.026891)
image 5107:      
image 3973:    
image 4233:     
image 3593:     
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:     
image 6117:    
evaluating validation preformance... 840/1000 (2.968358)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:     
image 1712:     
image 3313:    
image 5534:     
evaluating validation preformance... 850/1000 (3.581362)
image 4404:     
image 5501:     
image 5765:    
image 1838:     
image 4354:    
image 336:     
image 3596:      
image 1921:     
image 6261:     
image 2166:     
evaluating validation preformance... 860/1000 (3.516846)
image 4254:     
image 6842:     
image 1644:     
image 7371:     
image 4638:     
image 4031:     
image 2702:     
image 4927:     
image 3222:    
image 4002:     
evaluating validation preformance... 870/1000 (3.003509)
image 4934:    
image 6487:     
image 4217:    
image 6355:     
image 2793:     
image 7201:     
image 5681:     
image 1824:    
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (3.108112)
image 5460:     
image 3671:     
image 3602:     
image 3473:     
image 2048:    
image 1379:    
image 419:     
image 2314:    
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (3.508090)
image 7485:     
image 6102:    
image 1001:      
image 7167:     
image 4168:     
image 187:    
image 7798:     
image 4813:     
image 7753:     
image 210:     
evaluating validation preformance... 900/1000 (3.920540)
image 5664:     
image 4985:    
image 4082:     
image 6291:     
image 5573:     
image 1405:     
image 4431:     
image 2801:     
image 2398:    
image 7205:     
evaluating validation preformance... 910/1000 (2.896799)
image 1368:     
image 1925:     
image 5870:     
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (3.159575)
image 7152:     
image 4559:     
image 7233:     
image 1341:    
image 5337:     
image 3189:    
image 6274:      
image 7102:     
image 5532:     
image 2516:    
evaluating validation preformance... 930/1000 (3.059615)
image 5636:     
image 7799:     
image 6025:    
image 6907:     
image 2507:     
image 7014:    
image 5566:    
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (3.267649)
image 5860:     
image 3275:     
image 1935:     
image 3520:    
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (3.620840)
image 1081:     
image 1179:     
image 4316:     
image 3588:    
image 1085:     
image 3923:     
image 4229:     
image 3336:     
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (3.382004)
image 4935:    
image 1930:     
image 6850:     
image 5310:     
image 177:     
image 94:     
image 529:     
image 4632:     
image 3766:      
image 374:      
evaluating validation preformance... 970/1000 (3.072490)
image 5688:     
image 5448:    
image 5871:     
image 7516:    
image 3734:     
image 2921:      
image 7800:    
image 3999:     
image 6317:     
image 5931:     
evaluating validation preformance... 980/1000 (3.441169)
image 7352:    
image 5113:     
image 7822:    
image 4858:     
image 658:     
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (3.124962)
image 5789:      
image 5606:     
image 6107:     
image 7976:     
image 3890:     
image 5901:     
image 1163:     
image 2483:     
image 2591:     
image 7615:    
evaluating validation preformance... 1000/1000 (3.101220)
average loss on validation: 3.234
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2165815830230713
Cider scores: 0.31979787096009005
Read data: 0.3187394142150879
Cider scores: 0.3374944024128163
Read data: 0.28426170349121094
Cider scores: 0.3122967178685937
Read data: 0.2246694564819336
Cider scores: 0.2510058700625494
Read data: 0.24126410484313965
Cider scores: 0.30795414766735696
Read data: 0.17220640182495117
Cider scores: 0.2834999707289494
Read data: 0.19867229461669922
Cider scores: 0.2986143657368208
Read data: 0.17368340492248535
Cider scores: 0.3380772232279314
Read data: 0.17561745643615723
Cider scores: 0.32432543906061845
Read data: 0.17477893829345703
Cider scores: 0.3279510298376385
Read data: 0.23541712760925293
Cider scores: 0.28882424540303203
Read data: 0.17734837532043457
Cider scores: 0.32431719402859976
Read data: 0.18440461158752441
Cider scores: 0.35609193182403154
Read data: 0.17578673362731934
Cider scores: 0.3342923031279236
Read data: 0.18348026275634766
Cider scores: 0.2865825837233912
Read data: 0.16904973983764648
Cider scores: 0.37086365748609895
Read data: 0.16235065460205078
Cider scores: 0.28469384673354337
Read data: 0.15789389610290527
Cider scores: 0.4220181986592749
Read data: 0.1653614044189453
Cider scores: 0.3120065377272449
Read data: 0.1623547077178955
Cider scores: 0.43911386835714344
Average cider score on test set: 0.326
End calculating cider score on TEST data set
===============================================
Read data: 0.1605391502380371
iter 2000 (epoch 3), train_loss = 3.520, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 2001 (epoch 3), train_loss = 2.857, time/batch = 0.020
Read data: 0.00010633468627929688
iter 2002 (epoch 3), train_loss = 3.322, time/batch = 0.022
Read data: 0.00013017654418945312
iter 2003 (epoch 3), train_loss = 3.324, time/batch = 0.026
Read data: 0.00011181831359863281
iter 2004 (epoch 3), train_loss = 3.376, time/batch = 0.028
Read data: 0.00013947486877441406
iter 2005 (epoch 3), train_loss = 3.503, time/batch = 0.024
Read data: 0.00018095970153808594
iter 2006 (epoch 3), train_loss = 3.156, time/batch = 0.025
Read data: 0.0001697540283203125
iter 2007 (epoch 3), train_loss = 2.915, time/batch = 0.020
Read data: 0.00012493133544921875
iter 2008 (epoch 3), train_loss = 3.652, time/batch = 0.042
Read data: 0.0001494884490966797
iter 2009 (epoch 3), train_loss = 3.086, time/batch = 0.027
Read data: 0.0001163482666015625
iter 2010 (epoch 3), train_loss = 3.414, time/batch = 0.033
Read data: 0.00010323524475097656
iter 2011 (epoch 3), train_loss = 3.242, time/batch = 0.028
Read data: 0.00010633468627929688
iter 2012 (epoch 3), train_loss = 3.125, time/batch = 0.023
Read data: 0.00010752677917480469
iter 2013 (epoch 3), train_loss = 3.095, time/batch = 0.025
Read data: 0.00010752677917480469
iter 2014 (epoch 3), train_loss = 3.269, time/batch = 0.028
Read data: 0.00010156631469726562
iter 2015 (epoch 3), train_loss = 3.105, time/batch = 0.026
Read data: 0.00013637542724609375
iter 2016 (epoch 3), train_loss = 3.001, time/batch = 0.027
Read data: 0.00016236305236816406
iter 2017 (epoch 3), train_loss = 3.373, time/batch = 0.025
Read data: 9.918212890625e-05
iter 2018 (epoch 3), train_loss = 3.040, time/batch = 0.022
Read data: 0.00010514259338378906
iter 2019 (epoch 3), train_loss = 3.132, time/batch = 0.022
Read data: 0.00010943412780761719
iter 2020 (epoch 3), train_loss = 3.278, time/batch = 0.029
Read data: 0.00016927719116210938
iter 2021 (epoch 3), train_loss = 3.351, time/batch = 0.031
Read data: 0.00012183189392089844
iter 2022 (epoch 3), train_loss = 3.447, time/batch = 0.023
Read data: 0.00010561943054199219
iter 2023 (epoch 3), train_loss = 3.012, time/batch = 0.029
Read data: 0.00012230873107910156
iter 2024 (epoch 3), train_loss = 3.190, time/batch = 0.027
Read data: 0.00023937225341796875
iter 2025 (epoch 3), train_loss = 3.101, time/batch = 0.027
Read data: 0.00013256072998046875
iter 2026 (epoch 3), train_loss = 3.236, time/batch = 0.026
Read data: 0.00011086463928222656
iter 2027 (epoch 3), train_loss = 3.282, time/batch = 0.030
Read data: 0.00012230873107910156
iter 2028 (epoch 3), train_loss = 3.085, time/batch = 0.025
Read data: 0.00015115737915039062
iter 2029 (epoch 3), train_loss = 3.188, time/batch = 0.030
Read data: 9.870529174804688e-05
iter 2030 (epoch 3), train_loss = 3.272, time/batch = 0.024
Read data: 0.00012493133544921875
iter 2031 (epoch 3), train_loss = 2.952, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 2032 (epoch 3), train_loss = 3.328, time/batch = 0.028
Read data: 0.00010251998901367188
iter 2033 (epoch 3), train_loss = 3.445, time/batch = 0.021
Read data: 0.00011801719665527344
iter 2034 (epoch 3), train_loss = 3.117, time/batch = 0.026
Read data: 0.00011730194091796875
iter 2035 (epoch 3), train_loss = 3.323, time/batch = 0.024
Read data: 9.918212890625e-05
iter 2036 (epoch 3), train_loss = 3.049, time/batch = 0.031
Read data: 0.00012540817260742188
iter 2037 (epoch 3), train_loss = 3.452, time/batch = 0.032
Read data: 0.00010323524475097656
iter 2038 (epoch 3), train_loss = 3.132, time/batch = 0.022
Read data: 0.000125885009765625
iter 2039 (epoch 3), train_loss = 3.160, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 2040 (epoch 3), train_loss = 3.386, time/batch = 0.026
Read data: 0.00011181831359863281
iter 2041 (epoch 3), train_loss = 3.249, time/batch = 0.023
Read data: 0.0001125335693359375
iter 2042 (epoch 3), train_loss = 3.236, time/batch = 0.027
Read data: 0.00011610984802246094
iter 2043 (epoch 3), train_loss = 3.269, time/batch = 0.034
Read data: 0.00011873245239257812
iter 2044 (epoch 3), train_loss = 3.551, time/batch = 0.032
Read data: 0.00015783309936523438
iter 2045 (epoch 3), train_loss = 2.954, time/batch = 0.023
Read data: 0.00010251998901367188
iter 2046 (epoch 3), train_loss = 3.240, time/batch = 0.026
Read data: 0.00011539459228515625
iter 2047 (epoch 3), train_loss = 3.436, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 2048 (epoch 3), train_loss = 3.307, time/batch = 0.025
Read data: 0.00015878677368164062
iter 2049 (epoch 3), train_loss = 3.424, time/batch = 0.020
Read data: 9.036064147949219e-05
iter 2050 (epoch 3), train_loss = 3.212, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 2051 (epoch 3), train_loss = 3.891, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 2052 (epoch 3), train_loss = 3.019, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 2053 (epoch 3), train_loss = 3.089, time/batch = 0.022
Read data: 8.392333984375e-05
iter 2054 (epoch 3), train_loss = 3.060, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 2055 (epoch 3), train_loss = 3.123, time/batch = 0.021
Read data: 8.225440979003906e-05
iter 2056 (epoch 3), train_loss = 3.119, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 2057 (epoch 3), train_loss = 3.197, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 2058 (epoch 3), train_loss = 3.813, time/batch = 0.021
Read data: 0.00010752677917480469
iter 2059 (epoch 3), train_loss = 3.327, time/batch = 0.018
Read data: 7.033348083496094e-05
iter 2060 (epoch 3), train_loss = 3.487, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 2061 (epoch 3), train_loss = 3.566, time/batch = 0.029
Read data: 9.894371032714844e-05
iter 2062 (epoch 3), train_loss = 3.250, time/batch = 0.021
Read data: 0.00013875961303710938
iter 2063 (epoch 3), train_loss = 3.126, time/batch = 0.023
Read data: 7.009506225585938e-05
iter 2064 (epoch 3), train_loss = 2.751, time/batch = 0.023
Read data: 0.00013685226440429688
iter 2065 (epoch 3), train_loss = 3.332, time/batch = 0.027
Read data: 0.00010156631469726562
iter 2066 (epoch 3), train_loss = 3.072, time/batch = 0.018
Read data: 9.417533874511719e-05
iter 2067 (epoch 3), train_loss = 3.250, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 2068 (epoch 3), train_loss = 3.079, time/batch = 0.020
Read data: 0.00016307830810546875
iter 2069 (epoch 3), train_loss = 2.979, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 2070 (epoch 3), train_loss = 3.253, time/batch = 0.033
Read data: 0.00016760826110839844
iter 2071 (epoch 3), train_loss = 2.618, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 2072 (epoch 3), train_loss = 3.087, time/batch = 0.039
Read data: 8.678436279296875e-05
iter 2073 (epoch 3), train_loss = 3.373, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 2074 (epoch 3), train_loss = 3.334, time/batch = 0.031
Read data: 0.00033664703369140625
iter 2075 (epoch 3), train_loss = 3.210, time/batch = 0.021
Read data: 0.00010418891906738281
iter 2076 (epoch 3), train_loss = 3.608, time/batch = 0.029
Read data: 0.00012969970703125
iter 2077 (epoch 3), train_loss = 3.140, time/batch = 0.018
Read data: 0.00015163421630859375
iter 2078 (epoch 3), train_loss = 2.930, time/batch = 0.026
Read data: 0.00014662742614746094
iter 2079 (epoch 3), train_loss = 3.095, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 2080 (epoch 3), train_loss = 3.192, time/batch = 0.029
Read data: 0.0001614093780517578
iter 2081 (epoch 3), train_loss = 3.416, time/batch = 0.021
Read data: 0.00012254714965820312
iter 2082 (epoch 3), train_loss = 3.299, time/batch = 0.026
Read data: 0.00013136863708496094
iter 2083 (epoch 3), train_loss = 2.962, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 2084 (epoch 3), train_loss = 3.508, time/batch = 0.022
Read data: 0.00013899803161621094
iter 2085 (epoch 3), train_loss = 3.220, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 2086 (epoch 3), train_loss = 3.110, time/batch = 0.025
Read data: 0.00013685226440429688
iter 2087 (epoch 3), train_loss = 3.269, time/batch = 0.030
Read data: 0.0001266002655029297
iter 2088 (epoch 3), train_loss = 2.738, time/batch = 0.025
Read data: 0.00014090538024902344
iter 2089 (epoch 3), train_loss = 3.547, time/batch = 0.024
Read data: 0.00011992454528808594
iter 2090 (epoch 3), train_loss = 3.299, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 2091 (epoch 3), train_loss = 3.102, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 2092 (epoch 3), train_loss = 3.059, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 2093 (epoch 3), train_loss = 3.235, time/batch = 0.032
Read data: 6.747245788574219e-05
iter 2094 (epoch 3), train_loss = 2.733, time/batch = 0.020
Read data: 0.0001277923583984375
iter 2095 (epoch 3), train_loss = 3.335, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 2096 (epoch 3), train_loss = 3.219, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 2097 (epoch 3), train_loss = 3.202, time/batch = 0.025
Read data: 7.2479248046875e-05
iter 2098 (epoch 3), train_loss = 3.193, time/batch = 0.026
Read data: 0.0001456737518310547
iter 2099 (epoch 3), train_loss = 3.366, time/batch = 0.033
Read data: 0.00021696090698242188
iter 2100 (epoch 3), train_loss = 3.204, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 2101 (epoch 3), train_loss = 2.670, time/batch = 0.024
Read data: 6.771087646484375e-05
iter 2102 (epoch 3), train_loss = 3.614, time/batch = 0.034
Read data: 9.250640869140625e-05
iter 2103 (epoch 3), train_loss = 3.379, time/batch = 0.021
Read data: 7.915496826171875e-05
iter 2104 (epoch 3), train_loss = 3.854, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 2105 (epoch 3), train_loss = 2.994, time/batch = 0.018
Read data: 7.700920104980469e-05
iter 2106 (epoch 3), train_loss = 3.777, time/batch = 0.027
Read data: 0.00012969970703125
iter 2107 (epoch 3), train_loss = 3.095, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 2108 (epoch 3), train_loss = 3.189, time/batch = 0.028
Read data: 0.00017404556274414062
iter 2109 (epoch 3), train_loss = 3.204, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 2110 (epoch 3), train_loss = 3.579, time/batch = 0.021
Read data: 0.0001518726348876953
iter 2111 (epoch 3), train_loss = 3.271, time/batch = 0.022
Read data: 0.00020384788513183594
iter 2112 (epoch 3), train_loss = 3.073, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 2113 (epoch 3), train_loss = 3.107, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 2114 (epoch 3), train_loss = 3.210, time/batch = 0.021
Read data: 0.0001354217529296875
iter 2115 (epoch 3), train_loss = 3.119, time/batch = 0.031
Read data: 0.00012063980102539062
iter 2116 (epoch 3), train_loss = 3.324, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 2117 (epoch 3), train_loss = 3.650, time/batch = 0.024
Read data: 7.462501525878906e-05
iter 2118 (epoch 3), train_loss = 3.181, time/batch = 0.025
Read data: 0.00016617774963378906
iter 2119 (epoch 3), train_loss = 3.310, time/batch = 0.021
Read data: 0.00023794174194335938
iter 2120 (epoch 3), train_loss = 3.148, time/batch = 0.021
Read data: 8.988380432128906e-05
iter 2121 (epoch 3), train_loss = 3.254, time/batch = 0.025
Read data: 7.033348083496094e-05
iter 2122 (epoch 3), train_loss = 3.081, time/batch = 0.023
Read data: 0.00013375282287597656
iter 2123 (epoch 3), train_loss = 3.568, time/batch = 0.020
Read data: 9.274482727050781e-05
iter 2124 (epoch 3), train_loss = 3.773, time/batch = 0.032
Read data: 0.00023412704467773438
iter 2125 (epoch 3), train_loss = 3.056, time/batch = 0.024
Read data: 0.0001049041748046875
iter 2126 (epoch 3), train_loss = 2.949, time/batch = 0.018
Read data: 8.535385131835938e-05
iter 2127 (epoch 3), train_loss = 3.442, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 2128 (epoch 3), train_loss = 3.227, time/batch = 0.035
Read data: 9.393692016601562e-05
iter 2129 (epoch 3), train_loss = 3.483, time/batch = 0.019
Read data: 8.606910705566406e-05
iter 2130 (epoch 3), train_loss = 3.364, time/batch = 0.021
Read data: 0.00013017654418945312
iter 2131 (epoch 3), train_loss = 3.299, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 2132 (epoch 3), train_loss = 3.262, time/batch = 0.025
Read data: 0.0001354217529296875
iter 2133 (epoch 3), train_loss = 3.235, time/batch = 0.021
Read data: 0.00012135505676269531
iter 2134 (epoch 3), train_loss = 3.559, time/batch = 0.020
Read data: 9.250640869140625e-05
iter 2135 (epoch 3), train_loss = 3.209, time/batch = 0.023
Read data: 9.1552734375e-05
iter 2136 (epoch 3), train_loss = 3.267, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 2137 (epoch 3), train_loss = 3.279, time/batch = 0.023
Read data: 0.00012063980102539062
iter 2138 (epoch 3), train_loss = 3.396, time/batch = 0.019
Read data: 8.58306884765625e-05
iter 2139 (epoch 3), train_loss = 3.492, time/batch = 0.021
Read data: 8.058547973632812e-05
iter 2140 (epoch 3), train_loss = 2.955, time/batch = 0.021
Read data: 0.00794363021850586
iter 2141 (epoch 3), train_loss = 2.913, time/batch = 0.025
Read data: 7.081031799316406e-05
iter 2142 (epoch 3), train_loss = 3.309, time/batch = 0.018
Read data: 8.034706115722656e-05
iter 2143 (epoch 3), train_loss = 3.024, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 2144 (epoch 3), train_loss = 3.512, time/batch = 0.018
Read data: 0.011510848999023438
iter 2145 (epoch 3), train_loss = 3.525, time/batch = 0.029
Read data: 7.152557373046875e-05
iter 2146 (epoch 3), train_loss = 3.195, time/batch = 0.024
Read data: 0.00011372566223144531
iter 2147 (epoch 3), train_loss = 3.062, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 2148 (epoch 3), train_loss = 3.304, time/batch = 0.026
Read data: 0.00016164779663085938
iter 2149 (epoch 3), train_loss = 2.839, time/batch = 0.022
Read data: 0.00021004676818847656
iter 2150 (epoch 3), train_loss = 3.044, time/batch = 0.021
Read data: 8.320808410644531e-05
iter 2151 (epoch 3), train_loss = 3.245, time/batch = 0.033
Read data: 8.726119995117188e-05
iter 2152 (epoch 3), train_loss = 3.337, time/batch = 0.032
Read data: 0.0001385211944580078
iter 2153 (epoch 3), train_loss = 3.427, time/batch = 0.025
Read data: 6.794929504394531e-05
iter 2154 (epoch 3), train_loss = 3.041, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 2155 (epoch 3), train_loss = 2.916, time/batch = 0.020
Read data: 0.0001957416534423828
iter 2156 (epoch 3), train_loss = 3.553, time/batch = 0.028
Read data: 0.00013899803161621094
iter 2157 (epoch 3), train_loss = 3.217, time/batch = 0.022
Read data: 7.224082946777344e-05
iter 2158 (epoch 3), train_loss = 3.070, time/batch = 0.024
Read data: 0.00011205673217773438
iter 2159 (epoch 3), train_loss = 3.185, time/batch = 0.025
Read data: 0.00013399124145507812
iter 2160 (epoch 3), train_loss = 3.504, time/batch = 0.031
Read data: 0.0001392364501953125
iter 2161 (epoch 3), train_loss = 3.317, time/batch = 0.021
Read data: 6.866455078125e-05
iter 2162 (epoch 3), train_loss = 3.375, time/batch = 0.026
Read data: 6.699562072753906e-05
iter 2163 (epoch 3), train_loss = 3.332, time/batch = 0.023
Read data: 0.00014162063598632812
iter 2164 (epoch 3), train_loss = 3.348, time/batch = 0.034
Read data: 9.131431579589844e-05
iter 2165 (epoch 3), train_loss = 3.158, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 2166 (epoch 3), train_loss = 3.481, time/batch = 0.025
Read data: 7.43865966796875e-05
iter 2167 (epoch 3), train_loss = 2.944, time/batch = 0.020
Read data: 0.00014972686767578125
iter 2168 (epoch 3), train_loss = 3.509, time/batch = 0.035
Read data: 9.34600830078125e-05
iter 2169 (epoch 3), train_loss = 3.079, time/batch = 0.023
Read data: 7.43865966796875e-05
iter 2170 (epoch 3), train_loss = 3.925, time/batch = 0.023
Read data: 7.271766662597656e-05
iter 2171 (epoch 3), train_loss = 3.421, time/batch = 0.036
Read data: 9.179115295410156e-05
iter 2172 (epoch 3), train_loss = 3.575, time/batch = 0.029
Read data: 9.34600830078125e-05
iter 2173 (epoch 3), train_loss = 3.230, time/batch = 0.024
Read data: 6.866455078125e-05
iter 2174 (epoch 3), train_loss = 3.215, time/batch = 0.022
Read data: 0.00027871131896972656
iter 2175 (epoch 3), train_loss = 2.796, time/batch = 0.027
Read data: 0.0001323223114013672
iter 2176 (epoch 3), train_loss = 3.007, time/batch = 0.019
Read data: 9.322166442871094e-05
iter 2177 (epoch 3), train_loss = 3.346, time/batch = 0.021
Read data: 7.176399230957031e-05
iter 2178 (epoch 3), train_loss = 3.449, time/batch = 0.024
Read data: 0.00010609626770019531
iter 2179 (epoch 3), train_loss = 3.434, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 2180 (epoch 3), train_loss = 2.952, time/batch = 0.019
Read data: 9.083747863769531e-05
iter 2181 (epoch 3), train_loss = 3.477, time/batch = 0.024
Read data: 7.05718994140625e-05
iter 2182 (epoch 3), train_loss = 3.803, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 2183 (epoch 3), train_loss = 2.859, time/batch = 0.022
Read data: 0.00010085105895996094
iter 2184 (epoch 3), train_loss = 3.479, time/batch = 0.025
Read data: 0.00015401840209960938
iter 2185 (epoch 3), train_loss = 2.786, time/batch = 0.023
Read data: 7.128715515136719e-05
iter 2186 (epoch 3), train_loss = 3.327, time/batch = 0.020
Read data: 9.489059448242188e-05
iter 2187 (epoch 3), train_loss = 3.260, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 2188 (epoch 3), train_loss = 3.498, time/batch = 0.027
Read data: 0.0001399517059326172
iter 2189 (epoch 3), train_loss = 2.909, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 2190 (epoch 3), train_loss = 3.010, time/batch = 0.022
Read data: 9.1552734375e-05
iter 2191 (epoch 3), train_loss = 3.487, time/batch = 0.026
Read data: 0.00011301040649414062
iter 2192 (epoch 3), train_loss = 3.370, time/batch = 0.024
Read data: 0.00013399124145507812
iter 2193 (epoch 3), train_loss = 3.107, time/batch = 0.028
Read data: 9.584426879882812e-05
iter 2194 (epoch 3), train_loss = 3.384, time/batch = 0.022
Read data: 0.0001780986785888672
iter 2195 (epoch 3), train_loss = 3.353, time/batch = 0.030
Read data: 0.00010418891906738281
iter 2196 (epoch 3), train_loss = 3.599, time/batch = 0.026
Read data: 0.0001266002655029297
iter 2197 (epoch 3), train_loss = 3.244, time/batch = 0.022
Read data: 9.417533874511719e-05
iter 2198 (epoch 3), train_loss = 2.995, time/batch = 0.023
Read data: 0.00011181831359863281
iter 2199 (epoch 3), train_loss = 2.986, time/batch = 0.028
Read data: 0.0002582073211669922
iter 2200 (epoch 3), train_loss = 3.287, time/batch = 0.036
Read data: 0.00011730194091796875
iter 2201 (epoch 3), train_loss = 3.417, time/batch = 0.027
Read data: 0.00010824203491210938
iter 2202 (epoch 3), train_loss = 3.342, time/batch = 0.025
Read data: 0.0001327991485595703
iter 2203 (epoch 3), train_loss = 2.964, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 2204 (epoch 3), train_loss = 3.451, time/batch = 0.027
Read data: 0.00011587142944335938
iter 2205 (epoch 3), train_loss = 3.553, time/batch = 0.032
Read data: 9.059906005859375e-05
iter 2206 (epoch 3), train_loss = 3.080, time/batch = 0.025
Read data: 0.00012946128845214844
iter 2207 (epoch 3), train_loss = 3.327, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 2208 (epoch 3), train_loss = 3.215, time/batch = 0.024
Read data: 0.00013971328735351562
iter 2209 (epoch 3), train_loss = 3.282, time/batch = 0.023
Read data: 0.00010204315185546875
iter 2210 (epoch 3), train_loss = 3.144, time/batch = 0.028
Read data: 0.00011515617370605469
iter 2211 (epoch 3), train_loss = 3.330, time/batch = 0.025
Read data: 0.00011348724365234375
iter 2212 (epoch 3), train_loss = 3.042, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 2213 (epoch 3), train_loss = 3.296, time/batch = 0.025
Read data: 0.00011587142944335938
iter 2214 (epoch 3), train_loss = 3.251, time/batch = 0.024
Read data: 0.00011420249938964844
iter 2215 (epoch 3), train_loss = 3.160, time/batch = 0.032
Read data: 7.033348083496094e-05
iter 2216 (epoch 3), train_loss = 3.177, time/batch = 0.020
Read data: 9.72747802734375e-05
iter 2217 (epoch 3), train_loss = 3.477, time/batch = 0.027
Read data: 7.557868957519531e-05
iter 2218 (epoch 3), train_loss = 3.016, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 2219 (epoch 3), train_loss = 3.121, time/batch = 0.020
Read data: 0.00010800361633300781
iter 2220 (epoch 3), train_loss = 3.264, time/batch = 0.023
Read data: 0.00024247169494628906
iter 2221 (epoch 3), train_loss = 3.146, time/batch = 0.023
Read data: 0.00011563301086425781
iter 2222 (epoch 3), train_loss = 3.226, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 2223 (epoch 3), train_loss = 2.918, time/batch = 0.018
Read data: 7.367134094238281e-05
iter 2224 (epoch 3), train_loss = 3.458, time/batch = 0.021
Read data: 0.00010776519775390625
iter 2225 (epoch 3), train_loss = 2.788, time/batch = 0.030
Read data: 6.794929504394531e-05
iter 2226 (epoch 3), train_loss = 3.139, time/batch = 0.024
Read data: 0.00011110305786132812
iter 2227 (epoch 3), train_loss = 3.205, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 2228 (epoch 3), train_loss = 2.727, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 2229 (epoch 3), train_loss = 3.240, time/batch = 0.026
Read data: 0.00019049644470214844
iter 2230 (epoch 3), train_loss = 3.625, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 2231 (epoch 3), train_loss = 3.192, time/batch = 0.021
Read data: 7.700920104980469e-05
iter 2232 (epoch 3), train_loss = 2.868, time/batch = 0.024
Read data: 0.00012540817260742188
iter 2233 (epoch 3), train_loss = 2.808, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 2234 (epoch 3), train_loss = 3.045, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 2235 (epoch 3), train_loss = 3.190, time/batch = 0.020
Read data: 7.62939453125e-05
iter 2236 (epoch 3), train_loss = 3.034, time/batch = 0.021
Read data: 9.942054748535156e-05
iter 2237 (epoch 3), train_loss = 2.804, time/batch = 0.020
Read data: 0.00010156631469726562
iter 2238 (epoch 3), train_loss = 3.626, time/batch = 0.020
Read data: 0.00010728836059570312
iter 2239 (epoch 3), train_loss = 3.053, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 2240 (epoch 3), train_loss = 3.208, time/batch = 0.021
Read data: 0.00012159347534179688
iter 2241 (epoch 3), train_loss = 2.994, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 2242 (epoch 3), train_loss = 2.833, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 2243 (epoch 3), train_loss = 3.194, time/batch = 0.031
Read data: 7.605552673339844e-05
iter 2244 (epoch 3), train_loss = 3.221, time/batch = 0.024
Read data: 0.00012135505676269531
iter 2245 (epoch 3), train_loss = 3.291, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 2246 (epoch 3), train_loss = 3.412, time/batch = 0.022
Read data: 0.00010585784912109375
iter 2247 (epoch 3), train_loss = 3.162, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 2248 (epoch 3), train_loss = 2.910, time/batch = 0.024
Read data: 0.00011444091796875
iter 2249 (epoch 3), train_loss = 3.423, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 2250 (epoch 3), train_loss = 3.564, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 2251 (epoch 3), train_loss = 3.534, time/batch = 0.027
Read data: 7.367134094238281e-05
iter 2252 (epoch 3), train_loss = 3.249, time/batch = 0.031
Read data: 0.00010561943054199219
iter 2253 (epoch 3), train_loss = 3.071, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 2254 (epoch 3), train_loss = 2.829, time/batch = 0.023
Read data: 0.00014162063598632812
iter 2255 (epoch 3), train_loss = 3.345, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 2256 (epoch 3), train_loss = 3.232, time/batch = 0.027
Read data: 0.00016570091247558594
iter 2257 (epoch 3), train_loss = 3.450, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 2258 (epoch 3), train_loss = 2.714, time/batch = 0.018
Read data: 9.298324584960938e-05
iter 2259 (epoch 3), train_loss = 2.909, time/batch = 0.024
Read data: 0.0001227855682373047
iter 2260 (epoch 3), train_loss = 3.085, time/batch = 0.023
Read data: 0.0001437664031982422
iter 2261 (epoch 3), train_loss = 3.175, time/batch = 0.028
Read data: 0.00010251998901367188
iter 2262 (epoch 3), train_loss = 3.060, time/batch = 0.024
Read data: 0.0001163482666015625
iter 2263 (epoch 3), train_loss = 3.064, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 2264 (epoch 3), train_loss = 3.419, time/batch = 0.024
Read data: 0.00011348724365234375
iter 2265 (epoch 3), train_loss = 2.809, time/batch = 0.023
Read data: 0.00013399124145507812
iter 2266 (epoch 3), train_loss = 3.745, time/batch = 0.032
Read data: 0.00011944770812988281
iter 2267 (epoch 3), train_loss = 3.335, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 2268 (epoch 3), train_loss = 3.126, time/batch = 0.025
Read data: 0.00017380714416503906
iter 2269 (epoch 3), train_loss = 3.344, time/batch = 0.027
Read data: 0.0001087188720703125
iter 2270 (epoch 3), train_loss = 2.639, time/batch = 0.023
Read data: 0.0001251697540283203
iter 2271 (epoch 3), train_loss = 3.310, time/batch = 0.027
Read data: 0.00010228157043457031
iter 2272 (epoch 3), train_loss = 3.025, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 2273 (epoch 3), train_loss = 3.027, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 2274 (epoch 3), train_loss = 2.944, time/batch = 0.030
Read data: 0.00013256072998046875
iter 2275 (epoch 3), train_loss = 3.217, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 2276 (epoch 3), train_loss = 3.123, time/batch = 0.025
Read data: 0.00016570091247558594
iter 2277 (epoch 3), train_loss = 3.301, time/batch = 0.024
Read data: 0.00011515617370605469
iter 2278 (epoch 3), train_loss = 3.123, time/batch = 0.020
Read data: 0.00014400482177734375
iter 2279 (epoch 3), train_loss = 3.162, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 2280 (epoch 3), train_loss = 3.121, time/batch = 0.032
Read data: 0.0001327991485595703
iter 2281 (epoch 3), train_loss = 3.072, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 2282 (epoch 3), train_loss = 2.909, time/batch = 0.020
Read data: 0.008708715438842773
iter 2283 (epoch 3), train_loss = 3.271, time/batch = 0.020
Read data: 5.9604644775390625e-05
iter 2284 (epoch 3), train_loss = 2.731, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 2285 (epoch 3), train_loss = 3.678, time/batch = 0.027
Read data: 7.343292236328125e-05
iter 2286 (epoch 3), train_loss = 3.574, time/batch = 0.022
Read data: 0.008263349533081055
iter 2287 (epoch 3), train_loss = 3.123, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 2288 (epoch 3), train_loss = 2.776, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 2289 (epoch 3), train_loss = 3.128, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 2290 (epoch 3), train_loss = 3.507, time/batch = 0.026
Read data: 0.00012922286987304688
iter 2291 (epoch 3), train_loss = 2.847, time/batch = 0.024
Read data: 7.510185241699219e-05
iter 2292 (epoch 3), train_loss = 3.115, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 2293 (epoch 3), train_loss = 3.313, time/batch = 0.022
Read data: 8.034706115722656e-05
iter 2294 (epoch 3), train_loss = 2.998, time/batch = 0.023
Read data: 0.00018739700317382812
iter 2295 (epoch 3), train_loss = 3.107, time/batch = 0.020
Read data: 6.890296936035156e-05
iter 2296 (epoch 3), train_loss = 3.073, time/batch = 0.026
Read data: 0.00012969970703125
iter 2297 (epoch 3), train_loss = 2.966, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 2298 (epoch 3), train_loss = 3.034, time/batch = 0.030
Read data: 8.916854858398438e-05
iter 2299 (epoch 3), train_loss = 3.033, time/batch = 0.023
Read data: 0.00024008750915527344
iter 2300 (epoch 3), train_loss = 2.556, time/batch = 0.022
Read data: 7.343292236328125e-05
iter 2301 (epoch 3), train_loss = 3.092, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 2302 (epoch 3), train_loss = 3.342, time/batch = 0.022
Read data: 0.0065500736236572266
iter 2303 (epoch 3), train_loss = 2.937, time/batch = 0.019
Read data: 5.8650970458984375e-05
iter 2304 (epoch 3), train_loss = 2.982, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 2305 (epoch 3), train_loss = 3.039, time/batch = 0.025
Read data: 6.914138793945312e-05
iter 2306 (epoch 3), train_loss = 2.854, time/batch = 0.025
Read data: 0.008517026901245117
iter 2307 (epoch 3), train_loss = 3.227, time/batch = 0.019
Read data: 5.698204040527344e-05
iter 2308 (epoch 3), train_loss = 3.748, time/batch = 0.026
Read data: 0.0001285076141357422
iter 2309 (epoch 3), train_loss = 2.919, time/batch = 0.025
Read data: 6.794929504394531e-05
iter 2310 (epoch 3), train_loss = 2.824, time/batch = 0.024
Read data: 0.006510257720947266
iter 2311 (epoch 3), train_loss = 3.195, time/batch = 0.032
Read data: 0.00012254714965820312
iter 2312 (epoch 3), train_loss = 3.030, time/batch = 0.021
Read data: 0.00011849403381347656
iter 2313 (epoch 3), train_loss = 3.096, time/batch = 0.023
Read data: 0.0001308917999267578
iter 2314 (epoch 3), train_loss = 3.622, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 2315 (epoch 3), train_loss = 3.075, time/batch = 0.019
Read data: 5.6743621826171875e-05
iter 2316 (epoch 3), train_loss = 3.422, time/batch = 0.022
Read data: 0.00011444091796875
iter 2317 (epoch 3), train_loss = 2.926, time/batch = 0.023
Read data: 6.818771362304688e-05
iter 2318 (epoch 3), train_loss = 2.842, time/batch = 0.020
Read data: 0.006664276123046875
iter 2319 (epoch 3), train_loss = 2.897, time/batch = 0.023
Read data: 7.081031799316406e-05
iter 2320 (epoch 3), train_loss = 3.672, time/batch = 0.027
Read data: 0.0001552104949951172
iter 2321 (epoch 3), train_loss = 2.957, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 2322 (epoch 3), train_loss = 3.463, time/batch = 0.025
Read data: 0.0031342506408691406
iter 2323 (epoch 3), train_loss = 3.570, time/batch = 0.019
Read data: 5.3882598876953125e-05
iter 2324 (epoch 3), train_loss = 2.755, time/batch = 0.027
Read data: 0.0001647472381591797
iter 2325 (epoch 3), train_loss = 3.275, time/batch = 0.028
Read data: 6.890296936035156e-05
iter 2326 (epoch 3), train_loss = 3.146, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 2327 (epoch 3), train_loss = 3.416, time/batch = 0.021
Read data: 6.914138793945312e-05
iter 2328 (epoch 3), train_loss = 2.710, time/batch = 0.020
Read data: 0.00012135505676269531
iter 2329 (epoch 3), train_loss = 3.120, time/batch = 0.020
Read data: 8.082389831542969e-05
iter 2330 (epoch 3), train_loss = 3.665, time/batch = 0.020
Read data: 0.013672828674316406
iter 2331 (epoch 3), train_loss = 3.276, time/batch = 0.030
Read data: 7.462501525878906e-05
iter 2332 (epoch 3), train_loss = 2.832, time/batch = 0.027
Read data: 0.0001163482666015625
iter 2333 (epoch 3), train_loss = 3.485, time/batch = 0.028
Read data: 9.584426879882812e-05
iter 2334 (epoch 3), train_loss = 3.303, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 2335 (epoch 3), train_loss = 3.412, time/batch = 0.023
Read data: 7.200241088867188e-05
iter 2336 (epoch 3), train_loss = 3.201, time/batch = 0.032
Read data: 0.00011682510375976562
iter 2337 (epoch 3), train_loss = 3.163, time/batch = 0.029
Read data: 0.00013899803161621094
iter 2338 (epoch 3), train_loss = 3.373, time/batch = 0.030
Read data: 0.00013327598571777344
iter 2339 (epoch 3), train_loss = 2.771, time/batch = 0.022
Read data: 7.009506225585938e-05
iter 2340 (epoch 3), train_loss = 3.479, time/batch = 0.025
Read data: 0.00011754035949707031
iter 2341 (epoch 3), train_loss = 3.122, time/batch = 0.025
Read data: 0.0001246929168701172
iter 2342 (epoch 3), train_loss = 3.579, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 2343 (epoch 3), train_loss = 3.298, time/batch = 0.021
Read data: 7.343292236328125e-05
iter 2344 (epoch 3), train_loss = 3.631, time/batch = 0.029
Read data: 0.00010085105895996094
iter 2345 (epoch 3), train_loss = 3.512, time/batch = 0.031
Read data: 0.00013494491577148438
iter 2346 (epoch 3), train_loss = 3.180, time/batch = 0.027
Read data: 0.00012564659118652344
iter 2347 (epoch 3), train_loss = 2.664, time/batch = 0.021
Read data: 8.058547973632812e-05
iter 2348 (epoch 3), train_loss = 3.407, time/batch = 0.031
Read data: 9.560585021972656e-05
iter 2349 (epoch 3), train_loss = 3.346, time/batch = 0.028
Read data: 0.00020599365234375
iter 2350 (epoch 3), train_loss = 2.811, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 2351 (epoch 3), train_loss = 3.279, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 2352 (epoch 3), train_loss = 3.389, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 2353 (epoch 3), train_loss = 2.893, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 2354 (epoch 3), train_loss = 3.289, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 2355 (epoch 3), train_loss = 2.867, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 2356 (epoch 3), train_loss = 3.343, time/batch = 0.029
Read data: 8.988380432128906e-05
iter 2357 (epoch 3), train_loss = 3.371, time/batch = 0.028
Read data: 0.0002105236053466797
iter 2358 (epoch 3), train_loss = 3.572, time/batch = 0.034
Read data: 8.7738037109375e-05
iter 2359 (epoch 3), train_loss = 2.812, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 2360 (epoch 3), train_loss = 2.852, time/batch = 0.024
Read data: 0.000118255615234375
iter 2361 (epoch 3), train_loss = 3.238, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 2362 (epoch 3), train_loss = 3.585, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 2363 (epoch 3), train_loss = 2.998, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 2364 (epoch 3), train_loss = 2.829, time/batch = 0.024
Read data: 0.00013709068298339844
iter 2365 (epoch 3), train_loss = 3.404, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 2366 (epoch 3), train_loss = 2.891, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 2367 (epoch 3), train_loss = 3.411, time/batch = 0.036
Read data: 7.963180541992188e-05
iter 2368 (epoch 3), train_loss = 3.052, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 2369 (epoch 3), train_loss = 3.167, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 2370 (epoch 3), train_loss = 3.039, time/batch = 0.029
Read data: 0.00011396408081054688
iter 2371 (epoch 3), train_loss = 3.268, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 2372 (epoch 3), train_loss = 2.710, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 2373 (epoch 3), train_loss = 3.240, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 2374 (epoch 3), train_loss = 3.752, time/batch = 0.021
Read data: 8.368492126464844e-05
iter 2375 (epoch 3), train_loss = 3.487, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 2376 (epoch 3), train_loss = 2.891, time/batch = 0.018
Read data: 0.0001595020294189453
iter 2377 (epoch 3), train_loss = 3.038, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 2378 (epoch 3), train_loss = 3.304, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 2379 (epoch 3), train_loss = 3.094, time/batch = 0.020
Read data: 8.416175842285156e-05
iter 2380 (epoch 3), train_loss = 3.423, time/batch = 0.020
Read data: 0.00014328956604003906
iter 2381 (epoch 3), train_loss = 3.368, time/batch = 0.034
Read data: 8.344650268554688e-05
iter 2382 (epoch 3), train_loss = 3.233, time/batch = 0.023
Read data: 0.00015544891357421875
iter 2383 (epoch 3), train_loss = 3.229, time/batch = 0.020
Read data: 0.00010514259338378906
iter 2384 (epoch 3), train_loss = 2.752, time/batch = 0.020
Read data: 0.00017404556274414062
iter 2385 (epoch 3), train_loss = 3.574, time/batch = 0.020
Read data: 0.0001373291015625
iter 2386 (epoch 3), train_loss = 3.162, time/batch = 0.018
Read data: 0.00012373924255371094
iter 2387 (epoch 3), train_loss = 3.234, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 2388 (epoch 3), train_loss = 3.458, time/batch = 0.022
Read data: 0.00012922286987304688
iter 2389 (epoch 3), train_loss = 2.995, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 2390 (epoch 3), train_loss = 3.160, time/batch = 0.019
Read data: 8.797645568847656e-05
iter 2391 (epoch 3), train_loss = 3.142, time/batch = 0.025
Read data: 0.0009372234344482422
iter 2392 (epoch 3), train_loss = 3.108, time/batch = 0.026
Read data: 0.00013136863708496094
iter 2393 (epoch 3), train_loss = 2.816, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 2394 (epoch 3), train_loss = 2.873, time/batch = 0.020
Read data: 8.821487426757812e-05
iter 2395 (epoch 3), train_loss = 3.133, time/batch = 0.022
Read data: 8.320808410644531e-05
iter 2396 (epoch 3), train_loss = 3.266, time/batch = 0.026
Read data: 0.00013637542724609375
iter 2397 (epoch 3), train_loss = 2.952, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 2398 (epoch 3), train_loss = 3.548, time/batch = 0.021
Read data: 0.0001323223114013672
iter 2399 (epoch 3), train_loss = 3.127, time/batch = 0.025
Read data: 0.00012135505676269531
iter 2400 (epoch 3), train_loss = 3.367, time/batch = 0.019
Read data: 0.0001418590545654297
iter 2401 (epoch 4), train_loss = 3.576, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 2402 (epoch 4), train_loss = 3.050, time/batch = 0.020
Read data: 9.059906005859375e-05
iter 2403 (epoch 4), train_loss = 3.473, time/batch = 0.033
Read data: 0.00011444091796875
iter 2404 (epoch 4), train_loss = 3.247, time/batch = 0.022
Read data: 0.0001380443572998047
iter 2405 (epoch 4), train_loss = 2.860, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 2406 (epoch 4), train_loss = 2.744, time/batch = 0.020
Read data: 0.0001380443572998047
iter 2407 (epoch 4), train_loss = 2.846, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 2408 (epoch 4), train_loss = 3.384, time/batch = 0.023
Read data: 0.0002503395080566406
iter 2409 (epoch 4), train_loss = 3.018, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 2410 (epoch 4), train_loss = 3.102, time/batch = 0.020
Read data: 8.440017700195312e-05
iter 2411 (epoch 4), train_loss = 3.158, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 2412 (epoch 4), train_loss = 3.002, time/batch = 0.019
Read data: 0.00010251998901367188
iter 2413 (epoch 4), train_loss = 2.976, time/batch = 0.022
Read data: 9.298324584960938e-05
iter 2414 (epoch 4), train_loss = 3.048, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 2415 (epoch 4), train_loss = 3.181, time/batch = 0.022
Read data: 0.002402067184448242
iter 2416 (epoch 4), train_loss = 2.984, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 2417 (epoch 4), train_loss = 2.736, time/batch = 0.026
Read data: 9.822845458984375e-05
iter 2418 (epoch 4), train_loss = 3.374, time/batch = 0.022
Read data: 8.416175842285156e-05
iter 2419 (epoch 4), train_loss = 3.466, time/batch = 0.020
Read data: 0.011963605880737305
iter 2420 (epoch 4), train_loss = 3.563, time/batch = 0.018
Read data: 5.698204040527344e-05
iter 2421 (epoch 4), train_loss = 3.493, time/batch = 0.027
Read data: 9.608268737792969e-05
iter 2422 (epoch 4), train_loss = 3.152, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 2423 (epoch 4), train_loss = 3.328, time/batch = 0.024
Read data: 0.007306337356567383
iter 2424 (epoch 4), train_loss = 2.926, time/batch = 0.019
Read data: 0.0001506805419921875
iter 2425 (epoch 4), train_loss = 3.492, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 2426 (epoch 4), train_loss = 3.033, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 2427 (epoch 4), train_loss = 3.439, time/batch = 0.019
Read data: 0.01232290267944336
iter 2428 (epoch 4), train_loss = 3.419, time/batch = 0.021
Read data: 9.894371032714844e-05
iter 2429 (epoch 4), train_loss = 3.266, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 2430 (epoch 4), train_loss = 2.986, time/batch = 0.020
Read data: 8.344650268554688e-05
iter 2431 (epoch 4), train_loss = 3.119, time/batch = 0.025
Read data: 0.0066432952880859375
iter 2432 (epoch 4), train_loss = 2.829, time/batch = 0.022
Read data: 6.127357482910156e-05
iter 2433 (epoch 4), train_loss = 3.324, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 2434 (epoch 4), train_loss = 2.857, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 2435 (epoch 4), train_loss = 2.961, time/batch = 0.023
Read data: 0.007701873779296875
iter 2436 (epoch 4), train_loss = 2.877, time/batch = 0.023
Read data: 6.413459777832031e-05
iter 2437 (epoch 4), train_loss = 3.058, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 2438 (epoch 4), train_loss = 3.615, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 2439 (epoch 4), train_loss = 3.209, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 2440 (epoch 4), train_loss = 2.910, time/batch = 0.029
Read data: 0.00010037422180175781
iter 2441 (epoch 4), train_loss = 3.228, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 2442 (epoch 4), train_loss = 3.202, time/batch = 0.024
Read data: 0.0001456737518310547
iter 2443 (epoch 4), train_loss = 3.446, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 2444 (epoch 4), train_loss = 3.042, time/batch = 0.027
Read data: 9.965896606445312e-05
iter 2445 (epoch 4), train_loss = 3.514, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 2446 (epoch 4), train_loss = 3.564, time/batch = 0.029
Read data: 0.00015616416931152344
iter 2447 (epoch 4), train_loss = 2.863, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 2448 (epoch 4), train_loss = 2.864, time/batch = 0.021
Read data: 9.942054748535156e-05
iter 2449 (epoch 4), train_loss = 3.403, time/batch = 0.025
Read data: 0.00017905235290527344
iter 2450 (epoch 4), train_loss = 3.036, time/batch = 0.018
Read data: 9.131431579589844e-05
iter 2451 (epoch 4), train_loss = 2.767, time/batch = 0.028
Read data: 0.000148773193359375
iter 2452 (epoch 4), train_loss = 3.274, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 2453 (epoch 4), train_loss = 3.049, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 2454 (epoch 4), train_loss = 2.588, time/batch = 0.019
Read data: 8.726119995117188e-05
iter 2455 (epoch 4), train_loss = 2.843, time/batch = 0.032
Read data: 0.00010395050048828125
iter 2456 (epoch 4), train_loss = 3.030, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 2457 (epoch 4), train_loss = 3.067, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 2458 (epoch 4), train_loss = 3.397, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 2459 (epoch 4), train_loss = 2.750, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 2460 (epoch 4), train_loss = 3.349, time/batch = 0.020
Read data: 0.00012159347534179688
iter 2461 (epoch 4), train_loss = 3.372, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 2462 (epoch 4), train_loss = 3.096, time/batch = 0.021
Read data: 9.179115295410156e-05
iter 2463 (epoch 4), train_loss = 3.340, time/batch = 0.024
Read data: 0.011649608612060547
iter 2464 (epoch 4), train_loss = 3.575, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 2465 (epoch 4), train_loss = 2.939, time/batch = 0.020
Read data: 9.655952453613281e-05
iter 2466 (epoch 4), train_loss = 2.935, time/batch = 0.018
Read data: 8.487701416015625e-05
iter 2467 (epoch 4), train_loss = 3.492, time/batch = 0.025
Read data: 0.014258146286010742
iter 2468 (epoch 4), train_loss = 3.234, time/batch = 0.028
Read data: 7.295608520507812e-05
iter 2469 (epoch 4), train_loss = 3.451, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 2470 (epoch 4), train_loss = 3.204, time/batch = 0.021
Read data: 9.417533874511719e-05
iter 2471 (epoch 4), train_loss = 3.226, time/batch = 0.027
Read data: 0.0019147396087646484
iter 2472 (epoch 4), train_loss = 3.128, time/batch = 0.028
Read data: 7.033348083496094e-05
iter 2473 (epoch 4), train_loss = 3.099, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 2474 (epoch 4), train_loss = 3.119, time/batch = 0.020
Read data: 0.00019931793212890625
iter 2475 (epoch 4), train_loss = 3.305, time/batch = 0.021
Read data: 0.005596160888671875
iter 2476 (epoch 4), train_loss = 3.203, time/batch = 0.030
Read data: 7.510185241699219e-05
iter 2477 (epoch 4), train_loss = 2.847, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 2478 (epoch 4), train_loss = 2.856, time/batch = 0.017
Read data: 9.489059448242188e-05
iter 2479 (epoch 4), train_loss = 2.974, time/batch = 0.023
Read data: 0.010933637619018555
iter 2480 (epoch 4), train_loss = 3.182, time/batch = 0.025
Read data: 7.081031799316406e-05
iter 2481 (epoch 4), train_loss = 3.686, time/batch = 0.020
Read data: 8.559226989746094e-05
iter 2482 (epoch 4), train_loss = 3.240, time/batch = 0.020
Read data: 0.0001614093780517578
iter 2483 (epoch 4), train_loss = 3.406, time/batch = 0.023
Read data: 0.013800621032714844
iter 2484 (epoch 4), train_loss = 3.060, time/batch = 0.021
Read data: 6.866455078125e-05
iter 2485 (epoch 4), train_loss = 3.185, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 2486 (epoch 4), train_loss = 3.361, time/batch = 0.019
Read data: 8.749961853027344e-05
iter 2487 (epoch 4), train_loss = 3.024, time/batch = 0.029
Read data: 0.012120485305786133
iter 2488 (epoch 4), train_loss = 2.910, time/batch = 0.023
Read data: 7.05718994140625e-05
iter 2489 (epoch 4), train_loss = 2.965, time/batch = 0.019
Read data: 9.512901306152344e-05
iter 2490 (epoch 4), train_loss = 3.105, time/batch = 0.018
Read data: 6.151199340820312e-05
iter 2491 (epoch 4), train_loss = 3.363, time/batch = 0.025
Read data: 0.02068924903869629
iter 2492 (epoch 4), train_loss = 3.430, time/batch = 0.026
Read data: 7.390975952148438e-05
iter 2493 (epoch 4), train_loss = 3.146, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 2494 (epoch 4), train_loss = 2.950, time/batch = 0.023
Read data: 7.653236389160156e-05
iter 2495 (epoch 4), train_loss = 3.053, time/batch = 0.027
Read data: 0.003513336181640625
iter 2496 (epoch 4), train_loss = 2.579, time/batch = 0.023
Read data: 7.414817810058594e-05
iter 2497 (epoch 4), train_loss = 3.212, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 2498 (epoch 4), train_loss = 2.903, time/batch = 0.031
Read data: 0.00012421607971191406
iter 2499 (epoch 4), train_loss = 2.878, time/batch = 0.027
Read data: 0.0033080577850341797
iter 2500 (epoch 4), train_loss = 3.192, time/batch = 0.020
Read data: 6.437301635742188e-05
iter 2501 (epoch 4), train_loss = 3.374, time/batch = 0.022
Read data: 7.128715515136719e-05
iter 2502 (epoch 4), train_loss = 3.338, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 2503 (epoch 4), train_loss = 2.837, time/batch = 0.034
Read data: 9.608268737792969e-05
iter 2504 (epoch 4), train_loss = 2.811, time/batch = 0.022
Read data: 7.152557373046875e-05
iter 2505 (epoch 4), train_loss = 2.757, time/batch = 0.019
Read data: 0.0001232624053955078
iter 2506 (epoch 4), train_loss = 2.868, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 2507 (epoch 4), train_loss = 2.898, time/batch = 0.034
Read data: 9.632110595703125e-05
iter 2508 (epoch 4), train_loss = 2.995, time/batch = 0.018
Read data: 5.8650970458984375e-05
iter 2509 (epoch 4), train_loss = 2.963, time/batch = 0.018
Read data: 7.319450378417969e-05
iter 2510 (epoch 4), train_loss = 3.558, time/batch = 0.026
Read data: 6.937980651855469e-05
iter 2511 (epoch 4), train_loss = 2.977, time/batch = 0.029
Read data: 0.0031163692474365234
iter 2512 (epoch 4), train_loss = 3.215, time/batch = 0.021
Read data: 5.602836608886719e-05
iter 2513 (epoch 4), train_loss = 3.279, time/batch = 0.019
Read data: 7.653236389160156e-05
iter 2514 (epoch 4), train_loss = 3.022, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 2515 (epoch 4), train_loss = 3.181, time/batch = 0.029
Read data: 0.006946086883544922
iter 2516 (epoch 4), train_loss = 3.134, time/batch = 0.030
Read data: 5.91278076171875e-05
iter 2517 (epoch 4), train_loss = 2.711, time/batch = 0.018
Read data: 0.0001068115234375
iter 2518 (epoch 4), train_loss = 3.109, time/batch = 0.033
Read data: 7.748603820800781e-05
iter 2519 (epoch 4), train_loss = 3.320, time/batch = 0.029
Read data: 9.822845458984375e-05
iter 2520 (epoch 4), train_loss = 3.169, time/batch = 0.021
Read data: 5.7220458984375e-05
iter 2521 (epoch 4), train_loss = 2.851, time/batch = 0.018
Read data: 7.939338684082031e-05
iter 2522 (epoch 4), train_loss = 3.065, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 2523 (epoch 4), train_loss = 3.386, time/batch = 0.026
Read data: 0.009387969970703125
iter 2524 (epoch 4), train_loss = 3.212, time/batch = 0.029
Read data: 0.00015497207641601562
iter 2525 (epoch 4), train_loss = 2.887, time/batch = 0.018
Read data: 7.462501525878906e-05
iter 2526 (epoch 4), train_loss = 2.992, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 2527 (epoch 4), train_loss = 3.237, time/batch = 0.027
Read data: 0.007384061813354492
iter 2528 (epoch 4), train_loss = 3.503, time/batch = 0.018
Read data: 5.698204040527344e-05
iter 2529 (epoch 4), train_loss = 3.148, time/batch = 0.020
Read data: 7.867813110351562e-05
iter 2530 (epoch 4), train_loss = 3.313, time/batch = 0.035
Read data: 7.462501525878906e-05
iter 2531 (epoch 4), train_loss = 2.610, time/batch = 0.023
Read data: 0.004964590072631836
iter 2532 (epoch 4), train_loss = 2.668, time/batch = 0.021
Read data: 6.008148193359375e-05
iter 2533 (epoch 4), train_loss = 3.007, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 2534 (epoch 4), train_loss = 2.915, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 2535 (epoch 4), train_loss = 3.232, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 2536 (epoch 4), train_loss = 3.155, time/batch = 0.029
Read data: 5.745887756347656e-05
iter 2537 (epoch 4), train_loss = 2.888, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 2538 (epoch 4), train_loss = 3.157, time/batch = 0.024
Read data: 7.152557373046875e-05
iter 2539 (epoch 4), train_loss = 2.845, time/batch = 0.026
Read data: 0.002782106399536133
iter 2540 (epoch 4), train_loss = 2.498, time/batch = 0.018
Read data: 5.7220458984375e-05
iter 2541 (epoch 4), train_loss = 3.305, time/batch = 0.021
Read data: 7.271766662597656e-05
iter 2542 (epoch 4), train_loss = 2.957, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 2543 (epoch 4), train_loss = 2.838, time/batch = 0.026
Read data: 0.012124061584472656
iter 2544 (epoch 4), train_loss = 2.852, time/batch = 0.021
Read data: 5.817413330078125e-05
iter 2545 (epoch 4), train_loss = 2.933, time/batch = 0.021
Read data: 7.557868957519531e-05
iter 2546 (epoch 4), train_loss = 3.466, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 2547 (epoch 4), train_loss = 2.862, time/batch = 0.024
Read data: 0.014813661575317383
iter 2548 (epoch 4), train_loss = 3.211, time/batch = 0.024
Read data: 5.626678466796875e-05
iter 2549 (epoch 4), train_loss = 2.913, time/batch = 0.020
Read data: 0.0001957416534423828
iter 2550 (epoch 4), train_loss = 3.348, time/batch = 0.026
Read data: 7.367134094238281e-05
iter 2551 (epoch 4), train_loss = 3.072, time/batch = 0.022
Read data: 0.005337715148925781
iter 2552 (epoch 4), train_loss = 3.376, time/batch = 0.024
Read data: 6.0558319091796875e-05
iter 2553 (epoch 4), train_loss = 2.749, time/batch = 0.020
Read data: 8.511543273925781e-05
iter 2554 (epoch 4), train_loss = 2.670, time/batch = 0.024
Read data: 0.000125885009765625
iter 2555 (epoch 4), train_loss = 2.668, time/batch = 0.022
Read data: 0.012528419494628906
iter 2556 (epoch 4), train_loss = 3.557, time/batch = 0.019
Read data: 6.175041198730469e-05
iter 2557 (epoch 4), train_loss = 3.111, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 2558 (epoch 4), train_loss = 3.082, time/batch = 0.020
Read data: 8.249282836914062e-05
iter 2559 (epoch 4), train_loss = 3.240, time/batch = 0.018
Read data: 0.024228811264038086
iter 2560 (epoch 4), train_loss = 3.034, time/batch = 0.018
Read data: 5.793571472167969e-05
iter 2561 (epoch 4), train_loss = 3.140, time/batch = 0.023
Read data: 7.62939453125e-05
iter 2562 (epoch 4), train_loss = 3.267, time/batch = 0.025
Read data: 7.152557373046875e-05
iter 2563 (epoch 4), train_loss = 3.235, time/batch = 0.021
Read data: 0.014184951782226562
iter 2564 (epoch 4), train_loss = 2.970, time/batch = 0.019
Read data: 5.7697296142578125e-05
iter 2565 (epoch 4), train_loss = 3.254, time/batch = 0.021
Read data: 7.677078247070312e-05
iter 2566 (epoch 4), train_loss = 3.543, time/batch = 0.029
Read data: 7.009506225585938e-05
iter 2567 (epoch 4), train_loss = 3.655, time/batch = 0.027
Read data: 0.004718780517578125
iter 2568 (epoch 4), train_loss = 3.030, time/batch = 0.026
Read data: 5.936622619628906e-05
iter 2569 (epoch 4), train_loss = 3.149, time/batch = 0.020
Read data: 0.0002853870391845703
iter 2570 (epoch 4), train_loss = 3.184, time/batch = 0.034
Read data: 7.200241088867188e-05
iter 2571 (epoch 4), train_loss = 3.196, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 2572 (epoch 4), train_loss = 3.335, time/batch = 0.027
Read data: 5.698204040527344e-05
iter 2573 (epoch 4), train_loss = 3.037, time/batch = 0.019
Read data: 7.581710815429688e-05
iter 2574 (epoch 4), train_loss = 3.086, time/batch = 0.029
Read data: 7.128715515136719e-05
iter 2575 (epoch 4), train_loss = 3.036, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 2576 (epoch 4), train_loss = 3.021, time/batch = 0.029
Read data: 0.00014066696166992188
iter 2577 (epoch 4), train_loss = 3.295, time/batch = 0.028
Read data: 6.771087646484375e-05
iter 2578 (epoch 4), train_loss = 3.149, time/batch = 0.028
Read data: 0.00013208389282226562
iter 2579 (epoch 4), train_loss = 3.215, time/batch = 0.029
Read data: 9.989738464355469e-05
iter 2580 (epoch 4), train_loss = 3.067, time/batch = 0.027
Read data: 7.271766662597656e-05
iter 2581 (epoch 4), train_loss = 3.116, time/batch = 0.022
Read data: 6.628036499023438e-05
iter 2582 (epoch 4), train_loss = 3.261, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 2583 (epoch 4), train_loss = 2.985, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 2584 (epoch 4), train_loss = 3.102, time/batch = 0.021
Read data: 7.176399230957031e-05
iter 2585 (epoch 4), train_loss = 2.733, time/batch = 0.022
Read data: 7.319450378417969e-05
iter 2586 (epoch 4), train_loss = 3.525, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 2587 (epoch 4), train_loss = 3.354, time/batch = 0.031
Read data: 9.1552734375e-05
iter 2588 (epoch 4), train_loss = 2.871, time/batch = 0.021
Read data: 7.081031799316406e-05
iter 2589 (epoch 4), train_loss = 3.152, time/batch = 0.021
Read data: 7.677078247070312e-05
iter 2590 (epoch 4), train_loss = 3.069, time/batch = 0.029
Read data: 9.179115295410156e-05
iter 2591 (epoch 4), train_loss = 2.800, time/batch = 0.036
Read data: 9.083747863769531e-05
iter 2592 (epoch 4), train_loss = 3.182, time/batch = 0.023
Read data: 0.00015497207641601562
iter 2593 (epoch 4), train_loss = 3.423, time/batch = 0.027
Read data: 6.67572021484375e-05
iter 2594 (epoch 4), train_loss = 2.899, time/batch = 0.027
Read data: 9.918212890625e-05
iter 2595 (epoch 4), train_loss = 3.202, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 2596 (epoch 4), train_loss = 2.998, time/batch = 0.020
Read data: 0.00010347366333007812
iter 2597 (epoch 4), train_loss = 3.376, time/batch = 0.019
Read data: 6.961822509765625e-05
iter 2598 (epoch 4), train_loss = 2.676, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 2599 (epoch 4), train_loss = 2.856, time/batch = 0.026
Read data: 0.0001819133758544922
iter 2600 (epoch 4), train_loss = 3.145, time/batch = 0.021
Read data: 7.081031799316406e-05
iter 2601 (epoch 4), train_loss = 3.555, time/batch = 0.020
Read data: 7.271766662597656e-05
iter 2602 (epoch 4), train_loss = 3.183, time/batch = 0.027
Read data: 0.00023555755615234375
iter 2603 (epoch 4), train_loss = 3.309, time/batch = 0.032
Read data: 9.369850158691406e-05
iter 2604 (epoch 4), train_loss = 3.106, time/batch = 0.018
Read data: 7.390975952148438e-05
iter 2605 (epoch 4), train_loss = 2.957, time/batch = 0.021
Read data: 7.724761962890625e-05
iter 2606 (epoch 4), train_loss = 3.048, time/batch = 0.022
Read data: 0.00012993812561035156
iter 2607 (epoch 4), train_loss = 3.211, time/batch = 0.031
Read data: 9.584426879882812e-05
iter 2608 (epoch 4), train_loss = 3.200, time/batch = 0.023
Read data: 7.128715515136719e-05
iter 2609 (epoch 4), train_loss = 2.865, time/batch = 0.021
Read data: 7.462501525878906e-05
iter 2610 (epoch 4), train_loss = 2.754, time/batch = 0.024
Read data: 0.00011992454528808594
iter 2611 (epoch 4), train_loss = 2.835, time/batch = 0.026
Read data: 0.0001361370086669922
iter 2612 (epoch 4), train_loss = 3.339, time/batch = 0.023
Read data: 6.699562072753906e-05
iter 2613 (epoch 4), train_loss = 2.678, time/batch = 0.021
Read data: 0.00012493133544921875
iter 2614 (epoch 4), train_loss = 3.419, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 2615 (epoch 4), train_loss = 3.174, time/batch = 0.024
Read data: 0.0035216808319091797
iter 2616 (epoch 4), train_loss = 3.363, time/batch = 0.022
Read data: 7.152557373046875e-05
iter 2617 (epoch 4), train_loss = 2.755, time/batch = 0.019
Read data: 7.2479248046875e-05
iter 2618 (epoch 4), train_loss = 2.857, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 2619 (epoch 4), train_loss = 3.042, time/batch = 0.032
Read data: 0.00010132789611816406
iter 2620 (epoch 4), train_loss = 3.075, time/batch = 0.023
Read data: 7.319450378417969e-05
iter 2621 (epoch 4), train_loss = 3.107, time/batch = 0.018
Read data: 0.00011539459228515625
iter 2622 (epoch 4), train_loss = 2.905, time/batch = 0.021
Read data: 0.00013446807861328125
iter 2623 (epoch 4), train_loss = 3.103, time/batch = 0.019
Read data: 0.018750429153442383
iter 2624 (epoch 4), train_loss = 2.971, time/batch = 0.022
Read data: 0.0001595020294189453
iter 2625 (epoch 4), train_loss = 3.263, time/batch = 0.021
Read data: 7.271766662597656e-05
iter 2626 (epoch 4), train_loss = 3.333, time/batch = 0.027
Read data: 8.392333984375e-05
iter 2627 (epoch 4), train_loss = 2.648, time/batch = 0.026
Read data: 0.0035734176635742188
iter 2628 (epoch 4), train_loss = 2.827, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 2629 (epoch 4), train_loss = 3.052, time/batch = 0.023
Read data: 7.724761962890625e-05
iter 2630 (epoch 4), train_loss = 3.145, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 2631 (epoch 4), train_loss = 2.959, time/batch = 0.024
Read data: 0.003255128860473633
iter 2632 (epoch 4), train_loss = 3.153, time/batch = 0.018
Read data: 5.7697296142578125e-05
iter 2633 (epoch 4), train_loss = 3.126, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 2634 (epoch 4), train_loss = 3.100, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 2635 (epoch 4), train_loss = 3.013, time/batch = 0.020
Read data: 0.016000986099243164
iter 2636 (epoch 4), train_loss = 2.885, time/batch = 0.020
Read data: 5.8650970458984375e-05
iter 2637 (epoch 4), train_loss = 2.886, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 2638 (epoch 4), train_loss = 3.076, time/batch = 0.022
Read data: 8.320808410644531e-05
iter 2639 (epoch 4), train_loss = 3.078, time/batch = 0.018
Read data: 0.0189208984375
iter 2640 (epoch 4), train_loss = 3.361, time/batch = 0.021
Read data: 7.963180541992188e-05
iter 2641 (epoch 4), train_loss = 3.420, time/batch = 0.023
Read data: 7.295608520507812e-05
iter 2642 (epoch 4), train_loss = 2.715, time/batch = 0.020
Read data: 8.630752563476562e-05
iter 2643 (epoch 4), train_loss = 3.274, time/batch = 0.022
Read data: 0.013675689697265625
iter 2644 (epoch 4), train_loss = 2.914, time/batch = 0.022
Read data: 6.270408630371094e-05
iter 2645 (epoch 4), train_loss = 3.399, time/batch = 0.025
Read data: 7.295608520507812e-05
iter 2646 (epoch 4), train_loss = 3.632, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 2647 (epoch 4), train_loss = 3.162, time/batch = 0.021
Read data: 0.013535499572753906
iter 2648 (epoch 4), train_loss = 3.161, time/batch = 0.022
Read data: 7.581710815429688e-05
iter 2649 (epoch 4), train_loss = 3.437, time/batch = 0.025
Read data: 0.00016498565673828125
iter 2650 (epoch 4), train_loss = 3.261, time/batch = 0.035
Read data: 0.00015473365783691406
iter 2651 (epoch 4), train_loss = 3.142, time/batch = 0.026
Read data: 0.00013017654418945312
iter 2652 (epoch 4), train_loss = 3.176, time/batch = 0.027
Read data: 7.224082946777344e-05
iter 2653 (epoch 4), train_loss = 3.445, time/batch = 0.023
Read data: 7.176399230957031e-05
iter 2654 (epoch 4), train_loss = 2.870, time/batch = 0.020
Read data: 0.00010156631469726562
iter 2655 (epoch 4), train_loss = 2.933, time/batch = 0.024
Read data: 0.0025746822357177734
iter 2656 (epoch 4), train_loss = 3.342, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 2657 (epoch 4), train_loss = 2.819, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 2658 (epoch 4), train_loss = 2.905, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 2659 (epoch 4), train_loss = 2.816, time/batch = 0.026
Read data: 0.0055124759674072266
iter 2660 (epoch 4), train_loss = 3.379, time/batch = 0.031
Read data: 6.747245788574219e-05
iter 2661 (epoch 4), train_loss = 3.175, time/batch = 0.023
Read data: 7.700920104980469e-05
iter 2662 (epoch 4), train_loss = 3.072, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 2663 (epoch 4), train_loss = 3.250, time/batch = 0.024
Read data: 0.0017459392547607422
iter 2664 (epoch 4), train_loss = 3.377, time/batch = 0.026
Read data: 7.224082946777344e-05
iter 2665 (epoch 4), train_loss = 3.267, time/batch = 0.029
Read data: 7.104873657226562e-05
iter 2666 (epoch 4), train_loss = 3.366, time/batch = 0.023
Read data: 0.0001900196075439453
iter 2667 (epoch 4), train_loss = 2.730, time/batch = 0.027
Read data: 0.00013136863708496094
iter 2668 (epoch 4), train_loss = 3.008, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 2669 (epoch 4), train_loss = 3.367, time/batch = 0.023
Read data: 6.866455078125e-05
iter 2670 (epoch 4), train_loss = 3.197, time/batch = 0.019
Read data: 8.320808410644531e-05
iter 2671 (epoch 4), train_loss = 3.212, time/batch = 0.020
Read data: 0.010819196701049805
iter 2672 (epoch 4), train_loss = 3.600, time/batch = 0.035
Read data: 0.0001556873321533203
iter 2673 (epoch 4), train_loss = 2.902, time/batch = 0.024
Read data: 6.961822509765625e-05
iter 2674 (epoch 4), train_loss = 3.377, time/batch = 0.023
Read data: 0.0001285076141357422
iter 2675 (epoch 4), train_loss = 2.858, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 2676 (epoch 4), train_loss = 2.841, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 2677 (epoch 4), train_loss = 3.039, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 2678 (epoch 4), train_loss = 2.999, time/batch = 0.018
Read data: 8.535385131835938e-05
iter 2679 (epoch 4), train_loss = 3.170, time/batch = 0.027
Read data: 0.001981019973754883
iter 2680 (epoch 4), train_loss = 3.198, time/batch = 0.023
Read data: 7.367134094238281e-05
iter 2681 (epoch 4), train_loss = 3.318, time/batch = 0.023
Read data: 7.390975952148438e-05
iter 2682 (epoch 4), train_loss = 3.231, time/batch = 0.026
Read data: 0.00016427040100097656
iter 2683 (epoch 4), train_loss = 2.888, time/batch = 0.021
Read data: 0.007700443267822266
iter 2684 (epoch 4), train_loss = 3.306, time/batch = 0.027
Read data: 7.081031799316406e-05
iter 2685 (epoch 4), train_loss = 2.709, time/batch = 0.020
Read data: 0.00010704994201660156
iter 2686 (epoch 4), train_loss = 3.051, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 2687 (epoch 4), train_loss = 3.343, time/batch = 0.023
Read data: 0.006882190704345703
iter 2688 (epoch 4), train_loss = 3.075, time/batch = 0.022
Read data: 6.866455078125e-05
iter 2689 (epoch 4), train_loss = 3.158, time/batch = 0.020
Read data: 8.106231689453125e-05
iter 2690 (epoch 4), train_loss = 3.141, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 2691 (epoch 4), train_loss = 2.775, time/batch = 0.022
Read data: 0.018622159957885742
iter 2692 (epoch 4), train_loss = 2.892, time/batch = 0.023
Read data: 0.00010991096496582031
iter 2693 (epoch 4), train_loss = 3.330, time/batch = 0.024
Read data: 0.00010824203491210938
iter 2694 (epoch 4), train_loss = 3.445, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 2695 (epoch 4), train_loss = 3.426, time/batch = 0.032
Read data: 0.00011014938354492188
iter 2696 (epoch 4), train_loss = 3.302, time/batch = 0.021
Read data: 0.00012803077697753906
iter 2697 (epoch 4), train_loss = 3.226, time/batch = 0.022
Read data: 7.43865966796875e-05
iter 2698 (epoch 4), train_loss = 3.769, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 2699 (epoch 4), train_loss = 3.116, time/batch = 0.022
Read data: 0.013983726501464844
iter 2700 (epoch 4), train_loss = 3.267, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 2701 (epoch 4), train_loss = 3.330, time/batch = 0.027
Read data: 7.104873657226562e-05
iter 2702 (epoch 4), train_loss = 3.086, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 2703 (epoch 4), train_loss = 2.851, time/batch = 0.026
Read data: 0.0032148361206054688
iter 2704 (epoch 4), train_loss = 3.363, time/batch = 0.025
Read data: 6.699562072753906e-05
iter 2705 (epoch 4), train_loss = 2.995, time/batch = 0.019
Read data: 6.890296936035156e-05
iter 2706 (epoch 4), train_loss = 2.657, time/batch = 0.020
Read data: 0.00010609626770019531
iter 2707 (epoch 4), train_loss = 2.742, time/batch = 0.023
Read data: 0.011991500854492188
iter 2708 (epoch 4), train_loss = 3.133, time/batch = 0.020
Read data: 6.008148193359375e-05
iter 2709 (epoch 4), train_loss = 2.358, time/batch = 0.023
Read data: 6.985664367675781e-05
iter 2710 (epoch 4), train_loss = 3.045, time/batch = 0.021
Read data: 7.62939453125e-05
iter 2711 (epoch 4), train_loss = 3.173, time/batch = 0.023
Read data: 0.012259244918823242
iter 2712 (epoch 4), train_loss = 3.073, time/batch = 0.020
Read data: 7.581710815429688e-05
iter 2713 (epoch 4), train_loss = 3.168, time/batch = 0.020
Read data: 0.0001125335693359375
iter 2714 (epoch 4), train_loss = 2.908, time/batch = 0.020
Read data: 0.00012946128845214844
iter 2715 (epoch 4), train_loss = 3.170, time/batch = 0.024
Read data: 0.02003335952758789
iter 2716 (epoch 4), train_loss = 3.276, time/batch = 0.023
Read data: 0.00011491775512695312
iter 2717 (epoch 4), train_loss = 3.304, time/batch = 0.021
Read data: 7.128715515136719e-05
iter 2718 (epoch 4), train_loss = 3.108, time/batch = 0.020
Read data: 0.00020360946655273438
iter 2719 (epoch 4), train_loss = 2.988, time/batch = 0.024
Read data: 0.012878894805908203
iter 2720 (epoch 4), train_loss = 3.311, time/batch = 0.020
Read data: 0.00011444091796875
iter 2721 (epoch 4), train_loss = 2.870, time/batch = 0.022
Read data: 7.295608520507812e-05
iter 2722 (epoch 4), train_loss = 3.215, time/batch = 0.018
Read data: 8.511543273925781e-05
iter 2723 (epoch 4), train_loss = 3.088, time/batch = 0.023
Read data: 0.01849675178527832
iter 2724 (epoch 4), train_loss = 3.534, time/batch = 0.023
Read data: 0.000152587890625
iter 2725 (epoch 4), train_loss = 2.827, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 2726 (epoch 4), train_loss = 3.168, time/batch = 0.021
Read data: 0.00013184547424316406
iter 2727 (epoch 4), train_loss = 3.055, time/batch = 0.023
Read data: 0.01024770736694336
iter 2728 (epoch 4), train_loss = 2.891, time/batch = 0.025
Read data: 6.651878356933594e-05
iter 2729 (epoch 4), train_loss = 2.632, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 2730 (epoch 4), train_loss = 2.928, time/batch = 0.026
Read data: 0.0001087188720703125
iter 2731 (epoch 4), train_loss = 3.091, time/batch = 0.021
Read data: 0.008970499038696289
iter 2732 (epoch 4), train_loss = 2.944, time/batch = 0.021
Read data: 6.413459777832031e-05
iter 2733 (epoch 4), train_loss = 3.452, time/batch = 0.025
Read data: 7.2479248046875e-05
iter 2734 (epoch 4), train_loss = 3.404, time/batch = 0.023
Read data: 0.00013256072998046875
iter 2735 (epoch 4), train_loss = 3.232, time/batch = 0.025
Read data: 0.0074460506439208984
iter 2736 (epoch 4), train_loss = 2.542, time/batch = 0.018
Read data: 0.00011110305786132812
iter 2737 (epoch 4), train_loss = 3.012, time/batch = 0.022
Read data: 7.200241088867188e-05
iter 2738 (epoch 4), train_loss = 3.371, time/batch = 0.024
Read data: 0.00011396408081054688
iter 2739 (epoch 4), train_loss = 3.000, time/batch = 0.020
Read data: 0.016602516174316406
iter 2740 (epoch 4), train_loss = 3.183, time/batch = 0.025
Read data: 6.651878356933594e-05
iter 2741 (epoch 4), train_loss = 3.524, time/batch = 0.018
Read data: 8.106231689453125e-05
iter 2742 (epoch 4), train_loss = 3.248, time/batch = 0.028
Read data: 0.00014734268188476562
iter 2743 (epoch 4), train_loss = 3.073, time/batch = 0.023
Read data: 0.002310037612915039
iter 2744 (epoch 4), train_loss = 2.989, time/batch = 0.020
Read data: 0.0001571178436279297
iter 2745 (epoch 4), train_loss = 3.002, time/batch = 0.025
Read data: 7.319450378417969e-05
iter 2746 (epoch 4), train_loss = 3.070, time/batch = 0.027
Read data: 0.00015997886657714844
iter 2747 (epoch 4), train_loss = 3.347, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 2748 (epoch 4), train_loss = 3.266, time/batch = 0.018
Read data: 8.296966552734375e-05
iter 2749 (epoch 4), train_loss = 3.273, time/batch = 0.034
Read data: 0.00023365020751953125
iter 2750 (epoch 4), train_loss = 3.365, time/batch = 0.023
Read data: 0.0001575946807861328
iter 2751 (epoch 4), train_loss = 3.370, time/batch = 0.024
Read data: 0.003719329833984375
iter 2752 (epoch 4), train_loss = 3.514, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 2753 (epoch 4), train_loss = 2.616, time/batch = 0.020
Read data: 7.224082946777344e-05
iter 2754 (epoch 4), train_loss = 2.997, time/batch = 0.021
Read data: 0.00015664100646972656
iter 2755 (epoch 4), train_loss = 3.308, time/batch = 0.022
Read data: 0.010006427764892578
iter 2756 (epoch 4), train_loss = 2.589, time/batch = 0.021
Read data: 0.0001418590545654297
iter 2757 (epoch 4), train_loss = 3.113, time/batch = 0.022
Read data: 7.43865966796875e-05
iter 2758 (epoch 4), train_loss = 2.800, time/batch = 0.025
Read data: 0.00013136863708496094
iter 2759 (epoch 4), train_loss = 3.270, time/batch = 0.022
Read data: 0.009137392044067383
iter 2760 (epoch 4), train_loss = 3.356, time/batch = 0.018
Read data: 5.53131103515625e-05
iter 2761 (epoch 4), train_loss = 3.272, time/batch = 0.026
Read data: 7.367134094238281e-05
iter 2762 (epoch 4), train_loss = 3.369, time/batch = 0.023
Read data: 0.00013208389282226562
iter 2763 (epoch 4), train_loss = 2.820, time/batch = 0.022
Read data: 0.011137962341308594
iter 2764 (epoch 4), train_loss = 3.260, time/batch = 0.027
Read data: 6.318092346191406e-05
iter 2765 (epoch 4), train_loss = 2.797, time/batch = 0.025
Read data: 0.00013756752014160156
iter 2766 (epoch 4), train_loss = 3.228, time/batch = 0.021
Read data: 0.00014901161193847656
iter 2767 (epoch 4), train_loss = 3.104, time/batch = 0.021
Read data: 0.009497404098510742
iter 2768 (epoch 4), train_loss = 2.886, time/batch = 0.021
Read data: 0.00011205673217773438
iter 2769 (epoch 4), train_loss = 3.042, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 2770 (epoch 4), train_loss = 2.776, time/batch = 0.020
Read data: 0.00016188621520996094
iter 2771 (epoch 4), train_loss = 3.278, time/batch = 0.022
Read data: 0.01293039321899414
iter 2772 (epoch 4), train_loss = 3.414, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 2773 (epoch 4), train_loss = 2.910, time/batch = 0.021
Read data: 6.747245788574219e-05
iter 2774 (epoch 4), train_loss = 2.966, time/batch = 0.020
Read data: 0.0004296302795410156
iter 2775 (epoch 4), train_loss = 3.259, time/batch = 0.025
Read data: 0.012601375579833984
iter 2776 (epoch 4), train_loss = 2.897, time/batch = 0.020
Read data: 6.079673767089844e-05
iter 2777 (epoch 4), train_loss = 2.940, time/batch = 0.032
Read data: 7.319450378417969e-05
iter 2778 (epoch 4), train_loss = 3.144, time/batch = 0.028
Read data: 0.00011730194091796875
iter 2779 (epoch 4), train_loss = 3.350, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 2780 (epoch 4), train_loss = 3.014, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 2781 (epoch 4), train_loss = 2.787, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 2782 (epoch 4), train_loss = 2.640, time/batch = 0.021
Read data: 0.0001246929168701172
iter 2783 (epoch 4), train_loss = 3.126, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 2784 (epoch 4), train_loss = 2.766, time/batch = 0.023
Read data: 6.0558319091796875e-05
iter 2785 (epoch 4), train_loss = 3.140, time/batch = 0.020
Read data: 7.224082946777344e-05
iter 2786 (epoch 4), train_loss = 3.002, time/batch = 0.018
Read data: 7.2479248046875e-05
iter 2787 (epoch 4), train_loss = 3.078, time/batch = 0.023
Read data: 0.015398263931274414
iter 2788 (epoch 4), train_loss = 3.086, time/batch = 0.021
Read data: 0.00010037422180175781
iter 2789 (epoch 4), train_loss = 3.506, time/batch = 0.020
Read data: 7.05718994140625e-05
iter 2790 (epoch 4), train_loss = 3.014, time/batch = 0.028
Read data: 0.00012755393981933594
iter 2791 (epoch 4), train_loss = 3.121, time/batch = 0.024
Read data: 0.00858449935913086
iter 2792 (epoch 4), train_loss = 2.501, time/batch = 0.023
Read data: 0.00014019012451171875
iter 2793 (epoch 4), train_loss = 3.319, time/batch = 0.025
Read data: 7.534027099609375e-05
iter 2794 (epoch 4), train_loss = 3.195, time/batch = 0.024
Read data: 0.00015974044799804688
iter 2795 (epoch 4), train_loss = 2.760, time/batch = 0.022
Read data: 0.005003452301025391
iter 2796 (epoch 4), train_loss = 2.729, time/batch = 0.018
Read data: 7.891654968261719e-05
iter 2797 (epoch 4), train_loss = 3.010, time/batch = 0.022
Read data: 7.081031799316406e-05
iter 2798 (epoch 4), train_loss = 2.933, time/batch = 0.020
Read data: 7.152557373046875e-05
iter 2799 (epoch 4), train_loss = 3.160, time/batch = 0.024
Read data: 0.013814926147460938
iter 2800 (epoch 4), train_loss = 3.533, time/batch = 0.020
Read data: 0.00010347366333007812
iter 2801 (epoch 4), train_loss = 3.230, time/batch = 0.018
Read data: 6.866455078125e-05
iter 2802 (epoch 4), train_loss = 3.280, time/batch = 0.028
Read data: 0.00012135505676269531
iter 2803 (epoch 4), train_loss = 3.117, time/batch = 0.022
Read data: 0.009880542755126953
iter 2804 (epoch 4), train_loss = 2.938, time/batch = 0.025
Read data: 6.508827209472656e-05
iter 2805 (epoch 4), train_loss = 3.038, time/batch = 0.020
Read data: 7.176399230957031e-05
iter 2806 (epoch 4), train_loss = 3.467, time/batch = 0.027
Read data: 0.00012803077697753906
iter 2807 (epoch 4), train_loss = 2.776, time/batch = 0.022
Read data: 0.005350589752197266
iter 2808 (epoch 4), train_loss = 3.198, time/batch = 0.021
Read data: 9.846687316894531e-05
iter 2809 (epoch 4), train_loss = 3.493, time/batch = 0.018
Read data: 7.343292236328125e-05
iter 2810 (epoch 4), train_loss = 3.421, time/batch = 0.023
Read data: 6.651878356933594e-05
iter 2811 (epoch 4), train_loss = 2.924, time/batch = 0.024
Read data: 0.013443708419799805
iter 2812 (epoch 4), train_loss = 3.148, time/batch = 0.021
Read data: 6.747245788574219e-05
iter 2813 (epoch 4), train_loss = 3.309, time/batch = 0.025
Read data: 7.319450378417969e-05
iter 2814 (epoch 4), train_loss = 2.760, time/batch = 0.024
Read data: 7.43865966796875e-05
iter 2815 (epoch 4), train_loss = 2.926, time/batch = 0.023
Read data: 0.005093812942504883
iter 2816 (epoch 4), train_loss = 2.889, time/batch = 0.018
Read data: 5.6743621826171875e-05
iter 2817 (epoch 4), train_loss = 2.849, time/batch = 0.027
Read data: 7.152557373046875e-05
iter 2818 (epoch 4), train_loss = 2.652, time/batch = 0.021
Read data: 0.00014257431030273438
iter 2819 (epoch 4), train_loss = 3.447, time/batch = 0.020
Read data: 0.012487173080444336
iter 2820 (epoch 4), train_loss = 3.227, time/batch = 0.035
Read data: 6.604194641113281e-05
iter 2821 (epoch 4), train_loss = 3.038, time/batch = 0.024
Read data: 6.914138793945312e-05
iter 2822 (epoch 4), train_loss = 2.938, time/batch = 0.022
Read data: 0.00010442733764648438
iter 2823 (epoch 4), train_loss = 2.745, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 2824 (epoch 4), train_loss = 2.877, time/batch = 0.019
Read data: 0.00018453598022460938
iter 2825 (epoch 4), train_loss = 2.867, time/batch = 0.024
Read data: 0.00010204315185546875
iter 2826 (epoch 4), train_loss = 3.303, time/batch = 0.023
Read data: 0.0001556873321533203
iter 2827 (epoch 4), train_loss = 3.374, time/batch = 0.025
Read data: 0.006994009017944336
iter 2828 (epoch 4), train_loss = 3.271, time/batch = 0.023
Read data: 5.555152893066406e-05
iter 2829 (epoch 4), train_loss = 2.940, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 2830 (epoch 4), train_loss = 2.971, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 2831 (epoch 4), train_loss = 3.329, time/batch = 0.025
Read data: 0.0034923553466796875
iter 2832 (epoch 4), train_loss = 2.664, time/batch = 0.025
Read data: 5.745887756347656e-05
iter 2833 (epoch 4), train_loss = 3.189, time/batch = 0.027
Read data: 7.486343383789062e-05
iter 2834 (epoch 4), train_loss = 2.754, time/batch = 0.026
Read data: 6.747245788574219e-05
iter 2835 (epoch 4), train_loss = 3.102, time/batch = 0.021
Read data: 0.002560138702392578
iter 2836 (epoch 4), train_loss = 2.644, time/batch = 0.018
Read data: 5.91278076171875e-05
iter 2837 (epoch 4), train_loss = 3.332, time/batch = 0.022
Read data: 7.2479248046875e-05
iter 2838 (epoch 4), train_loss = 3.126, time/batch = 0.024
Read data: 0.0001499652862548828
iter 2839 (epoch 4), train_loss = 3.531, time/batch = 0.021
Read data: 0.012814521789550781
iter 2840 (epoch 4), train_loss = 3.101, time/batch = 0.020
Read data: 0.00011801719665527344
iter 2841 (epoch 4), train_loss = 3.027, time/batch = 0.021
Read data: 7.009506225585938e-05
iter 2842 (epoch 4), train_loss = 2.728, time/batch = 0.019
Read data: 0.00013065338134765625
iter 2843 (epoch 4), train_loss = 3.019, time/batch = 0.028
Read data: 0.014502525329589844
iter 2844 (epoch 4), train_loss = 3.006, time/batch = 0.023
Read data: 5.91278076171875e-05
iter 2845 (epoch 4), train_loss = 2.745, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 2846 (epoch 4), train_loss = 2.928, time/batch = 0.023
Read data: 0.00012421607971191406
iter 2847 (epoch 4), train_loss = 3.075, time/batch = 0.019
Read data: 0.008964776992797852
iter 2848 (epoch 4), train_loss = 2.929, time/batch = 0.020
Read data: 5.8650970458984375e-05
iter 2849 (epoch 4), train_loss = 2.914, time/batch = 0.020
Read data: 0.0001614093780517578
iter 2850 (epoch 4), train_loss = 3.468, time/batch = 0.028
Read data: 7.557868957519531e-05
iter 2851 (epoch 4), train_loss = 3.264, time/batch = 0.025
Read data: 0.006056070327758789
iter 2852 (epoch 4), train_loss = 3.126, time/batch = 0.021
Read data: 5.841255187988281e-05
iter 2853 (epoch 4), train_loss = 3.038, time/batch = 0.023
Read data: 0.00013375282287597656
iter 2854 (epoch 4), train_loss = 3.309, time/batch = 0.030
Read data: 6.580352783203125e-05
iter 2855 (epoch 4), train_loss = 3.168, time/batch = 0.024
Read data: 0.004349231719970703
iter 2856 (epoch 4), train_loss = 2.864, time/batch = 0.020
Read data: 8.559226989746094e-05
iter 2857 (epoch 4), train_loss = 2.839, time/batch = 0.023
Read data: 7.43865966796875e-05
iter 2858 (epoch 4), train_loss = 3.093, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 2859 (epoch 4), train_loss = 2.761, time/batch = 0.024
Read data: 0.01483917236328125
iter 2860 (epoch 4), train_loss = 3.501, time/batch = 0.024
Read data: 6.67572021484375e-05
iter 2861 (epoch 4), train_loss = 3.572, time/batch = 0.024
Read data: 7.009506225585938e-05
iter 2862 (epoch 4), train_loss = 3.072, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 2863 (epoch 4), train_loss = 2.975, time/batch = 0.020
Read data: 0.013797760009765625
iter 2864 (epoch 4), train_loss = 3.103, time/batch = 0.025
Read data: 6.532669067382812e-05
iter 2865 (epoch 4), train_loss = 2.727, time/batch = 0.031
Read data: 0.00010371208190917969
iter 2866 (epoch 4), train_loss = 3.405, time/batch = 0.022
Read data: 0.00014328956604003906
iter 2867 (epoch 4), train_loss = 3.265, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 2868 (epoch 4), train_loss = 3.290, time/batch = 0.021
Read data: 5.91278076171875e-05
iter 2869 (epoch 4), train_loss = 2.878, time/batch = 0.023
Read data: 0.0001380443572998047
iter 2870 (epoch 4), train_loss = 3.127, time/batch = 0.025
Read data: 0.00013065338134765625
iter 2871 (epoch 4), train_loss = 3.290, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 2872 (epoch 4), train_loss = 3.011, time/batch = 0.020
Read data: 5.626678466796875e-05
iter 2873 (epoch 4), train_loss = 2.996, time/batch = 0.025
Read data: 0.00010585784912109375
iter 2874 (epoch 4), train_loss = 3.005, time/batch = 0.028
Read data: 0.00016689300537109375
iter 2875 (epoch 4), train_loss = 3.283, time/batch = 0.025
Read data: 0.00012874603271484375
iter 2876 (epoch 4), train_loss = 2.587, time/batch = 0.020
Read data: 6.079673767089844e-05
iter 2877 (epoch 4), train_loss = 3.042, time/batch = 0.021
Read data: 7.176399230957031e-05
iter 2878 (epoch 4), train_loss = 3.186, time/batch = 0.030
Read data: 0.0001304149627685547
iter 2879 (epoch 4), train_loss = 2.832, time/batch = 0.022
Read data: 0.0056819915771484375
iter 2880 (epoch 4), train_loss = 2.995, time/batch = 0.021
Read data: 7.05718994140625e-05
iter 2881 (epoch 4), train_loss = 2.835, time/batch = 0.020
Read data: 7.462501525878906e-05
iter 2882 (epoch 4), train_loss = 2.887, time/batch = 0.024
Read data: 0.00012040138244628906
iter 2883 (epoch 4), train_loss = 2.776, time/batch = 0.025
Read data: 0.010716915130615234
iter 2884 (epoch 4), train_loss = 3.213, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 2885 (epoch 4), train_loss = 3.363, time/batch = 0.022
Read data: 7.557868957519531e-05
iter 2886 (epoch 4), train_loss = 3.129, time/batch = 0.023
Read data: 0.00011801719665527344
iter 2887 (epoch 4), train_loss = 3.504, time/batch = 0.023
Read data: 0.0033233165740966797
iter 2888 (epoch 4), train_loss = 2.400, time/batch = 0.018
Read data: 5.8650970458984375e-05
iter 2889 (epoch 4), train_loss = 2.893, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 2890 (epoch 4), train_loss = 2.919, time/batch = 0.029
Read data: 7.128715515136719e-05
iter 2891 (epoch 4), train_loss = 3.392, time/batch = 0.026
Read data: 0.00341033935546875
iter 2892 (epoch 4), train_loss = 3.298, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 2893 (epoch 4), train_loss = 2.971, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 2894 (epoch 4), train_loss = 2.432, time/batch = 0.019
Read data: 7.677078247070312e-05
iter 2895 (epoch 4), train_loss = 2.688, time/batch = 0.024
Read data: 0.002842426300048828
iter 2896 (epoch 4), train_loss = 2.681, time/batch = 0.021
Read data: 5.5789947509765625e-05
iter 2897 (epoch 4), train_loss = 3.330, time/batch = 0.022
Read data: 6.937980651855469e-05
iter 2898 (epoch 4), train_loss = 3.207, time/batch = 0.021
Read data: 9.393692016601562e-05
iter 2899 (epoch 4), train_loss = 3.518, time/batch = 0.027
Read data: 0.009759187698364258
iter 2900 (epoch 4), train_loss = 2.846, time/batch = 0.018
Read data: 6.651878356933594e-05
iter 2901 (epoch 4), train_loss = 2.738, time/batch = 0.022
Read data: 0.00016546249389648438
iter 2902 (epoch 4), train_loss = 3.129, time/batch = 0.027
Read data: 0.00013971328735351562
iter 2903 (epoch 4), train_loss = 3.227, time/batch = 0.022
Read data: 0.013321161270141602
iter 2904 (epoch 4), train_loss = 3.040, time/batch = 0.021
Read data: 5.7697296142578125e-05
iter 2905 (epoch 4), train_loss = 2.825, time/batch = 0.025
Read data: 7.414817810058594e-05
iter 2906 (epoch 4), train_loss = 2.827, time/batch = 0.024
Read data: 0.00012302398681640625
iter 2907 (epoch 4), train_loss = 2.846, time/batch = 0.020
Read data: 0.010252952575683594
iter 2908 (epoch 4), train_loss = 3.520, time/batch = 0.022
Read data: 5.4836273193359375e-05
iter 2909 (epoch 4), train_loss = 2.784, time/batch = 0.020
Read data: 0.00010800361633300781
iter 2910 (epoch 4), train_loss = 2.870, time/batch = 0.024
Read data: 7.319450378417969e-05
iter 2911 (epoch 4), train_loss = 2.825, time/batch = 0.022
Read data: 0.012135982513427734
iter 2912 (epoch 4), train_loss = 2.803, time/batch = 0.019
Read data: 5.412101745605469e-05
iter 2913 (epoch 4), train_loss = 3.077, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 2914 (epoch 4), train_loss = 2.540, time/batch = 0.022
Read data: 7.319450378417969e-05
iter 2915 (epoch 4), train_loss = 3.323, time/batch = 0.025
Read data: 0.010267972946166992
iter 2916 (epoch 4), train_loss = 2.941, time/batch = 0.021
Read data: 5.650520324707031e-05
iter 2917 (epoch 4), train_loss = 2.757, time/batch = 0.023
Read data: 6.937980651855469e-05
iter 2918 (epoch 4), train_loss = 2.709, time/batch = 0.025
Read data: 0.0016207695007324219
iter 2919 (epoch 4), train_loss = 3.093, time/batch = 0.018
Read data: 0.014726638793945312
iter 2920 (epoch 4), train_loss = 2.933, time/batch = 0.019
Read data: 5.817413330078125e-05
iter 2921 (epoch 4), train_loss = 3.468, time/batch = 0.029
Read data: 7.367134094238281e-05
iter 2922 (epoch 4), train_loss = 2.863, time/batch = 0.026
Read data: 6.365776062011719e-05
iter 2923 (epoch 4), train_loss = 3.363, time/batch = 0.021
Read data: 0.010170698165893555
iter 2924 (epoch 4), train_loss = 3.279, time/batch = 0.021
Read data: 5.5789947509765625e-05
iter 2925 (epoch 4), train_loss = 2.818, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 2926 (epoch 4), train_loss = 2.884, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 2927 (epoch 4), train_loss = 3.291, time/batch = 0.024
Read data: 0.011354446411132812
iter 2928 (epoch 4), train_loss = 3.186, time/batch = 0.019
Read data: 5.888938903808594e-05
iter 2929 (epoch 4), train_loss = 3.265, time/batch = 0.019
Read data: 0.0002529621124267578
iter 2930 (epoch 4), train_loss = 3.020, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 2931 (epoch 4), train_loss = 2.712, time/batch = 0.021
Read data: 0.016378402709960938
iter 2932 (epoch 4), train_loss = 2.896, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 2933 (epoch 4), train_loss = 3.093, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 2934 (epoch 4), train_loss = 2.885, time/batch = 0.022
Read data: 0.00011467933654785156
iter 2935 (epoch 4), train_loss = 3.129, time/batch = 0.023
Read data: 0.007546186447143555
iter 2936 (epoch 4), train_loss = 2.878, time/batch = 0.021
Read data: 5.507469177246094e-05
iter 2937 (epoch 4), train_loss = 3.302, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 2938 (epoch 4), train_loss = 3.132, time/batch = 0.023
Read data: 7.128715515136719e-05
iter 2939 (epoch 4), train_loss = 2.985, time/batch = 0.025
Read data: 0.0060443878173828125
iter 2940 (epoch 4), train_loss = 2.895, time/batch = 0.019
Read data: 5.602836608886719e-05
iter 2941 (epoch 4), train_loss = 2.860, time/batch = 0.020
Read data: 0.00015306472778320312
iter 2942 (epoch 4), train_loss = 3.583, time/batch = 0.020
Read data: 0.00011873245239257812
iter 2943 (epoch 4), train_loss = 2.815, time/batch = 0.020
Read data: 0.023777008056640625
iter 2944 (epoch 4), train_loss = 3.047, time/batch = 0.028
Read data: 5.626678466796875e-05
iter 2945 (epoch 4), train_loss = 3.089, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 2946 (epoch 4), train_loss = 3.011, time/batch = 0.022
Read data: 0.00011444091796875
iter 2947 (epoch 4), train_loss = 2.860, time/batch = 0.027
Read data: 9.1552734375e-05
iter 2948 (epoch 4), train_loss = 2.691, time/batch = 0.022
Read data: 5.53131103515625e-05
iter 2949 (epoch 4), train_loss = 3.082, time/batch = 0.021
Read data: 0.0002810955047607422
iter 2950 (epoch 4), train_loss = 2.682, time/batch = 0.021
Read data: 7.200241088867188e-05
iter 2951 (epoch 4), train_loss = 3.118, time/batch = 0.022
Read data: 0.016306161880493164
iter 2952 (epoch 4), train_loss = 3.099, time/batch = 0.019
Read data: 5.745887756347656e-05
iter 2953 (epoch 4), train_loss = 3.010, time/batch = 0.020
Read data: 0.00013208389282226562
iter 2954 (epoch 4), train_loss = 3.443, time/batch = 0.035
Read data: 0.00011515617370605469
iter 2955 (epoch 4), train_loss = 3.143, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 2956 (epoch 4), train_loss = 3.308, time/batch = 0.021
Read data: 5.626678466796875e-05
iter 2957 (epoch 4), train_loss = 3.050, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 2958 (epoch 4), train_loss = 2.981, time/batch = 0.024
Read data: 0.00011777877807617188
iter 2959 (epoch 4), train_loss = 2.960, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 2960 (epoch 4), train_loss = 3.149, time/batch = 0.025
Read data: 5.459785461425781e-05
iter 2961 (epoch 4), train_loss = 2.968, time/batch = 0.023
Read data: 0.00013637542724609375
iter 2962 (epoch 4), train_loss = 3.433, time/batch = 0.031
Read data: 6.747245788574219e-05
iter 2963 (epoch 4), train_loss = 2.944, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 2964 (epoch 4), train_loss = 2.976, time/batch = 0.024
Read data: 5.793571472167969e-05
iter 2965 (epoch 4), train_loss = 3.215, time/batch = 0.024
Read data: 0.00011229515075683594
iter 2966 (epoch 4), train_loss = 3.142, time/batch = 0.026
Read data: 0.0001246929168701172
iter 2967 (epoch 4), train_loss = 3.046, time/batch = 0.026
Read data: 0.00013399124145507812
iter 2968 (epoch 4), train_loss = 2.896, time/batch = 0.024
Read data: 7.581710815429688e-05
iter 2969 (epoch 4), train_loss = 2.533, time/batch = 0.022
Read data: 0.0001163482666015625
iter 2970 (epoch 4), train_loss = 3.265, time/batch = 0.026
Read data: 0.00010180473327636719
iter 2971 (epoch 4), train_loss = 2.999, time/batch = 0.028
Read data: 0.00013017654418945312
iter 2972 (epoch 4), train_loss = 2.943, time/batch = 0.024
Read data: 6.985664367675781e-05
iter 2973 (epoch 4), train_loss = 3.247, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 2974 (epoch 4), train_loss = 2.834, time/batch = 0.026
Read data: 0.00022339820861816406
iter 2975 (epoch 4), train_loss = 3.189, time/batch = 0.027
Read data: 0.00012564659118652344
iter 2976 (epoch 4), train_loss = 2.809, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 2977 (epoch 4), train_loss = 2.993, time/batch = 0.023
Read data: 0.00013947486877441406
iter 2978 (epoch 4), train_loss = 3.047, time/batch = 0.031
Read data: 0.0001068115234375
iter 2979 (epoch 4), train_loss = 3.257, time/batch = 0.024
Read data: 0.0001220703125
iter 2980 (epoch 4), train_loss = 2.839, time/batch = 0.022
Read data: 7.677078247070312e-05
iter 2981 (epoch 4), train_loss = 2.636, time/batch = 0.029
Read data: 8.96453857421875e-05
iter 2982 (epoch 4), train_loss = 2.986, time/batch = 0.028
Read data: 0.00012063980102539062
iter 2983 (epoch 4), train_loss = 3.240, time/batch = 0.028
Read data: 0.00011873245239257812
iter 2984 (epoch 4), train_loss = 3.003, time/batch = 0.020
Read data: 0.00011563301086425781
iter 2985 (epoch 4), train_loss = 3.046, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 2986 (epoch 4), train_loss = 3.383, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 2987 (epoch 4), train_loss = 3.172, time/batch = 0.022
Read data: 0.00012612342834472656
iter 2988 (epoch 4), train_loss = 3.652, time/batch = 0.022
Read data: 0.00011301040649414062
iter 2989 (epoch 4), train_loss = 3.059, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 2990 (epoch 4), train_loss = 3.377, time/batch = 0.026
Read data: 0.00010752677917480469
iter 2991 (epoch 4), train_loss = 2.988, time/batch = 0.028
Read data: 0.001279592514038086
iter 2992 (epoch 4), train_loss = 2.878, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 2993 (epoch 4), train_loss = 3.172, time/batch = 0.031
Read data: 6.961822509765625e-05
iter 2994 (epoch 4), train_loss = 3.456, time/batch = 0.035
Read data: 0.0001647472381591797
iter 2995 (epoch 4), train_loss = 3.190, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 2996 (epoch 4), train_loss = 3.045, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 2997 (epoch 4), train_loss = 2.949, time/batch = 0.025
Read data: 6.747245788574219e-05
iter 2998 (epoch 4), train_loss = 3.025, time/batch = 0.026
Read data: 0.00011849403381347656
iter 2999 (epoch 4), train_loss = 2.981, time/batch = 0.027
image 976:     
image 5399:     
image 6910:      
image 660:      
image 6372:     
image 616:     
image 2678:     
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (3.070408)
image 2798:     
image 5884:    
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.642380)
image 6903:      
image 3301:    
image 2019:     
image 5535:     
image 7680:     
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (3.047818)
image 4604:     
image 5745:     
image 5288:    
image 1562:      
image 7807:      
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.178990)
image 2938:    
image 5183:     
image 2380:      
image 6973:     
image 5629:     
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.956918)
image 4940:      
image 4905:    
image 469:      
image 102:     
image 6009:     
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (3.225128)
image 4389:     
image 4281:      
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:     
image 2973:    
image 5641:    
evaluating validation preformance... 70/1000 (2.989596)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:      
image 2242:     
evaluating validation preformance... 80/1000 (3.118918)
image 3276:      
image 3812:     
image 1400:    
image 3443:     
image 5027:     
image 7251:      
image 7305:     
image 1480:     
image 4806:      
image 766:    
evaluating validation preformance... 90/1000 (2.455483)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:      
image 6553:      
evaluating validation preformance... 100/1000 (3.348684)
image 2800:    
image 7249:     
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:    
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (3.235976)
image 1122:    
image 509:    
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:     
image 3979:     
image 5302:     
evaluating validation preformance... 120/1000 (2.799535)
image 3477:     
image 1212:     
image 3809:     
image 4329:    
image 3500:     
image 4913:    
image 4589:      
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (3.256493)
image 6214:     
image 429:     
image 7743:     
image 3657:    
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (3.081467)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:      
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.319957)
image 1865:      
image 3830:    
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:      
image 820:     
image 7993:      
evaluating validation preformance... 160/1000 (3.157331)
image 4297:    
image 3315:     
image 1107:     
image 2051:     
image 4713:     
image 8036:     
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.955006)
image 7922:     
image 2353:     
image 4580:    
image 5905:      
image 6488:     
image 3000:    
image 1806:    
image 7761:    
image 3014:     
image 3687:    
evaluating validation preformance... 180/1000 (2.940454)
image 2313:      
image 6289:    
image 8084:     
image 2696:      
image 5830:     
image 6240:      
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.939035)
image 5372:     
image 7529:    
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:     
image 6894:     
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.733381)
image 5159:     
image 1199:    
image 2456:     
image 3402:    
image 7631:     
image 3562:     
image 405:     
image 2532:     
image 2844:    
image 4023:     
evaluating validation preformance... 210/1000 (2.924602)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:     
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (3.069588)
image 4024:     
image 1894:     
image 7297:      
image 1796:    
image 7075:    
image 2258:    
image 5122:      
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.851793)
image 1917:    
image 5844:      
image 1661:    
image 1510:    
image 4630:    
image 6741:     
image 1020:      
image 5967:    
image 8014:     
image 5594:     
evaluating validation preformance... 240/1000 (2.632310)
image 7143:     
image 6019:     
image 885:    
image 2802:     
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (3.009920)
image 3028:    
image 3141:    
image 7137:      
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.866441)
image 492:    
image 5429:     
image 6968:     
image 2672:     
image 6920:     
image 6211:     
image 3326:     
image 1870:     
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.247927)
image 833:     
image 5483:    
image 2476:      
image 5930:     
image 59:    
image 5007:    
image 2884:    
image 486:     
image 7629:    
image 2054:      
evaluating validation preformance... 280/1000 (3.009693)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:     
image 2130:     
evaluating validation preformance... 290/1000 (3.029976)
image 6835:     
image 4698:     
image 7212:     
image 5933:     
image 2431:     
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.600705)
image 2805:    
image 4374:     
image 25:     
image 7702:     
image 256:     
image 7362:     
image 2148:     
image 1974:      
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (3.264345)
image 3553:    
image 5971:     
image 122:     
image 3212:      
image 7223:    
image 7007:     
image 6064:    
image 7358:     
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.808822)
image 489:     
image 5316:     
image 2613:      
image 7935:    
image 7768:     
image 7894:      
image 6267:     
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (3.098943)
image 5179:     
image 3754:    
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:     
image 4524:    
image 3972:     
evaluating validation preformance... 340/1000 (2.853325)
image 4542:     
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:      
evaluating validation preformance... 350/1000 (3.008370)
image 6881:     
image 942:     
image 2775:     
image 3311:     
image 4587:      
image 1215:    
image 5241:     
image 6606:     
image 2387:     
image 3342:      
evaluating validation preformance... 360/1000 (2.348981)
image 2905:    
image 7814:     
image 56:     
image 5034:    
image 7946:    
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (3.006869)
image 4351:    
image 1054:    
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (3.184895)
image 2458:     
image 1084:     
image 4835:    
image 867:    
image 723:     
image 6255:     
image 5255:     
image 3598:     
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (3.227855)
image 828:     
image 2733:    
image 791:      
image 5408:    UNK
image 7842:     
image 1117:      
image 5817:      
image 1231:     
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.716716)
image 2627:     
image 7172:     
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:     
image 7546:      
evaluating validation preformance... 410/1000 (2.613690)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.662636)
image 30:    
image 5540:    
image 2445:      
image 5896:      
image 7607:    
image 1426:      
image 6977:    
image 877:    
image 2408:    
image 7706:    
evaluating validation preformance... 430/1000 (3.222035)
image 385:     
image 6938:     
image 2381:      
image 5796:    
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (3.171808)
image 1731:     
image 978:    
image 6033:     
image 5080:     
image 7804:     
image 439:     
image 4790:     
image 5855:     
image 4245:      
image 973:    UNK
evaluating validation preformance... 450/1000 (2.663047)
image 2241:     
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:     
image 975:     
image 3818:     
image 6995:     
image 3682:     
evaluating validation preformance... 460/1000 (3.303843)
image 7979:     
image 1618:     
image 7608:    
image 6393:     
image 5100:     
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:     
evaluating validation preformance... 470/1000 (3.622048)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:      
image 6862:     
image 7450:    
image 841:    
image 1118:     
image 6114:      
evaluating validation preformance... 480/1000 (3.329503)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:      
image 1040:     
image 3823:    
image 1595:     
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.745720)
image 2044:    
image 4349:     
image 3855:      
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:     
evaluating validation preformance... 500/1000 (2.953907)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:      
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.426387)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:     
image 5416:     
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (3.102196)
image 6806:     
image 6464:     
image 1872:     
image 1575:    
image 3045:      
image 303:     
image 5552:      
image 4628:    
image 1314:    
image 6335:     
evaluating validation preformance... 530/1000 (2.806370)
image 5619:     
image 4391:     
image 891:     
image 3072:    
image 7781:      
image 6163:     
image 7376:      
image 6034:    
image 6062:     
image 3170:    
evaluating validation preformance... 540/1000 (2.997726)
image 5292:      
image 2901:     
image 3568:     
image 690:      
image 3345:    
image 6234:    
image 5074:     
image 4696:     
image 1183:     
image 1961:      
evaluating validation preformance... 550/1000 (3.095172)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:    
image 5079:     
image 6169:    
image 4340:     
image 2134:     
evaluating validation preformance... 560/1000 (3.085489)
image 6056:     
image 6419:    
image 275:     
image 7441:     
image 7893:    
image 3623:     
image 7232:     
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (3.167586)
image 7936:     
image 5433:    
image 5691:      
image 1628:      
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:     
evaluating validation preformance... 580/1000 (2.802771)
image 2135:      
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (3.036828)
image 4420:     
image 1734:      
image 7239:     
image 7447:     
image 8009:    
image 4510:     
image 7495:     
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (3.068554)
image 353:     
image 1095:     
image 3583:     
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:     
image 1773:    
image 4823:     
evaluating validation preformance... 610/1000 (3.154016)
image 69:     
image 3465:    
image 6179:     
image 552:    
image 511:     
image 761:     
image 5742:    
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (3.038520)
image 6575:      
image 5695:    
image 7418:     
image 1948:     
image 4012:     
image 6981:    
image 989:      
image 2847:     
image 4456:     
image 2351:     
evaluating validation preformance... 630/1000 (2.790350)
image 8074:    
image 1904:    
image 7917:      
image 2394:     
image 4406:    
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.921336)
image 5313:     
image 2377:     
image 6058:     
image 4661:     
image 2955:     
image 3333:     
image 7124:     
image 4278:      
image 953:     
image 4037:     
evaluating validation preformance... 650/1000 (3.014653)
image 8065:    
image 3577:     
image 3254:     
image 4562:      
image 5462:     
image 2824:     
image 1639:     
image 1475:    
image 3991:     
image 1023:     
evaluating validation preformance... 660/1000 (3.087427)
image 5701:     
image 1709:     
image 4811:      
image 622:    
image 5997:     
image 1608:      
image 4119:      
image 1619:      
image 5652:      
image 1972:     
evaluating validation preformance... 670/1000 (3.279333)
image 7877:     
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:    
image 6722:     
image 7784:      
evaluating validation preformance... 680/1000 (3.494355)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:      
image 4382:     
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (3.332644)
image 6860:    
image 576:      
image 6580:     
image 1497:     
image 3360:     
image 4939:     
image 6225:    
image 3669:     
image 980:     
image 5362:      
evaluating validation preformance... 700/1000 (3.318195)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:    
image 650:     
image 4911:     
image 34:     
image 7801:     
image 1129:     
evaluating validation preformance... 710/1000 (2.890298)
image 7368:     
image 709:     
image 3197:     
image 5214:     
image 445:      
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.979841)
image 5729:      
image 6395:      
image 516:      
image 1026:    
image 2972:      
image 3005:     
image 1241:    
image 2743:      
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.711101)
image 2527:     
image 6266:     
image 4161:    
image 1139:       
image 3781:     
image 6081:      
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.834862)
image 2239:    
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (3.249097)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:     
image 3780:     
image 7174:     
evaluating validation preformance... 760/1000 (3.363663)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:     
image 2452:     
image 5400:     
image 1357:     
image 3449:      
evaluating validation preformance... 770/1000 (2.606490)
image 6220:    
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:      
image 2329:     
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (3.152138)
image 6867:     
image 5525:     
image 4746:    
image 5531:     
image 5425:     
image 6978:    
image 3450:     
image 3312:     
image 7824:      
image 2032:    
evaluating validation preformance... 790/1000 (3.662385)
image 5047:      
image 325:     
image 7626:    UNK
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.639423)
image 7288:      
image 7302:     
image 3055:    
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.880460)
image 614:     
image 7295:     
image 4110:     
image 5402:      
image 3060:     
image 1317:     
image 3339:    
image 1052:     
image 3701:     
image 4194:      
evaluating validation preformance... 820/1000 (2.447299)
image 7204:     
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:     
image 7147:    
image 6348:    
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.820625)
image 5107:    
image 3973:     
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:      
image 6117:    
evaluating validation preformance... 840/1000 (2.760939)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:     
evaluating validation preformance... 850/1000 (3.363647)
image 4404:     
image 5501:     
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:     
image 6261:     
image 2166:      
evaluating validation preformance... 860/1000 (3.295672)
image 4254:     
image 6842:     
image 1644:    
image 7371:     
image 4638:     
image 4031:     
image 2702:     
image 4927:      
image 3222:     
image 4002:     
evaluating validation preformance... 870/1000 (2.789155)
image 4934:    
image 6487:     
image 4217:    
image 6355:     
image 2793:     
image 7201:     
image 5681:      
image 1824:     
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.958472)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:     
image 419:    
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (3.350667)
image 7485:     
image 6102:    
image 1001:      
image 7167:     
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:     
evaluating validation preformance... 900/1000 (3.762731)
image 5664:     
image 4985:     
image 4082:      
image 6291:     
image 5573:     
image 1405:    
image 4431:     
image 2801:    
image 2398:     
image 7205:     
evaluating validation preformance... 910/1000 (2.697061)
image 1368:     
image 1925:      
image 5870:     
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:     
image 844:     
evaluating validation preformance... 920/1000 (2.975466)
image 7152:      
image 4559:     
image 7233:      
image 1341:     
image 5337:      
image 3189:     
image 6274:      
image 7102:     
image 5532:     
image 2516:    
evaluating validation preformance... 930/1000 (2.839359)
image 5636:     
image 7799:     
image 6025:     
image 6907:     
image 2507:     
image 7014:    
image 5566:     
image 5161:     
image 652:     
image 4412:     
evaluating validation preformance... 940/1000 (3.025262)
image 5860:     
image 3275:     
image 1935:     
image 3520:    
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (3.455352)
image 1081:    
image 1179:     
image 4316:    
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (3.179824)
image 4935:     
image 1930:    
image 6850:     
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:      
image 374:      
evaluating validation preformance... 970/1000 (2.838893)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:     
image 2921:    
image 7800:    
image 3999:     
image 6317:     
image 5931:     
evaluating validation preformance... 980/1000 (3.261789)
image 7352:     
image 5113:     
image 7822:    
image 4858:    
image 658:     
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:     
evaluating validation preformance... 990/1000 (2.937703)
image 5789:      
image 5606:     
image 6107:     
image 7976:     
image 3890:     
image 5901:     
image 1163:      
image 2483:    
image 2591:     
image 7615:    
evaluating validation preformance... 1000/1000 (2.857650)
average loss on validation: 3.031
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3284592628479004
Cider scores: 0.38885918823782334
Read data: 0.23509597778320312
Cider scores: 0.3758819329726386
Read data: 0.23071742057800293
Cider scores: 0.3597044904981069
Read data: 0.21488618850708008
Cider scores: 0.37829389832202925
Read data: 0.23504137992858887
Cider scores: 0.33970450051984
Read data: 0.18374037742614746
Cider scores: 0.343970624165792
Read data: 0.20491433143615723
Cider scores: 0.32808182296012445
Read data: 0.17970490455627441
Cider scores: 0.380958184354544
Read data: 0.17716097831726074
Cider scores: 0.3089595306224953
Read data: 0.18701791763305664
Cider scores: 0.41849122983083287
Read data: 0.2368166446685791
Cider scores: 0.3449956564169394
Read data: 0.17829513549804688
Cider scores: 0.34063531265997077
Read data: 0.17754673957824707
Cider scores: 0.4070826397720142
Read data: 0.17945122718811035
Cider scores: 0.39892708119413356
Read data: 0.17796707153320312
Cider scores: 0.3769116873744649
Read data: 0.17044878005981445
Cider scores: 0.4430089034037655
Read data: 0.15965723991394043
Cider scores: 0.3313836447024421
Read data: 0.16324424743652344
Cider scores: 0.4551068212951159
Read data: 0.1655406951904297
Cider scores: 0.45857680352088936
Read data: 0.15980291366577148
Cider scores: 0.5083570799202941
Average cider score on test set: 0.384
End calculating cider score on TEST data set
===============================================
Read data: 0.16199493408203125
iter 3000 (epoch 4), train_loss = 3.108, time/batch = 0.024
Read data: 0.00010204315185546875
iter 3001 (epoch 5), train_loss = 3.168, time/batch = 0.023
Read data: 0.00011157989501953125
iter 3002 (epoch 5), train_loss = 3.453, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 3003 (epoch 5), train_loss = 2.984, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 3004 (epoch 5), train_loss = 2.926, time/batch = 0.027
Read data: 0.00010180473327636719
iter 3005 (epoch 5), train_loss = 2.796, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 3006 (epoch 5), train_loss = 2.814, time/batch = 0.022
Read data: 0.00017333030700683594
iter 3007 (epoch 5), train_loss = 3.103, time/batch = 0.022
Read data: 0.00011014938354492188
iter 3008 (epoch 5), train_loss = 3.197, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 3009 (epoch 5), train_loss = 3.208, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 3010 (epoch 5), train_loss = 3.052, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 3011 (epoch 5), train_loss = 3.003, time/batch = 0.026
Read data: 0.00017714500427246094
iter 3012 (epoch 5), train_loss = 3.151, time/batch = 0.022
Read data: 9.870529174804688e-05
iter 3013 (epoch 5), train_loss = 3.351, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 3014 (epoch 5), train_loss = 3.227, time/batch = 0.027
Read data: 0.00010538101196289062
iter 3015 (epoch 5), train_loss = 2.948, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 3016 (epoch 5), train_loss = 3.217, time/batch = 0.029
Read data: 9.465217590332031e-05
iter 3017 (epoch 5), train_loss = 3.307, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 3018 (epoch 5), train_loss = 3.353, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 3019 (epoch 5), train_loss = 3.200, time/batch = 0.021
Read data: 8.296966552734375e-05
iter 3020 (epoch 5), train_loss = 3.006, time/batch = 0.019
Read data: 0.0001533031463623047
iter 3021 (epoch 5), train_loss = 2.678, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 3022 (epoch 5), train_loss = 2.944, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 3023 (epoch 5), train_loss = 2.894, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 3024 (epoch 5), train_loss = 3.233, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 3025 (epoch 5), train_loss = 3.043, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 3026 (epoch 5), train_loss = 2.861, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 3027 (epoch 5), train_loss = 2.769, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 3028 (epoch 5), train_loss = 3.477, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 3029 (epoch 5), train_loss = 3.053, time/batch = 0.032
Read data: 0.00012135505676269531
iter 3030 (epoch 5), train_loss = 3.238, time/batch = 0.029
Read data: 0.00010085105895996094
iter 3031 (epoch 5), train_loss = 3.352, time/batch = 0.023
Read data: 8.392333984375e-05
iter 3032 (epoch 5), train_loss = 3.007, time/batch = 0.024
Read data: 0.00010466575622558594
iter 3033 (epoch 5), train_loss = 2.945, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 3034 (epoch 5), train_loss = 2.806, time/batch = 0.028
Read data: 9.846687316894531e-05
iter 3035 (epoch 5), train_loss = 2.710, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 3036 (epoch 5), train_loss = 3.197, time/batch = 0.030
Read data: 8.988380432128906e-05
iter 3037 (epoch 5), train_loss = 3.401, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 3038 (epoch 5), train_loss = 3.390, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 3039 (epoch 5), train_loss = 3.353, time/batch = 0.032
Read data: 0.00012493133544921875
iter 3040 (epoch 5), train_loss = 3.270, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 3041 (epoch 5), train_loss = 3.203, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 3042 (epoch 5), train_loss = 3.682, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 3043 (epoch 5), train_loss = 3.216, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 3044 (epoch 5), train_loss = 3.188, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 3045 (epoch 5), train_loss = 2.942, time/batch = 0.027
Read data: 7.43865966796875e-05
iter 3046 (epoch 5), train_loss = 2.716, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 3047 (epoch 5), train_loss = 2.883, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 3048 (epoch 5), train_loss = 2.961, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 3049 (epoch 5), train_loss = 3.281, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 3050 (epoch 5), train_loss = 3.066, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 3051 (epoch 5), train_loss = 3.549, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 3052 (epoch 5), train_loss = 3.104, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 3053 (epoch 5), train_loss = 2.811, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 3054 (epoch 5), train_loss = 2.892, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 3055 (epoch 5), train_loss = 3.074, time/batch = 0.021
Read data: 9.775161743164062e-05
iter 3056 (epoch 5), train_loss = 3.213, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 3057 (epoch 5), train_loss = 3.144, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 3058 (epoch 5), train_loss = 2.996, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 3059 (epoch 5), train_loss = 2.769, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 3060 (epoch 5), train_loss = 3.289, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 3061 (epoch 5), train_loss = 2.934, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 3062 (epoch 5), train_loss = 3.190, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 3063 (epoch 5), train_loss = 3.618, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 3064 (epoch 5), train_loss = 3.166, time/batch = 0.025
Read data: 9.417533874511719e-05
iter 3065 (epoch 5), train_loss = 3.619, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 3066 (epoch 5), train_loss = 3.174, time/batch = 0.026
Read data: 7.534027099609375e-05
iter 3067 (epoch 5), train_loss = 3.455, time/batch = 0.026
Read data: 0.00011277198791503906
iter 3068 (epoch 5), train_loss = 3.396, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 3069 (epoch 5), train_loss = 3.153, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 3070 (epoch 5), train_loss = 2.885, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 3071 (epoch 5), train_loss = 2.788, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 3072 (epoch 5), train_loss = 3.142, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 3073 (epoch 5), train_loss = 3.224, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 3074 (epoch 5), train_loss = 2.801, time/batch = 0.024
Read data: 0.000209808349609375
iter 3075 (epoch 5), train_loss = 3.063, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 3076 (epoch 5), train_loss = 2.965, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 3077 (epoch 5), train_loss = 3.037, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 3078 (epoch 5), train_loss = 2.952, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 3079 (epoch 5), train_loss = 2.894, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 3080 (epoch 5), train_loss = 3.193, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 3081 (epoch 5), train_loss = 3.061, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 3082 (epoch 5), train_loss = 2.677, time/batch = 0.020
Read data: 0.00010323524475097656
iter 3083 (epoch 5), train_loss = 2.631, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 3084 (epoch 5), train_loss = 2.422, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 3085 (epoch 5), train_loss = 2.725, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 3086 (epoch 5), train_loss = 2.901, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 3087 (epoch 5), train_loss = 2.915, time/batch = 0.023
Read data: 8.392333984375e-05
iter 3088 (epoch 5), train_loss = 3.128, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 3089 (epoch 5), train_loss = 2.633, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 3090 (epoch 5), train_loss = 3.435, time/batch = 0.032
Read data: 9.250640869140625e-05
iter 3091 (epoch 5), train_loss = 3.423, time/batch = 0.028
Read data: 9.1552734375e-05
iter 3092 (epoch 5), train_loss = 2.899, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 3093 (epoch 5), train_loss = 2.653, time/batch = 0.019
Read data: 0.00010085105895996094
iter 3094 (epoch 5), train_loss = 3.059, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 3095 (epoch 5), train_loss = 2.588, time/batch = 0.025
Read data: 0.00014257431030273438
iter 3096 (epoch 5), train_loss = 3.159, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 3097 (epoch 5), train_loss = 3.016, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 3098 (epoch 5), train_loss = 3.481, time/batch = 0.030
Read data: 9.179115295410156e-05
iter 3099 (epoch 5), train_loss = 2.998, time/batch = 0.026
Read data: 0.0002200603485107422
iter 3100 (epoch 5), train_loss = 3.043, time/batch = 0.029
Read data: 7.677078247070312e-05
iter 3101 (epoch 5), train_loss = 2.869, time/batch = 0.024
Read data: 0.00012087821960449219
iter 3102 (epoch 5), train_loss = 3.256, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 3103 (epoch 5), train_loss = 3.476, time/batch = 0.021
Read data: 0.00013184547424316406
iter 3104 (epoch 5), train_loss = 3.151, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 3105 (epoch 5), train_loss = 2.684, time/batch = 0.031
Read data: 0.00013256072998046875
iter 3106 (epoch 5), train_loss = 2.955, time/batch = 0.021
Read data: 0.00010824203491210938
iter 3107 (epoch 5), train_loss = 3.227, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 3108 (epoch 5), train_loss = 3.025, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 3109 (epoch 5), train_loss = 3.346, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 3110 (epoch 5), train_loss = 2.844, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 3111 (epoch 5), train_loss = 2.906, time/batch = 0.023
Read data: 0.00011587142944335938
iter 3112 (epoch 5), train_loss = 3.186, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 3113 (epoch 5), train_loss = 2.709, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 3114 (epoch 5), train_loss = 3.175, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 3115 (epoch 5), train_loss = 3.160, time/batch = 0.036
Read data: 0.000118255615234375
iter 3116 (epoch 5), train_loss = 2.412, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 3117 (epoch 5), train_loss = 2.829, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 3118 (epoch 5), train_loss = 2.532, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 3119 (epoch 5), train_loss = 2.923, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 3120 (epoch 5), train_loss = 3.284, time/batch = 0.025
Read data: 0.0001220703125
iter 3121 (epoch 5), train_loss = 3.492, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 3122 (epoch 5), train_loss = 3.544, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 3123 (epoch 5), train_loss = 2.984, time/batch = 0.020
Read data: 8.726119995117188e-05
iter 3124 (epoch 5), train_loss = 3.497, time/batch = 0.027
Read data: 0.00021696090698242188
iter 3125 (epoch 5), train_loss = 3.638, time/batch = 0.034
Read data: 8.082389831542969e-05
iter 3126 (epoch 5), train_loss = 3.148, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 3127 (epoch 5), train_loss = 3.564, time/batch = 0.031
Read data: 9.1552734375e-05
iter 3128 (epoch 5), train_loss = 2.932, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3129 (epoch 5), train_loss = 2.911, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 3130 (epoch 5), train_loss = 3.003, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 3131 (epoch 5), train_loss = 2.745, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 3132 (epoch 5), train_loss = 3.175, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 3133 (epoch 5), train_loss = 3.050, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 3134 (epoch 5), train_loss = 3.573, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 3135 (epoch 5), train_loss = 2.819, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 3136 (epoch 5), train_loss = 2.899, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 3137 (epoch 5), train_loss = 3.181, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 3138 (epoch 5), train_loss = 2.793, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 3139 (epoch 5), train_loss = 2.557, time/batch = 0.023
Read data: 0.0002372264862060547
iter 3140 (epoch 5), train_loss = 3.203, time/batch = 0.032
Read data: 9.703636169433594e-05
iter 3141 (epoch 5), train_loss = 2.739, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 3142 (epoch 5), train_loss = 2.997, time/batch = 0.023
Read data: 7.653236389160156e-05
iter 3143 (epoch 5), train_loss = 3.297, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 3144 (epoch 5), train_loss = 3.060, time/batch = 0.026
Read data: 9.584426879882812e-05
iter 3145 (epoch 5), train_loss = 2.966, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 3146 (epoch 5), train_loss = 3.252, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 3147 (epoch 5), train_loss = 2.978, time/batch = 0.024
Read data: 0.00013971328735351562
iter 3148 (epoch 5), train_loss = 2.690, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 3149 (epoch 5), train_loss = 3.159, time/batch = 0.026
Read data: 0.0001347064971923828
iter 3150 (epoch 5), train_loss = 2.648, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 3151 (epoch 5), train_loss = 2.836, time/batch = 0.022
Read data: 0.0001461505889892578
iter 3152 (epoch 5), train_loss = 3.200, time/batch = 0.037
Read data: 8.20159912109375e-05
iter 3153 (epoch 5), train_loss = 3.060, time/batch = 0.036
Read data: 0.0001366138458251953
iter 3154 (epoch 5), train_loss = 3.091, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 3155 (epoch 5), train_loss = 3.166, time/batch = 0.024
Read data: 0.0001220703125
iter 3156 (epoch 5), train_loss = 2.647, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 3157 (epoch 5), train_loss = 2.997, time/batch = 0.028
Read data: 0.00015497207641601562
iter 3158 (epoch 5), train_loss = 3.228, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 3159 (epoch 5), train_loss = 2.825, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 3160 (epoch 5), train_loss = 3.459, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 3161 (epoch 5), train_loss = 3.243, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 3162 (epoch 5), train_loss = 3.293, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 3163 (epoch 5), train_loss = 3.330, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 3164 (epoch 5), train_loss = 2.734, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 3165 (epoch 5), train_loss = 3.356, time/batch = 0.025
Read data: 0.00015616416931152344
iter 3166 (epoch 5), train_loss = 3.253, time/batch = 0.027
Read data: 7.605552673339844e-05
iter 3167 (epoch 5), train_loss = 2.962, time/batch = 0.022
Read data: 0.00017142295837402344
iter 3168 (epoch 5), train_loss = 3.066, time/batch = 0.033
Read data: 7.867813110351562e-05
iter 3169 (epoch 5), train_loss = 3.135, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 3170 (epoch 5), train_loss = 2.430, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 3171 (epoch 5), train_loss = 3.313, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 3172 (epoch 5), train_loss = 3.544, time/batch = 0.031
Read data: 0.00010418891906738281
iter 3173 (epoch 5), train_loss = 3.699, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 3174 (epoch 5), train_loss = 3.157, time/batch = 0.027
Read data: 0.00022172927856445312
iter 3175 (epoch 5), train_loss = 3.187, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 3176 (epoch 5), train_loss = 3.097, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 3177 (epoch 5), train_loss = 2.860, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 3178 (epoch 5), train_loss = 3.093, time/batch = 0.032
Read data: 0.00014710426330566406
iter 3179 (epoch 5), train_loss = 2.951, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 3180 (epoch 5), train_loss = 2.911, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 3181 (epoch 5), train_loss = 3.131, time/batch = 0.031
Read data: 0.0001246929168701172
iter 3182 (epoch 5), train_loss = 3.342, time/batch = 0.028
Read data: 0.00010156631469726562
iter 3183 (epoch 5), train_loss = 3.297, time/batch = 0.027
Read data: 0.0001671314239501953
iter 3184 (epoch 5), train_loss = 3.033, time/batch = 0.044
Read data: 0.00011134147644042969
iter 3185 (epoch 5), train_loss = 2.961, time/batch = 0.027
Read data: 0.00011110305786132812
iter 3186 (epoch 5), train_loss = 2.969, time/batch = 0.032
Read data: 7.43865966796875e-05
iter 3187 (epoch 5), train_loss = 3.019, time/batch = 0.030
Read data: 0.00011420249938964844
iter 3188 (epoch 5), train_loss = 3.124, time/batch = 0.033
Read data: 0.0002300739288330078
iter 3189 (epoch 5), train_loss = 3.348, time/batch = 0.025
Read data: 0.0001125335693359375
iter 3190 (epoch 5), train_loss = 3.233, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 3191 (epoch 5), train_loss = 2.939, time/batch = 0.030
Read data: 0.00016117095947265625
iter 3192 (epoch 5), train_loss = 3.321, time/batch = 0.029
Read data: 0.00010848045349121094
iter 3193 (epoch 5), train_loss = 2.798, time/batch = 0.028
Read data: 0.00010752677917480469
iter 3194 (epoch 5), train_loss = 2.897, time/batch = 0.032
Read data: 7.772445678710938e-05
iter 3195 (epoch 5), train_loss = 3.047, time/batch = 0.026
Read data: 0.0001728534698486328
iter 3196 (epoch 5), train_loss = 3.104, time/batch = 0.030
Read data: 0.00012636184692382812
iter 3197 (epoch 5), train_loss = 2.874, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 3198 (epoch 5), train_loss = 3.189, time/batch = 0.022
Read data: 0.0017218589782714844
iter 3199 (epoch 5), train_loss = 3.075, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 3200 (epoch 5), train_loss = 2.969, time/batch = 0.024
Read data: 0.00015544891357421875
iter 3201 (epoch 5), train_loss = 2.853, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 3202 (epoch 5), train_loss = 3.272, time/batch = 0.025
Read data: 0.00010323524475097656
iter 3203 (epoch 5), train_loss = 3.086, time/batch = 0.024
Read data: 0.00013446807861328125
iter 3204 (epoch 5), train_loss = 3.069, time/batch = 0.026
Read data: 0.00010967254638671875
iter 3205 (epoch 5), train_loss = 2.774, time/batch = 0.025
Read data: 0.0001373291015625
iter 3206 (epoch 5), train_loss = 2.584, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 3207 (epoch 5), train_loss = 2.780, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 3208 (epoch 5), train_loss = 3.401, time/batch = 0.026
Read data: 0.00014209747314453125
iter 3209 (epoch 5), train_loss = 2.911, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 3210 (epoch 5), train_loss = 2.995, time/batch = 0.030
Read data: 0.00015473365783691406
iter 3211 (epoch 5), train_loss = 2.962, time/batch = 0.025
Read data: 0.00013208389282226562
iter 3212 (epoch 5), train_loss = 3.198, time/batch = 0.032
Read data: 0.0001361370086669922
iter 3213 (epoch 5), train_loss = 3.829, time/batch = 0.038
Read data: 0.00013637542724609375
iter 3214 (epoch 5), train_loss = 3.452, time/batch = 0.026
Read data: 0.0001385211944580078
iter 3215 (epoch 5), train_loss = 2.819, time/batch = 0.025
Read data: 0.00012922286987304688
iter 3216 (epoch 5), train_loss = 2.499, time/batch = 0.026
Read data: 0.0001246929168701172
iter 3217 (epoch 5), train_loss = 2.830, time/batch = 0.028
Read data: 0.00010180473327636719
iter 3218 (epoch 5), train_loss = 2.943, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 3219 (epoch 5), train_loss = 3.111, time/batch = 0.022
Read data: 0.0001201629638671875
iter 3220 (epoch 5), train_loss = 3.389, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 3221 (epoch 5), train_loss = 3.402, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 3222 (epoch 5), train_loss = 2.587, time/batch = 0.024
Read data: 0.00015163421630859375
iter 3223 (epoch 5), train_loss = 3.162, time/batch = 0.024
Read data: 0.00011992454528808594
iter 3224 (epoch 5), train_loss = 3.347, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 3225 (epoch 5), train_loss = 2.960, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3226 (epoch 5), train_loss = 3.135, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 3227 (epoch 5), train_loss = 3.066, time/batch = 0.032
Read data: 0.00012350082397460938
iter 3228 (epoch 5), train_loss = 2.624, time/batch = 0.021
Read data: 0.00012230873107910156
iter 3229 (epoch 5), train_loss = 3.409, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 3230 (epoch 5), train_loss = 3.035, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 3231 (epoch 5), train_loss = 3.507, time/batch = 0.028
Read data: 0.00011014938354492188
iter 3232 (epoch 5), train_loss = 3.310, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 3233 (epoch 5), train_loss = 2.995, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 3234 (epoch 5), train_loss = 3.441, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 3235 (epoch 5), train_loss = 3.102, time/batch = 0.026
Read data: 0.00010085105895996094
iter 3236 (epoch 5), train_loss = 2.751, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 3237 (epoch 5), train_loss = 3.176, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 3238 (epoch 5), train_loss = 3.033, time/batch = 0.024
Read data: 0.0001761913299560547
iter 3239 (epoch 5), train_loss = 2.810, time/batch = 0.020
Read data: 0.00010466575622558594
iter 3240 (epoch 5), train_loss = 2.868, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 3241 (epoch 5), train_loss = 3.453, time/batch = 0.040
Read data: 8.559226989746094e-05
iter 3242 (epoch 5), train_loss = 2.634, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 3243 (epoch 5), train_loss = 2.713, time/batch = 0.024
Read data: 0.00012350082397460938
iter 3244 (epoch 5), train_loss = 3.064, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 3245 (epoch 5), train_loss = 2.917, time/batch = 0.023
Read data: 0.00013494491577148438
iter 3246 (epoch 5), train_loss = 3.325, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 3247 (epoch 5), train_loss = 3.627, time/batch = 0.024
Read data: 0.0001266002655029297
iter 3248 (epoch 5), train_loss = 2.922, time/batch = 0.024
Read data: 0.00013780593872070312
iter 3249 (epoch 5), train_loss = 2.965, time/batch = 0.024
Read data: 0.00023794174194335938
iter 3250 (epoch 5), train_loss = 3.444, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 3251 (epoch 5), train_loss = 2.813, time/batch = 0.023
Read data: 0.00012612342834472656
iter 3252 (epoch 5), train_loss = 2.420, time/batch = 0.031
Read data: 9.942054748535156e-05
iter 3253 (epoch 5), train_loss = 3.341, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 3254 (epoch 5), train_loss = 3.222, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 3255 (epoch 5), train_loss = 3.117, time/batch = 0.020
Read data: 8.0108642578125e-05
iter 3256 (epoch 5), train_loss = 3.544, time/batch = 0.035
Read data: 0.00012063980102539062
iter 3257 (epoch 5), train_loss = 3.217, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 3258 (epoch 5), train_loss = 2.646, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 3259 (epoch 5), train_loss = 2.748, time/batch = 0.030
Read data: 9.202957153320312e-05
iter 3260 (epoch 5), train_loss = 2.767, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 3261 (epoch 5), train_loss = 3.215, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 3262 (epoch 5), train_loss = 3.001, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 3263 (epoch 5), train_loss = 3.261, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 3264 (epoch 5), train_loss = 2.966, time/batch = 0.023
Read data: 0.00011849403381347656
iter 3265 (epoch 5), train_loss = 2.878, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 3266 (epoch 5), train_loss = 2.962, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 3267 (epoch 5), train_loss = 3.172, time/batch = 0.020
Read data: 0.00013256072998046875
iter 3268 (epoch 5), train_loss = 2.921, time/batch = 0.032
Read data: 0.00012922286987304688
iter 3269 (epoch 5), train_loss = 2.904, time/batch = 0.024
Read data: 9.1552734375e-05
iter 3270 (epoch 5), train_loss = 2.745, time/batch = 0.027
Read data: 7.462501525878906e-05
iter 3271 (epoch 5), train_loss = 2.649, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 3272 (epoch 5), train_loss = 3.196, time/batch = 0.023
Read data: 0.0001385211944580078
iter 3273 (epoch 5), train_loss = 3.083, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 3274 (epoch 5), train_loss = 2.742, time/batch = 0.026
Read data: 0.0002338886260986328
iter 3275 (epoch 5), train_loss = 2.751, time/batch = 0.026
Read data: 0.00013327598571777344
iter 3276 (epoch 5), train_loss = 3.726, time/batch = 0.030
Read data: 0.00011801719665527344
iter 3277 (epoch 5), train_loss = 3.124, time/batch = 0.029
Read data: 8.654594421386719e-05
iter 3278 (epoch 5), train_loss = 3.088, time/batch = 0.021
Read data: 0.0001251697540283203
iter 3279 (epoch 5), train_loss = 3.324, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 3280 (epoch 5), train_loss = 3.086, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 3281 (epoch 5), train_loss = 3.219, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 3282 (epoch 5), train_loss = 2.889, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 3283 (epoch 5), train_loss = 3.233, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 3284 (epoch 5), train_loss = 3.495, time/batch = 0.034
Read data: 8.344650268554688e-05
iter 3285 (epoch 5), train_loss = 3.763, time/batch = 0.039
Read data: 9.560585021972656e-05
iter 3286 (epoch 5), train_loss = 3.151, time/batch = 0.027
Read data: 9.632110595703125e-05
iter 3287 (epoch 5), train_loss = 3.193, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 3288 (epoch 5), train_loss = 2.851, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 3289 (epoch 5), train_loss = 3.037, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 3290 (epoch 5), train_loss = 2.918, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 3291 (epoch 5), train_loss = 2.927, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 3292 (epoch 5), train_loss = 2.886, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 3293 (epoch 5), train_loss = 2.552, time/batch = 0.023
Read data: 0.0001232624053955078
iter 3294 (epoch 5), train_loss = 3.207, time/batch = 0.034
Read data: 7.748603820800781e-05
iter 3295 (epoch 5), train_loss = 2.943, time/batch = 0.025
Read data: 0.0001270771026611328
iter 3296 (epoch 5), train_loss = 3.001, time/batch = 0.027
Read data: 0.00012040138244628906
iter 3297 (epoch 5), train_loss = 2.894, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 3298 (epoch 5), train_loss = 2.718, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 3299 (epoch 5), train_loss = 3.102, time/batch = 0.025
Read data: 0.00012493133544921875
iter 3300 (epoch 5), train_loss = 3.267, time/batch = 0.028
Read data: 0.00013756752014160156
iter 3301 (epoch 5), train_loss = 3.247, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 3302 (epoch 5), train_loss = 2.968, time/batch = 0.034
Read data: 0.00016045570373535156
iter 3303 (epoch 5), train_loss = 3.086, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 3304 (epoch 5), train_loss = 3.179, time/batch = 0.031
Read data: 0.00012969970703125
iter 3305 (epoch 5), train_loss = 3.166, time/batch = 0.033
Read data: 9.012222290039062e-05
iter 3306 (epoch 5), train_loss = 3.029, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 3307 (epoch 5), train_loss = 3.058, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 3308 (epoch 5), train_loss = 3.007, time/batch = 0.024
Read data: 0.00012302398681640625
iter 3309 (epoch 5), train_loss = 3.268, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 3310 (epoch 5), train_loss = 3.052, time/batch = 0.020
Read data: 7.677078247070312e-05
iter 3311 (epoch 5), train_loss = 3.029, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 3312 (epoch 5), train_loss = 2.871, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 3313 (epoch 5), train_loss = 3.411, time/batch = 0.029
Read data: 9.202957153320312e-05
iter 3314 (epoch 5), train_loss = 2.867, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 3315 (epoch 5), train_loss = 3.131, time/batch = 0.028
Read data: 0.00012087821960449219
iter 3316 (epoch 5), train_loss = 3.204, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 3317 (epoch 5), train_loss = 3.056, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 3318 (epoch 5), train_loss = 3.042, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 3319 (epoch 5), train_loss = 3.256, time/batch = 0.028
Read data: 9.417533874511719e-05
iter 3320 (epoch 5), train_loss = 2.813, time/batch = 0.042
Read data: 0.0001316070556640625
iter 3321 (epoch 5), train_loss = 3.059, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 3322 (epoch 5), train_loss = 2.910, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 3323 (epoch 5), train_loss = 2.865, time/batch = 0.027
Read data: 0.0001270771026611328
iter 3324 (epoch 5), train_loss = 2.936, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 3325 (epoch 5), train_loss = 3.099, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3326 (epoch 5), train_loss = 2.967, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 3327 (epoch 5), train_loss = 2.912, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 3328 (epoch 5), train_loss = 2.880, time/batch = 0.034
Read data: 8.559226989746094e-05
iter 3329 (epoch 5), train_loss = 3.026, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 3330 (epoch 5), train_loss = 3.239, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 3331 (epoch 5), train_loss = 2.973, time/batch = 0.032
Read data: 8.726119995117188e-05
iter 3332 (epoch 5), train_loss = 2.993, time/batch = 0.030
Read data: 0.00013208389282226562
iter 3333 (epoch 5), train_loss = 3.010, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 3334 (epoch 5), train_loss = 3.031, time/batch = 0.026
Read data: 0.00013208389282226562
iter 3335 (epoch 5), train_loss = 3.301, time/batch = 0.032
Read data: 0.00012421607971191406
iter 3336 (epoch 5), train_loss = 3.268, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 3337 (epoch 5), train_loss = 2.903, time/batch = 0.027
Read data: 0.00012803077697753906
iter 3338 (epoch 5), train_loss = 2.867, time/batch = 0.026
Read data: 8.392333984375e-05
iter 3339 (epoch 5), train_loss = 3.341, time/batch = 0.032
Read data: 0.00012636184692382812
iter 3340 (epoch 5), train_loss = 3.053, time/batch = 0.023
Read data: 8.535385131835938e-05
iter 3341 (epoch 5), train_loss = 2.957, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 3342 (epoch 5), train_loss = 2.474, time/batch = 0.020
Read data: 7.987022399902344e-05
iter 3343 (epoch 5), train_loss = 2.965, time/batch = 0.024
Read data: 0.00013566017150878906
iter 3344 (epoch 5), train_loss = 2.723, time/batch = 0.028
Read data: 0.0001366138458251953
iter 3345 (epoch 5), train_loss = 2.632, time/batch = 0.033
Read data: 7.987022399902344e-05
iter 3346 (epoch 5), train_loss = 2.884, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 3347 (epoch 5), train_loss = 2.965, time/batch = 0.024
Read data: 0.00010371208190917969
iter 3348 (epoch 5), train_loss = 3.724, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 3349 (epoch 5), train_loss = 2.816, time/batch = 0.034
Read data: 0.0002186298370361328
iter 3350 (epoch 5), train_loss = 3.107, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 3351 (epoch 5), train_loss = 3.167, time/batch = 0.026
Read data: 0.0001704692840576172
iter 3352 (epoch 5), train_loss = 3.102, time/batch = 0.020
Read data: 0.0001227855682373047
iter 3353 (epoch 5), train_loss = 3.177, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 3354 (epoch 5), train_loss = 3.311, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3355 (epoch 5), train_loss = 3.080, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 3356 (epoch 5), train_loss = 2.874, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 3357 (epoch 5), train_loss = 3.299, time/batch = 0.028
Read data: 0.0001246929168701172
iter 3358 (epoch 5), train_loss = 3.280, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 3359 (epoch 5), train_loss = 3.119, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 3360 (epoch 5), train_loss = 2.800, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 3361 (epoch 5), train_loss = 3.190, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 3362 (epoch 5), train_loss = 2.974, time/batch = 0.022
Read data: 0.0001246929168701172
iter 3363 (epoch 5), train_loss = 3.121, time/batch = 0.020
Read data: 0.00013303756713867188
iter 3364 (epoch 5), train_loss = 2.596, time/batch = 0.022
Read data: 0.0001926422119140625
iter 3365 (epoch 5), train_loss = 3.057, time/batch = 0.028
Read data: 9.1552734375e-05
iter 3366 (epoch 5), train_loss = 2.705, time/batch = 0.029
Read data: 0.00010442733764648438
iter 3367 (epoch 5), train_loss = 3.084, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 3368 (epoch 5), train_loss = 3.290, time/batch = 0.033
Read data: 8.296966552734375e-05
iter 3369 (epoch 5), train_loss = 3.441, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 3370 (epoch 5), train_loss = 3.197, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 3371 (epoch 5), train_loss = 3.407, time/batch = 0.024
Read data: 0.0001239776611328125
iter 3372 (epoch 5), train_loss = 3.147, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 3373 (epoch 5), train_loss = 2.734, time/batch = 0.024
Read data: 0.0001366138458251953
iter 3374 (epoch 5), train_loss = 2.955, time/batch = 0.026
Read data: 0.0003337860107421875
iter 3375 (epoch 5), train_loss = 2.867, time/batch = 0.025
Read data: 0.00010371208190917969
iter 3376 (epoch 5), train_loss = 3.634, time/batch = 0.023
Read data: 9.274482727050781e-05
iter 3377 (epoch 5), train_loss = 2.791, time/batch = 0.032
Read data: 9.751319885253906e-05
iter 3378 (epoch 5), train_loss = 3.097, time/batch = 0.023
Read data: 0.00010371208190917969
iter 3379 (epoch 5), train_loss = 3.034, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 3380 (epoch 5), train_loss = 2.897, time/batch = 0.027
Read data: 0.00013399124145507812
iter 3381 (epoch 5), train_loss = 3.001, time/batch = 0.024
Read data: 0.0001347064971923828
iter 3382 (epoch 5), train_loss = 2.926, time/batch = 0.025
Read data: 0.00013971328735351562
iter 3383 (epoch 5), train_loss = 3.119, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 3384 (epoch 5), train_loss = 2.639, time/batch = 0.022
Read data: 0.00013208389282226562
iter 3385 (epoch 5), train_loss = 3.193, time/batch = 0.028
Read data: 0.0001327991485595703
iter 3386 (epoch 5), train_loss = 2.788, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 3387 (epoch 5), train_loss = 3.404, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 3388 (epoch 5), train_loss = 2.788, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 3389 (epoch 5), train_loss = 3.324, time/batch = 0.025
Read data: 0.0001010894775390625
iter 3390 (epoch 5), train_loss = 2.848, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 3391 (epoch 5), train_loss = 2.701, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 3392 (epoch 5), train_loss = 3.261, time/batch = 0.026
Read data: 0.00010752677917480469
iter 3393 (epoch 5), train_loss = 2.733, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 3394 (epoch 5), train_loss = 2.686, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 3395 (epoch 5), train_loss = 2.938, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 3396 (epoch 5), train_loss = 2.611, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 3397 (epoch 5), train_loss = 2.954, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 3398 (epoch 5), train_loss = 3.046, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 3399 (epoch 5), train_loss = 3.018, time/batch = 0.026
Read data: 0.000255584716796875
iter 3400 (epoch 5), train_loss = 3.637, time/batch = 0.036
Read data: 0.00012564659118652344
iter 3401 (epoch 5), train_loss = 3.113, time/batch = 0.028
Read data: 9.894371032714844e-05
iter 3402 (epoch 5), train_loss = 2.759, time/batch = 0.024
Read data: 0.00011682510375976562
iter 3403 (epoch 5), train_loss = 3.464, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 3404 (epoch 5), train_loss = 3.631, time/batch = 0.023
Read data: 8.392333984375e-05
iter 3405 (epoch 5), train_loss = 2.877, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 3406 (epoch 5), train_loss = 2.622, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 3407 (epoch 5), train_loss = 3.335, time/batch = 0.022
Read data: 7.724761962890625e-05
iter 3408 (epoch 5), train_loss = 3.024, time/batch = 0.023
Read data: 0.00012969970703125
iter 3409 (epoch 5), train_loss = 3.215, time/batch = 0.026
Read data: 0.0001461505889892578
iter 3410 (epoch 5), train_loss = 2.747, time/batch = 0.029
Read data: 9.179115295410156e-05
iter 3411 (epoch 5), train_loss = 3.799, time/batch = 0.023
Read data: 0.00013494491577148438
iter 3412 (epoch 5), train_loss = 2.873, time/batch = 0.026
Read data: 0.00010371208190917969
iter 3413 (epoch 5), train_loss = 3.200, time/batch = 0.040
Read data: 8.940696716308594e-05
iter 3414 (epoch 5), train_loss = 3.106, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 3415 (epoch 5), train_loss = 2.826, time/batch = 0.030
Read data: 9.012222290039062e-05
iter 3416 (epoch 5), train_loss = 3.095, time/batch = 0.025
Read data: 0.0001304149627685547
iter 3417 (epoch 5), train_loss = 2.899, time/batch = 0.032
Read data: 0.00014400482177734375
iter 3418 (epoch 5), train_loss = 2.951, time/batch = 0.022
Read data: 0.0001347064971923828
iter 3419 (epoch 5), train_loss = 2.931, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 3420 (epoch 5), train_loss = 3.294, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 3421 (epoch 5), train_loss = 2.762, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 3422 (epoch 5), train_loss = 3.068, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3423 (epoch 5), train_loss = 2.570, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 3424 (epoch 5), train_loss = 3.480, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 3425 (epoch 5), train_loss = 3.171, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 3426 (epoch 5), train_loss = 3.096, time/batch = 0.022
Read data: 7.677078247070312e-05
iter 3427 (epoch 5), train_loss = 3.287, time/batch = 0.023
Read data: 0.00010395050048828125
iter 3428 (epoch 5), train_loss = 2.387, time/batch = 0.026
Read data: 0.00013828277587890625
iter 3429 (epoch 5), train_loss = 2.568, time/batch = 0.022
Read data: 0.00011849403381347656
iter 3430 (epoch 5), train_loss = 2.822, time/batch = 0.030
Read data: 0.00011944770812988281
iter 3431 (epoch 5), train_loss = 3.242, time/batch = 0.022
Read data: 0.00013780593872070312
iter 3432 (epoch 5), train_loss = 2.964, time/batch = 0.031
Read data: 9.942054748535156e-05
iter 3433 (epoch 5), train_loss = 2.771, time/batch = 0.030
Read data: 0.0001232624053955078
iter 3434 (epoch 5), train_loss = 2.879, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 3435 (epoch 5), train_loss = 2.362, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 3436 (epoch 5), train_loss = 2.932, time/batch = 0.025
Read data: 0.0001049041748046875
iter 3437 (epoch 5), train_loss = 2.959, time/batch = 0.027
Read data: 0.00013637542724609375
iter 3438 (epoch 5), train_loss = 2.885, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 3439 (epoch 5), train_loss = 2.842, time/batch = 0.022
Read data: 8.416175842285156e-05
iter 3440 (epoch 5), train_loss = 3.197, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 3441 (epoch 5), train_loss = 2.786, time/batch = 0.027
Read data: 9.918212890625e-05
iter 3442 (epoch 5), train_loss = 3.209, time/batch = 0.029
Read data: 0.00012135505676269531
iter 3443 (epoch 5), train_loss = 3.630, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 3444 (epoch 5), train_loss = 2.718, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 3445 (epoch 5), train_loss = 2.852, time/batch = 0.027
Read data: 0.00010895729064941406
iter 3446 (epoch 5), train_loss = 2.776, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 3447 (epoch 5), train_loss = 2.878, time/batch = 0.028
Read data: 0.0001227855682373047
iter 3448 (epoch 5), train_loss = 3.048, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 3449 (epoch 5), train_loss = 3.228, time/batch = 0.034
Read data: 0.00021982192993164062
iter 3450 (epoch 5), train_loss = 2.930, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 3451 (epoch 5), train_loss = 3.152, time/batch = 0.028
Read data: 0.00013208389282226562
iter 3452 (epoch 5), train_loss = 3.040, time/batch = 0.031
Read data: 9.107589721679688e-05
iter 3453 (epoch 5), train_loss = 2.891, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 3454 (epoch 5), train_loss = 2.376, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 3455 (epoch 5), train_loss = 3.043, time/batch = 0.028
Read data: 0.0001246929168701172
iter 3456 (epoch 5), train_loss = 2.931, time/batch = 0.024
Read data: 0.00013899803161621094
iter 3457 (epoch 5), train_loss = 3.078, time/batch = 0.020
Read data: 9.655952453613281e-05
iter 3458 (epoch 5), train_loss = 3.040, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 3459 (epoch 5), train_loss = 3.159, time/batch = 0.024
Read data: 0.00013828277587890625
iter 3460 (epoch 5), train_loss = 2.934, time/batch = 0.028
Read data: 0.00010752677917480469
iter 3461 (epoch 5), train_loss = 2.908, time/batch = 0.024
Read data: 0.00013446807861328125
iter 3462 (epoch 5), train_loss = 3.424, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 3463 (epoch 5), train_loss = 2.661, time/batch = 0.024
Read data: 0.00168609619140625
iter 3464 (epoch 5), train_loss = 2.909, time/batch = 0.023
Read data: 0.00012922286987304688
iter 3465 (epoch 5), train_loss = 3.539, time/batch = 0.023
Read data: 0.00013589859008789062
iter 3466 (epoch 5), train_loss = 2.740, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 3467 (epoch 5), train_loss = 3.239, time/batch = 0.024
Read data: 0.000133514404296875
iter 3468 (epoch 5), train_loss = 2.739, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 3469 (epoch 5), train_loss = 3.177, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 3470 (epoch 5), train_loss = 3.011, time/batch = 0.021
Read data: 9.799003601074219e-05
iter 3471 (epoch 5), train_loss = 2.944, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 3472 (epoch 5), train_loss = 2.850, time/batch = 0.020
Read data: 0.00012946128845214844
iter 3473 (epoch 5), train_loss = 2.540, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 3474 (epoch 5), train_loss = 2.816, time/batch = 0.025
Read data: 0.00025725364685058594
iter 3475 (epoch 5), train_loss = 3.234, time/batch = 0.024
Read data: 0.00013780593872070312
iter 3476 (epoch 5), train_loss = 3.122, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 3477 (epoch 5), train_loss = 2.850, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 3478 (epoch 5), train_loss = 3.228, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 3479 (epoch 5), train_loss = 3.375, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 3480 (epoch 5), train_loss = 2.885, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 3481 (epoch 5), train_loss = 3.004, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 3482 (epoch 5), train_loss = 3.157, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 3483 (epoch 5), train_loss = 3.164, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 3484 (epoch 5), train_loss = 2.986, time/batch = 0.027
Read data: 0.00011372566223144531
iter 3485 (epoch 5), train_loss = 3.281, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 3486 (epoch 5), train_loss = 2.984, time/batch = 0.023
Read data: 0.00010180473327636719
iter 3487 (epoch 5), train_loss = 2.950, time/batch = 0.030
Read data: 0.00013518333435058594
iter 3488 (epoch 5), train_loss = 3.221, time/batch = 0.023
Read data: 0.00010037422180175781
iter 3489 (epoch 5), train_loss = 3.196, time/batch = 0.027
Read data: 0.0001354217529296875
iter 3490 (epoch 5), train_loss = 2.669, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 3491 (epoch 5), train_loss = 2.783, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 3492 (epoch 5), train_loss = 3.099, time/batch = 0.023
Read data: 0.0001366138458251953
iter 3493 (epoch 5), train_loss = 3.018, time/batch = 0.026
Read data: 0.0001399517059326172
iter 3494 (epoch 5), train_loss = 2.686, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 3495 (epoch 5), train_loss = 3.003, time/batch = 0.025
Read data: 0.00010657310485839844
iter 3496 (epoch 5), train_loss = 2.965, time/batch = 0.024
Read data: 0.00010943412780761719
iter 3497 (epoch 5), train_loss = 2.981, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 3498 (epoch 5), train_loss = 2.797, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 3499 (epoch 5), train_loss = 3.495, time/batch = 0.027
Read data: 0.00025463104248046875
iter 3500 (epoch 5), train_loss = 2.681, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 3501 (epoch 5), train_loss = 2.798, time/batch = 0.031
Read data: 8.726119995117188e-05
iter 3502 (epoch 5), train_loss = 2.720, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 3503 (epoch 5), train_loss = 2.990, time/batch = 0.024
Read data: 0.000118255615234375
iter 3504 (epoch 5), train_loss = 3.071, time/batch = 0.027
Read data: 0.00012373924255371094
iter 3505 (epoch 5), train_loss = 2.652, time/batch = 0.022
Read data: 0.00013947486877441406
iter 3506 (epoch 5), train_loss = 3.059, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 3507 (epoch 5), train_loss = 3.378, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 3508 (epoch 5), train_loss = 3.134, time/batch = 0.024
Read data: 0.0001380443572998047
iter 3509 (epoch 5), train_loss = 2.965, time/batch = 0.020
Read data: 0.00013375282287597656
iter 3510 (epoch 5), train_loss = 2.546, time/batch = 0.023
Read data: 0.00014066696166992188
iter 3511 (epoch 5), train_loss = 2.756, time/batch = 0.026
Read data: 9.918212890625e-05
iter 3512 (epoch 5), train_loss = 3.122, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 3513 (epoch 5), train_loss = 3.160, time/batch = 0.035
Read data: 8.20159912109375e-05
iter 3514 (epoch 5), train_loss = 2.775, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 3515 (epoch 5), train_loss = 2.987, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 3516 (epoch 5), train_loss = 2.647, time/batch = 0.026
Read data: 0.00012874603271484375
iter 3517 (epoch 5), train_loss = 2.991, time/batch = 0.022
Read data: 9.870529174804688e-05
iter 3518 (epoch 5), train_loss = 3.172, time/batch = 0.029
Read data: 9.298324584960938e-05
iter 3519 (epoch 5), train_loss = 3.088, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 3520 (epoch 5), train_loss = 3.068, time/batch = 0.028
Read data: 0.00011754035949707031
iter 3521 (epoch 5), train_loss = 2.557, time/batch = 0.027
Read data: 0.00010251998901367188
iter 3522 (epoch 5), train_loss = 2.665, time/batch = 0.030
Read data: 0.0001304149627685547
iter 3523 (epoch 5), train_loss = 3.206, time/batch = 0.025
Read data: 0.0001239776611328125
iter 3524 (epoch 5), train_loss = 2.810, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 3525 (epoch 5), train_loss = 2.860, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 3526 (epoch 5), train_loss = 3.521, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 3527 (epoch 5), train_loss = 3.023, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 3528 (epoch 5), train_loss = 3.112, time/batch = 0.024
Read data: 0.0001201629638671875
iter 3529 (epoch 5), train_loss = 3.065, time/batch = 0.033
Read data: 8.58306884765625e-05
iter 3530 (epoch 5), train_loss = 3.227, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 3531 (epoch 5), train_loss = 2.938, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 3532 (epoch 5), train_loss = 2.706, time/batch = 0.021
Read data: 0.00012302398681640625
iter 3533 (epoch 5), train_loss = 3.295, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 3534 (epoch 5), train_loss = 3.143, time/batch = 0.032
Read data: 7.414817810058594e-05
iter 3535 (epoch 5), train_loss = 3.084, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 3536 (epoch 5), train_loss = 2.954, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 3537 (epoch 5), train_loss = 2.819, time/batch = 0.033
Read data: 8.273124694824219e-05
iter 3538 (epoch 5), train_loss = 3.506, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 3539 (epoch 5), train_loss = 2.611, time/batch = 0.024
Read data: 0.00011944770812988281
iter 3540 (epoch 5), train_loss = 2.766, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 3541 (epoch 5), train_loss = 3.375, time/batch = 0.025
Read data: 0.0001423358917236328
iter 3542 (epoch 5), train_loss = 3.047, time/batch = 0.027
Read data: 0.0001418590545654297
iter 3543 (epoch 5), train_loss = 3.012, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 3544 (epoch 5), train_loss = 2.956, time/batch = 0.022
Read data: 0.00010204315185546875
iter 3545 (epoch 5), train_loss = 2.780, time/batch = 0.028
Read data: 0.00014090538024902344
iter 3546 (epoch 5), train_loss = 2.927, time/batch = 0.025
Read data: 0.0001652240753173828
iter 3547 (epoch 5), train_loss = 2.979, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 3548 (epoch 5), train_loss = 3.093, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 3549 (epoch 5), train_loss = 2.815, time/batch = 0.029
Read data: 0.0002818107604980469
iter 3550 (epoch 5), train_loss = 3.278, time/batch = 0.026
Read data: 0.00012993812561035156
iter 3551 (epoch 5), train_loss = 3.885, time/batch = 0.028
Read data: 0.00012445449829101562
iter 3552 (epoch 5), train_loss = 2.889, time/batch = 0.024
Read data: 0.00012087821960449219
iter 3553 (epoch 5), train_loss = 2.579, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 3554 (epoch 5), train_loss = 3.143, time/batch = 0.025
Read data: 0.00011968612670898438
iter 3555 (epoch 5), train_loss = 3.159, time/batch = 0.024
Read data: 8.392333984375e-05
iter 3556 (epoch 5), train_loss = 2.958, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 3557 (epoch 5), train_loss = 2.677, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 3558 (epoch 5), train_loss = 2.918, time/batch = 0.028
Read data: 0.00010514259338378906
iter 3559 (epoch 5), train_loss = 2.923, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 3560 (epoch 5), train_loss = 2.949, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 3561 (epoch 5), train_loss = 3.007, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 3562 (epoch 5), train_loss = 2.956, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 3563 (epoch 5), train_loss = 3.031, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 3564 (epoch 5), train_loss = 2.798, time/batch = 0.019
Read data: 0.00012993812561035156
iter 3565 (epoch 5), train_loss = 2.937, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 3566 (epoch 5), train_loss = 3.119, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 3567 (epoch 5), train_loss = 3.066, time/batch = 0.024
Read data: 0.000133514404296875
iter 3568 (epoch 5), train_loss = 3.112, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 3569 (epoch 5), train_loss = 2.604, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 3570 (epoch 5), train_loss = 2.926, time/batch = 0.024
Read data: 0.00015401840209960938
iter 3571 (epoch 5), train_loss = 2.909, time/batch = 0.033
Read data: 8.726119995117188e-05
iter 3572 (epoch 5), train_loss = 2.755, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 3573 (epoch 5), train_loss = 2.908, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 3574 (epoch 5), train_loss = 2.953, time/batch = 0.026
Read data: 0.00021886825561523438
iter 3575 (epoch 5), train_loss = 3.098, time/batch = 0.024
Read data: 0.00013208389282226562
iter 3576 (epoch 5), train_loss = 3.050, time/batch = 0.028
Read data: 0.0001239776611328125
iter 3577 (epoch 5), train_loss = 3.115, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3578 (epoch 5), train_loss = 3.169, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3579 (epoch 5), train_loss = 2.865, time/batch = 0.026
Read data: 0.00012159347534179688
iter 3580 (epoch 5), train_loss = 3.272, time/batch = 0.021
Read data: 9.799003601074219e-05
iter 3581 (epoch 5), train_loss = 2.747, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 3582 (epoch 5), train_loss = 2.550, time/batch = 0.022
Read data: 0.00017547607421875
iter 3583 (epoch 5), train_loss = 3.006, time/batch = 0.028
Read data: 0.00013685226440429688
iter 3584 (epoch 5), train_loss = 3.037, time/batch = 0.030
Read data: 0.00012183189392089844
iter 3585 (epoch 5), train_loss = 3.025, time/batch = 0.028
Read data: 7.510185241699219e-05
iter 3586 (epoch 5), train_loss = 2.836, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3587 (epoch 5), train_loss = 2.725, time/batch = 0.024
Read data: 0.00012254714965820312
iter 3588 (epoch 5), train_loss = 3.309, time/batch = 0.027
Read data: 0.00012040138244628906
iter 3589 (epoch 5), train_loss = 2.970, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 3590 (epoch 5), train_loss = 3.170, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 3591 (epoch 5), train_loss = 2.648, time/batch = 0.023
Read data: 0.0009713172912597656
iter 3592 (epoch 5), train_loss = 2.908, time/batch = 0.026
Read data: 0.0001227855682373047
iter 3593 (epoch 5), train_loss = 3.254, time/batch = 0.029
Read data: 8.869171142578125e-05
iter 3594 (epoch 5), train_loss = 2.989, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 3595 (epoch 5), train_loss = 3.140, time/batch = 0.032
Read data: 0.00012183189392089844
iter 3596 (epoch 5), train_loss = 2.791, time/batch = 0.026
Read data: 0.0001246929168701172
iter 3597 (epoch 5), train_loss = 3.088, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 3598 (epoch 5), train_loss = 3.605, time/batch = 0.037
Read data: 0.00014734268188476562
iter 3599 (epoch 5), train_loss = 3.262, time/batch = 0.024
Read data: 0.00022530555725097656
iter 3600 (epoch 5), train_loss = 3.277, time/batch = 0.032
Read data: 0.000133514404296875
iter 3601 (epoch 6), train_loss = 2.882, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 3602 (epoch 6), train_loss = 2.723, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 3603 (epoch 6), train_loss = 3.212, time/batch = 0.035
Read data: 8.368492126464844e-05
iter 3604 (epoch 6), train_loss = 2.660, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 3605 (epoch 6), train_loss = 2.777, time/batch = 0.025
Read data: 0.00010943412780761719
iter 3606 (epoch 6), train_loss = 3.371, time/batch = 0.029
Read data: 0.0001347064971923828
iter 3607 (epoch 6), train_loss = 2.983, time/batch = 0.028
Read data: 8.869171142578125e-05
iter 3608 (epoch 6), train_loss = 3.310, time/batch = 0.035
Read data: 8.797645568847656e-05
iter 3609 (epoch 6), train_loss = 2.847, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 3610 (epoch 6), train_loss = 3.264, time/batch = 0.039
Read data: 0.00015473365783691406
iter 3611 (epoch 6), train_loss = 2.767, time/batch = 0.025
Read data: 0.00012636184692382812
iter 3612 (epoch 6), train_loss = 2.950, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 3613 (epoch 6), train_loss = 2.780, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 3614 (epoch 6), train_loss = 2.626, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3615 (epoch 6), train_loss = 2.604, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 3616 (epoch 6), train_loss = 2.875, time/batch = 0.031
Read data: 9.083747863769531e-05
iter 3617 (epoch 6), train_loss = 3.164, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3618 (epoch 6), train_loss = 3.412, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 3619 (epoch 6), train_loss = 3.068, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 3620 (epoch 6), train_loss = 2.626, time/batch = 0.029
Read data: 0.0001552104949951172
iter 3621 (epoch 6), train_loss = 3.082, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 3622 (epoch 6), train_loss = 2.875, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 3623 (epoch 6), train_loss = 2.622, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 3624 (epoch 6), train_loss = 3.278, time/batch = 0.031
Read data: 7.653236389160156e-05
iter 3625 (epoch 6), train_loss = 2.953, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 3626 (epoch 6), train_loss = 2.659, time/batch = 0.020
Read data: 0.00017762184143066406
iter 3627 (epoch 6), train_loss = 2.773, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 3628 (epoch 6), train_loss = 3.142, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 3629 (epoch 6), train_loss = 3.319, time/batch = 0.030
Read data: 9.965896606445312e-05
iter 3630 (epoch 6), train_loss = 2.951, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 3631 (epoch 6), train_loss = 3.179, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 3632 (epoch 6), train_loss = 3.301, time/batch = 0.037
Read data: 8.416175842285156e-05
iter 3633 (epoch 6), train_loss = 3.044, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 3634 (epoch 6), train_loss = 2.959, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 3635 (epoch 6), train_loss = 3.172, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 3636 (epoch 6), train_loss = 2.231, time/batch = 0.020
Read data: 8.249282836914062e-05
iter 3637 (epoch 6), train_loss = 3.314, time/batch = 0.034
Read data: 8.082389831542969e-05
iter 3638 (epoch 6), train_loss = 3.198, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 3639 (epoch 6), train_loss = 2.966, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 3640 (epoch 6), train_loss = 3.276, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 3641 (epoch 6), train_loss = 3.072, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 3642 (epoch 6), train_loss = 2.785, time/batch = 0.034
Read data: 7.915496826171875e-05
iter 3643 (epoch 6), train_loss = 2.758, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 3644 (epoch 6), train_loss = 3.232, time/batch = 0.023
Read data: 7.557868957519531e-05
iter 3645 (epoch 6), train_loss = 3.081, time/batch = 0.022
Read data: 9.632110595703125e-05
iter 3646 (epoch 6), train_loss = 2.830, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 3647 (epoch 6), train_loss = 2.801, time/batch = 0.030
Read data: 0.00015234947204589844
iter 3648 (epoch 6), train_loss = 2.944, time/batch = 0.024
Read data: 0.00015544891357421875
iter 3649 (epoch 6), train_loss = 2.982, time/batch = 0.032
Read data: 0.0001709461212158203
iter 3650 (epoch 6), train_loss = 3.118, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 3651 (epoch 6), train_loss = 2.714, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 3652 (epoch 6), train_loss = 3.399, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 3653 (epoch 6), train_loss = 3.113, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 3654 (epoch 6), train_loss = 3.132, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 3655 (epoch 6), train_loss = 2.736, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 3656 (epoch 6), train_loss = 2.980, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 3657 (epoch 6), train_loss = 3.120, time/batch = 0.026
Read data: 0.00011515617370605469
iter 3658 (epoch 6), train_loss = 3.312, time/batch = 0.028
Read data: 0.00015425682067871094
iter 3659 (epoch 6), train_loss = 2.730, time/batch = 0.029
Read data: 7.677078247070312e-05
iter 3660 (epoch 6), train_loss = 2.610, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 3661 (epoch 6), train_loss = 3.241, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 3662 (epoch 6), train_loss = 3.401, time/batch = 0.021
Read data: 7.62939453125e-05
iter 3663 (epoch 6), train_loss = 2.963, time/batch = 0.025
Read data: 0.00014829635620117188
iter 3664 (epoch 6), train_loss = 2.794, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 3665 (epoch 6), train_loss = 3.151, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 3666 (epoch 6), train_loss = 2.984, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 3667 (epoch 6), train_loss = 2.838, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 3668 (epoch 6), train_loss = 2.842, time/batch = 0.028
Read data: 0.00017309188842773438
iter 3669 (epoch 6), train_loss = 2.885, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 3670 (epoch 6), train_loss = 2.829, time/batch = 0.023
Read data: 0.00015592575073242188
iter 3671 (epoch 6), train_loss = 2.797, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 3672 (epoch 6), train_loss = 3.084, time/batch = 0.025
Read data: 0.00017595291137695312
iter 3673 (epoch 6), train_loss = 2.882, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 3674 (epoch 6), train_loss = 2.739, time/batch = 0.040
Read data: 0.00021910667419433594
iter 3675 (epoch 6), train_loss = 3.596, time/batch = 0.034
Read data: 0.00011682510375976562
iter 3676 (epoch 6), train_loss = 3.611, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 3677 (epoch 6), train_loss = 3.427, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 3678 (epoch 6), train_loss = 3.082, time/batch = 0.035
Read data: 0.0001354217529296875
iter 3679 (epoch 6), train_loss = 2.914, time/batch = 0.031
Read data: 0.00011754035949707031
iter 3680 (epoch 6), train_loss = 3.112, time/batch = 0.025
Read data: 0.00012063980102539062
iter 3681 (epoch 6), train_loss = 3.029, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 3682 (epoch 6), train_loss = 2.833, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 3683 (epoch 6), train_loss = 2.690, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 3684 (epoch 6), train_loss = 3.451, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3685 (epoch 6), train_loss = 2.613, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 3686 (epoch 6), train_loss = 2.945, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 3687 (epoch 6), train_loss = 2.834, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 3688 (epoch 6), train_loss = 3.061, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 3689 (epoch 6), train_loss = 2.765, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 3690 (epoch 6), train_loss = 2.693, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 3691 (epoch 6), train_loss = 3.062, time/batch = 0.027
Read data: 7.510185241699219e-05
iter 3692 (epoch 6), train_loss = 2.590, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 3693 (epoch 6), train_loss = 2.895, time/batch = 0.030
Read data: 9.369850158691406e-05
iter 3694 (epoch 6), train_loss = 3.102, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 3695 (epoch 6), train_loss = 3.071, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 3696 (epoch 6), train_loss = 2.553, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 3697 (epoch 6), train_loss = 2.688, time/batch = 0.033
Read data: 8.726119995117188e-05
iter 3698 (epoch 6), train_loss = 3.458, time/batch = 0.034
Read data: 8.893013000488281e-05
iter 3699 (epoch 6), train_loss = 3.131, time/batch = 0.032
Read data: 0.0002288818359375
iter 3700 (epoch 6), train_loss = 2.563, time/batch = 0.020
Read data: 0.00016307830810546875
iter 3701 (epoch 6), train_loss = 2.919, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 3702 (epoch 6), train_loss = 3.401, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 3703 (epoch 6), train_loss = 3.056, time/batch = 0.027
Read data: 0.00010085105895996094
iter 3704 (epoch 6), train_loss = 2.979, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 3705 (epoch 6), train_loss = 3.172, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 3706 (epoch 6), train_loss = 2.147, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 3707 (epoch 6), train_loss = 2.631, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 3708 (epoch 6), train_loss = 3.102, time/batch = 0.022
Read data: 0.00013113021850585938
iter 3709 (epoch 6), train_loss = 2.848, time/batch = 0.031
Read data: 9.393692016601562e-05
iter 3710 (epoch 6), train_loss = 2.986, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 3711 (epoch 6), train_loss = 2.763, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 3712 (epoch 6), train_loss = 2.459, time/batch = 0.026
Read data: 0.0001380443572998047
iter 3713 (epoch 6), train_loss = 3.213, time/batch = 0.033
Read data: 0.0001010894775390625
iter 3714 (epoch 6), train_loss = 3.131, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 3715 (epoch 6), train_loss = 2.737, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 3716 (epoch 6), train_loss = 2.866, time/batch = 0.023
Read data: 9.1552734375e-05
iter 3717 (epoch 6), train_loss = 3.041, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 3718 (epoch 6), train_loss = 2.879, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 3719 (epoch 6), train_loss = 2.874, time/batch = 0.023
Read data: 0.00010228157043457031
iter 3720 (epoch 6), train_loss = 3.179, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 3721 (epoch 6), train_loss = 2.876, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 3722 (epoch 6), train_loss = 3.371, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 3723 (epoch 6), train_loss = 2.779, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 3724 (epoch 6), train_loss = 3.229, time/batch = 0.023
Read data: 0.0019643306732177734
iter 3725 (epoch 6), train_loss = 2.912, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 3726 (epoch 6), train_loss = 3.032, time/batch = 0.027
Read data: 0.00010251998901367188
iter 3727 (epoch 6), train_loss = 3.435, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 3728 (epoch 6), train_loss = 3.010, time/batch = 0.034
Read data: 9.036064147949219e-05
iter 3729 (epoch 6), train_loss = 2.990, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 3730 (epoch 6), train_loss = 3.210, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 3731 (epoch 6), train_loss = 2.564, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 3732 (epoch 6), train_loss = 3.202, time/batch = 0.022
Read data: 0.00014662742614746094
iter 3733 (epoch 6), train_loss = 3.632, time/batch = 0.031
Read data: 9.72747802734375e-05
iter 3734 (epoch 6), train_loss = 2.995, time/batch = 0.022
Read data: 9.584426879882812e-05
iter 3735 (epoch 6), train_loss = 3.463, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 3736 (epoch 6), train_loss = 3.150, time/batch = 0.027
Read data: 0.00011730194091796875
iter 3737 (epoch 6), train_loss = 3.020, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 3738 (epoch 6), train_loss = 2.945, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 3739 (epoch 6), train_loss = 2.670, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 3740 (epoch 6), train_loss = 3.093, time/batch = 0.028
Read data: 0.00011944770812988281
iter 3741 (epoch 6), train_loss = 2.810, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 3742 (epoch 6), train_loss = 2.530, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 3743 (epoch 6), train_loss = 3.094, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 3744 (epoch 6), train_loss = 3.143, time/batch = 0.024
Read data: 0.00012183189392089844
iter 3745 (epoch 6), train_loss = 3.087, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 3746 (epoch 6), train_loss = 2.947, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 3747 (epoch 6), train_loss = 2.929, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 3748 (epoch 6), train_loss = 3.155, time/batch = 0.023
Read data: 0.00013756752014160156
iter 3749 (epoch 6), train_loss = 3.600, time/batch = 0.032
Read data: 0.00017905235290527344
iter 3750 (epoch 6), train_loss = 3.196, time/batch = 0.031
Read data: 0.000110626220703125
iter 3751 (epoch 6), train_loss = 2.534, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 3752 (epoch 6), train_loss = 3.062, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 3753 (epoch 6), train_loss = 3.131, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 3754 (epoch 6), train_loss = 3.014, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 3755 (epoch 6), train_loss = 3.364, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 3756 (epoch 6), train_loss = 2.383, time/batch = 0.020
Read data: 9.632110595703125e-05
iter 3757 (epoch 6), train_loss = 2.295, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 3758 (epoch 6), train_loss = 2.643, time/batch = 0.023
Read data: 0.00013780593872070312
iter 3759 (epoch 6), train_loss = 2.995, time/batch = 0.024
Read data: 0.0001289844512939453
iter 3760 (epoch 6), train_loss = 3.191, time/batch = 0.030
Read data: 9.179115295410156e-05
iter 3761 (epoch 6), train_loss = 2.815, time/batch = 0.030
Read data: 9.942054748535156e-05
iter 3762 (epoch 6), train_loss = 2.920, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 3763 (epoch 6), train_loss = 2.636, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 3764 (epoch 6), train_loss = 3.333, time/batch = 0.028
Read data: 0.00012731552124023438
iter 3765 (epoch 6), train_loss = 3.150, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 3766 (epoch 6), train_loss = 2.529, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 3767 (epoch 6), train_loss = 2.603, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 3768 (epoch 6), train_loss = 3.112, time/batch = 0.020
Read data: 9.179115295410156e-05
iter 3769 (epoch 6), train_loss = 2.826, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 3770 (epoch 6), train_loss = 3.251, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 3771 (epoch 6), train_loss = 3.129, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 3772 (epoch 6), train_loss = 3.321, time/batch = 0.035
Read data: 0.0001270771026611328
iter 3773 (epoch 6), train_loss = 3.442, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 3774 (epoch 6), train_loss = 2.904, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 3775 (epoch 6), train_loss = 3.276, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 3776 (epoch 6), train_loss = 2.960, time/batch = 0.024
Read data: 0.00014448165893554688
iter 3777 (epoch 6), train_loss = 2.805, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 3778 (epoch 6), train_loss = 3.438, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 3779 (epoch 6), train_loss = 2.774, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 3780 (epoch 6), train_loss = 3.165, time/batch = 0.034
Read data: 8.916854858398438e-05
iter 3781 (epoch 6), train_loss = 2.562, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 3782 (epoch 6), train_loss = 3.075, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 3783 (epoch 6), train_loss = 3.398, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 3784 (epoch 6), train_loss = 3.041, time/batch = 0.022
Read data: 0.000133514404296875
iter 3785 (epoch 6), train_loss = 3.142, time/batch = 0.028
Read data: 9.489059448242188e-05
iter 3786 (epoch 6), train_loss = 2.688, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 3787 (epoch 6), train_loss = 3.208, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 3788 (epoch 6), train_loss = 2.903, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 3789 (epoch 6), train_loss = 3.015, time/batch = 0.025
Read data: 0.00016617774963378906
iter 3790 (epoch 6), train_loss = 2.822, time/batch = 0.028
Read data: 0.00015282630920410156
iter 3791 (epoch 6), train_loss = 3.082, time/batch = 0.025
Read data: 0.000141143798828125
iter 3792 (epoch 6), train_loss = 3.099, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 3793 (epoch 6), train_loss = 2.955, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 3794 (epoch 6), train_loss = 2.979, time/batch = 0.024
Read data: 0.00011205673217773438
iter 3795 (epoch 6), train_loss = 3.252, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 3796 (epoch 6), train_loss = 3.200, time/batch = 0.026
Read data: 0.00012731552124023438
iter 3797 (epoch 6), train_loss = 2.917, time/batch = 0.029
Read data: 0.00015163421630859375
iter 3798 (epoch 6), train_loss = 2.941, time/batch = 0.031
Read data: 0.0001323223114013672
iter 3799 (epoch 6), train_loss = 3.176, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 3800 (epoch 6), train_loss = 3.180, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 3801 (epoch 6), train_loss = 2.470, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 3802 (epoch 6), train_loss = 2.808, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 3803 (epoch 6), train_loss = 2.955, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 3804 (epoch 6), train_loss = 3.105, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 3805 (epoch 6), train_loss = 2.782, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 3806 (epoch 6), train_loss = 2.921, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 3807 (epoch 6), train_loss = 3.233, time/batch = 0.023
Read data: 0.00013685226440429688
iter 3808 (epoch 6), train_loss = 2.938, time/batch = 0.028
Read data: 0.00013637542724609375
iter 3809 (epoch 6), train_loss = 2.998, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 3810 (epoch 6), train_loss = 2.507, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 3811 (epoch 6), train_loss = 2.840, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 3812 (epoch 6), train_loss = 2.851, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 3813 (epoch 6), train_loss = 2.988, time/batch = 0.026
Read data: 0.00014138221740722656
iter 3814 (epoch 6), train_loss = 2.964, time/batch = 0.025
Read data: 0.00012564659118652344
iter 3815 (epoch 6), train_loss = 3.641, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 3816 (epoch 6), train_loss = 3.179, time/batch = 0.036
Read data: 0.00012922286987304688
iter 3817 (epoch 6), train_loss = 3.471, time/batch = 0.031
Read data: 0.00012993812561035156
iter 3818 (epoch 6), train_loss = 2.712, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 3819 (epoch 6), train_loss = 3.210, time/batch = 0.021
Read data: 8.416175842285156e-05
iter 3820 (epoch 6), train_loss = 3.015, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 3821 (epoch 6), train_loss = 2.793, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 3822 (epoch 6), train_loss = 3.092, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 3823 (epoch 6), train_loss = 3.544, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 3824 (epoch 6), train_loss = 3.435, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 3825 (epoch 6), train_loss = 2.808, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 3826 (epoch 6), train_loss = 3.127, time/batch = 0.033
Read data: 0.0001621246337890625
iter 3827 (epoch 6), train_loss = 2.746, time/batch = 0.028
Read data: 8.392333984375e-05
iter 3828 (epoch 6), train_loss = 3.180, time/batch = 0.032
Read data: 0.0001246929168701172
iter 3829 (epoch 6), train_loss = 2.650, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 3830 (epoch 6), train_loss = 2.867, time/batch = 0.032
Read data: 8.940696716308594e-05
iter 3831 (epoch 6), train_loss = 2.971, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 3832 (epoch 6), train_loss = 2.901, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 3833 (epoch 6), train_loss = 2.895, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 3834 (epoch 6), train_loss = 3.363, time/batch = 0.030
Read data: 0.0001556873321533203
iter 3835 (epoch 6), train_loss = 3.095, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 3836 (epoch 6), train_loss = 3.551, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 3837 (epoch 6), train_loss = 2.853, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 3838 (epoch 6), train_loss = 3.353, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 3839 (epoch 6), train_loss = 2.880, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 3840 (epoch 6), train_loss = 2.963, time/batch = 0.025
Read data: 0.00013518333435058594
iter 3841 (epoch 6), train_loss = 2.589, time/batch = 0.034
Read data: 7.700920104980469e-05
iter 3842 (epoch 6), train_loss = 3.027, time/batch = 0.039
Read data: 8.487701416015625e-05
iter 3843 (epoch 6), train_loss = 3.086, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 3844 (epoch 6), train_loss = 2.940, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 3845 (epoch 6), train_loss = 3.141, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 3846 (epoch 6), train_loss = 2.808, time/batch = 0.030
Read data: 0.0001251697540283203
iter 3847 (epoch 6), train_loss = 3.099, time/batch = 0.037
Read data: 0.00011038780212402344
iter 3848 (epoch 6), train_loss = 2.877, time/batch = 0.030
Read data: 0.00014925003051757812
iter 3849 (epoch 6), train_loss = 2.682, time/batch = 0.029
Read data: 0.0002803802490234375
iter 3850 (epoch 6), train_loss = 2.744, time/batch = 0.029
Read data: 0.00010180473327636719
iter 3851 (epoch 6), train_loss = 2.930, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 3852 (epoch 6), train_loss = 2.688, time/batch = 0.026
Read data: 0.00012350082397460938
iter 3853 (epoch 6), train_loss = 2.789, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 3854 (epoch 6), train_loss = 2.984, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 3855 (epoch 6), train_loss = 3.082, time/batch = 0.023
Read data: 0.00010323524475097656
iter 3856 (epoch 6), train_loss = 3.057, time/batch = 0.026
Read data: 0.0001354217529296875
iter 3857 (epoch 6), train_loss = 2.314, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 3858 (epoch 6), train_loss = 2.680, time/batch = 0.029
Read data: 0.00010466575622558594
iter 3859 (epoch 6), train_loss = 2.747, time/batch = 0.030
Read data: 0.0002830028533935547
iter 3860 (epoch 6), train_loss = 2.809, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 3861 (epoch 6), train_loss = 2.663, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 3862 (epoch 6), train_loss = 2.973, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 3863 (epoch 6), train_loss = 2.781, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 3864 (epoch 6), train_loss = 3.040, time/batch = 0.028
Read data: 0.00013375282287597656
iter 3865 (epoch 6), train_loss = 2.357, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 3866 (epoch 6), train_loss = 3.226, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 3867 (epoch 6), train_loss = 3.381, time/batch = 0.024
Read data: 0.0017364025115966797
iter 3868 (epoch 6), train_loss = 2.455, time/batch = 0.020
Read data: 0.00013875961303710938
iter 3869 (epoch 6), train_loss = 2.719, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 3870 (epoch 6), train_loss = 2.311, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 3871 (epoch 6), train_loss = 2.619, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 3872 (epoch 6), train_loss = 3.113, time/batch = 0.028
Read data: 0.00013566017150878906
iter 3873 (epoch 6), train_loss = 2.980, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 3874 (epoch 6), train_loss = 2.599, time/batch = 0.027
Read data: 0.00020051002502441406
iter 3875 (epoch 6), train_loss = 2.949, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 3876 (epoch 6), train_loss = 2.837, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 3877 (epoch 6), train_loss = 2.969, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 3878 (epoch 6), train_loss = 3.279, time/batch = 0.033
Read data: 7.963180541992188e-05
iter 3879 (epoch 6), train_loss = 2.858, time/batch = 0.031
Read data: 0.0001380443572998047
iter 3880 (epoch 6), train_loss = 2.633, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 3881 (epoch 6), train_loss = 3.097, time/batch = 0.023
Read data: 0.00010156631469726562
iter 3882 (epoch 6), train_loss = 3.341, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 3883 (epoch 6), train_loss = 3.340, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 3884 (epoch 6), train_loss = 2.846, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 3885 (epoch 6), train_loss = 3.024, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 3886 (epoch 6), train_loss = 3.249, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 3887 (epoch 6), train_loss = 2.925, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 3888 (epoch 6), train_loss = 3.025, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 3889 (epoch 6), train_loss = 3.253, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 3890 (epoch 6), train_loss = 2.978, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 3891 (epoch 6), train_loss = 2.875, time/batch = 0.029
Read data: 0.00011086463928222656
iter 3892 (epoch 6), train_loss = 2.798, time/batch = 0.039
Read data: 0.00014543533325195312
iter 3893 (epoch 6), train_loss = 2.973, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 3894 (epoch 6), train_loss = 2.564, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 3895 (epoch 6), train_loss = 3.036, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 3896 (epoch 6), train_loss = 2.660, time/batch = 0.022
Read data: 0.000118255615234375
iter 3897 (epoch 6), train_loss = 2.476, time/batch = 0.023
Read data: 0.0001354217529296875
iter 3898 (epoch 6), train_loss = 2.984, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 3899 (epoch 6), train_loss = 2.998, time/batch = 0.033
Read data: 8.797645568847656e-05
iter 3900 (epoch 6), train_loss = 2.592, time/batch = 0.021
Read data: 0.0001468658447265625
iter 3901 (epoch 6), train_loss = 2.978, time/batch = 0.035
Read data: 8.940696716308594e-05
iter 3902 (epoch 6), train_loss = 2.949, time/batch = 0.037
Read data: 0.00011324882507324219
iter 3903 (epoch 6), train_loss = 2.628, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 3904 (epoch 6), train_loss = 3.162, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 3905 (epoch 6), train_loss = 3.017, time/batch = 0.031
Read data: 8.654594421386719e-05
iter 3906 (epoch 6), train_loss = 2.932, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 3907 (epoch 6), train_loss = 2.750, time/batch = 0.034
Read data: 0.00011992454528808594
iter 3908 (epoch 6), train_loss = 3.207, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 3909 (epoch 6), train_loss = 3.206, time/batch = 0.026
Read data: 0.0001888275146484375
iter 3910 (epoch 6), train_loss = 3.227, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 3911 (epoch 6), train_loss = 3.296, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 3912 (epoch 6), train_loss = 2.929, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 3913 (epoch 6), train_loss = 3.566, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 3914 (epoch 6), train_loss = 3.285, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 3915 (epoch 6), train_loss = 2.542, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 3916 (epoch 6), train_loss = 2.772, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 3917 (epoch 6), train_loss = 2.861, time/batch = 0.019
Read data: 0.0001327991485595703
iter 3918 (epoch 6), train_loss = 2.837, time/batch = 0.032
Read data: 0.00011277198791503906
iter 3919 (epoch 6), train_loss = 2.917, time/batch = 0.023
Read data: 0.00011682510375976562
iter 3920 (epoch 6), train_loss = 2.867, time/batch = 0.027
Read data: 9.72747802734375e-05
iter 3921 (epoch 6), train_loss = 3.018, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 3922 (epoch 6), train_loss = 2.937, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 3923 (epoch 6), train_loss = 3.175, time/batch = 0.025
Read data: 0.00011801719665527344
iter 3924 (epoch 6), train_loss = 2.816, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 3925 (epoch 6), train_loss = 2.793, time/batch = 0.023
Read data: 0.00013494491577148438
iter 3926 (epoch 6), train_loss = 3.070, time/batch = 0.021
Read data: 9.775161743164062e-05
iter 3927 (epoch 6), train_loss = 3.018, time/batch = 0.023
Read data: 0.00012087821960449219
iter 3928 (epoch 6), train_loss = 2.859, time/batch = 0.028
Read data: 0.00011706352233886719
iter 3929 (epoch 6), train_loss = 2.699, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 3930 (epoch 6), train_loss = 3.151, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 3931 (epoch 6), train_loss = 2.795, time/batch = 0.025
Read data: 0.00011396408081054688
iter 3932 (epoch 6), train_loss = 2.800, time/batch = 0.031
Read data: 7.867813110351562e-05
iter 3933 (epoch 6), train_loss = 2.915, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 3934 (epoch 6), train_loss = 3.181, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 3935 (epoch 6), train_loss = 3.163, time/batch = 0.021
Read data: 0.0001308917999267578
iter 3936 (epoch 6), train_loss = 2.896, time/batch = 0.035
Read data: 7.653236389160156e-05
iter 3937 (epoch 6), train_loss = 3.768, time/batch = 0.026
Read data: 0.00011324882507324219
iter 3938 (epoch 6), train_loss = 2.801, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 3939 (epoch 6), train_loss = 2.731, time/batch = 0.023
Read data: 7.724761962890625e-05
iter 3940 (epoch 6), train_loss = 2.822, time/batch = 0.031
Read data: 7.891654968261719e-05
iter 3941 (epoch 6), train_loss = 2.896, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 3942 (epoch 6), train_loss = 3.331, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 3943 (epoch 6), train_loss = 2.887, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 3944 (epoch 6), train_loss = 2.636, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 3945 (epoch 6), train_loss = 2.725, time/batch = 0.021
Read data: 0.00012946128845214844
iter 3946 (epoch 6), train_loss = 2.812, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 3947 (epoch 6), train_loss = 2.838, time/batch = 0.025
Read data: 0.00011610984802246094
iter 3948 (epoch 6), train_loss = 2.355, time/batch = 0.025
Read data: 0.00011849403381347656
iter 3949 (epoch 6), train_loss = 2.526, time/batch = 0.030
Read data: 0.00016736984252929688
iter 3950 (epoch 6), train_loss = 3.185, time/batch = 0.020
Read data: 8.869171142578125e-05
iter 3951 (epoch 6), train_loss = 3.003, time/batch = 0.034
Read data: 7.843971252441406e-05
iter 3952 (epoch 6), train_loss = 2.613, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 3953 (epoch 6), train_loss = 2.955, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 3954 (epoch 6), train_loss = 2.724, time/batch = 0.021
Read data: 7.843971252441406e-05
iter 3955 (epoch 6), train_loss = 3.051, time/batch = 0.025
Read data: 0.00011897087097167969
iter 3956 (epoch 6), train_loss = 3.120, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 3957 (epoch 6), train_loss = 3.568, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 3958 (epoch 6), train_loss = 2.477, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 3959 (epoch 6), train_loss = 2.810, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 3960 (epoch 6), train_loss = 3.052, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 3961 (epoch 6), train_loss = 2.777, time/batch = 0.025
Read data: 0.00011539459228515625
iter 3962 (epoch 6), train_loss = 3.099, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 3963 (epoch 6), train_loss = 3.190, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 3964 (epoch 6), train_loss = 2.933, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 3965 (epoch 6), train_loss = 2.946, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 3966 (epoch 6), train_loss = 2.686, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 3967 (epoch 6), train_loss = 2.891, time/batch = 0.021
Read data: 0.0001010894775390625
iter 3968 (epoch 6), train_loss = 2.543, time/batch = 0.021
Read data: 0.0001201629638671875
iter 3969 (epoch 6), train_loss = 3.365, time/batch = 0.026
Read data: 0.00012230873107910156
iter 3970 (epoch 6), train_loss = 2.710, time/batch = 0.024
Read data: 0.00015115737915039062
iter 3971 (epoch 6), train_loss = 2.608, time/batch = 0.027
Read data: 0.00012135505676269531
iter 3972 (epoch 6), train_loss = 3.051, time/batch = 0.030
Read data: 7.724761962890625e-05
iter 3973 (epoch 6), train_loss = 3.362, time/batch = 0.030
Read data: 9.894371032714844e-05
iter 3974 (epoch 6), train_loss = 2.844, time/batch = 0.034
Read data: 0.00011157989501953125
iter 3975 (epoch 6), train_loss = 3.195, time/batch = 0.027
Read data: 0.00011157989501953125
iter 3976 (epoch 6), train_loss = 2.842, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 3977 (epoch 6), train_loss = 3.012, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 3978 (epoch 6), train_loss = 2.891, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 3979 (epoch 6), train_loss = 2.719, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 3980 (epoch 6), train_loss = 2.840, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 3981 (epoch 6), train_loss = 3.164, time/batch = 0.024
Read data: 0.0001201629638671875
iter 3982 (epoch 6), train_loss = 2.924, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 3983 (epoch 6), train_loss = 2.959, time/batch = 0.027
Read data: 0.00012826919555664062
iter 3984 (epoch 6), train_loss = 2.597, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 3985 (epoch 6), train_loss = 2.706, time/batch = 0.021
Read data: 0.00013875961303710938
iter 3986 (epoch 6), train_loss = 3.084, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 3987 (epoch 6), train_loss = 2.971, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 3988 (epoch 6), train_loss = 3.226, time/batch = 0.023
Read data: 0.00012183189392089844
iter 3989 (epoch 6), train_loss = 2.985, time/batch = 0.027
Read data: 0.00011849403381347656
iter 3990 (epoch 6), train_loss = 3.235, time/batch = 0.022
Read data: 9.918212890625e-05
iter 3991 (epoch 6), train_loss = 2.922, time/batch = 0.023
Read data: 0.00012993812561035156
iter 3992 (epoch 6), train_loss = 2.662, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 3993 (epoch 6), train_loss = 2.973, time/batch = 0.021
Read data: 9.393692016601562e-05
iter 3994 (epoch 6), train_loss = 2.876, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 3995 (epoch 6), train_loss = 2.937, time/batch = 0.028
Read data: 0.0001475811004638672
iter 3996 (epoch 6), train_loss = 2.739, time/batch = 0.028
Read data: 0.00011944770812988281
iter 3997 (epoch 6), train_loss = 2.787, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 3998 (epoch 6), train_loss = 3.150, time/batch = 0.024
Read data: 0.0001087188720703125
iter 3999 (epoch 6), train_loss = 2.922, time/batch = 0.022
image 976:     
image 5399:    
image 6910:      
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:    UNK
evaluating validation preformance... 10/1000 (2.955808)
image 2798:     
image 5884:    
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.548134)
image 6903:     
image 3301:    
image 2019:     
image 5535:    
image 7680:     
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.946016)
image 4604:     
image 5745:     
image 5288:    
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.105629)
image 2938:    
image 5183:     
image 2380:      
image 6973:     
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.821007)
image 4940:      
image 4905:    
image 469:      
image 102:    
image 6009:    
image 4271:    
image 6329:     
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (3.129003)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:    
evaluating validation preformance... 70/1000 (2.889296)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:      
image 2242:    
evaluating validation preformance... 80/1000 (2.973413)
image 3276:      
image 3812:    
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:     
image 1480:     
image 4806:      
image 766:    
evaluating validation preformance... 90/1000 (2.339344)
image 6124:     
image 5415:    
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:      
image 6553:      
evaluating validation preformance... 100/1000 (3.238196)
image 2800:    
image 7249:     
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (3.117439)
image 1122:     
image 509:    
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:     
image 3979:      
image 5302:    
evaluating validation preformance... 120/1000 (2.672456)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:    
image 4589:    
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (3.135940)
image 6214:     
image 429:     
image 7743:     
image 3657:    
image 4535:    
image 5542:     
image 8068:    UNK
image 4450:    
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.996134)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:     
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.200731)
image 1865:      
image 3830:    
image 360:      
image 5097:     
image 4455:    
image 1153:    
image 1248:     
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (3.042771)
image 4297:    
image 3315:     
image 1107:     
image 2051:     
image 4713:     
image 8036:     
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.840464)
image 7922:     
image 2353:     
image 4580:    
image 5905:      
image 6488:    
image 3000:    
image 1806:    
image 7761:    
image 3014:     
image 3687:    
evaluating validation preformance... 180/1000 (2.874589)
image 2313:    
image 6289:    
image 8084:     
image 2696:    
image 5830:     
image 6240:    
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.823048)
image 5372:     
image 7529:    
image 875:    
image 2107:    
image 8015:    
image 6565:     
image 6174:     
image 6894:     
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.595219)
image 5159:    
image 1199:    
image 2456:     
image 3402:    
image 7631:     
image 3562:    
image 405:    
image 2532:    UNK
image 2844:    
image 4023:     
evaluating validation preformance... 210/1000 (2.782022)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:     
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.918440)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:    
image 2258:    
image 5122:      
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.681942)
image 1917:    
image 5844:      
image 1661:    
image 1510:     
image 4630:    
image 6741:     
image 1020:      
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.504416)
image 7143:     
image 6019:     
image 885:    
image 2802:     
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (2.886554)
image 3028:    
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.765350)
image 492:    
image 5429:     
image 6968:     
image 2672:     
image 6920:     
image 6211:     
image 3326:     
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.158341)
image 833:     
image 5483:    
image 2476:      
image 5930:     
image 59:     
image 5007:     
image 2884:    
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.893182)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.886895)
image 6835:     
image 4698:     
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.463178)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:     
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (3.118236)
image 3553:    
image 5971:     
image 122:     
image 3212:      
image 7223:    
image 7007:     
image 6064:    
image 7358:     
image 5096:     
image 6423:     
evaluating validation preformance... 320/1000 (2.708491)
image 489:     
image 5316:     
image 2613:      
image 7935:    
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (3.000805)
image 5179:    
image 3754:    
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:     
image 4524:    
image 3972:     
evaluating validation preformance... 340/1000 (2.737725)
image 4542:      
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:     
image 5385:    
image 2794:     
image 7785:    
image 2085:     
evaluating validation preformance... 350/1000 (2.905839)
image 6881:    
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:    
image 5241:     
image 6606:    
image 2387:     
image 3342:      
evaluating validation preformance... 360/1000 (2.268060)
image 2905:    
image 7814:     
image 56:     
image 5034:    
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.876455)
image 4351:    
image 1054:    
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (3.027676)
image 2458:     
image 1084:     
image 4835:    
image 867:    
image 723:     
image 6255:     
image 5255:     
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (3.103016)
image 828:     
image 2733:    
image 791:      
image 5408:    
image 7842:     
image 1117:      
image 5817:      
image 1231:    
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.592551)
image 2627:    
image 7172:    
image 1991:    
image 7413:     
image 2105:    
image 3919:     
image 7980:    
image 670:     
image 2325:     
image 7546:      
evaluating validation preformance... 410/1000 (2.483710)
image 4359:     
image 2372:    
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:    
image 7020:     
evaluating validation preformance... 420/1000 (2.566131)
image 30:    
image 5540:    
image 2445:      
image 5896:      
image 7607:    
image 1426:      
image 6977:    
image 877:    
image 2408:    
image 7706:     
evaluating validation preformance... 430/1000 (3.107919)
image 385:     
image 6938:     
image 2381:    
image 5796:    
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (3.080903)
image 1731:      
image 978:    
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:    
image 5855:    
image 4245:      
image 973:    
evaluating validation preformance... 450/1000 (2.528281)
image 2241:     
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:     
image 6995:     
image 3682:     
evaluating validation preformance... 460/1000 (3.132046)
image 7979:     
image 1618:     
image 7608:    
image 6393:     
image 5100:     
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.525970)
image 4503:     
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    UNK
image 6114:      
evaluating validation preformance... 480/1000 (3.201714)
image 358:     
image 4663:    
image 5541:    
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.607683)
image 2044:    
image 4349:     
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:    
image 6820:     
image 1485:     
image 5744:     
evaluating validation preformance... 500/1000 (2.835217)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.334034)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    
image 5416:     
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.949426)
image 6806:     
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:     
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.709387)
image 5619:    
image 4391:     
image 891:     
image 3072:    
image 7781:    
image 6163:     
image 7376:      
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.863289)
image 5292:      
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:     
image 4696:     
image 1183:     
image 1961:      
evaluating validation preformance... 550/1000 (2.971900)
image 5439:     
image 7981:    
image 6012:    
image 4732:     
image 6630:    
image 994:    
image 5079:     
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.939721)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:     
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (3.016316)
image 7936:     
image 5433:    
image 5691:      
image 1628:      
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:     
evaluating validation preformance... 580/1000 (2.675692)
image 2135:      
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.921534)
image 4420:    
image 1734:    
image 7239:     
image 7447:     
image 8009:    
image 4510:     
image 7495:     
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.934098)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:     
image 1773:    
image 4823:     
evaluating validation preformance... 610/1000 (3.069062)
image 69:     
image 3465:    
image 6179:     
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:      
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.848661)
image 6575:      
image 5695:    
image 7418:     
image 1948:     
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:     
evaluating validation preformance... 630/1000 (2.686762)
image 8074:    
image 1904:    
image 7917:      
image 2394:     
image 4406:     
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.785753)
image 5313:     
image 2377:     
image 6058:     
image 4661:     
image 2955:     
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:     
evaluating validation preformance... 650/1000 (2.897830)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:     
image 1639:     
image 1475:    
image 3991:    
image 1023:    
evaluating validation preformance... 660/1000 (2.945363)
image 5701:      
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:     
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (3.210992)
image 7877:     
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:    
image 7587:     
image 4848:    
image 6722:    UNK
image 7784:      
evaluating validation preformance... 680/1000 (3.347161)
image 1445:     
image 6841:     
image 2896:    
image 6947:     
image 4782:    
image 7669:      
image 4382:     
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (3.207545)
image 6860:    
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:    
image 6225:    
image 3669:     
image 980:     
image 5362:      
evaluating validation preformance... 700/1000 (3.221514)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:    
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.787885)
image 7368:     
image 709:     
image 3197:     
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.890300)
image 5729:     
image 6395:    
image 516:    
image 1026:    
image 2972:      
image 3005:    
image 1241:    
image 2743:    
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.605158)
image 2527:    
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:    
image 997:    
image 5092:     
image 7789:     
image 2504:      
evaluating validation preformance... 740/1000 (2.743043)
image 2239:    
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (3.127317)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.230139)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:     
image 2452:     
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.501983)
image 6220:     
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:      
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (3.027689)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.568262)
image 5047:      
image 325:     
image 7626:     
image 4552:    
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.549098)
image 7288:      
image 7302:     
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.744372)
image 614:     
image 7295:     
image 4110:     
image 5402:     
image 3060:    UNK
image 1317:      
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (2.308397)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:     
image 7147:    
image 6348:    
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.715414)
image 5107:    
image 3973:    
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.660685)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:    
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:     
evaluating validation preformance... 850/1000 (3.258877)
image 4404:     
image 5501:     
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:     
image 6261:     
image 2166:      
evaluating validation preformance... 860/1000 (3.160467)
image 4254:    
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:     
image 4927:     
image 3222:    
image 4002:    
evaluating validation preformance... 870/1000 (2.643783)
image 4934:     
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:     
image 5681:      
image 1824:     
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.877173)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (3.256928)
image 7485:     
image 6102:    
image 1001:    
image 7167:     
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:    
image 210:     
evaluating validation preformance... 900/1000 (3.678124)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:    
image 2398:     
image 7205:     
evaluating validation preformance... 910/1000 (2.548281)
image 1368:     
image 1925:     
image 5870:     
image 4915:     
image 3879:     
image 1002:    
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.856071)
image 7152:     
image 4559:     
image 7233:    
image 1341:     
image 5337:      
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:    
evaluating validation preformance... 930/1000 (2.741132)
image 5636:     
image 7799:     
image 6025:    
image 6907:     
image 2507:     
image 7014:    
image 5566:     
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.889815)
image 5860:     
image 3275:     
image 1935:     
image 3520:    
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (3.357692)
image 1081:    
image 1179:     
image 4316:    
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (3.058508)
image 4935:     
image 1930:     
image 6850:    
image 5310:    
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.693098)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:    
image 7800:    
image 3999:     
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (3.116746)
image 7352:     
image 5113:    
image 7822:    
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.781544)
image 5789:      
image 5606:      
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:     
image 7615:    
evaluating validation preformance... 1000/1000 (2.712518)
average loss on validation: 2.912
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2231531143188477
Cider scores: 0.4224235507725882
Read data: 0.21979546546936035
Cider scores: 0.43237942365414567
Read data: 0.20630455017089844
Cider scores: 0.4409918054166019
Read data: 0.23181605339050293
Cider scores: 0.3754687011364659
Read data: 0.2431786060333252
Cider scores: 0.40467456118674666
Read data: 0.2066783905029297
Cider scores: 0.3583552481681294
Read data: 0.17588043212890625
Cider scores: 0.3684634565603778
Read data: 0.19428801536560059
Cider scores: 0.4665737430754752
Read data: 0.18538594245910645
Cider scores: 0.3706433985256229
Read data: 0.2356107234954834
Cider scores: 0.5418676185892286
Read data: 0.19741153717041016
Cider scores: 0.4228736591585644
Read data: 0.17406487464904785
Cider scores: 0.4694248156224851
Read data: 0.17723488807678223
Cider scores: 0.4445109047119265
Read data: 0.17893147468566895
Cider scores: 0.4114504141024445
Read data: 0.1775379180908203
Cider scores: 0.41478052805783894
Read data: 0.16565537452697754
Cider scores: 0.525557486276136
Read data: 0.16027259826660156
Cider scores: 0.3867814707779492
Read data: 0.1585681438446045
Cider scores: 0.53648728714625
Read data: 0.15910601615905762
Cider scores: 0.36968253093191883
Read data: 0.16356182098388672
Cider scores: 0.5461889015883047
Average cider score on test set: 0.435
End calculating cider score on TEST data set
===============================================
Read data: 0.16495704650878906
iter 4000 (epoch 6), train_loss = 2.668, time/batch = 0.021
Read data: 0.00010800361633300781
iter 4001 (epoch 6), train_loss = 3.342, time/batch = 0.024
Read data: 0.00011587142944335938
iter 4002 (epoch 6), train_loss = 3.013, time/batch = 0.024
Read data: 0.00012087821960449219
iter 4003 (epoch 6), train_loss = 2.737, time/batch = 0.020
Read data: 0.00010800361633300781
iter 4004 (epoch 6), train_loss = 3.303, time/batch = 0.026
Read data: 0.0001392364501953125
iter 4005 (epoch 6), train_loss = 2.903, time/batch = 0.024
Read data: 0.0001246929168701172
iter 4006 (epoch 6), train_loss = 3.342, time/batch = 0.039
Read data: 0.00010085105895996094
iter 4007 (epoch 6), train_loss = 3.263, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 4008 (epoch 6), train_loss = 3.065, time/batch = 0.033
Read data: 9.894371032714844e-05
iter 4009 (epoch 6), train_loss = 3.280, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 4010 (epoch 6), train_loss = 2.963, time/batch = 0.020
Read data: 9.584426879882812e-05
iter 4011 (epoch 6), train_loss = 3.171, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 4012 (epoch 6), train_loss = 3.190, time/batch = 0.026
Read data: 0.0001804828643798828
iter 4013 (epoch 6), train_loss = 2.582, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 4014 (epoch 6), train_loss = 3.242, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 4015 (epoch 6), train_loss = 3.128, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 4016 (epoch 6), train_loss = 2.696, time/batch = 0.034
Read data: 9.799003601074219e-05
iter 4017 (epoch 6), train_loss = 3.176, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 4018 (epoch 6), train_loss = 2.785, time/batch = 0.034
Read data: 8.702278137207031e-05
iter 4019 (epoch 6), train_loss = 3.602, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 4020 (epoch 6), train_loss = 3.131, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 4021 (epoch 6), train_loss = 3.208, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 4022 (epoch 6), train_loss = 2.835, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 4023 (epoch 6), train_loss = 2.767, time/batch = 0.025
Read data: 0.0001068115234375
iter 4024 (epoch 6), train_loss = 2.846, time/batch = 0.028
Read data: 0.00026035308837890625
iter 4025 (epoch 6), train_loss = 3.007, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4026 (epoch 6), train_loss = 2.704, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 4027 (epoch 6), train_loss = 3.022, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 4028 (epoch 6), train_loss = 2.734, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 4029 (epoch 6), train_loss = 2.918, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 4030 (epoch 6), train_loss = 2.673, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 4031 (epoch 6), train_loss = 3.194, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 4032 (epoch 6), train_loss = 2.922, time/batch = 0.031
Read data: 0.00010013580322265625
iter 4033 (epoch 6), train_loss = 2.859, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 4034 (epoch 6), train_loss = 3.188, time/batch = 0.021
Read data: 9.989738464355469e-05
iter 4035 (epoch 6), train_loss = 2.509, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 4036 (epoch 6), train_loss = 2.830, time/batch = 0.028
Read data: 0.00015115737915039062
iter 4037 (epoch 6), train_loss = 3.375, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 4038 (epoch 6), train_loss = 2.885, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4039 (epoch 6), train_loss = 2.810, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 4040 (epoch 6), train_loss = 3.034, time/batch = 0.027
Read data: 0.00010633468627929688
iter 4041 (epoch 6), train_loss = 2.942, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 4042 (epoch 6), train_loss = 2.763, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 4043 (epoch 6), train_loss = 2.828, time/batch = 0.029
Read data: 7.605552673339844e-05
iter 4044 (epoch 6), train_loss = 2.975, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 4045 (epoch 6), train_loss = 2.315, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 4046 (epoch 6), train_loss = 3.148, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 4047 (epoch 6), train_loss = 2.860, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 4048 (epoch 6), train_loss = 2.699, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 4049 (epoch 6), train_loss = 3.011, time/batch = 0.024
Read data: 0.0002608299255371094
iter 4050 (epoch 6), train_loss = 2.802, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 4051 (epoch 6), train_loss = 2.811, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 4052 (epoch 6), train_loss = 3.253, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 4053 (epoch 6), train_loss = 2.888, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 4054 (epoch 6), train_loss = 2.620, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 4055 (epoch 6), train_loss = 2.852, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 4056 (epoch 6), train_loss = 2.866, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 4057 (epoch 6), train_loss = 3.262, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 4058 (epoch 6), train_loss = 2.956, time/batch = 0.029
Read data: 7.557868957519531e-05
iter 4059 (epoch 6), train_loss = 2.387, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 4060 (epoch 6), train_loss = 2.605, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 4061 (epoch 6), train_loss = 2.794, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 4062 (epoch 6), train_loss = 2.884, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 4063 (epoch 6), train_loss = 2.807, time/batch = 0.025
Read data: 0.00010180473327636719
iter 4064 (epoch 6), train_loss = 2.719, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 4065 (epoch 6), train_loss = 2.390, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 4066 (epoch 6), train_loss = 2.900, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 4067 (epoch 6), train_loss = 2.975, time/batch = 0.027
Read data: 0.00012755393981933594
iter 4068 (epoch 6), train_loss = 3.078, time/batch = 0.035
Read data: 7.867813110351562e-05
iter 4069 (epoch 6), train_loss = 2.900, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 4070 (epoch 6), train_loss = 2.957, time/batch = 0.019
Read data: 8.606910705566406e-05
iter 4071 (epoch 6), train_loss = 2.836, time/batch = 0.025
Read data: 0.00013065338134765625
iter 4072 (epoch 6), train_loss = 2.831, time/batch = 0.028
Read data: 0.00014472007751464844
iter 4073 (epoch 6), train_loss = 2.803, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 4074 (epoch 6), train_loss = 3.847, time/batch = 0.030
Read data: 0.00021338462829589844
iter 4075 (epoch 6), train_loss = 3.121, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 4076 (epoch 6), train_loss = 2.294, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 4077 (epoch 6), train_loss = 2.844, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 4078 (epoch 6), train_loss = 2.774, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 4079 (epoch 6), train_loss = 2.930, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 4080 (epoch 6), train_loss = 3.153, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 4081 (epoch 6), train_loss = 3.246, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 4082 (epoch 6), train_loss = 2.368, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 4083 (epoch 6), train_loss = 2.984, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 4084 (epoch 6), train_loss = 3.042, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 4085 (epoch 6), train_loss = 2.956, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 4086 (epoch 6), train_loss = 3.134, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 4087 (epoch 6), train_loss = 3.103, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 4088 (epoch 6), train_loss = 2.911, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 4089 (epoch 6), train_loss = 2.832, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 4090 (epoch 6), train_loss = 2.721, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 4091 (epoch 6), train_loss = 3.594, time/batch = 0.028
Read data: 0.0001456737518310547
iter 4092 (epoch 6), train_loss = 3.186, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 4093 (epoch 6), train_loss = 3.234, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 4094 (epoch 6), train_loss = 3.112, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 4095 (epoch 6), train_loss = 2.563, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 4096 (epoch 6), train_loss = 2.729, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 4097 (epoch 6), train_loss = 3.214, time/batch = 0.028
Read data: 9.846687316894531e-05
iter 4098 (epoch 6), train_loss = 2.380, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 4099 (epoch 6), train_loss = 3.085, time/batch = 0.025
Read data: 0.0002143383026123047
iter 4100 (epoch 6), train_loss = 3.141, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 4101 (epoch 6), train_loss = 3.070, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 4102 (epoch 6), train_loss = 2.805, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 4103 (epoch 6), train_loss = 3.153, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 4104 (epoch 6), train_loss = 2.897, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4105 (epoch 6), train_loss = 3.238, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 4106 (epoch 6), train_loss = 2.730, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 4107 (epoch 6), train_loss = 3.314, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 4108 (epoch 6), train_loss = 3.466, time/batch = 0.038
Read data: 7.939338684082031e-05
iter 4109 (epoch 6), train_loss = 2.962, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 4110 (epoch 6), train_loss = 2.744, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 4111 (epoch 6), train_loss = 2.910, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 4112 (epoch 6), train_loss = 2.754, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 4113 (epoch 6), train_loss = 3.379, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 4114 (epoch 6), train_loss = 2.756, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 4115 (epoch 6), train_loss = 2.950, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 4116 (epoch 6), train_loss = 2.836, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 4117 (epoch 6), train_loss = 3.411, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 4118 (epoch 6), train_loss = 2.571, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 4119 (epoch 6), train_loss = 2.727, time/batch = 0.021
Read data: 0.00013017654418945312
iter 4120 (epoch 6), train_loss = 3.523, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 4121 (epoch 6), train_loss = 2.741, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 4122 (epoch 6), train_loss = 2.847, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 4123 (epoch 6), train_loss = 3.279, time/batch = 0.031
Read data: 0.0001308917999267578
iter 4124 (epoch 6), train_loss = 2.858, time/batch = 0.023
Read data: 7.581710815429688e-05
iter 4125 (epoch 6), train_loss = 3.421, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 4126 (epoch 6), train_loss = 2.670, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 4127 (epoch 6), train_loss = 3.293, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 4128 (epoch 6), train_loss = 2.694, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 4129 (epoch 6), train_loss = 3.272, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 4130 (epoch 6), train_loss = 2.556, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 4131 (epoch 6), train_loss = 2.969, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 4132 (epoch 6), train_loss = 2.888, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 4133 (epoch 6), train_loss = 2.654, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 4134 (epoch 6), train_loss = 2.891, time/batch = 0.032
Read data: 7.772445678710938e-05
iter 4135 (epoch 6), train_loss = 3.148, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 4136 (epoch 6), train_loss = 3.484, time/batch = 0.036
Read data: 9.179115295410156e-05
iter 4137 (epoch 6), train_loss = 2.795, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 4138 (epoch 6), train_loss = 2.556, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 4139 (epoch 6), train_loss = 2.943, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 4140 (epoch 6), train_loss = 3.357, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 4141 (epoch 6), train_loss = 2.967, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 4142 (epoch 6), train_loss = 2.988, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 4143 (epoch 6), train_loss = 2.972, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 4144 (epoch 6), train_loss = 3.482, time/batch = 0.025
Read data: 0.00014162063598632812
iter 4145 (epoch 6), train_loss = 2.770, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 4146 (epoch 6), train_loss = 2.957, time/batch = 0.033
Read data: 7.62939453125e-05
iter 4147 (epoch 6), train_loss = 3.219, time/batch = 0.029
Read data: 0.00016999244689941406
iter 4148 (epoch 6), train_loss = 3.212, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 4149 (epoch 6), train_loss = 2.389, time/batch = 0.026
Read data: 0.0002605915069580078
iter 4150 (epoch 6), train_loss = 2.929, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 4151 (epoch 6), train_loss = 2.653, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 4152 (epoch 6), train_loss = 2.916, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 4153 (epoch 6), train_loss = 3.058, time/batch = 0.021
Read data: 9.512901306152344e-05
iter 4154 (epoch 6), train_loss = 2.857, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 4155 (epoch 6), train_loss = 3.139, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 4156 (epoch 6), train_loss = 2.845, time/batch = 0.033
Read data: 9.202957153320312e-05
iter 4157 (epoch 6), train_loss = 3.237, time/batch = 0.027
Read data: 0.0001366138458251953
iter 4158 (epoch 6), train_loss = 3.348, time/batch = 0.032
Read data: 8.606910705566406e-05
iter 4159 (epoch 6), train_loss = 3.102, time/batch = 0.026
Read data: 0.0001659393310546875
iter 4160 (epoch 6), train_loss = 3.154, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 4161 (epoch 6), train_loss = 2.981, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 4162 (epoch 6), train_loss = 3.170, time/batch = 0.038
Read data: 8.916854858398438e-05
iter 4163 (epoch 6), train_loss = 2.910, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 4164 (epoch 6), train_loss = 2.512, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 4165 (epoch 6), train_loss = 2.972, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 4166 (epoch 6), train_loss = 2.825, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 4167 (epoch 6), train_loss = 2.464, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 4168 (epoch 6), train_loss = 2.825, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 4169 (epoch 6), train_loss = 2.727, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 4170 (epoch 6), train_loss = 2.866, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 4171 (epoch 6), train_loss = 2.993, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 4172 (epoch 6), train_loss = 3.225, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 4173 (epoch 6), train_loss = 2.702, time/batch = 0.020
Read data: 9.751319885253906e-05
iter 4174 (epoch 6), train_loss = 2.972, time/batch = 0.025
Read data: 0.0003554821014404297
iter 4175 (epoch 6), train_loss = 2.527, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 4176 (epoch 6), train_loss = 2.718, time/batch = 0.025
Read data: 0.00014972686767578125
iter 4177 (epoch 6), train_loss = 3.185, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 4178 (epoch 6), train_loss = 3.167, time/batch = 0.032
Read data: 7.867813110351562e-05
iter 4179 (epoch 6), train_loss = 3.139, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 4180 (epoch 6), train_loss = 2.453, time/batch = 0.020
Read data: 8.344650268554688e-05
iter 4181 (epoch 6), train_loss = 2.607, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 4182 (epoch 6), train_loss = 2.368, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 4183 (epoch 6), train_loss = 2.645, time/batch = 0.027
Read data: 9.5367431640625e-05
iter 4184 (epoch 6), train_loss = 2.702, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 4185 (epoch 6), train_loss = 2.897, time/batch = 0.024
Read data: 0.00012969970703125
iter 4186 (epoch 6), train_loss = 3.337, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 4187 (epoch 6), train_loss = 2.819, time/batch = 0.025
Read data: 0.00015783309936523438
iter 4188 (epoch 6), train_loss = 2.981, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 4189 (epoch 6), train_loss = 2.996, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 4190 (epoch 6), train_loss = 2.931, time/batch = 0.023
Read data: 0.00010967254638671875
iter 4191 (epoch 6), train_loss = 2.989, time/batch = 0.040
Read data: 0.0010671615600585938
iter 4192 (epoch 6), train_loss = 2.987, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 4193 (epoch 6), train_loss = 3.163, time/batch = 0.031
Read data: 7.677078247070312e-05
iter 4194 (epoch 6), train_loss = 2.882, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 4195 (epoch 6), train_loss = 2.836, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 4196 (epoch 6), train_loss = 2.854, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 4197 (epoch 6), train_loss = 2.784, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 4198 (epoch 6), train_loss = 2.473, time/batch = 0.025
Read data: 0.00017023086547851562
iter 4199 (epoch 6), train_loss = 2.580, time/batch = 0.027
Read data: 0.0002865791320800781
iter 4200 (epoch 6), train_loss = 3.229, time/batch = 0.038
Read data: 7.796287536621094e-05
iter 4201 (epoch 7), train_loss = 3.042, time/batch = 0.029
Read data: 9.083747863769531e-05
iter 4202 (epoch 7), train_loss = 2.954, time/batch = 0.028
Read data: 0.00013637542724609375
iter 4203 (epoch 7), train_loss = 3.298, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 4204 (epoch 7), train_loss = 2.880, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 4205 (epoch 7), train_loss = 3.034, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 4206 (epoch 7), train_loss = 3.246, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 4207 (epoch 7), train_loss = 2.605, time/batch = 0.027
Read data: 0.00015306472778320312
iter 4208 (epoch 7), train_loss = 3.007, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 4209 (epoch 7), train_loss = 3.413, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 4210 (epoch 7), train_loss = 2.934, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 4211 (epoch 7), train_loss = 2.638, time/batch = 0.030
Read data: 0.00015854835510253906
iter 4212 (epoch 7), train_loss = 2.678, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 4213 (epoch 7), train_loss = 3.126, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 4214 (epoch 7), train_loss = 3.054, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 4215 (epoch 7), train_loss = 2.854, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 4216 (epoch 7), train_loss = 2.670, time/batch = 0.026
Read data: 7.62939453125e-05
iter 4217 (epoch 7), train_loss = 2.935, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 4218 (epoch 7), train_loss = 3.134, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 4219 (epoch 7), train_loss = 2.535, time/batch = 0.025
Read data: 0.00013136863708496094
iter 4220 (epoch 7), train_loss = 2.919, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 4221 (epoch 7), train_loss = 2.588, time/batch = 0.021
Read data: 9.775161743164062e-05
iter 4222 (epoch 7), train_loss = 3.385, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 4223 (epoch 7), train_loss = 2.863, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 4224 (epoch 7), train_loss = 3.326, time/batch = 0.026
Read data: 0.00014448165893554688
iter 4225 (epoch 7), train_loss = 2.732, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 4226 (epoch 7), train_loss = 2.696, time/batch = 0.034
Read data: 7.82012939453125e-05
iter 4227 (epoch 7), train_loss = 3.299, time/batch = 0.028
Read data: 0.00013184547424316406
iter 4228 (epoch 7), train_loss = 2.475, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 4229 (epoch 7), train_loss = 2.568, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 4230 (epoch 7), train_loss = 3.337, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 4231 (epoch 7), train_loss = 2.878, time/batch = 0.022
Read data: 7.843971252441406e-05
iter 4232 (epoch 7), train_loss = 2.796, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 4233 (epoch 7), train_loss = 2.836, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 4234 (epoch 7), train_loss = 3.265, time/batch = 0.026
Read data: 9.393692016601562e-05
iter 4235 (epoch 7), train_loss = 2.693, time/batch = 0.035
Read data: 0.00014710426330566406
iter 4236 (epoch 7), train_loss = 2.999, time/batch = 0.029
Read data: 9.751319885253906e-05
iter 4237 (epoch 7), train_loss = 2.836, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 4238 (epoch 7), train_loss = 3.085, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4239 (epoch 7), train_loss = 2.674, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 4240 (epoch 7), train_loss = 2.518, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 4241 (epoch 7), train_loss = 2.908, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 4242 (epoch 7), train_loss = 2.981, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 4243 (epoch 7), train_loss = 3.281, time/batch = 0.032
Read data: 0.0001266002655029297
iter 4244 (epoch 7), train_loss = 2.926, time/batch = 0.028
Read data: 0.00013399124145507812
iter 4245 (epoch 7), train_loss = 3.122, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 4246 (epoch 7), train_loss = 3.070, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 4247 (epoch 7), train_loss = 2.949, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 4248 (epoch 7), train_loss = 3.102, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 4249 (epoch 7), train_loss = 2.649, time/batch = 0.031
Read data: 0.00020647048950195312
iter 4250 (epoch 7), train_loss = 2.870, time/batch = 0.024
Read data: 0.00010514259338378906
iter 4251 (epoch 7), train_loss = 3.216, time/batch = 0.033
Read data: 0.00011134147644042969
iter 4252 (epoch 7), train_loss = 2.668, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 4253 (epoch 7), train_loss = 2.571, time/batch = 0.031
Read data: 0.0001163482666015625
iter 4254 (epoch 7), train_loss = 2.869, time/batch = 0.030
Read data: 0.00011658668518066406
iter 4255 (epoch 7), train_loss = 2.886, time/batch = 0.028
Read data: 0.00011396408081054688
iter 4256 (epoch 7), train_loss = 3.124, time/batch = 0.034
Read data: 8.845329284667969e-05
iter 4257 (epoch 7), train_loss = 2.832, time/batch = 0.025
Read data: 0.0001087188720703125
iter 4258 (epoch 7), train_loss = 2.552, time/batch = 0.031
Read data: 0.0001266002655029297
iter 4259 (epoch 7), train_loss = 2.900, time/batch = 0.029
Read data: 0.00011372566223144531
iter 4260 (epoch 7), train_loss = 2.567, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 4261 (epoch 7), train_loss = 2.876, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 4262 (epoch 7), train_loss = 2.368, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 4263 (epoch 7), train_loss = 3.145, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 4264 (epoch 7), train_loss = 2.769, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 4265 (epoch 7), train_loss = 2.766, time/batch = 0.028
Read data: 0.0001499652862548828
iter 4266 (epoch 7), train_loss = 2.659, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 4267 (epoch 7), train_loss = 2.950, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 4268 (epoch 7), train_loss = 3.050, time/batch = 0.028
Read data: 0.00011873245239257812
iter 4269 (epoch 7), train_loss = 3.005, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 4270 (epoch 7), train_loss = 2.916, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 4271 (epoch 7), train_loss = 3.540, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4272 (epoch 7), train_loss = 2.957, time/batch = 0.026
Read data: 0.0001385211944580078
iter 4273 (epoch 7), train_loss = 2.840, time/batch = 0.039
Read data: 8.296966552734375e-05
iter 4274 (epoch 7), train_loss = 2.267, time/batch = 0.028
Read data: 0.00017309188842773438
iter 4275 (epoch 7), train_loss = 2.570, time/batch = 0.031
Read data: 8.797645568847656e-05
iter 4276 (epoch 7), train_loss = 2.793, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 4277 (epoch 7), train_loss = 2.977, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 4278 (epoch 7), train_loss = 3.143, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 4279 (epoch 7), train_loss = 2.927, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 4280 (epoch 7), train_loss = 3.308, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 4281 (epoch 7), train_loss = 2.733, time/batch = 0.033
Read data: 0.00013303756713867188
iter 4282 (epoch 7), train_loss = 3.154, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 4283 (epoch 7), train_loss = 3.075, time/batch = 0.030
Read data: 9.512901306152344e-05
iter 4284 (epoch 7), train_loss = 2.966, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 4285 (epoch 7), train_loss = 3.356, time/batch = 0.028
Read data: 0.00014209747314453125
iter 4286 (epoch 7), train_loss = 2.815, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 4287 (epoch 7), train_loss = 2.657, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 4288 (epoch 7), train_loss = 3.354, time/batch = 0.029
Read data: 0.00017762184143066406
iter 4289 (epoch 7), train_loss = 2.611, time/batch = 0.030
Read data: 8.797645568847656e-05
iter 4290 (epoch 7), train_loss = 2.980, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 4291 (epoch 7), train_loss = 3.350, time/batch = 0.034
Read data: 8.511543273925781e-05
iter 4292 (epoch 7), train_loss = 2.800, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 4293 (epoch 7), train_loss = 2.562, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 4294 (epoch 7), train_loss = 3.108, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 4295 (epoch 7), train_loss = 3.108, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 4296 (epoch 7), train_loss = 2.970, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 4297 (epoch 7), train_loss = 3.125, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 4298 (epoch 7), train_loss = 3.057, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 4299 (epoch 7), train_loss = 3.145, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 4300 (epoch 7), train_loss = 2.921, time/batch = 0.028
Read data: 0.0001366138458251953
iter 4301 (epoch 7), train_loss = 2.702, time/batch = 0.022
Read data: 0.00013184547424316406
iter 4302 (epoch 7), train_loss = 2.925, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 4303 (epoch 7), train_loss = 2.665, time/batch = 0.026
Read data: 7.557868957519531e-05
iter 4304 (epoch 7), train_loss = 3.279, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 4305 (epoch 7), train_loss = 3.003, time/batch = 0.034
Read data: 8.463859558105469e-05
iter 4306 (epoch 7), train_loss = 2.827, time/batch = 0.032
Read data: 8.630752563476562e-05
iter 4307 (epoch 7), train_loss = 2.649, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 4308 (epoch 7), train_loss = 2.364, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 4309 (epoch 7), train_loss = 3.012, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 4310 (epoch 7), train_loss = 3.051, time/batch = 0.024
Read data: 0.00012564659118652344
iter 4311 (epoch 7), train_loss = 2.672, time/batch = 0.026
Read data: 0.00014495849609375
iter 4312 (epoch 7), train_loss = 2.808, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 4313 (epoch 7), train_loss = 3.073, time/batch = 0.028
Read data: 0.00013494491577148438
iter 4314 (epoch 7), train_loss = 2.874, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 4315 (epoch 7), train_loss = 2.613, time/batch = 0.021
Read data: 9.5367431640625e-05
iter 4316 (epoch 7), train_loss = 2.719, time/batch = 0.028
Read data: 0.0001285076141357422
iter 4317 (epoch 7), train_loss = 2.866, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 4318 (epoch 7), train_loss = 2.937, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 4319 (epoch 7), train_loss = 2.499, time/batch = 0.023
Read data: 0.0001571178436279297
iter 4320 (epoch 7), train_loss = 2.729, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 4321 (epoch 7), train_loss = 3.115, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 4322 (epoch 7), train_loss = 2.725, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 4323 (epoch 7), train_loss = 2.546, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 4324 (epoch 7), train_loss = 2.846, time/batch = 0.026
Read data: 0.0001316070556640625
iter 4325 (epoch 7), train_loss = 2.329, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 4326 (epoch 7), train_loss = 2.819, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 4327 (epoch 7), train_loss = 3.086, time/batch = 0.044
Read data: 9.179115295410156e-05
iter 4328 (epoch 7), train_loss = 3.277, time/batch = 0.028
Read data: 0.0001461505889892578
iter 4329 (epoch 7), train_loss = 2.964, time/batch = 0.034
Read data: 7.843971252441406e-05
iter 4330 (epoch 7), train_loss = 3.074, time/batch = 0.029
Read data: 0.00011014938354492188
iter 4331 (epoch 7), train_loss = 2.973, time/batch = 0.027
Read data: 0.00010323524475097656
iter 4332 (epoch 7), train_loss = 2.741, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 4333 (epoch 7), train_loss = 3.075, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 4334 (epoch 7), train_loss = 2.892, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 4335 (epoch 7), train_loss = 2.822, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 4336 (epoch 7), train_loss = 2.670, time/batch = 0.021
Read data: 0.0001575946807861328
iter 4337 (epoch 7), train_loss = 2.966, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 4338 (epoch 7), train_loss = 3.128, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 4339 (epoch 7), train_loss = 2.311, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 4340 (epoch 7), train_loss = 2.808, time/batch = 0.023
Read data: 0.00017690658569335938
iter 4341 (epoch 7), train_loss = 3.161, time/batch = 0.032
Read data: 8.249282836914062e-05
iter 4342 (epoch 7), train_loss = 2.377, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 4343 (epoch 7), train_loss = 3.076, time/batch = 0.039
Read data: 0.00014472007751464844
iter 4344 (epoch 7), train_loss = 2.726, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 4345 (epoch 7), train_loss = 2.883, time/batch = 0.031
Read data: 8.7738037109375e-05
iter 4346 (epoch 7), train_loss = 2.652, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 4347 (epoch 7), train_loss = 3.084, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 4348 (epoch 7), train_loss = 2.615, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 4349 (epoch 7), train_loss = 2.852, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 4350 (epoch 7), train_loss = 3.208, time/batch = 0.034
Read data: 9.465217590332031e-05
iter 4351 (epoch 7), train_loss = 3.038, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 4352 (epoch 7), train_loss = 3.145, time/batch = 0.021
Read data: 0.00012803077697753906
iter 4353 (epoch 7), train_loss = 2.884, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 4354 (epoch 7), train_loss = 2.815, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 4355 (epoch 7), train_loss = 2.499, time/batch = 0.025
Read data: 0.00010156631469726562
iter 4356 (epoch 7), train_loss = 3.085, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 4357 (epoch 7), train_loss = 2.717, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 4358 (epoch 7), train_loss = 3.039, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4359 (epoch 7), train_loss = 2.953, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 4360 (epoch 7), train_loss = 3.306, time/batch = 0.025
Read data: 0.0018076896667480469
iter 4361 (epoch 7), train_loss = 3.027, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 4362 (epoch 7), train_loss = 2.970, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 4363 (epoch 7), train_loss = 3.049, time/batch = 0.042
Read data: 9.107589721679688e-05
iter 4364 (epoch 7), train_loss = 2.858, time/batch = 0.023
Read data: 0.0001704692840576172
iter 4365 (epoch 7), train_loss = 3.137, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 4366 (epoch 7), train_loss = 2.920, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 4367 (epoch 7), train_loss = 2.597, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 4368 (epoch 7), train_loss = 2.870, time/batch = 0.025
Read data: 0.00013828277587890625
iter 4369 (epoch 7), train_loss = 2.947, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 4370 (epoch 7), train_loss = 3.043, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 4371 (epoch 7), train_loss = 3.048, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 4372 (epoch 7), train_loss = 3.367, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 4373 (epoch 7), train_loss = 3.072, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 4374 (epoch 7), train_loss = 2.720, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 4375 (epoch 7), train_loss = 2.829, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 4376 (epoch 7), train_loss = 3.039, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 4377 (epoch 7), train_loss = 3.079, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 4378 (epoch 7), train_loss = 3.375, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 4379 (epoch 7), train_loss = 2.951, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 4380 (epoch 7), train_loss = 2.746, time/batch = 0.024
Read data: 0.00015783309936523438
iter 4381 (epoch 7), train_loss = 2.981, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 4382 (epoch 7), train_loss = 2.971, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 4383 (epoch 7), train_loss = 2.756, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4384 (epoch 7), train_loss = 2.650, time/batch = 0.026
Read data: 0.00012612342834472656
iter 4385 (epoch 7), train_loss = 2.924, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 4386 (epoch 7), train_loss = 3.188, time/batch = 0.021
Read data: 0.00011754035949707031
iter 4387 (epoch 7), train_loss = 2.590, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 4388 (epoch 7), train_loss = 2.370, time/batch = 0.022
Read data: 0.00013566017150878906
iter 4389 (epoch 7), train_loss = 2.883, time/batch = 0.029
Read data: 9.942054748535156e-05
iter 4390 (epoch 7), train_loss = 2.559, time/batch = 0.021
Read data: 0.0001742839813232422
iter 4391 (epoch 7), train_loss = 2.953, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 4392 (epoch 7), train_loss = 3.025, time/batch = 0.028
Read data: 9.918212890625e-05
iter 4393 (epoch 7), train_loss = 2.963, time/batch = 0.025
Read data: 0.0001385211944580078
iter 4394 (epoch 7), train_loss = 2.790, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 4395 (epoch 7), train_loss = 2.911, time/batch = 0.033
Read data: 7.772445678710938e-05
iter 4396 (epoch 7), train_loss = 2.657, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 4397 (epoch 7), train_loss = 2.982, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 4398 (epoch 7), train_loss = 2.943, time/batch = 0.028
Read data: 0.00015878677368164062
iter 4399 (epoch 7), train_loss = 3.424, time/batch = 0.026
Read data: 0.0002675056457519531
iter 4400 (epoch 7), train_loss = 2.916, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 4401 (epoch 7), train_loss = 3.294, time/batch = 0.025
Read data: 0.00010180473327636719
iter 4402 (epoch 7), train_loss = 2.626, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 4403 (epoch 7), train_loss = 2.944, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 4404 (epoch 7), train_loss = 2.543, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 4405 (epoch 7), train_loss = 2.897, time/batch = 0.021
Read data: 8.392333984375e-05
iter 4406 (epoch 7), train_loss = 2.763, time/batch = 0.034
Read data: 0.0001513957977294922
iter 4407 (epoch 7), train_loss = 2.799, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 4408 (epoch 7), train_loss = 2.639, time/batch = 0.022
Read data: 0.00010013580322265625
iter 4409 (epoch 7), train_loss = 3.186, time/batch = 0.023
Read data: 0.0001373291015625
iter 4410 (epoch 7), train_loss = 2.277, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 4411 (epoch 7), train_loss = 3.006, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 4412 (epoch 7), train_loss = 2.795, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 4413 (epoch 7), train_loss = 2.793, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4414 (epoch 7), train_loss = 2.901, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 4415 (epoch 7), train_loss = 2.830, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 4416 (epoch 7), train_loss = 3.057, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 4417 (epoch 7), train_loss = 2.482, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 4418 (epoch 7), train_loss = 2.982, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 4419 (epoch 7), train_loss = 2.925, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 4420 (epoch 7), train_loss = 3.605, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 4421 (epoch 7), train_loss = 2.700, time/batch = 0.025
Read data: 0.00011324882507324219
iter 4422 (epoch 7), train_loss = 3.068, time/batch = 0.033
Read data: 8.153915405273438e-05
iter 4423 (epoch 7), train_loss = 2.524, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 4424 (epoch 7), train_loss = 2.827, time/batch = 0.030
Read data: 0.00020503997802734375
iter 4425 (epoch 7), train_loss = 2.751, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4426 (epoch 7), train_loss = 2.899, time/batch = 0.022
Read data: 0.00013518333435058594
iter 4427 (epoch 7), train_loss = 2.390, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 4428 (epoch 7), train_loss = 2.979, time/batch = 0.022
Read data: 0.00013184547424316406
iter 4429 (epoch 7), train_loss = 2.976, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 4430 (epoch 7), train_loss = 3.051, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 4431 (epoch 7), train_loss = 3.020, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 4432 (epoch 7), train_loss = 3.009, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 4433 (epoch 7), train_loss = 3.169, time/batch = 0.022
Read data: 9.965896606445312e-05
iter 4434 (epoch 7), train_loss = 2.997, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 4435 (epoch 7), train_loss = 2.804, time/batch = 0.021
Read data: 9.512901306152344e-05
iter 4436 (epoch 7), train_loss = 2.745, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 4437 (epoch 7), train_loss = 2.691, time/batch = 0.025
Read data: 0.0001728534698486328
iter 4438 (epoch 7), train_loss = 2.942, time/batch = 0.023
Read data: 0.00013637542724609375
iter 4439 (epoch 7), train_loss = 2.834, time/batch = 0.025
Read data: 0.0001342296600341797
iter 4440 (epoch 7), train_loss = 3.019, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 4441 (epoch 7), train_loss = 2.815, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 4442 (epoch 7), train_loss = 2.827, time/batch = 0.027
Read data: 0.00013518333435058594
iter 4443 (epoch 7), train_loss = 2.700, time/batch = 0.037
Read data: 7.82012939453125e-05
iter 4444 (epoch 7), train_loss = 2.904, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 4445 (epoch 7), train_loss = 2.700, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4446 (epoch 7), train_loss = 3.339, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 4447 (epoch 7), train_loss = 3.382, time/batch = 0.033
Read data: 8.58306884765625e-05
iter 4448 (epoch 7), train_loss = 2.628, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 4449 (epoch 7), train_loss = 3.073, time/batch = 0.035
Read data: 0.00010967254638671875
iter 4450 (epoch 7), train_loss = 2.568, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 4451 (epoch 7), train_loss = 2.609, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 4452 (epoch 7), train_loss = 2.665, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 4453 (epoch 7), train_loss = 3.221, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 4454 (epoch 7), train_loss = 2.482, time/batch = 0.028
Read data: 0.00010943412780761719
iter 4455 (epoch 7), train_loss = 2.850, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 4456 (epoch 7), train_loss = 2.947, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 4457 (epoch 7), train_loss = 3.036, time/batch = 0.030
Read data: 0.00016164779663085938
iter 4458 (epoch 7), train_loss = 3.084, time/batch = 0.026
Read data: 0.0001380443572998047
iter 4459 (epoch 7), train_loss = 2.831, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4460 (epoch 7), train_loss = 2.738, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 4461 (epoch 7), train_loss = 3.059, time/batch = 0.029
Read data: 8.392333984375e-05
iter 4462 (epoch 7), train_loss = 2.732, time/batch = 0.027
Read data: 0.00012636184692382812
iter 4463 (epoch 7), train_loss = 3.296, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 4464 (epoch 7), train_loss = 3.070, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 4465 (epoch 7), train_loss = 2.890, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 4466 (epoch 7), train_loss = 3.138, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 4467 (epoch 7), train_loss = 2.768, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 4468 (epoch 7), train_loss = 3.153, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 4469 (epoch 7), train_loss = 3.016, time/batch = 0.040
Read data: 0.00016498565673828125
iter 4470 (epoch 7), train_loss = 2.681, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 4471 (epoch 7), train_loss = 2.991, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 4472 (epoch 7), train_loss = 2.985, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 4473 (epoch 7), train_loss = 3.232, time/batch = 0.033
Read data: 0.00016260147094726562
iter 4474 (epoch 7), train_loss = 2.721, time/batch = 0.024
Read data: 0.00021696090698242188
iter 4475 (epoch 7), train_loss = 3.239, time/batch = 0.039
Read data: 8.749961853027344e-05
iter 4476 (epoch 7), train_loss = 2.635, time/batch = 0.026
Read data: 0.0001232624053955078
iter 4477 (epoch 7), train_loss = 3.205, time/batch = 0.025
Read data: 0.0001671314239501953
iter 4478 (epoch 7), train_loss = 2.570, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 4479 (epoch 7), train_loss = 2.866, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 4480 (epoch 7), train_loss = 2.874, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 4481 (epoch 7), train_loss = 3.179, time/batch = 0.033
Read data: 0.0001266002655029297
iter 4482 (epoch 7), train_loss = 2.594, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 4483 (epoch 7), train_loss = 2.837, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 4484 (epoch 7), train_loss = 3.106, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 4485 (epoch 7), train_loss = 2.509, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 4486 (epoch 7), train_loss = 2.850, time/batch = 0.027
Read data: 0.0001678466796875
iter 4487 (epoch 7), train_loss = 2.448, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 4488 (epoch 7), train_loss = 2.719, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 4489 (epoch 7), train_loss = 3.147, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 4490 (epoch 7), train_loss = 2.585, time/batch = 0.021
Read data: 0.00013494491577148438
iter 4491 (epoch 7), train_loss = 2.786, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 4492 (epoch 7), train_loss = 2.450, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 4493 (epoch 7), train_loss = 2.911, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 4494 (epoch 7), train_loss = 3.179, time/batch = 0.039
Read data: 0.00015807151794433594
iter 4495 (epoch 7), train_loss = 3.345, time/batch = 0.031
Read data: 9.369850158691406e-05
iter 4496 (epoch 7), train_loss = 2.632, time/batch = 0.022
Read data: 8.320808410644531e-05
iter 4497 (epoch 7), train_loss = 2.842, time/batch = 0.025
Read data: 0.00010037422180175781
iter 4498 (epoch 7), train_loss = 2.840, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 4499 (epoch 7), train_loss = 2.538, time/batch = 0.025
Read data: 0.00018835067749023438
iter 4500 (epoch 7), train_loss = 2.738, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 4501 (epoch 7), train_loss = 2.806, time/batch = 0.021
Read data: 0.0001442432403564453
iter 4502 (epoch 7), train_loss = 3.094, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 4503 (epoch 7), train_loss = 3.218, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4504 (epoch 7), train_loss = 2.728, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 4505 (epoch 7), train_loss = 2.683, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 4506 (epoch 7), train_loss = 3.351, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4507 (epoch 7), train_loss = 2.521, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 4508 (epoch 7), train_loss = 2.619, time/batch = 0.027
Read data: 0.0001049041748046875
iter 4509 (epoch 7), train_loss = 3.132, time/batch = 0.025
Read data: 0.0001385211944580078
iter 4510 (epoch 7), train_loss = 2.572, time/batch = 0.038
Read data: 8.153915405273438e-05
iter 4511 (epoch 7), train_loss = 2.936, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 4512 (epoch 7), train_loss = 2.567, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 4513 (epoch 7), train_loss = 2.662, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4514 (epoch 7), train_loss = 2.919, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 4515 (epoch 7), train_loss = 2.609, time/batch = 0.022
Read data: 9.72747802734375e-05
iter 4516 (epoch 7), train_loss = 2.837, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 4517 (epoch 7), train_loss = 2.969, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 4518 (epoch 7), train_loss = 2.780, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 4519 (epoch 7), train_loss = 2.503, time/batch = 0.021
Read data: 0.00010204315185546875
iter 4520 (epoch 7), train_loss = 2.555, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 4521 (epoch 7), train_loss = 2.409, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 4522 (epoch 7), train_loss = 2.907, time/batch = 0.031
Read data: 9.393692016601562e-05
iter 4523 (epoch 7), train_loss = 2.983, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 4524 (epoch 7), train_loss = 2.640, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 4525 (epoch 7), train_loss = 2.867, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 4526 (epoch 7), train_loss = 2.893, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 4527 (epoch 7), train_loss = 3.000, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 4528 (epoch 7), train_loss = 2.864, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 4529 (epoch 7), train_loss = 2.949, time/batch = 0.023
Read data: 0.0001323223114013672
iter 4530 (epoch 7), train_loss = 2.575, time/batch = 0.025
Read data: 0.00017499923706054688
iter 4531 (epoch 7), train_loss = 2.685, time/batch = 0.036
Read data: 8.368492126464844e-05
iter 4532 (epoch 7), train_loss = 2.686, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 4533 (epoch 7), train_loss = 2.942, time/batch = 0.026
Read data: 0.00013518333435058594
iter 4534 (epoch 7), train_loss = 2.876, time/batch = 0.035
Read data: 8.559226989746094e-05
iter 4535 (epoch 7), train_loss = 2.458, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 4536 (epoch 7), train_loss = 3.114, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 4537 (epoch 7), train_loss = 2.610, time/batch = 0.024
Read data: 0.00012969970703125
iter 4538 (epoch 7), train_loss = 3.161, time/batch = 0.021
Read data: 0.00011754035949707031
iter 4539 (epoch 7), train_loss = 3.165, time/batch = 0.034
Read data: 8.225440979003906e-05
iter 4540 (epoch 7), train_loss = 2.671, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 4541 (epoch 7), train_loss = 2.841, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 4542 (epoch 7), train_loss = 2.801, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 4543 (epoch 7), train_loss = 3.151, time/batch = 0.027
Read data: 9.632110595703125e-05
iter 4544 (epoch 7), train_loss = 2.892, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 4545 (epoch 7), train_loss = 2.867, time/batch = 0.020
Read data: 9.34600830078125e-05
iter 4546 (epoch 7), train_loss = 2.982, time/batch = 0.027
Read data: 0.0001361370086669922
iter 4547 (epoch 7), train_loss = 2.949, time/batch = 0.029
Read data: 9.560585021972656e-05
iter 4548 (epoch 7), train_loss = 2.637, time/batch = 0.035
Read data: 8.153915405273438e-05
iter 4549 (epoch 7), train_loss = 2.988, time/batch = 0.026
Read data: 0.00011944770812988281
iter 4550 (epoch 7), train_loss = 3.357, time/batch = 0.033
Read data: 8.940696716308594e-05
iter 4551 (epoch 7), train_loss = 3.011, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 4552 (epoch 7), train_loss = 3.329, time/batch = 0.032
Read data: 0.00013875961303710938
iter 4553 (epoch 7), train_loss = 3.158, time/batch = 0.022
Read data: 0.00012946128845214844
iter 4554 (epoch 7), train_loss = 2.857, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 4555 (epoch 7), train_loss = 2.998, time/batch = 0.030
Read data: 8.916854858398438e-05
iter 4556 (epoch 7), train_loss = 3.232, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 4557 (epoch 7), train_loss = 2.458, time/batch = 0.021
Read data: 0.00010943412780761719
iter 4558 (epoch 7), train_loss = 2.954, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 4559 (epoch 7), train_loss = 3.064, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 4560 (epoch 7), train_loss = 3.203, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 4561 (epoch 7), train_loss = 3.247, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 4562 (epoch 7), train_loss = 3.160, time/batch = 0.025
Read data: 0.0001399517059326172
iter 4563 (epoch 7), train_loss = 2.333, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 4564 (epoch 7), train_loss = 3.054, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 4565 (epoch 7), train_loss = 2.873, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 4566 (epoch 7), train_loss = 2.696, time/batch = 0.027
Read data: 0.00017499923706054688
iter 4567 (epoch 7), train_loss = 3.121, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 4568 (epoch 7), train_loss = 2.815, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 4569 (epoch 7), train_loss = 2.998, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 4570 (epoch 7), train_loss = 3.248, time/batch = 0.025
Read data: 0.00013566017150878906
iter 4571 (epoch 7), train_loss = 2.452, time/batch = 0.024
Read data: 0.00010061264038085938
iter 4572 (epoch 7), train_loss = 2.956, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 4573 (epoch 7), train_loss = 3.067, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 4574 (epoch 7), train_loss = 2.739, time/batch = 0.027
Read data: 0.00018310546875
iter 4575 (epoch 7), train_loss = 3.010, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 4576 (epoch 7), train_loss = 2.632, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 4577 (epoch 7), train_loss = 3.006, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 4578 (epoch 7), train_loss = 2.503, time/batch = 0.033
Read data: 0.000133514404296875
iter 4579 (epoch 7), train_loss = 2.986, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 4580 (epoch 7), train_loss = 2.951, time/batch = 0.032
Read data: 8.678436279296875e-05
iter 4581 (epoch 7), train_loss = 2.771, time/batch = 0.024
Read data: 0.00012421607971191406
iter 4582 (epoch 7), train_loss = 2.769, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 4583 (epoch 7), train_loss = 2.830, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 4584 (epoch 7), train_loss = 2.600, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 4585 (epoch 7), train_loss = 3.158, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 4586 (epoch 7), train_loss = 2.586, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 4587 (epoch 7), train_loss = 2.520, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 4588 (epoch 7), train_loss = 2.646, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 4589 (epoch 7), train_loss = 3.066, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 4590 (epoch 7), train_loss = 3.029, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 4591 (epoch 7), train_loss = 3.265, time/batch = 0.021
Read data: 8.153915405273438e-05
iter 4592 (epoch 7), train_loss = 2.442, time/batch = 0.020
Read data: 9.036064147949219e-05
iter 4593 (epoch 7), train_loss = 2.893, time/batch = 0.022
Read data: 0.0001468658447265625
iter 4594 (epoch 7), train_loss = 2.800, time/batch = 0.031
Read data: 0.00012135505676269531
iter 4595 (epoch 7), train_loss = 3.130, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 4596 (epoch 7), train_loss = 3.289, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 4597 (epoch 7), train_loss = 2.943, time/batch = 0.038
Read data: 7.915496826171875e-05
iter 4598 (epoch 7), train_loss = 2.896, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 4599 (epoch 7), train_loss = 3.099, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 4600 (epoch 7), train_loss = 2.856, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 4601 (epoch 7), train_loss = 2.960, time/batch = 0.022
Read data: 0.00010037422180175781
iter 4602 (epoch 7), train_loss = 3.188, time/batch = 0.040
Read data: 0.0001404285430908203
iter 4603 (epoch 7), train_loss = 3.477, time/batch = 0.027
Read data: 9.608268737792969e-05
iter 4604 (epoch 7), train_loss = 2.884, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 4605 (epoch 7), train_loss = 2.778, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 4606 (epoch 7), train_loss = 2.820, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 4607 (epoch 7), train_loss = 2.566, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 4608 (epoch 7), train_loss = 2.458, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 4609 (epoch 7), train_loss = 2.479, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 4610 (epoch 7), train_loss = 3.044, time/batch = 0.021
Read data: 0.00011897087097167969
iter 4611 (epoch 7), train_loss = 3.030, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 4612 (epoch 7), train_loss = 2.687, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 4613 (epoch 7), train_loss = 2.849, time/batch = 0.023
Read data: 9.1552734375e-05
iter 4614 (epoch 7), train_loss = 3.163, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 4615 (epoch 7), train_loss = 2.939, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 4616 (epoch 7), train_loss = 3.171, time/batch = 0.023
Read data: 0.00010061264038085938
iter 4617 (epoch 7), train_loss = 3.242, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 4618 (epoch 7), train_loss = 3.240, time/batch = 0.025
Read data: 0.0001442432403564453
iter 4619 (epoch 7), train_loss = 2.679, time/batch = 0.029
Read data: 9.489059448242188e-05
iter 4620 (epoch 7), train_loss = 3.029, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 4621 (epoch 7), train_loss = 3.013, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 4622 (epoch 7), train_loss = 2.758, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 4623 (epoch 7), train_loss = 2.958, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4624 (epoch 7), train_loss = 2.712, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 4625 (epoch 7), train_loss = 3.228, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 4626 (epoch 7), train_loss = 2.658, time/batch = 0.026
Read data: 9.417533874511719e-05
iter 4627 (epoch 7), train_loss = 2.923, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 4628 (epoch 7), train_loss = 3.149, time/batch = 0.032
Read data: 7.891654968261719e-05
iter 4629 (epoch 7), train_loss = 2.759, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 4630 (epoch 7), train_loss = 2.955, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 4631 (epoch 7), train_loss = 2.796, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 4632 (epoch 7), train_loss = 2.741, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 4633 (epoch 7), train_loss = 3.067, time/batch = 0.023
Read data: 0.00010466575622558594
iter 4634 (epoch 7), train_loss = 3.163, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 4635 (epoch 7), train_loss = 2.901, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 4636 (epoch 7), train_loss = 3.112, time/batch = 0.029
Read data: 7.581710815429688e-05
iter 4637 (epoch 7), train_loss = 2.844, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 4638 (epoch 7), train_loss = 2.427, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 4639 (epoch 7), train_loss = 2.488, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 4640 (epoch 7), train_loss = 2.883, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 4641 (epoch 7), train_loss = 2.439, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 4642 (epoch 7), train_loss = 2.561, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 4643 (epoch 7), train_loss = 2.625, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 4644 (epoch 7), train_loss = 3.042, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 4645 (epoch 7), train_loss = 2.663, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 4646 (epoch 7), train_loss = 2.824, time/batch = 0.023
Read data: 0.00011491775512695312
iter 4647 (epoch 7), train_loss = 2.498, time/batch = 0.025
Read data: 0.00015497207641601562
iter 4648 (epoch 7), train_loss = 2.607, time/batch = 0.024
Read data: 0.00016260147094726562
iter 4649 (epoch 7), train_loss = 2.676, time/batch = 0.031
Read data: 0.000244140625
iter 4650 (epoch 7), train_loss = 3.129, time/batch = 0.030
Read data: 9.441375732421875e-05
iter 4651 (epoch 7), train_loss = 2.934, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 4652 (epoch 7), train_loss = 3.630, time/batch = 0.030
Read data: 9.250640869140625e-05
iter 4653 (epoch 7), train_loss = 2.881, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 4654 (epoch 7), train_loss = 3.131, time/batch = 0.034
Read data: 0.00017380714416503906
iter 4655 (epoch 7), train_loss = 2.951, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 4656 (epoch 7), train_loss = 3.103, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 4657 (epoch 7), train_loss = 2.519, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 4658 (epoch 7), train_loss = 2.928, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 4659 (epoch 7), train_loss = 3.035, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 4660 (epoch 7), train_loss = 2.875, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 4661 (epoch 7), train_loss = 2.837, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4662 (epoch 7), train_loss = 2.879, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4663 (epoch 7), train_loss = 3.090, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 4664 (epoch 7), train_loss = 3.131, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 4665 (epoch 7), train_loss = 3.127, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 4666 (epoch 7), train_loss = 3.126, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 4667 (epoch 7), train_loss = 3.188, time/batch = 0.034
Read data: 7.939338684082031e-05
iter 4668 (epoch 7), train_loss = 2.773, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 4669 (epoch 7), train_loss = 2.380, time/batch = 0.020
Read data: 9.703636169433594e-05
iter 4670 (epoch 7), train_loss = 2.567, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 4671 (epoch 7), train_loss = 3.257, time/batch = 0.028
Read data: 0.00014638900756835938
iter 4672 (epoch 7), train_loss = 2.767, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 4673 (epoch 7), train_loss = 3.035, time/batch = 0.034
Read data: 8.7738037109375e-05
iter 4674 (epoch 7), train_loss = 2.670, time/batch = 0.026
Read data: 0.00011682510375976562
iter 4675 (epoch 7), train_loss = 2.713, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 4676 (epoch 7), train_loss = 3.302, time/batch = 0.028
Read data: 8.392333984375e-05
iter 4677 (epoch 7), train_loss = 2.801, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 4678 (epoch 7), train_loss = 3.133, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 4679 (epoch 7), train_loss = 3.265, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 4680 (epoch 7), train_loss = 2.387, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 4681 (epoch 7), train_loss = 3.057, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 4682 (epoch 7), train_loss = 3.285, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 4683 (epoch 7), train_loss = 2.991, time/batch = 0.027
Read data: 9.846687316894531e-05
iter 4684 (epoch 7), train_loss = 2.793, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 4685 (epoch 7), train_loss = 2.655, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 4686 (epoch 7), train_loss = 3.088, time/batch = 0.033
Read data: 0.00011324882507324219
iter 4687 (epoch 7), train_loss = 2.753, time/batch = 0.019
Read data: 8.7738037109375e-05
iter 4688 (epoch 7), train_loss = 2.537, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 4689 (epoch 7), train_loss = 2.878, time/batch = 0.026
Read data: 0.00010013580322265625
iter 4690 (epoch 7), train_loss = 2.970, time/batch = 0.018
Read data: 8.511543273925781e-05
iter 4691 (epoch 7), train_loss = 3.448, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 4692 (epoch 7), train_loss = 2.986, time/batch = 0.031
Read data: 0.00010800361633300781
iter 4693 (epoch 7), train_loss = 3.299, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 4694 (epoch 7), train_loss = 2.984, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 4695 (epoch 7), train_loss = 3.020, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 4696 (epoch 7), train_loss = 2.995, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4697 (epoch 7), train_loss = 2.989, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 4698 (epoch 7), train_loss = 2.968, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 4699 (epoch 7), train_loss = 2.686, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 4700 (epoch 7), train_loss = 2.762, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 4701 (epoch 7), train_loss = 2.823, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 4702 (epoch 7), train_loss = 3.510, time/batch = 0.034
Read data: 8.893013000488281e-05
iter 4703 (epoch 7), train_loss = 2.645, time/batch = 0.028
Read data: 0.00012731552124023438
iter 4704 (epoch 7), train_loss = 2.970, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 4705 (epoch 7), train_loss = 3.394, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 4706 (epoch 7), train_loss = 2.666, time/batch = 0.022
Read data: 0.00010752677917480469
iter 4707 (epoch 7), train_loss = 3.186, time/batch = 0.026
Read data: 0.000102996826171875
iter 4708 (epoch 7), train_loss = 2.530, time/batch = 0.020
Read data: 9.059906005859375e-05
iter 4709 (epoch 7), train_loss = 2.948, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 4710 (epoch 7), train_loss = 2.818, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 4711 (epoch 7), train_loss = 2.878, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 4712 (epoch 7), train_loss = 3.121, time/batch = 0.021
Read data: 0.00010895729064941406
iter 4713 (epoch 7), train_loss = 2.477, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 4714 (epoch 7), train_loss = 2.825, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 4715 (epoch 7), train_loss = 3.134, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 4716 (epoch 7), train_loss = 3.312, time/batch = 0.035
Read data: 8.940696716308594e-05
iter 4717 (epoch 7), train_loss = 2.611, time/batch = 0.037
Read data: 8.940696716308594e-05
iter 4718 (epoch 7), train_loss = 2.609, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 4719 (epoch 7), train_loss = 3.188, time/batch = 0.026
Read data: 0.0001385211944580078
iter 4720 (epoch 7), train_loss = 2.865, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 4721 (epoch 7), train_loss = 2.698, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 4722 (epoch 7), train_loss = 2.981, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 4723 (epoch 7), train_loss = 3.041, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 4724 (epoch 7), train_loss = 2.906, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4725 (epoch 7), train_loss = 2.681, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 4726 (epoch 7), train_loss = 3.215, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 4727 (epoch 7), train_loss = 3.297, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 4728 (epoch 7), train_loss = 2.737, time/batch = 0.033
Read data: 9.250640869140625e-05
iter 4729 (epoch 7), train_loss = 3.010, time/batch = 0.033
Read data: 8.940696716308594e-05
iter 4730 (epoch 7), train_loss = 2.680, time/batch = 0.022
Read data: 8.392333984375e-05
iter 4731 (epoch 7), train_loss = 3.138, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 4732 (epoch 7), train_loss = 2.898, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 4733 (epoch 7), train_loss = 2.946, time/batch = 0.028
Read data: 0.00011706352233886719
iter 4734 (epoch 7), train_loss = 2.669, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 4735 (epoch 7), train_loss = 2.834, time/batch = 0.023
Read data: 8.392333984375e-05
iter 4736 (epoch 7), train_loss = 2.691, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 4737 (epoch 7), train_loss = 3.125, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 4738 (epoch 7), train_loss = 2.929, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 4739 (epoch 7), train_loss = 2.935, time/batch = 0.026
Read data: 0.000110626220703125
iter 4740 (epoch 7), train_loss = 3.057, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 4741 (epoch 7), train_loss = 2.691, time/batch = 0.026
Read data: 9.965896606445312e-05
iter 4742 (epoch 7), train_loss = 2.834, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4743 (epoch 7), train_loss = 2.655, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 4744 (epoch 7), train_loss = 2.992, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 4745 (epoch 7), train_loss = 2.927, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 4746 (epoch 7), train_loss = 2.861, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 4747 (epoch 7), train_loss = 2.877, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 4748 (epoch 7), train_loss = 2.464, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 4749 (epoch 7), train_loss = 3.056, time/batch = 0.027
Read data: 0.00018262863159179688
iter 4750 (epoch 7), train_loss = 2.971, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 4751 (epoch 7), train_loss = 2.659, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 4752 (epoch 7), train_loss = 2.697, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 4753 (epoch 7), train_loss = 2.917, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 4754 (epoch 7), train_loss = 2.812, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 4755 (epoch 7), train_loss = 3.180, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 4756 (epoch 7), train_loss = 2.706, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 4757 (epoch 7), train_loss = 2.946, time/batch = 0.024
Read data: 9.989738464355469e-05
iter 4758 (epoch 7), train_loss = 2.642, time/batch = 0.025
Read data: 0.00011134147644042969
iter 4759 (epoch 7), train_loss = 1.971, time/batch = 0.026
Read data: 0.00012969970703125
iter 4760 (epoch 7), train_loss = 3.166, time/batch = 0.030
Read data: 8.96453857421875e-05
iter 4761 (epoch 7), train_loss = 2.610, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4762 (epoch 7), train_loss = 2.978, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 4763 (epoch 7), train_loss = 2.933, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 4764 (epoch 7), train_loss = 2.920, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 4765 (epoch 7), train_loss = 2.653, time/batch = 0.029
Read data: 0.00010228157043457031
iter 4766 (epoch 7), train_loss = 2.559, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 4767 (epoch 7), train_loss = 3.001, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 4768 (epoch 7), train_loss = 2.903, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 4769 (epoch 7), train_loss = 2.727, time/batch = 0.020
Read data: 9.1552734375e-05
iter 4770 (epoch 7), train_loss = 2.365, time/batch = 0.025
Read data: 0.00010013580322265625
iter 4771 (epoch 7), train_loss = 2.831, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 4772 (epoch 7), train_loss = 2.631, time/batch = 0.027
Read data: 9.846687316894531e-05
iter 4773 (epoch 7), train_loss = 2.630, time/batch = 0.028
Read data: 9.775161743164062e-05
iter 4774 (epoch 7), train_loss = 2.993, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 4775 (epoch 7), train_loss = 2.696, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 4776 (epoch 7), train_loss = 2.912, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 4777 (epoch 7), train_loss = 2.690, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 4778 (epoch 7), train_loss = 2.612, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 4779 (epoch 7), train_loss = 2.925, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 4780 (epoch 7), train_loss = 2.782, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 4781 (epoch 7), train_loss = 3.133, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 4782 (epoch 7), train_loss = 2.883, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 4783 (epoch 7), train_loss = 3.074, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 4784 (epoch 7), train_loss = 3.057, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 4785 (epoch 7), train_loss = 2.510, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 4786 (epoch 7), train_loss = 2.650, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 4787 (epoch 7), train_loss = 2.663, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 4788 (epoch 7), train_loss = 2.678, time/batch = 0.023
Read data: 0.00010061264038085938
iter 4789 (epoch 7), train_loss = 2.696, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 4790 (epoch 7), train_loss = 2.779, time/batch = 0.030
Read data: 8.916854858398438e-05
iter 4791 (epoch 7), train_loss = 2.637, time/batch = 0.027
Read data: 0.0010874271392822266
iter 4792 (epoch 7), train_loss = 2.497, time/batch = 0.022
Read data: 9.989738464355469e-05
iter 4793 (epoch 7), train_loss = 2.857, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 4794 (epoch 7), train_loss = 2.809, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 4795 (epoch 7), train_loss = 3.117, time/batch = 0.037
Read data: 8.344650268554688e-05
iter 4796 (epoch 7), train_loss = 2.570, time/batch = 0.027
Read data: 0.00011658668518066406
iter 4797 (epoch 7), train_loss = 2.879, time/batch = 0.024
Read data: 0.0001404285430908203
iter 4798 (epoch 7), train_loss = 2.276, time/batch = 0.019
Read data: 7.963180541992188e-05
iter 4799 (epoch 7), train_loss = 2.723, time/batch = 0.025
Read data: 0.0001780986785888672
iter 4800 (epoch 7), train_loss = 2.814, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 4801 (epoch 8), train_loss = 2.971, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 4802 (epoch 8), train_loss = 3.095, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 4803 (epoch 8), train_loss = 2.867, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 4804 (epoch 8), train_loss = 2.296, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4805 (epoch 8), train_loss = 3.038, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 4806 (epoch 8), train_loss = 2.838, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 4807 (epoch 8), train_loss = 2.491, time/batch = 0.023
Read data: 0.00010395050048828125
iter 4808 (epoch 8), train_loss = 3.225, time/batch = 0.035
Read data: 8.130073547363281e-05
iter 4809 (epoch 8), train_loss = 2.922, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 4810 (epoch 8), train_loss = 3.195, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 4811 (epoch 8), train_loss = 2.847, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 4812 (epoch 8), train_loss = 2.731, time/batch = 0.027
Read data: 9.703636169433594e-05
iter 4813 (epoch 8), train_loss = 3.300, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 4814 (epoch 8), train_loss = 2.637, time/batch = 0.024
Read data: 9.1552734375e-05
iter 4815 (epoch 8), train_loss = 3.065, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 4816 (epoch 8), train_loss = 2.291, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 4817 (epoch 8), train_loss = 2.949, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 4818 (epoch 8), train_loss = 2.788, time/batch = 0.021
Read data: 9.417533874511719e-05
iter 4819 (epoch 8), train_loss = 2.478, time/batch = 0.023
Read data: 9.918212890625e-05
iter 4820 (epoch 8), train_loss = 2.687, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 4821 (epoch 8), train_loss = 3.011, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 4822 (epoch 8), train_loss = 2.993, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 4823 (epoch 8), train_loss = 3.128, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 4824 (epoch 8), train_loss = 2.732, time/batch = 0.024
Read data: 0.0001704692840576172
iter 4825 (epoch 8), train_loss = 2.870, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 4826 (epoch 8), train_loss = 3.032, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 4827 (epoch 8), train_loss = 2.675, time/batch = 0.023
Read data: 0.0001068115234375
iter 4828 (epoch 8), train_loss = 2.965, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 4829 (epoch 8), train_loss = 2.882, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 4830 (epoch 8), train_loss = 3.237, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 4831 (epoch 8), train_loss = 2.814, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 4832 (epoch 8), train_loss = 3.295, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 4833 (epoch 8), train_loss = 3.119, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 4834 (epoch 8), train_loss = 3.036, time/batch = 0.025
Read data: 8.392333984375e-05
iter 4835 (epoch 8), train_loss = 2.965, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 4836 (epoch 8), train_loss = 2.783, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 4837 (epoch 8), train_loss = 3.117, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 4838 (epoch 8), train_loss = 3.081, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 4839 (epoch 8), train_loss = 2.623, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 4840 (epoch 8), train_loss = 2.823, time/batch = 0.032
Read data: 8.606910705566406e-05
iter 4841 (epoch 8), train_loss = 2.587, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 4842 (epoch 8), train_loss = 2.786, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 4843 (epoch 8), train_loss = 2.937, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 4844 (epoch 8), train_loss = 2.852, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 4845 (epoch 8), train_loss = 2.309, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 4846 (epoch 8), train_loss = 2.874, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 4847 (epoch 8), train_loss = 3.352, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 4848 (epoch 8), train_loss = 2.827, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 4849 (epoch 8), train_loss = 2.818, time/batch = 0.024
Read data: 0.00016808509826660156
iter 4850 (epoch 8), train_loss = 2.655, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 4851 (epoch 8), train_loss = 2.642, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 4852 (epoch 8), train_loss = 2.912, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 4853 (epoch 8), train_loss = 3.307, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 4854 (epoch 8), train_loss = 2.571, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 4855 (epoch 8), train_loss = 2.516, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 4856 (epoch 8), train_loss = 3.104, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 4857 (epoch 8), train_loss = 2.588, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 4858 (epoch 8), train_loss = 2.776, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 4859 (epoch 8), train_loss = 3.143, time/batch = 0.034
Read data: 8.559226989746094e-05
iter 4860 (epoch 8), train_loss = 3.000, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 4861 (epoch 8), train_loss = 2.817, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 4862 (epoch 8), train_loss = 2.564, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 4863 (epoch 8), train_loss = 3.236, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 4864 (epoch 8), train_loss = 2.723, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 4865 (epoch 8), train_loss = 2.527, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 4866 (epoch 8), train_loss = 3.149, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 4867 (epoch 8), train_loss = 2.933, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 4868 (epoch 8), train_loss = 2.737, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 4869 (epoch 8), train_loss = 2.503, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 4870 (epoch 8), train_loss = 2.847, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 4871 (epoch 8), train_loss = 2.824, time/batch = 0.022
Read data: 0.00012135505676269531
iter 4872 (epoch 8), train_loss = 2.733, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 4873 (epoch 8), train_loss = 2.954, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 4874 (epoch 8), train_loss = 3.086, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 4875 (epoch 8), train_loss = 2.862, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 4876 (epoch 8), train_loss = 2.826, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 4877 (epoch 8), train_loss = 2.584, time/batch = 0.025
Read data: 0.00010824203491210938
iter 4878 (epoch 8), train_loss = 2.868, time/batch = 0.021
Read data: 8.869171142578125e-05
iter 4879 (epoch 8), train_loss = 2.731, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 4880 (epoch 8), train_loss = 2.545, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 4881 (epoch 8), train_loss = 3.257, time/batch = 0.036
Read data: 8.249282836914062e-05
iter 4882 (epoch 8), train_loss = 2.654, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 4883 (epoch 8), train_loss = 2.545, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 4884 (epoch 8), train_loss = 3.144, time/batch = 0.035
Read data: 9.202957153320312e-05
iter 4885 (epoch 8), train_loss = 3.079, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 4886 (epoch 8), train_loss = 3.076, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 4887 (epoch 8), train_loss = 2.775, time/batch = 0.030
Read data: 8.392333984375e-05
iter 4888 (epoch 8), train_loss = 3.023, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 4889 (epoch 8), train_loss = 2.547, time/batch = 0.022
Read data: 7.843971252441406e-05
iter 4890 (epoch 8), train_loss = 2.939, time/batch = 0.024
Read data: 9.799003601074219e-05
iter 4891 (epoch 8), train_loss = 2.596, time/batch = 0.020
Read data: 0.00015544891357421875
iter 4892 (epoch 8), train_loss = 2.959, time/batch = 0.025
Read data: 0.00010347366333007812
iter 4893 (epoch 8), train_loss = 3.036, time/batch = 0.033
Read data: 0.00010228157043457031
iter 4894 (epoch 8), train_loss = 2.626, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 4895 (epoch 8), train_loss = 3.084, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 4896 (epoch 8), train_loss = 2.650, time/batch = 0.037
Read data: 9.560585021972656e-05
iter 4897 (epoch 8), train_loss = 2.570, time/batch = 0.028
Read data: 0.00013637542724609375
iter 4898 (epoch 8), train_loss = 2.653, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 4899 (epoch 8), train_loss = 3.249, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 4900 (epoch 8), train_loss = 3.085, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 4901 (epoch 8), train_loss = 2.727, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 4902 (epoch 8), train_loss = 3.465, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 4903 (epoch 8), train_loss = 3.031, time/batch = 0.023
Read data: 0.00010156631469726562
iter 4904 (epoch 8), train_loss = 2.629, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 4905 (epoch 8), train_loss = 2.658, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 4906 (epoch 8), train_loss = 2.616, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 4907 (epoch 8), train_loss = 2.865, time/batch = 0.025
Read data: 9.1552734375e-05
iter 4908 (epoch 8), train_loss = 2.565, time/batch = 0.035
Read data: 7.987022399902344e-05
iter 4909 (epoch 8), train_loss = 2.809, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 4910 (epoch 8), train_loss = 3.147, time/batch = 0.036
Read data: 8.559226989746094e-05
iter 4911 (epoch 8), train_loss = 2.643, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 4912 (epoch 8), train_loss = 3.017, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 4913 (epoch 8), train_loss = 2.638, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 4914 (epoch 8), train_loss = 2.354, time/batch = 0.028
Read data: 0.00010180473327636719
iter 4915 (epoch 8), train_loss = 2.290, time/batch = 0.022
Read data: 9.298324584960938e-05
iter 4916 (epoch 8), train_loss = 2.798, time/batch = 0.033
Read data: 0.0001232624053955078
iter 4917 (epoch 8), train_loss = 2.642, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 4918 (epoch 8), train_loss = 2.952, time/batch = 0.024
Read data: 7.62939453125e-05
iter 4919 (epoch 8), train_loss = 2.748, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 4920 (epoch 8), train_loss = 2.826, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 4921 (epoch 8), train_loss = 2.560, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 4922 (epoch 8), train_loss = 2.449, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 4923 (epoch 8), train_loss = 2.436, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 4924 (epoch 8), train_loss = 3.097, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 4925 (epoch 8), train_loss = 2.832, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 4926 (epoch 8), train_loss = 3.116, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 4927 (epoch 8), train_loss = 2.930, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 4928 (epoch 8), train_loss = 2.858, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 4929 (epoch 8), train_loss = 2.855, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 4930 (epoch 8), train_loss = 2.683, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 4931 (epoch 8), train_loss = 2.962, time/batch = 0.027
Read data: 0.0001049041748046875
iter 4932 (epoch 8), train_loss = 3.029, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 4933 (epoch 8), train_loss = 3.071, time/batch = 0.034
Read data: 8.296966552734375e-05
iter 4934 (epoch 8), train_loss = 2.338, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 4935 (epoch 8), train_loss = 3.171, time/batch = 0.035
Read data: 7.796287536621094e-05
iter 4936 (epoch 8), train_loss = 2.876, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 4937 (epoch 8), train_loss = 2.563, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 4938 (epoch 8), train_loss = 2.401, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 4939 (epoch 8), train_loss = 2.644, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 4940 (epoch 8), train_loss = 2.897, time/batch = 0.029
Read data: 9.465217590332031e-05
iter 4941 (epoch 8), train_loss = 2.957, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 4942 (epoch 8), train_loss = 2.742, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 4943 (epoch 8), train_loss = 2.776, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 4944 (epoch 8), train_loss = 2.810, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 4945 (epoch 8), train_loss = 2.834, time/batch = 0.018
Read data: 8.988380432128906e-05
iter 4946 (epoch 8), train_loss = 2.786, time/batch = 0.026
Read data: 0.00011658668518066406
iter 4947 (epoch 8), train_loss = 2.789, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 4948 (epoch 8), train_loss = 3.185, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 4949 (epoch 8), train_loss = 2.265, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 4950 (epoch 8), train_loss = 2.756, time/batch = 0.034
Read data: 8.225440979003906e-05
iter 4951 (epoch 8), train_loss = 3.056, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 4952 (epoch 8), train_loss = 2.405, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 4953 (epoch 8), train_loss = 3.028, time/batch = 0.028
Read data: 7.581710815429688e-05
iter 4954 (epoch 8), train_loss = 2.828, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 4955 (epoch 8), train_loss = 2.895, time/batch = 0.032
Read data: 8.392333984375e-05
iter 4956 (epoch 8), train_loss = 2.967, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 4957 (epoch 8), train_loss = 2.639, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 4958 (epoch 8), train_loss = 3.363, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 4959 (epoch 8), train_loss = 2.542, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 4960 (epoch 8), train_loss = 2.636, time/batch = 0.032
Read data: 0.00011515617370605469
iter 4961 (epoch 8), train_loss = 2.690, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 4962 (epoch 8), train_loss = 2.920, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 4963 (epoch 8), train_loss = 2.808, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 4964 (epoch 8), train_loss = 3.059, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 4965 (epoch 8), train_loss = 3.215, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 4966 (epoch 8), train_loss = 2.741, time/batch = 0.030
Read data: 9.1552734375e-05
iter 4967 (epoch 8), train_loss = 3.139, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 4968 (epoch 8), train_loss = 2.947, time/batch = 0.021
Read data: 0.00010347366333007812
iter 4969 (epoch 8), train_loss = 2.598, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 4970 (epoch 8), train_loss = 2.603, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 4971 (epoch 8), train_loss = 3.006, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 4972 (epoch 8), train_loss = 2.493, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 4973 (epoch 8), train_loss = 3.126, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 4974 (epoch 8), train_loss = 2.742, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 4975 (epoch 8), train_loss = 2.715, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 4976 (epoch 8), train_loss = 3.134, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 4977 (epoch 8), train_loss = 2.699, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 4978 (epoch 8), train_loss = 2.763, time/batch = 0.028
Read data: 9.632110595703125e-05
iter 4979 (epoch 8), train_loss = 2.472, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 4980 (epoch 8), train_loss = 2.875, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 4981 (epoch 8), train_loss = 2.779, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 4982 (epoch 8), train_loss = 2.607, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 4983 (epoch 8), train_loss = 3.120, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 4984 (epoch 8), train_loss = 2.955, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 4985 (epoch 8), train_loss = 3.007, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 4986 (epoch 8), train_loss = 2.911, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 4987 (epoch 8), train_loss = 2.739, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 4988 (epoch 8), train_loss = 2.707, time/batch = 0.025
Read data: 9.655952453613281e-05
iter 4989 (epoch 8), train_loss = 2.657, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 4990 (epoch 8), train_loss = 2.656, time/batch = 0.023
Read data: 9.274482727050781e-05
iter 4991 (epoch 8), train_loss = 3.277, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 4992 (epoch 8), train_loss = 2.958, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 4993 (epoch 8), train_loss = 3.101, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 4994 (epoch 8), train_loss = 2.808, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 4995 (epoch 8), train_loss = 2.834, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 4996 (epoch 8), train_loss = 2.941, time/batch = 0.030
Read data: 8.797645568847656e-05
iter 4997 (epoch 8), train_loss = 2.911, time/batch = 0.023
Read data: 8.392333984375e-05
iter 4998 (epoch 8), train_loss = 2.995, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 4999 (epoch 8), train_loss = 3.129, time/batch = 0.023
image 976:     
image 5399:    
image 6910:      
image 660:     
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.909024)
image 2798:     
image 5884:    
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.467923)
image 6903:      
image 3301:    
image 2019:     
image 5535:    
image 7680:     
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.848261)
image 4604:     
image 5745:     
image 5288:    
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (3.016851)
image 2938:    
image 5183:     
image 2380:      
image 6973:     
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.711510)
image 4940:      
image 4905:    
image 469:      
image 102:    
image 6009:    
image 4271:     
image 6329:     
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (3.055137)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:    
evaluating validation preformance... 70/1000 (2.812196)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.887292)
image 3276:      
image 3812:     
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:     
image 1480:      
image 4806:      
image 766:    
evaluating validation preformance... 90/1000 (2.286451)
image 6124:     
image 5415:    
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (3.156134)
image 2800:    
image 7249:    
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (3.064707)
image 1122:     
image 509:    
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.620217)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:    UNK
image 4913:    
image 4589:    
image 5863:    
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (3.051226)
image 6214:     
image 429:     
image 7743:    
image 3657:    
image 4535:     
image 5542:     
image 8068:    UNK
image 4450:    
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.917794)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:    
image 197:    
image 519:      
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.125664)
image 1865:      
image 3830:    
image 360:      
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.970047)
image 4297:    
image 3315:     
image 1107:     
image 2051:     
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.764157)
image 7922:     
image 2353:     
image 4580:    
image 5905:      
image 6488:     
image 3000:    
image 1806:    
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.817360)
image 2313:    
image 6289:    
image 8084:     
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.715197)
image 5372:    
image 7529:    
image 875:    
image 2107:    
image 8015:     
image 6565:     
image 6174:     
image 6894:    
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.498954)
image 5159:    
image 1199:    
image 2456:     
image 3402:      
image 7631:     
image 3562:    
image 405:    
image 2532:     
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.674849)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:      
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.816038)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:     
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.566041)
image 1917:     
image 5844:      
image 1661:     
image 1510:     
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:     
image 5594:     
evaluating validation preformance... 240/1000 (2.438095)
image 7143:     
image 6019:     
image 885:     
image 2802:     
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.814092)
image 3028:    
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.677306)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:    
image 6211:     
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.076876)
image 833:     
image 5483:    
image 2476:      
image 5930:     
image 59:     
image 5007:     
image 2884:    
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.783655)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.762135)
image 6835:     
image 4698:     
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.359467)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:    
image 1974:     
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (3.026109)
image 3553:    
image 5971:     
image 122:    
image 3212:     
image 7223:    
image 7007:     
image 6064:    
image 7358:    
image 5096:     
image 6423:     
evaluating validation preformance... 320/1000 (2.641127)
image 489:     
image 5316:     
image 2613:      
image 7935:      
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.938490)
image 5179:    
image 3754:    
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    
image 3972:     
evaluating validation preformance... 340/1000 (2.693950)
image 4542:      
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:      
evaluating validation preformance... 350/1000 (2.815156)
image 6881:    
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.193977)
image 2905:    
image 7814:     
image 56:     
image 5034:    
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.800516)
image 4351:     
image 1054:    UNK
image 129:     
image 2849:    
image 725:    
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.903431)
image 2458:     
image 1084:     
image 4835:    
image 867:    
image 723:     
image 6255:     
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (3.028673)
image 828:    
image 2733:    
image 791:      
image 5408:    
image 7842:     
image 1117:      
image 5817:      
image 1231:     
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.474694)
image 2627:    
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:     
image 7546:     
evaluating validation preformance... 410/1000 (2.376669)
image 4359:     
image 2372:     
image 4472:     
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:    
evaluating validation preformance... 420/1000 (2.479409)
image 30:    
image 5540:    
image 2445:      
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:    
image 2408:    
image 7706:     
evaluating validation preformance... 430/1000 (3.023349)
image 385:     
image 6938:      
image 2381:    
image 5796:    
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (3.024333)
image 1731:      
image 978:    
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:    
image 5855:     
image 4245:      
image 973:    
evaluating validation preformance... 450/1000 (2.447019)
image 2241:     
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:    
image 3682:     
evaluating validation preformance... 460/1000 (3.012513)
image 7979:     
image 1618:    
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.445289)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    UNK
image 6114:      
evaluating validation preformance... 480/1000 (3.143786)
image 358:     
image 4663:    
image 5541:    
image 4485:    
image 2727:      
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.552925)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:    
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.750049)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.244973)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:     
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.859873)
image 6806:    
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.653483)
image 5619:     
image 4391:    
image 891:     
image 3072:    
image 7781:    
image 6163:     
image 7376:      
image 6034:    
image 6062:     
image 3170:    
evaluating validation preformance... 540/1000 (2.776968)
image 5292:      
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:     
image 4696:     
image 1183:      
image 1961:      
evaluating validation preformance... 550/1000 (2.874132)
image 5439:     
image 7981:    UNK
image 6012:    
image 4732:     
image 6630:    
image 994:    
image 5079:    
image 6169:    
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.852933)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK
image 7893:     
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.871240)
image 7936:     
image 5433:    
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.628397)
image 2135:      
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.828389)
image 4420:    
image 1734:    
image 7239:     
image 7447:    
image 8009:    
image 4510:     
image 7495:     
image 2530:      
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.854762)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:    
image 3253:    
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.995531)
image 69:     
image 3465:    
image 6179:     
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.727151)
image 6575:      
image 5695:    
image 7418:     
image 1948:     
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.639540)
image 8074:    
image 1904:    
image 7917:      
image 2394:     
image 4406:    UNK
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.713252)
image 5313:     
image 2377:     
image 6058:     
image 4661:     
image 2955:    
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:     
evaluating validation preformance... 650/1000 (2.800449)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:     
image 1639:     
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.872154)
image 5701:      
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:     
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (3.128020)
image 7877:    
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:    
image 7587:     
image 4848:    
image 6722:    UNK
image 7784:      
evaluating validation preformance... 680/1000 (3.261523)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:      
image 4382:     
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (3.120247)
image 6860:    
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:    
image 6225:    
image 3669:     
image 980:    
image 5362:      
evaluating validation preformance... 700/1000 (3.134351)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:    
image 650:     
image 4911:     
image 34:     
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.728702)
image 7368:     
image 709:     
image 3197:     
image 5214:    
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.799735)
image 5729:     
image 6395:      
image 516:    
image 1026:    
image 2972:      
image 3005:    
image 1241:    
image 2743:    
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.520629)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:    
image 997:     
image 5092:     
image 7789:     
image 2504:      
evaluating validation preformance... 740/1000 (2.664253)
image 2239:    
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (3.016276)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.164504)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:     
image 2452:     
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.422891)
image 6220:     
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:      
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.960644)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:      
image 3312:    
image 7824:      
image 2032:    
evaluating validation preformance... 790/1000 (3.445184)
image 5047:      
image 325:     
image 7626:    UNK
image 4552:     
image 983:    UNK
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.446007)
image 7288:     
image 7302:    
image 3055:    
image 5250:     
image 1158:     
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.627448)
image 614:    
image 7295:     
image 4110:     
image 5402:     
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (2.225289)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:     
image 7147:    
image 6348:    
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.630400)
image 5107:    
image 3973:    
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.609744)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:    
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (3.126284)
image 4404:    
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:     
image 6261:     
image 2166:      
evaluating validation preformance... 860/1000 (3.061748)
image 4254:    
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:     
image 4002:    
evaluating validation preformance... 870/1000 (2.569842)
image 4934:     
image 6487:     
image 4217:    
image 6355:     
image 2793:     
image 7201:     
image 5681:     
image 1824:     
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.808638)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (3.122854)
image 7485:     
image 6102:    
image 1001:    
image 7167:     
image 4168:     
image 187:    
image 7798:     
image 4813:    
image 7753:    UNK
image 210:    
evaluating validation preformance... 900/1000 (3.629520)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:      
image 4431:    
image 2801:     
image 2398:    
image 7205:     
evaluating validation preformance... 910/1000 (2.486738)
image 1368:     
image 1925:     
image 5870:     
image 4915:     
image 3879:     
image 1002:    
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.766980)
image 7152:    
image 4559:     
image 7233:    
image 1341:     
image 5337:      
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.710323)
image 5636:     
image 7799:     
image 6025:    
image 6907:      
image 2507:     
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.825239)
image 5860:     
image 3275:     
image 1935:     
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (3.289991)
image 1081:    
image 1179:     
image 4316:    
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.988696)
image 4935:     
image 1930:     
image 6850:    
image 5310:    
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.591053)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:    
image 7800:    
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.970520)
image 7352:     
image 5113:    
image 7822:    
image 4858:    
image 658:     
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.677049)
image 5789:      
image 5606:     
image 6107:     
image 7976:    
image 3890:    
image 5901:     
image 1163:    
image 2483:    
image 2591:     
image 7615:    
evaluating validation preformance... 1000/1000 (2.580564)
average loss on validation: 2.827
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3103396892547607
Cider scores: 0.43875076218795833
Read data: 0.2579495906829834
Cider scores: 0.4933834282164108
Read data: 0.23221921920776367
Cider scores: 0.4809181148493017
Read data: 0.27306175231933594
Cider scores: 0.3514533922390478
Read data: 0.2057650089263916
Cider scores: 0.40269919825811
Read data: 0.20068097114562988
Cider scores: 0.39288169436025727
Read data: 0.21881937980651855
Cider scores: 0.4040944769653396
Read data: 0.1783616542816162
Cider scores: 0.4469354225198612
Read data: 0.17096662521362305
Cider scores: 0.4058126974158432
Read data: 0.18674683570861816
Cider scores: 0.5101934063825587
Read data: 0.23587989807128906
Cider scores: 0.4382329553004441
Read data: 0.1783912181854248
Cider scores: 0.42170170467560686
Read data: 0.17798161506652832
Cider scores: 0.4656261038143048
Read data: 0.17331910133361816
Cider scores: 0.4276590648044178
Read data: 0.17802643775939941
Cider scores: 0.5416359636055416
Read data: 0.1693129539489746
Cider scores: 0.5151581562832397
Read data: 0.16435790061950684
Cider scores: 0.3927326058369033
Read data: 0.16245603561401367
Cider scores: 0.5531520816938723
Read data: 0.17371320724487305
Cider scores: 0.47754896806588076
Read data: 0.16140460968017578
Cider scores: 0.524499869272863
Average cider score on test set: 0.454
End calculating cider score on TEST data set
===============================================
Read data: 0.16155433654785156
iter 5000 (epoch 8), train_loss = 2.823, time/batch = 0.027
Read data: 0.00012445449829101562
iter 5001 (epoch 8), train_loss = 2.578, time/batch = 0.028
Read data: 0.00014328956604003906
iter 5002 (epoch 8), train_loss = 3.183, time/batch = 0.023
Read data: 0.00015425682067871094
iter 5003 (epoch 8), train_loss = 2.780, time/batch = 0.023
Read data: 0.00014781951904296875
iter 5004 (epoch 8), train_loss = 2.451, time/batch = 0.036
Read data: 0.00015044212341308594
iter 5005 (epoch 8), train_loss = 2.828, time/batch = 0.035
Read data: 0.00012564659118652344
iter 5006 (epoch 8), train_loss = 2.833, time/batch = 0.029
Read data: 0.00012540817260742188
iter 5007 (epoch 8), train_loss = 2.286, time/batch = 0.026
Read data: 0.00022912025451660156
iter 5008 (epoch 8), train_loss = 2.683, time/batch = 0.030
Read data: 0.00010585784912109375
iter 5009 (epoch 8), train_loss = 3.276, time/batch = 0.031
Read data: 0.0001823902130126953
iter 5010 (epoch 8), train_loss = 2.996, time/batch = 0.025
Read data: 0.00012421607971191406
iter 5011 (epoch 8), train_loss = 2.572, time/batch = 0.028
Read data: 0.00010919570922851562
iter 5012 (epoch 8), train_loss = 2.851, time/batch = 0.027
Read data: 0.00011181831359863281
iter 5013 (epoch 8), train_loss = 3.236, time/batch = 0.042
Read data: 0.00013494491577148438
iter 5014 (epoch 8), train_loss = 2.887, time/batch = 0.026
Read data: 0.00012493133544921875
iter 5015 (epoch 8), train_loss = 2.912, time/batch = 0.033
Read data: 9.632110595703125e-05
iter 5016 (epoch 8), train_loss = 2.400, time/batch = 0.029
Read data: 0.00013184547424316406
iter 5017 (epoch 8), train_loss = 3.176, time/batch = 0.033
Read data: 0.00011444091796875
iter 5018 (epoch 8), train_loss = 2.889, time/batch = 0.036
Read data: 8.344650268554688e-05
iter 5019 (epoch 8), train_loss = 2.290, time/batch = 0.026
Read data: 0.00011563301086425781
iter 5020 (epoch 8), train_loss = 2.502, time/batch = 0.031
Read data: 0.00011467933654785156
iter 5021 (epoch 8), train_loss = 2.433, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 5022 (epoch 8), train_loss = 2.739, time/batch = 0.024
Read data: 0.0025238990783691406
iter 5023 (epoch 8), train_loss = 3.016, time/batch = 0.023
Read data: 0.00010967254638671875
iter 5024 (epoch 8), train_loss = 2.680, time/batch = 0.023
Read data: 0.0002675056457519531
iter 5025 (epoch 8), train_loss = 2.796, time/batch = 0.023
Read data: 0.00010251998901367188
iter 5026 (epoch 8), train_loss = 3.058, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 5027 (epoch 8), train_loss = 3.088, time/batch = 0.035
Read data: 8.797645568847656e-05
iter 5028 (epoch 8), train_loss = 2.982, time/batch = 0.030
Read data: 0.0001628398895263672
iter 5029 (epoch 8), train_loss = 2.913, time/batch = 0.023
Read data: 0.00014400482177734375
iter 5030 (epoch 8), train_loss = 2.760, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 5031 (epoch 8), train_loss = 2.892, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 5032 (epoch 8), train_loss = 2.758, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 5033 (epoch 8), train_loss = 2.529, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 5034 (epoch 8), train_loss = 2.346, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 5035 (epoch 8), train_loss = 2.712, time/batch = 0.021
Read data: 9.703636169433594e-05
iter 5036 (epoch 8), train_loss = 2.818, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 5037 (epoch 8), train_loss = 2.752, time/batch = 0.032
Read data: 9.083747863769531e-05
iter 5038 (epoch 8), train_loss = 2.680, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 5039 (epoch 8), train_loss = 3.162, time/batch = 0.022
Read data: 0.00013589859008789062
iter 5040 (epoch 8), train_loss = 2.697, time/batch = 0.035
Read data: 8.392333984375e-05
iter 5041 (epoch 8), train_loss = 3.115, time/batch = 0.024
Read data: 0.0001010894775390625
iter 5042 (epoch 8), train_loss = 2.534, time/batch = 0.030
Read data: 0.0001461505889892578
iter 5043 (epoch 8), train_loss = 2.538, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 5044 (epoch 8), train_loss = 2.946, time/batch = 0.022
Read data: 9.894371032714844e-05
iter 5045 (epoch 8), train_loss = 2.487, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 5046 (epoch 8), train_loss = 2.796, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 5047 (epoch 8), train_loss = 2.404, time/batch = 0.023
Read data: 0.0001399517059326172
iter 5048 (epoch 8), train_loss = 2.429, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 5049 (epoch 8), train_loss = 2.825, time/batch = 0.030
Read data: 0.00023412704467773438
iter 5050 (epoch 8), train_loss = 2.751, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 5051 (epoch 8), train_loss = 2.539, time/batch = 0.022
Read data: 0.00013208389282226562
iter 5052 (epoch 8), train_loss = 2.514, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 5053 (epoch 8), train_loss = 2.511, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 5054 (epoch 8), train_loss = 2.668, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 5055 (epoch 8), train_loss = 3.215, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 5056 (epoch 8), train_loss = 2.689, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 5057 (epoch 8), train_loss = 2.596, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 5058 (epoch 8), train_loss = 3.142, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 5059 (epoch 8), train_loss = 3.129, time/batch = 0.027
Read data: 0.0001366138458251953
iter 5060 (epoch 8), train_loss = 2.833, time/batch = 0.028
Read data: 8.392333984375e-05
iter 5061 (epoch 8), train_loss = 2.437, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 5062 (epoch 8), train_loss = 2.639, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 5063 (epoch 8), train_loss = 2.953, time/batch = 0.035
Read data: 9.512901306152344e-05
iter 5064 (epoch 8), train_loss = 2.820, time/batch = 0.033
Read data: 0.0001342296600341797
iter 5065 (epoch 8), train_loss = 2.761, time/batch = 0.030
Read data: 7.557868957519531e-05
iter 5066 (epoch 8), train_loss = 2.434, time/batch = 0.020
Read data: 8.0108642578125e-05
iter 5067 (epoch 8), train_loss = 2.720, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 5068 (epoch 8), train_loss = 2.702, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 5069 (epoch 8), train_loss = 3.057, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 5070 (epoch 8), train_loss = 2.754, time/batch = 0.024
Read data: 0.00010752677917480469
iter 5071 (epoch 8), train_loss = 2.508, time/batch = 0.026
Read data: 0.00013589859008789062
iter 5072 (epoch 8), train_loss = 2.682, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 5073 (epoch 8), train_loss = 2.782, time/batch = 0.030
Read data: 9.441375732421875e-05
iter 5074 (epoch 8), train_loss = 2.642, time/batch = 0.021
Read data: 0.0017788410186767578
iter 5075 (epoch 8), train_loss = 2.844, time/batch = 0.020
Read data: 0.00012946128845214844
iter 5076 (epoch 8), train_loss = 2.730, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 5077 (epoch 8), train_loss = 2.913, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 5078 (epoch 8), train_loss = 2.581, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 5079 (epoch 8), train_loss = 2.488, time/batch = 0.027
Read data: 9.918212890625e-05
iter 5080 (epoch 8), train_loss = 2.715, time/batch = 0.026
Read data: 0.00010156631469726562
iter 5081 (epoch 8), train_loss = 2.308, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 5082 (epoch 8), train_loss = 2.603, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 5083 (epoch 8), train_loss = 2.871, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 5084 (epoch 8), train_loss = 2.346, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 5085 (epoch 8), train_loss = 2.478, time/batch = 0.024
Read data: 0.0001518726348876953
iter 5086 (epoch 8), train_loss = 3.090, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 5087 (epoch 8), train_loss = 2.592, time/batch = 0.024
Read data: 0.0001049041748046875
iter 5088 (epoch 8), train_loss = 3.045, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 5089 (epoch 8), train_loss = 3.001, time/batch = 0.030
Read data: 9.5367431640625e-05
iter 5090 (epoch 8), train_loss = 3.307, time/batch = 0.031
Read data: 0.00011205673217773438
iter 5091 (epoch 8), train_loss = 2.993, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 5092 (epoch 8), train_loss = 2.876, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 5093 (epoch 8), train_loss = 2.598, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 5094 (epoch 8), train_loss = 3.103, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 5095 (epoch 8), train_loss = 3.216, time/batch = 0.030
Read data: 0.0001456737518310547
iter 5096 (epoch 8), train_loss = 3.002, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 5097 (epoch 8), train_loss = 2.989, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5098 (epoch 8), train_loss = 2.878, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 5099 (epoch 8), train_loss = 3.093, time/batch = 0.026
Read data: 0.00022363662719726562
iter 5100 (epoch 8), train_loss = 3.169, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 5101 (epoch 8), train_loss = 2.942, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 5102 (epoch 8), train_loss = 2.499, time/batch = 0.033
Read data: 7.939338684082031e-05
iter 5103 (epoch 8), train_loss = 3.024, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 5104 (epoch 8), train_loss = 2.409, time/batch = 0.027
Read data: 0.00013446807861328125
iter 5105 (epoch 8), train_loss = 3.179, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 5106 (epoch 8), train_loss = 2.524, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 5107 (epoch 8), train_loss = 2.934, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 5108 (epoch 8), train_loss = 3.171, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 5109 (epoch 8), train_loss = 3.088, time/batch = 0.020
Read data: 8.96453857421875e-05
iter 5110 (epoch 8), train_loss = 3.021, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 5111 (epoch 8), train_loss = 2.849, time/batch = 0.030
Read data: 9.298324584960938e-05
iter 5112 (epoch 8), train_loss = 2.973, time/batch = 0.028
Read data: 9.965896606445312e-05
iter 5113 (epoch 8), train_loss = 2.349, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 5114 (epoch 8), train_loss = 2.620, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 5115 (epoch 8), train_loss = 2.573, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 5116 (epoch 8), train_loss = 2.895, time/batch = 0.022
Read data: 9.894371032714844e-05
iter 5117 (epoch 8), train_loss = 3.107, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 5118 (epoch 8), train_loss = 3.046, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 5119 (epoch 8), train_loss = 2.261, time/batch = 0.024
Read data: 0.00013375282287597656
iter 5120 (epoch 8), train_loss = 2.603, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 5121 (epoch 8), train_loss = 3.216, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 5122 (epoch 8), train_loss = 2.454, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 5123 (epoch 8), train_loss = 3.206, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 5124 (epoch 8), train_loss = 2.834, time/batch = 0.027
Read data: 0.00021219253540039062
iter 5125 (epoch 8), train_loss = 2.288, time/batch = 0.024
Read data: 0.0001010894775390625
iter 5126 (epoch 8), train_loss = 2.852, time/batch = 0.024
Read data: 0.00010466575622558594
iter 5127 (epoch 8), train_loss = 3.412, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 5128 (epoch 8), train_loss = 2.626, time/batch = 0.020
Read data: 9.012222290039062e-05
iter 5129 (epoch 8), train_loss = 2.708, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 5130 (epoch 8), train_loss = 3.034, time/batch = 0.028
Read data: 0.0001239776611328125
iter 5131 (epoch 8), train_loss = 2.422, time/batch = 0.028
Read data: 0.00011849403381347656
iter 5132 (epoch 8), train_loss = 2.712, time/batch = 0.022
Read data: 0.0001456737518310547
iter 5133 (epoch 8), train_loss = 2.924, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 5134 (epoch 8), train_loss = 2.723, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 5135 (epoch 8), train_loss = 2.916, time/batch = 0.023
Read data: 0.00014543533325195312
iter 5136 (epoch 8), train_loss = 3.057, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 5137 (epoch 8), train_loss = 2.647, time/batch = 0.026
Read data: 0.0001316070556640625
iter 5138 (epoch 8), train_loss = 3.045, time/batch = 0.026
Read data: 0.000141143798828125
iter 5139 (epoch 8), train_loss = 3.036, time/batch = 0.023
Read data: 0.00010657310485839844
iter 5140 (epoch 8), train_loss = 2.854, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 5141 (epoch 8), train_loss = 2.884, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 5142 (epoch 8), train_loss = 2.535, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 5143 (epoch 8), train_loss = 2.579, time/batch = 0.022
Read data: 9.608268737792969e-05
iter 5144 (epoch 8), train_loss = 2.447, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 5145 (epoch 8), train_loss = 2.633, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 5146 (epoch 8), train_loss = 2.515, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 5147 (epoch 8), train_loss = 3.142, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 5148 (epoch 8), train_loss = 2.318, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 5149 (epoch 8), train_loss = 2.727, time/batch = 0.026
Read data: 0.0002467632293701172
iter 5150 (epoch 8), train_loss = 2.695, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 5151 (epoch 8), train_loss = 3.039, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 5152 (epoch 8), train_loss = 2.649, time/batch = 0.021
Read data: 9.918212890625e-05
iter 5153 (epoch 8), train_loss = 2.780, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 5154 (epoch 8), train_loss = 2.773, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 5155 (epoch 8), train_loss = 2.796, time/batch = 0.024
Read data: 0.0001392364501953125
iter 5156 (epoch 8), train_loss = 2.455, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 5157 (epoch 8), train_loss = 2.403, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 5158 (epoch 8), train_loss = 2.968, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 5159 (epoch 8), train_loss = 2.904, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 5160 (epoch 8), train_loss = 2.984, time/batch = 0.024
Read data: 0.00013256072998046875
iter 5161 (epoch 8), train_loss = 2.529, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 5162 (epoch 8), train_loss = 2.584, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 5163 (epoch 8), train_loss = 2.544, time/batch = 0.026
Read data: 9.965896606445312e-05
iter 5164 (epoch 8), train_loss = 2.776, time/batch = 0.022
Read data: 0.00013518333435058594
iter 5165 (epoch 8), train_loss = 2.617, time/batch = 0.025
Read data: 0.0001647472381591797
iter 5166 (epoch 8), train_loss = 2.911, time/batch = 0.028
Read data: 9.942054748535156e-05
iter 5167 (epoch 8), train_loss = 2.563, time/batch = 0.022
Read data: 9.465217590332031e-05
iter 5168 (epoch 8), train_loss = 3.010, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 5169 (epoch 8), train_loss = 2.709, time/batch = 0.026
Read data: 0.00016808509826660156
iter 5170 (epoch 8), train_loss = 2.765, time/batch = 0.033
Read data: 9.179115295410156e-05
iter 5171 (epoch 8), train_loss = 2.837, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5172 (epoch 8), train_loss = 2.959, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 5173 (epoch 8), train_loss = 2.688, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5174 (epoch 8), train_loss = 2.935, time/batch = 0.025
Read data: 0.0001895427703857422
iter 5175 (epoch 8), train_loss = 3.151, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 5176 (epoch 8), train_loss = 2.761, time/batch = 0.033
Read data: 8.153915405273438e-05
iter 5177 (epoch 8), train_loss = 2.738, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 5178 (epoch 8), train_loss = 3.125, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 5179 (epoch 8), train_loss = 3.147, time/batch = 0.028
Read data: 8.392333984375e-05
iter 5180 (epoch 8), train_loss = 2.633, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 5181 (epoch 8), train_loss = 2.788, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 5182 (epoch 8), train_loss = 2.790, time/batch = 0.024
Read data: 0.00013375282287597656
iter 5183 (epoch 8), train_loss = 2.861, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 5184 (epoch 8), train_loss = 3.157, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 5185 (epoch 8), train_loss = 2.893, time/batch = 0.022
Read data: 8.034706115722656e-05
iter 5186 (epoch 8), train_loss = 2.749, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 5187 (epoch 8), train_loss = 2.717, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 5188 (epoch 8), train_loss = 2.731, time/batch = 0.020
Read data: 9.179115295410156e-05
iter 5189 (epoch 8), train_loss = 2.835, time/batch = 0.023
Read data: 0.00010824203491210938
iter 5190 (epoch 8), train_loss = 3.119, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 5191 (epoch 8), train_loss = 3.048, time/batch = 0.024
Read data: 0.00013899803161621094
iter 5192 (epoch 8), train_loss = 2.874, time/batch = 0.025
Read data: 0.00010538101196289062
iter 5193 (epoch 8), train_loss = 3.150, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 5194 (epoch 8), train_loss = 2.850, time/batch = 0.030
Read data: 0.00010538101196289062
iter 5195 (epoch 8), train_loss = 3.277, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 5196 (epoch 8), train_loss = 3.235, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 5197 (epoch 8), train_loss = 2.660, time/batch = 0.021
Read data: 9.298324584960938e-05
iter 5198 (epoch 8), train_loss = 2.377, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 5199 (epoch 8), train_loss = 2.887, time/batch = 0.023
Read data: 0.00030231475830078125
iter 5200 (epoch 8), train_loss = 3.008, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 5201 (epoch 8), train_loss = 3.110, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 5202 (epoch 8), train_loss = 3.011, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 5203 (epoch 8), train_loss = 2.790, time/batch = 0.021
Read data: 9.989738464355469e-05
iter 5204 (epoch 8), train_loss = 2.771, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 5205 (epoch 8), train_loss = 2.871, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 5206 (epoch 8), train_loss = 2.744, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 5207 (epoch 8), train_loss = 2.774, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 5208 (epoch 8), train_loss = 2.921, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 5209 (epoch 8), train_loss = 2.995, time/batch = 0.022
Read data: 9.918212890625e-05
iter 5210 (epoch 8), train_loss = 2.607, time/batch = 0.028
Read data: 9.965896606445312e-05
iter 5211 (epoch 8), train_loss = 2.788, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 5212 (epoch 8), train_loss = 2.947, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 5213 (epoch 8), train_loss = 2.721, time/batch = 0.024
Read data: 7.581710815429688e-05
iter 5214 (epoch 8), train_loss = 2.290, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 5215 (epoch 8), train_loss = 2.548, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 5216 (epoch 8), train_loss = 3.011, time/batch = 0.020
Read data: 0.00010919570922851562
iter 5217 (epoch 8), train_loss = 2.956, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 5218 (epoch 8), train_loss = 2.964, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 5219 (epoch 8), train_loss = 3.226, time/batch = 0.039
Read data: 8.654594421386719e-05
iter 5220 (epoch 8), train_loss = 2.854, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 5221 (epoch 8), train_loss = 2.811, time/batch = 0.021
Read data: 8.177757263183594e-05
iter 5222 (epoch 8), train_loss = 2.640, time/batch = 0.022
Read data: 7.843971252441406e-05
iter 5223 (epoch 8), train_loss = 2.725, time/batch = 0.021
Read data: 0.00014400482177734375
iter 5224 (epoch 8), train_loss = 2.294, time/batch = 0.023
Read data: 0.0002148151397705078
iter 5225 (epoch 8), train_loss = 2.770, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 5226 (epoch 8), train_loss = 2.856, time/batch = 0.025
Read data: 8.392333984375e-05
iter 5227 (epoch 8), train_loss = 2.911, time/batch = 0.027
Read data: 0.00012731552124023438
iter 5228 (epoch 8), train_loss = 2.661, time/batch = 0.025
Read data: 0.00014162063598632812
iter 5229 (epoch 8), train_loss = 3.025, time/batch = 0.034
Read data: 9.5367431640625e-05
iter 5230 (epoch 8), train_loss = 3.066, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 5231 (epoch 8), train_loss = 2.332, time/batch = 0.024
Read data: 9.512901306152344e-05
iter 5232 (epoch 8), train_loss = 2.991, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 5233 (epoch 8), train_loss = 2.910, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 5234 (epoch 8), train_loss = 2.795, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 5235 (epoch 8), train_loss = 3.084, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 5236 (epoch 8), train_loss = 3.085, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 5237 (epoch 8), train_loss = 2.837, time/batch = 0.028
Read data: 0.00010251998901367188
iter 5238 (epoch 8), train_loss = 2.870, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 5239 (epoch 8), train_loss = 2.995, time/batch = 0.027
Read data: 0.00012636184692382812
iter 5240 (epoch 8), train_loss = 2.967, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5241 (epoch 8), train_loss = 2.965, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 5242 (epoch 8), train_loss = 2.596, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 5243 (epoch 8), train_loss = 3.153, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 5244 (epoch 8), train_loss = 2.796, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 5245 (epoch 8), train_loss = 3.026, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 5246 (epoch 8), train_loss = 3.114, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 5247 (epoch 8), train_loss = 2.807, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 5248 (epoch 8), train_loss = 2.557, time/batch = 0.021
Read data: 0.00010180473327636719
iter 5249 (epoch 8), train_loss = 3.006, time/batch = 0.024
Read data: 0.0002753734588623047
iter 5250 (epoch 8), train_loss = 2.846, time/batch = 0.026
Read data: 7.510185241699219e-05
iter 5251 (epoch 8), train_loss = 2.456, time/batch = 0.024
Read data: 0.0001327991485595703
iter 5252 (epoch 8), train_loss = 2.650, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 5253 (epoch 8), train_loss = 2.711, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 5254 (epoch 8), train_loss = 2.546, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 5255 (epoch 8), train_loss = 2.444, time/batch = 0.023
Read data: 0.00013375282287597656
iter 5256 (epoch 8), train_loss = 2.939, time/batch = 0.035
Read data: 8.225440979003906e-05
iter 5257 (epoch 8), train_loss = 2.756, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 5258 (epoch 8), train_loss = 2.343, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 5259 (epoch 8), train_loss = 2.715, time/batch = 0.026
Read data: 0.00011324882507324219
iter 5260 (epoch 8), train_loss = 3.180, time/batch = 0.030
Read data: 9.417533874511719e-05
iter 5261 (epoch 8), train_loss = 3.139, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 5262 (epoch 8), train_loss = 2.981, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 5263 (epoch 8), train_loss = 2.542, time/batch = 0.023
Read data: 0.00013065338134765625
iter 5264 (epoch 8), train_loss = 2.955, time/batch = 0.021
Read data: 9.608268737792969e-05
iter 5265 (epoch 8), train_loss = 2.861, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 5266 (epoch 8), train_loss = 3.239, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 5267 (epoch 8), train_loss = 3.104, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 5268 (epoch 8), train_loss = 3.074, time/batch = 0.026
Read data: 0.00010561943054199219
iter 5269 (epoch 8), train_loss = 2.960, time/batch = 0.023
Read data: 0.00011682510375976562
iter 5270 (epoch 8), train_loss = 2.657, time/batch = 0.027
Read data: 7.653236389160156e-05
iter 5271 (epoch 8), train_loss = 2.559, time/batch = 0.023
Read data: 0.00010085105895996094
iter 5272 (epoch 8), train_loss = 2.857, time/batch = 0.023
Read data: 0.0001392364501953125
iter 5273 (epoch 8), train_loss = 2.917, time/batch = 0.028
Read data: 0.00010204315185546875
iter 5274 (epoch 8), train_loss = 3.394, time/batch = 0.022
Read data: 0.00019598007202148438
iter 5275 (epoch 8), train_loss = 2.726, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 5276 (epoch 8), train_loss = 2.754, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 5277 (epoch 8), train_loss = 2.842, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 5278 (epoch 8), train_loss = 3.255, time/batch = 0.027
Read data: 7.62939453125e-05
iter 5279 (epoch 8), train_loss = 3.401, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 5280 (epoch 8), train_loss = 3.174, time/batch = 0.026
Read data: 0.0001227855682373047
iter 5281 (epoch 8), train_loss = 3.083, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5282 (epoch 8), train_loss = 2.823, time/batch = 0.018
Read data: 8.845329284667969e-05
iter 5283 (epoch 8), train_loss = 2.638, time/batch = 0.028
Read data: 0.00014352798461914062
iter 5284 (epoch 8), train_loss = 3.153, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 5285 (epoch 8), train_loss = 2.856, time/batch = 0.029
Read data: 9.846687316894531e-05
iter 5286 (epoch 8), train_loss = 2.664, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 5287 (epoch 8), train_loss = 3.051, time/batch = 0.025
Read data: 0.00018548965454101562
iter 5288 (epoch 8), train_loss = 2.968, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 5289 (epoch 8), train_loss = 3.288, time/batch = 0.024
Read data: 7.62939453125e-05
iter 5290 (epoch 8), train_loss = 2.857, time/batch = 0.020
Read data: 8.96453857421875e-05
iter 5291 (epoch 8), train_loss = 2.764, time/batch = 0.023
Read data: 0.0001361370086669922
iter 5292 (epoch 8), train_loss = 2.692, time/batch = 0.026
Read data: 0.00013899803161621094
iter 5293 (epoch 8), train_loss = 2.556, time/batch = 0.023
Read data: 8.535385131835938e-05
iter 5294 (epoch 8), train_loss = 2.684, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 5295 (epoch 8), train_loss = 2.541, time/batch = 0.027
Read data: 0.00013899803161621094
iter 5296 (epoch 8), train_loss = 2.423, time/batch = 0.024
Read data: 0.00013828277587890625
iter 5297 (epoch 8), train_loss = 2.927, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 5298 (epoch 8), train_loss = 2.999, time/batch = 0.029
Read data: 7.557868957519531e-05
iter 5299 (epoch 8), train_loss = 2.919, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 5300 (epoch 8), train_loss = 2.898, time/batch = 0.023
Read data: 0.0001354217529296875
iter 5301 (epoch 8), train_loss = 2.652, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 5302 (epoch 8), train_loss = 3.182, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 5303 (epoch 8), train_loss = 2.506, time/batch = 0.024
Read data: 0.00013709068298339844
iter 5304 (epoch 8), train_loss = 2.492, time/batch = 0.026
Read data: 0.0017521381378173828
iter 5305 (epoch 8), train_loss = 2.636, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 5306 (epoch 8), train_loss = 2.627, time/batch = 0.032
Read data: 0.00011992454528808594
iter 5307 (epoch 8), train_loss = 2.503, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 5308 (epoch 8), train_loss = 2.867, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 5309 (epoch 8), train_loss = 3.259, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 5310 (epoch 8), train_loss = 2.478, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 5311 (epoch 8), train_loss = 2.520, time/batch = 0.023
Read data: 0.00013637542724609375
iter 5312 (epoch 8), train_loss = 2.635, time/batch = 0.023
Read data: 0.0001361370086669922
iter 5313 (epoch 8), train_loss = 2.636, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 5314 (epoch 8), train_loss = 2.657, time/batch = 0.026
Read data: 0.0001399517059326172
iter 5315 (epoch 8), train_loss = 3.000, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 5316 (epoch 8), train_loss = 2.922, time/batch = 0.025
Read data: 0.0001430511474609375
iter 5317 (epoch 8), train_loss = 2.580, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 5318 (epoch 8), train_loss = 2.420, time/batch = 0.028
Read data: 0.00013589859008789062
iter 5319 (epoch 8), train_loss = 2.939, time/batch = 0.026
Read data: 0.0001385211944580078
iter 5320 (epoch 8), train_loss = 2.542, time/batch = 0.022
Read data: 0.0001049041748046875
iter 5321 (epoch 8), train_loss = 2.538, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 5322 (epoch 8), train_loss = 2.802, time/batch = 0.028
Read data: 9.465217590332031e-05
iter 5323 (epoch 8), train_loss = 3.026, time/batch = 0.028
Read data: 0.0001342296600341797
iter 5324 (epoch 8), train_loss = 3.073, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 5325 (epoch 8), train_loss = 2.944, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 5326 (epoch 8), train_loss = 2.715, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 5327 (epoch 8), train_loss = 2.550, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 5328 (epoch 8), train_loss = 2.947, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 5329 (epoch 8), train_loss = 2.700, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 5330 (epoch 8), train_loss = 2.767, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 5331 (epoch 8), train_loss = 2.761, time/batch = 0.026
Read data: 0.00011539459228515625
iter 5332 (epoch 8), train_loss = 2.619, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 5333 (epoch 8), train_loss = 2.986, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 5334 (epoch 8), train_loss = 2.912, time/batch = 0.024
Read data: 0.00017833709716796875
iter 5335 (epoch 8), train_loss = 2.996, time/batch = 0.025
Read data: 0.00012803077697753906
iter 5336 (epoch 8), train_loss = 2.958, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 5337 (epoch 8), train_loss = 2.561, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 5338 (epoch 8), train_loss = 2.534, time/batch = 0.021
Read data: 0.0001609325408935547
iter 5339 (epoch 8), train_loss = 3.152, time/batch = 0.025
Read data: 0.00013828277587890625
iter 5340 (epoch 8), train_loss = 2.692, time/batch = 0.028
Read data: 0.0001392364501953125
iter 5341 (epoch 8), train_loss = 2.715, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 5342 (epoch 8), train_loss = 2.437, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 5343 (epoch 8), train_loss = 2.783, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 5344 (epoch 8), train_loss = 2.604, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 5345 (epoch 8), train_loss = 2.847, time/batch = 0.024
Read data: 9.1552734375e-05
iter 5346 (epoch 8), train_loss = 3.279, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 5347 (epoch 8), train_loss = 2.776, time/batch = 0.030
Read data: 8.392333984375e-05
iter 5348 (epoch 8), train_loss = 2.497, time/batch = 0.021
Read data: 0.0001323223114013672
iter 5349 (epoch 8), train_loss = 2.457, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 5350 (epoch 8), train_loss = 2.930, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5351 (epoch 8), train_loss = 2.694, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 5352 (epoch 8), train_loss = 2.944, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 5353 (epoch 8), train_loss = 2.944, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 5354 (epoch 8), train_loss = 2.697, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 5355 (epoch 8), train_loss = 3.139, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 5356 (epoch 8), train_loss = 2.685, time/batch = 0.020
Read data: 0.0001125335693359375
iter 5357 (epoch 8), train_loss = 2.417, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 5358 (epoch 8), train_loss = 3.021, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 5359 (epoch 8), train_loss = 2.762, time/batch = 0.026
Read data: 0.00013518333435058594
iter 5360 (epoch 8), train_loss = 2.495, time/batch = 0.027
Read data: 0.0001163482666015625
iter 5361 (epoch 8), train_loss = 2.481, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 5362 (epoch 8), train_loss = 2.510, time/batch = 0.022
Read data: 7.390975952148438e-05
iter 5363 (epoch 8), train_loss = 2.684, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 5364 (epoch 8), train_loss = 2.620, time/batch = 0.026
Read data: 0.00010013580322265625
iter 5365 (epoch 8), train_loss = 2.544, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 5366 (epoch 8), train_loss = 2.829, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 5367 (epoch 8), train_loss = 2.749, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 5368 (epoch 8), train_loss = 2.964, time/batch = 0.022
Read data: 0.0017535686492919922
iter 5369 (epoch 8), train_loss = 2.740, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 5370 (epoch 8), train_loss = 2.837, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 5371 (epoch 8), train_loss = 2.635, time/batch = 0.025
Read data: 0.0001354217529296875
iter 5372 (epoch 8), train_loss = 2.608, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 5373 (epoch 8), train_loss = 2.797, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 5374 (epoch 8), train_loss = 2.677, time/batch = 0.030
Read data: 7.534027099609375e-05
iter 5375 (epoch 8), train_loss = 3.196, time/batch = 0.032
Read data: 0.00014019012451171875
iter 5376 (epoch 8), train_loss = 3.142, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 5377 (epoch 8), train_loss = 2.866, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 5378 (epoch 8), train_loss = 3.217, time/batch = 0.038
Read data: 0.0001418590545654297
iter 5379 (epoch 8), train_loss = 2.828, time/batch = 0.026
Read data: 0.00013303756713867188
iter 5380 (epoch 8), train_loss = 2.800, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 5381 (epoch 8), train_loss = 2.744, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 5382 (epoch 8), train_loss = 3.122, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 5383 (epoch 8), train_loss = 3.006, time/batch = 0.027
Read data: 0.0001227855682373047
iter 5384 (epoch 8), train_loss = 2.982, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 5385 (epoch 8), train_loss = 2.639, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 5386 (epoch 8), train_loss = 2.425, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 5387 (epoch 8), train_loss = 3.417, time/batch = 0.039
Read data: 8.416175842285156e-05
iter 5388 (epoch 8), train_loss = 2.475, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 5389 (epoch 8), train_loss = 2.863, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 5390 (epoch 8), train_loss = 2.727, time/batch = 0.035
Read data: 8.225440979003906e-05
iter 5391 (epoch 8), train_loss = 2.861, time/batch = 0.021
Read data: 0.0009992122650146484
iter 5392 (epoch 8), train_loss = 2.632, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 5393 (epoch 8), train_loss = 2.820, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5394 (epoch 8), train_loss = 2.995, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 5395 (epoch 8), train_loss = 3.271, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 5396 (epoch 8), train_loss = 2.648, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 5397 (epoch 8), train_loss = 2.806, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 5398 (epoch 8), train_loss = 2.796, time/batch = 0.022
Read data: 7.62939453125e-05
iter 5399 (epoch 8), train_loss = 3.066, time/batch = 0.029
Read data: 0.00017213821411132812
iter 5400 (epoch 8), train_loss = 2.694, time/batch = 0.026
Read data: 9.870529174804688e-05
iter 5401 (epoch 9), train_loss = 3.133, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 5402 (epoch 9), train_loss = 2.828, time/batch = 0.024
Read data: 7.510185241699219e-05
iter 5403 (epoch 9), train_loss = 2.719, time/batch = 0.027
Read data: 0.00011372566223144531
iter 5404 (epoch 9), train_loss = 3.084, time/batch = 0.037
Read data: 8.440017700195312e-05
iter 5405 (epoch 9), train_loss = 3.279, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 5406 (epoch 9), train_loss = 2.748, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 5407 (epoch 9), train_loss = 2.774, time/batch = 0.027
Read data: 0.00012540817260742188
iter 5408 (epoch 9), train_loss = 2.983, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 5409 (epoch 9), train_loss = 2.632, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 5410 (epoch 9), train_loss = 2.479, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 5411 (epoch 9), train_loss = 3.012, time/batch = 0.022
Read data: 0.0001361370086669922
iter 5412 (epoch 9), train_loss = 3.036, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 5413 (epoch 9), train_loss = 3.137, time/batch = 0.025
Read data: 0.00011301040649414062
iter 5414 (epoch 9), train_loss = 2.440, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 5415 (epoch 9), train_loss = 2.709, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 5416 (epoch 9), train_loss = 3.013, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 5417 (epoch 9), train_loss = 3.213, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 5418 (epoch 9), train_loss = 2.735, time/batch = 0.035
Read data: 8.7738037109375e-05
iter 5419 (epoch 9), train_loss = 2.614, time/batch = 0.024
Read data: 0.0002033710479736328
iter 5420 (epoch 9), train_loss = 2.656, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 5421 (epoch 9), train_loss = 2.488, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 5422 (epoch 9), train_loss = 2.411, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 5423 (epoch 9), train_loss = 2.838, time/batch = 0.022
Read data: 0.00012969970703125
iter 5424 (epoch 9), train_loss = 2.722, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 5425 (epoch 9), train_loss = 3.145, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 5426 (epoch 9), train_loss = 2.690, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5427 (epoch 9), train_loss = 2.600, time/batch = 0.024
Read data: 0.00011706352233886719
iter 5428 (epoch 9), train_loss = 2.983, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 5429 (epoch 9), train_loss = 2.924, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 5430 (epoch 9), train_loss = 2.595, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 5431 (epoch 9), train_loss = 2.804, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 5432 (epoch 9), train_loss = 2.657, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 5433 (epoch 9), train_loss = 2.757, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 5434 (epoch 9), train_loss = 2.646, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5435 (epoch 9), train_loss = 2.583, time/batch = 0.024
Read data: 0.00011849403381347656
iter 5436 (epoch 9), train_loss = 2.913, time/batch = 0.022
Read data: 0.00010085105895996094
iter 5437 (epoch 9), train_loss = 2.707, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 5438 (epoch 9), train_loss = 2.794, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 5439 (epoch 9), train_loss = 3.003, time/batch = 0.027
Read data: 0.00011730194091796875
iter 5440 (epoch 9), train_loss = 2.792, time/batch = 0.021
Read data: 7.772445678710938e-05
iter 5441 (epoch 9), train_loss = 2.865, time/batch = 0.025
Read data: 0.00012922286987304688
iter 5442 (epoch 9), train_loss = 2.701, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 5443 (epoch 9), train_loss = 3.183, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 5444 (epoch 9), train_loss = 2.673, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 5445 (epoch 9), train_loss = 2.611, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 5446 (epoch 9), train_loss = 2.684, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 5447 (epoch 9), train_loss = 2.557, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 5448 (epoch 9), train_loss = 2.447, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 5449 (epoch 9), train_loss = 2.907, time/batch = 0.024
Read data: 0.00017547607421875
iter 5450 (epoch 9), train_loss = 2.919, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 5451 (epoch 9), train_loss = 2.620, time/batch = 0.026
Read data: 0.00013875961303710938
iter 5452 (epoch 9), train_loss = 2.763, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 5453 (epoch 9), train_loss = 2.497, time/batch = 0.034
Read data: 8.249282836914062e-05
iter 5454 (epoch 9), train_loss = 2.697, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 5455 (epoch 9), train_loss = 2.728, time/batch = 0.032
Read data: 8.392333984375e-05
iter 5456 (epoch 9), train_loss = 2.861, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 5457 (epoch 9), train_loss = 2.681, time/batch = 0.032
Read data: 0.0001418590545654297
iter 5458 (epoch 9), train_loss = 2.328, time/batch = 0.030
Read data: 8.702278137207031e-05
iter 5459 (epoch 9), train_loss = 3.131, time/batch = 0.028
Read data: 0.0001533031463623047
iter 5460 (epoch 9), train_loss = 3.050, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 5461 (epoch 9), train_loss = 2.693, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 5462 (epoch 9), train_loss = 2.441, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 5463 (epoch 9), train_loss = 2.609, time/batch = 0.026
Read data: 0.0001327991485595703
iter 5464 (epoch 9), train_loss = 2.787, time/batch = 0.024
Read data: 9.512901306152344e-05
iter 5465 (epoch 9), train_loss = 2.747, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 5466 (epoch 9), train_loss = 2.468, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 5467 (epoch 9), train_loss = 2.546, time/batch = 0.033
Read data: 8.726119995117188e-05
iter 5468 (epoch 9), train_loss = 2.890, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 5469 (epoch 9), train_loss = 2.678, time/batch = 0.024
Read data: 0.0001595020294189453
iter 5470 (epoch 9), train_loss = 2.969, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 5471 (epoch 9), train_loss = 2.202, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 5472 (epoch 9), train_loss = 2.688, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 5473 (epoch 9), train_loss = 2.146, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 5474 (epoch 9), train_loss = 2.620, time/batch = 0.024
Read data: 0.0001690387725830078
iter 5475 (epoch 9), train_loss = 2.209, time/batch = 0.024
Read data: 0.00010228157043457031
iter 5476 (epoch 9), train_loss = 2.443, time/batch = 0.026
Read data: 0.0001049041748046875
iter 5477 (epoch 9), train_loss = 2.708, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 5478 (epoch 9), train_loss = 2.724, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 5479 (epoch 9), train_loss = 2.498, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 5480 (epoch 9), train_loss = 2.973, time/batch = 0.022
Read data: 9.417533874511719e-05
iter 5481 (epoch 9), train_loss = 2.643, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 5482 (epoch 9), train_loss = 2.460, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 5483 (epoch 9), train_loss = 3.072, time/batch = 0.023
Read data: 0.0001251697540283203
iter 5484 (epoch 9), train_loss = 2.444, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 5485 (epoch 9), train_loss = 2.686, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 5486 (epoch 9), train_loss = 2.368, time/batch = 0.035
Read data: 7.867813110351562e-05
iter 5487 (epoch 9), train_loss = 3.031, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 5488 (epoch 9), train_loss = 2.856, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 5489 (epoch 9), train_loss = 2.765, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 5490 (epoch 9), train_loss = 2.453, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 5491 (epoch 9), train_loss = 2.817, time/batch = 0.023
Read data: 0.00011658668518066406
iter 5492 (epoch 9), train_loss = 3.116, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 5493 (epoch 9), train_loss = 2.789, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 5494 (epoch 9), train_loss = 2.993, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 5495 (epoch 9), train_loss = 2.905, time/batch = 0.021
Read data: 0.00011968612670898438
iter 5496 (epoch 9), train_loss = 3.038, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 5497 (epoch 9), train_loss = 2.372, time/batch = 0.020
Read data: 9.679794311523438e-05
iter 5498 (epoch 9), train_loss = 2.643, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 5499 (epoch 9), train_loss = 2.953, time/batch = 0.024
Read data: 0.00026226043701171875
iter 5500 (epoch 9), train_loss = 2.560, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 5501 (epoch 9), train_loss = 2.973, time/batch = 0.024
Read data: 7.605552673339844e-05
iter 5502 (epoch 9), train_loss = 2.761, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 5503 (epoch 9), train_loss = 2.902, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 5504 (epoch 9), train_loss = 2.762, time/batch = 0.029
Read data: 9.274482727050781e-05
iter 5505 (epoch 9), train_loss = 3.132, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 5506 (epoch 9), train_loss = 2.490, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 5507 (epoch 9), train_loss = 2.650, time/batch = 0.024
Read data: 0.0001373291015625
iter 5508 (epoch 9), train_loss = 2.834, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 5509 (epoch 9), train_loss = 2.630, time/batch = 0.022
Read data: 0.00022339820861816406
iter 5510 (epoch 9), train_loss = 2.788, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 5511 (epoch 9), train_loss = 2.913, time/batch = 0.034
Read data: 0.00011873245239257812
iter 5512 (epoch 9), train_loss = 2.561, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 5513 (epoch 9), train_loss = 2.894, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 5514 (epoch 9), train_loss = 2.462, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 5515 (epoch 9), train_loss = 2.679, time/batch = 0.024
Read data: 0.00013113021850585938
iter 5516 (epoch 9), train_loss = 3.061, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 5517 (epoch 9), train_loss = 2.546, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 5518 (epoch 9), train_loss = 2.897, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 5519 (epoch 9), train_loss = 2.724, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 5520 (epoch 9), train_loss = 2.855, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 5521 (epoch 9), train_loss = 3.294, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 5522 (epoch 9), train_loss = 2.760, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 5523 (epoch 9), train_loss = 2.854, time/batch = 0.030
Read data: 8.392333984375e-05
iter 5524 (epoch 9), train_loss = 2.846, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 5525 (epoch 9), train_loss = 2.486, time/batch = 0.021
Read data: 9.703636169433594e-05
iter 5526 (epoch 9), train_loss = 2.239, time/batch = 0.025
Read data: 9.131431579589844e-05
iter 5527 (epoch 9), train_loss = 2.988, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 5528 (epoch 9), train_loss = 2.954, time/batch = 0.030
Read data: 9.298324584960938e-05
iter 5529 (epoch 9), train_loss = 3.357, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 5530 (epoch 9), train_loss = 3.081, time/batch = 0.024
Read data: 8.392333984375e-05
iter 5531 (epoch 9), train_loss = 2.782, time/batch = 0.025
Read data: 0.00010704994201660156
iter 5532 (epoch 9), train_loss = 2.539, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 5533 (epoch 9), train_loss = 2.951, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 5534 (epoch 9), train_loss = 2.984, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 5535 (epoch 9), train_loss = 2.523, time/batch = 0.028
Read data: 0.00013685226440429688
iter 5536 (epoch 9), train_loss = 2.723, time/batch = 0.030
Read data: 0.00010085105895996094
iter 5537 (epoch 9), train_loss = 2.462, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 5538 (epoch 9), train_loss = 2.522, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 5539 (epoch 9), train_loss = 2.912, time/batch = 0.029
Read data: 0.00012993812561035156
iter 5540 (epoch 9), train_loss = 2.394, time/batch = 0.020
Read data: 8.630752563476562e-05
iter 5541 (epoch 9), train_loss = 2.803, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 5542 (epoch 9), train_loss = 2.615, time/batch = 0.034
Read data: 7.748603820800781e-05
iter 5543 (epoch 9), train_loss = 2.836, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 5544 (epoch 9), train_loss = 2.575, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 5545 (epoch 9), train_loss = 2.706, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 5546 (epoch 9), train_loss = 2.766, time/batch = 0.020
Read data: 8.821487426757812e-05
iter 5547 (epoch 9), train_loss = 2.628, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 5548 (epoch 9), train_loss = 2.846, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 5549 (epoch 9), train_loss = 3.224, time/batch = 0.022
Read data: 0.0002551078796386719
iter 5550 (epoch 9), train_loss = 2.509, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 5551 (epoch 9), train_loss = 2.855, time/batch = 0.023
Read data: 0.00012803077697753906
iter 5552 (epoch 9), train_loss = 2.984, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 5553 (epoch 9), train_loss = 2.495, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 5554 (epoch 9), train_loss = 2.481, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 5555 (epoch 9), train_loss = 2.579, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 5556 (epoch 9), train_loss = 2.582, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 5557 (epoch 9), train_loss = 2.503, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 5558 (epoch 9), train_loss = 3.002, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 5559 (epoch 9), train_loss = 3.149, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 5560 (epoch 9), train_loss = 2.578, time/batch = 0.033
Read data: 8.535385131835938e-05
iter 5561 (epoch 9), train_loss = 2.847, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 5562 (epoch 9), train_loss = 2.615, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 5563 (epoch 9), train_loss = 3.360, time/batch = 0.035
Read data: 8.463859558105469e-05
iter 5564 (epoch 9), train_loss = 2.767, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 5565 (epoch 9), train_loss = 2.638, time/batch = 0.023
Read data: 7.724761962890625e-05
iter 5566 (epoch 9), train_loss = 2.659, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 5567 (epoch 9), train_loss = 2.695, time/batch = 0.024
Read data: 0.00014019012451171875
iter 5568 (epoch 9), train_loss = 2.792, time/batch = 0.028
Read data: 9.1552734375e-05
iter 5569 (epoch 9), train_loss = 2.853, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 5570 (epoch 9), train_loss = 3.200, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 5571 (epoch 9), train_loss = 3.156, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 5572 (epoch 9), train_loss = 2.743, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 5573 (epoch 9), train_loss = 2.618, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 5574 (epoch 9), train_loss = 2.803, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5575 (epoch 9), train_loss = 2.538, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 5576 (epoch 9), train_loss = 2.528, time/batch = 0.024
Read data: 7.557868957519531e-05
iter 5577 (epoch 9), train_loss = 2.604, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 5578 (epoch 9), train_loss = 2.401, time/batch = 0.039
Read data: 7.987022399902344e-05
iter 5579 (epoch 9), train_loss = 2.770, time/batch = 0.021
Read data: 0.00011944770812988281
iter 5580 (epoch 9), train_loss = 2.526, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 5581 (epoch 9), train_loss = 2.740, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 5582 (epoch 9), train_loss = 2.930, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 5583 (epoch 9), train_loss = 3.047, time/batch = 0.025
Read data: 0.0001456737518310547
iter 5584 (epoch 9), train_loss = 2.227, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 5585 (epoch 9), train_loss = 2.831, time/batch = 0.033
Read data: 7.915496826171875e-05
iter 5586 (epoch 9), train_loss = 2.642, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 5587 (epoch 9), train_loss = 2.876, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 5588 (epoch 9), train_loss = 2.763, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 5589 (epoch 9), train_loss = 3.000, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 5590 (epoch 9), train_loss = 2.852, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 5591 (epoch 9), train_loss = 2.957, time/batch = 0.027
Read data: 0.0001285076141357422
iter 5592 (epoch 9), train_loss = 2.584, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 5593 (epoch 9), train_loss = 3.293, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 5594 (epoch 9), train_loss = 2.140, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 5595 (epoch 9), train_loss = 2.791, time/batch = 0.026
Read data: 0.00012183189392089844
iter 5596 (epoch 9), train_loss = 2.475, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 5597 (epoch 9), train_loss = 2.727, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 5598 (epoch 9), train_loss = 3.023, time/batch = 0.029
Read data: 0.0001354217529296875
iter 5599 (epoch 9), train_loss = 2.857, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 5600 (epoch 9), train_loss = 2.923, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 5601 (epoch 9), train_loss = 2.712, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 5602 (epoch 9), train_loss = 2.918, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5603 (epoch 9), train_loss = 2.945, time/batch = 0.028
Read data: 0.0001361370086669922
iter 5604 (epoch 9), train_loss = 3.034, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 5605 (epoch 9), train_loss = 2.491, time/batch = 0.020
Read data: 9.226799011230469e-05
iter 5606 (epoch 9), train_loss = 3.044, time/batch = 0.032
Read data: 7.891654968261719e-05
iter 5607 (epoch 9), train_loss = 2.675, time/batch = 0.020
Read data: 0.00014972686767578125
iter 5608 (epoch 9), train_loss = 2.263, time/batch = 0.024
Read data: 9.560585021972656e-05
iter 5609 (epoch 9), train_loss = 2.794, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 5610 (epoch 9), train_loss = 2.856, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 5611 (epoch 9), train_loss = 2.767, time/batch = 0.024
Read data: 0.00017714500427246094
iter 5612 (epoch 9), train_loss = 3.117, time/batch = 0.024
Read data: 0.00013113021850585938
iter 5613 (epoch 9), train_loss = 2.719, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 5614 (epoch 9), train_loss = 2.840, time/batch = 0.027
Read data: 9.1552734375e-05
iter 5615 (epoch 9), train_loss = 2.654, time/batch = 0.029
Read data: 9.34600830078125e-05
iter 5616 (epoch 9), train_loss = 2.578, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 5617 (epoch 9), train_loss = 2.977, time/batch = 0.027
Read data: 0.00011587142944335938
iter 5618 (epoch 9), train_loss = 2.857, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 5619 (epoch 9), train_loss = 2.773, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 5620 (epoch 9), train_loss = 2.287, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 5621 (epoch 9), train_loss = 2.785, time/batch = 0.032
Read data: 7.724761962890625e-05
iter 5622 (epoch 9), train_loss = 2.919, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 5623 (epoch 9), train_loss = 2.922, time/batch = 0.037
Read data: 0.00012445449829101562
iter 5624 (epoch 9), train_loss = 2.643, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 5625 (epoch 9), train_loss = 2.998, time/batch = 0.030
Read data: 8.678436279296875e-05
iter 5626 (epoch 9), train_loss = 2.901, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 5627 (epoch 9), train_loss = 2.512, time/batch = 0.032
Read data: 0.0001289844512939453
iter 5628 (epoch 9), train_loss = 3.009, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 5629 (epoch 9), train_loss = 2.772, time/batch = 0.027
Read data: 8.392333984375e-05
iter 5630 (epoch 9), train_loss = 3.012, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 5631 (epoch 9), train_loss = 2.084, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 5632 (epoch 9), train_loss = 2.849, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 5633 (epoch 9), train_loss = 2.723, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 5634 (epoch 9), train_loss = 2.773, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 5635 (epoch 9), train_loss = 2.925, time/batch = 0.023
Read data: 0.0001347064971923828
iter 5636 (epoch 9), train_loss = 2.904, time/batch = 0.022
Read data: 0.0001723766326904297
iter 5637 (epoch 9), train_loss = 2.460, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 5638 (epoch 9), train_loss = 2.700, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 5639 (epoch 9), train_loss = 2.575, time/batch = 0.024
Read data: 0.0001361370086669922
iter 5640 (epoch 9), train_loss = 2.677, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 5641 (epoch 9), train_loss = 2.748, time/batch = 0.023
Read data: 0.0001742839813232422
iter 5642 (epoch 9), train_loss = 2.856, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 5643 (epoch 9), train_loss = 2.696, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 5644 (epoch 9), train_loss = 2.826, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 5645 (epoch 9), train_loss = 2.768, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 5646 (epoch 9), train_loss = 2.732, time/batch = 0.026
Read data: 9.1552734375e-05
iter 5647 (epoch 9), train_loss = 2.797, time/batch = 0.026
Read data: 0.0001399517059326172
iter 5648 (epoch 9), train_loss = 2.658, time/batch = 0.035
Read data: 8.034706115722656e-05
iter 5649 (epoch 9), train_loss = 2.435, time/batch = 0.027
Read data: 0.00022339820861816406
iter 5650 (epoch 9), train_loss = 2.702, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 5651 (epoch 9), train_loss = 2.816, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 5652 (epoch 9), train_loss = 2.846, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 5653 (epoch 9), train_loss = 2.769, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 5654 (epoch 9), train_loss = 3.217, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 5655 (epoch 9), train_loss = 2.969, time/batch = 0.025
Read data: 8.392333984375e-05
iter 5656 (epoch 9), train_loss = 2.662, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 5657 (epoch 9), train_loss = 2.914, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 5658 (epoch 9), train_loss = 2.261, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 5659 (epoch 9), train_loss = 3.024, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 5660 (epoch 9), train_loss = 2.646, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 5661 (epoch 9), train_loss = 2.603, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 5662 (epoch 9), train_loss = 2.682, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 5663 (epoch 9), train_loss = 2.645, time/batch = 0.028
Read data: 0.00014901161193847656
iter 5664 (epoch 9), train_loss = 2.889, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 5665 (epoch 9), train_loss = 2.630, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 5666 (epoch 9), train_loss = 2.762, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 5667 (epoch 9), train_loss = 2.790, time/batch = 0.026
Read data: 0.0001251697540283203
iter 5668 (epoch 9), train_loss = 2.989, time/batch = 0.023
Read data: 0.00017023086547851562
iter 5669 (epoch 9), train_loss = 2.754, time/batch = 0.031
Read data: 0.0001456737518310547
iter 5670 (epoch 9), train_loss = 2.978, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 5671 (epoch 9), train_loss = 2.836, time/batch = 0.021
Read data: 0.00010132789611816406
iter 5672 (epoch 9), train_loss = 2.795, time/batch = 0.033
Read data: 7.796287536621094e-05
iter 5673 (epoch 9), train_loss = 2.380, time/batch = 0.028
Read data: 8.392333984375e-05
iter 5674 (epoch 9), train_loss = 2.700, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 5675 (epoch 9), train_loss = 2.650, time/batch = 0.026
Read data: 0.00012421607971191406
iter 5676 (epoch 9), train_loss = 2.857, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 5677 (epoch 9), train_loss = 2.739, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 5678 (epoch 9), train_loss = 2.576, time/batch = 0.035
Read data: 8.225440979003906e-05
iter 5679 (epoch 9), train_loss = 2.945, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 5680 (epoch 9), train_loss = 2.378, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 5681 (epoch 9), train_loss = 2.417, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 5682 (epoch 9), train_loss = 2.803, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 5683 (epoch 9), train_loss = 2.761, time/batch = 0.026
Read data: 0.00011658668518066406
iter 5684 (epoch 9), train_loss = 2.825, time/batch = 0.024
Read data: 0.000133514404296875
iter 5685 (epoch 9), train_loss = 2.717, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 5686 (epoch 9), train_loss = 2.612, time/batch = 0.036
Read data: 7.891654968261719e-05
iter 5687 (epoch 9), train_loss = 2.757, time/batch = 0.037
Read data: 8.821487426757812e-05
iter 5688 (epoch 9), train_loss = 2.966, time/batch = 0.025
Read data: 0.000141143798828125
iter 5689 (epoch 9), train_loss = 2.794, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 5690 (epoch 9), train_loss = 2.754, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 5691 (epoch 9), train_loss = 2.892, time/batch = 0.024
Read data: 9.965896606445312e-05
iter 5692 (epoch 9), train_loss = 3.285, time/batch = 0.035
Read data: 7.82012939453125e-05
iter 5693 (epoch 9), train_loss = 3.303, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 5694 (epoch 9), train_loss = 3.056, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 5695 (epoch 9), train_loss = 2.905, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 5696 (epoch 9), train_loss = 2.897, time/batch = 0.025
Read data: 0.00011706352233886719
iter 5697 (epoch 9), train_loss = 2.677, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 5698 (epoch 9), train_loss = 2.570, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 5699 (epoch 9), train_loss = 2.746, time/batch = 0.030
Read data: 0.00017333030700683594
iter 5700 (epoch 9), train_loss = 2.273, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 5701 (epoch 9), train_loss = 2.491, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 5702 (epoch 9), train_loss = 2.738, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 5703 (epoch 9), train_loss = 2.838, time/batch = 0.025
Read data: 0.000102996826171875
iter 5704 (epoch 9), train_loss = 2.638, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 5705 (epoch 9), train_loss = 2.662, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 5706 (epoch 9), train_loss = 2.485, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 5707 (epoch 9), train_loss = 2.972, time/batch = 0.023
Read data: 0.00013685226440429688
iter 5708 (epoch 9), train_loss = 2.909, time/batch = 0.026
Read data: 0.0001418590545654297
iter 5709 (epoch 9), train_loss = 3.101, time/batch = 0.028
Read data: 0.00010323524475097656
iter 5710 (epoch 9), train_loss = 2.884, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 5711 (epoch 9), train_loss = 2.547, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5712 (epoch 9), train_loss = 3.129, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 5713 (epoch 9), train_loss = 2.773, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 5714 (epoch 9), train_loss = 2.688, time/batch = 0.025
Read data: 0.00011801719665527344
iter 5715 (epoch 9), train_loss = 2.837, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 5716 (epoch 9), train_loss = 2.650, time/batch = 0.025
Read data: 0.0001323223114013672
iter 5717 (epoch 9), train_loss = 2.749, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 5718 (epoch 9), train_loss = 2.667, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 5719 (epoch 9), train_loss = 2.778, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 5720 (epoch 9), train_loss = 2.869, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 5721 (epoch 9), train_loss = 3.116, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 5722 (epoch 9), train_loss = 2.868, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 5723 (epoch 9), train_loss = 2.889, time/batch = 0.025
Read data: 0.0001277923583984375
iter 5724 (epoch 9), train_loss = 2.854, time/batch = 0.024
Read data: 0.00022792816162109375
iter 5725 (epoch 9), train_loss = 3.163, time/batch = 0.032
Read data: 0.0001456737518310547
iter 5726 (epoch 9), train_loss = 2.695, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 5727 (epoch 9), train_loss = 2.908, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 5728 (epoch 9), train_loss = 2.916, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 5729 (epoch 9), train_loss = 2.699, time/batch = 0.023
Read data: 0.00013828277587890625
iter 5730 (epoch 9), train_loss = 2.853, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 5731 (epoch 9), train_loss = 2.848, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 5732 (epoch 9), train_loss = 2.495, time/batch = 0.027
Read data: 9.608268737792969e-05
iter 5733 (epoch 9), train_loss = 3.064, time/batch = 0.026
Read data: 0.0001373291015625
iter 5734 (epoch 9), train_loss = 3.052, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 5735 (epoch 9), train_loss = 2.534, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 5736 (epoch 9), train_loss = 2.823, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 5737 (epoch 9), train_loss = 2.970, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 5738 (epoch 9), train_loss = 3.009, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 5739 (epoch 9), train_loss = 2.448, time/batch = 0.026
Read data: 8.392333984375e-05
iter 5740 (epoch 9), train_loss = 2.724, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 5741 (epoch 9), train_loss = 2.859, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 5742 (epoch 9), train_loss = 2.847, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 5743 (epoch 9), train_loss = 2.590, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 5744 (epoch 9), train_loss = 2.776, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 5745 (epoch 9), train_loss = 2.761, time/batch = 0.023
Read data: 0.00010085105895996094
iter 5746 (epoch 9), train_loss = 2.937, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 5747 (epoch 9), train_loss = 3.229, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 5748 (epoch 9), train_loss = 3.052, time/batch = 0.021
Read data: 0.0001747608184814453
iter 5749 (epoch 9), train_loss = 2.426, time/batch = 0.026
Read data: 0.0002684593200683594
iter 5750 (epoch 9), train_loss = 2.689, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 5751 (epoch 9), train_loss = 2.123, time/batch = 0.020
Read data: 0.00010204315185546875
iter 5752 (epoch 9), train_loss = 2.379, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 5753 (epoch 9), train_loss = 2.523, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 5754 (epoch 9), train_loss = 2.611, time/batch = 0.024
Read data: 9.894371032714844e-05
iter 5755 (epoch 9), train_loss = 2.520, time/batch = 0.027
Read data: 0.0001399517059326172
iter 5756 (epoch 9), train_loss = 2.629, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 5757 (epoch 9), train_loss = 3.019, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 5758 (epoch 9), train_loss = 2.616, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 5759 (epoch 9), train_loss = 2.575, time/batch = 0.024
Read data: 9.1552734375e-05
iter 5760 (epoch 9), train_loss = 2.594, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 5761 (epoch 9), train_loss = 3.303, time/batch = 0.031
Read data: 0.0001442432403564453
iter 5762 (epoch 9), train_loss = 2.558, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 5763 (epoch 9), train_loss = 2.419, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 5764 (epoch 9), train_loss = 3.003, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 5765 (epoch 9), train_loss = 2.725, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5766 (epoch 9), train_loss = 2.561, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 5767 (epoch 9), train_loss = 2.561, time/batch = 0.024
Read data: 0.00013017654418945312
iter 5768 (epoch 9), train_loss = 2.507, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 5769 (epoch 9), train_loss = 2.993, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 5770 (epoch 9), train_loss = 2.866, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 5771 (epoch 9), train_loss = 2.795, time/batch = 0.024
Read data: 0.0001251697540283203
iter 5772 (epoch 9), train_loss = 2.950, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 5773 (epoch 9), train_loss = 3.229, time/batch = 0.035
Read data: 8.463859558105469e-05
iter 5774 (epoch 9), train_loss = 2.876, time/batch = 0.030
Read data: 0.0002739429473876953
iter 5775 (epoch 9), train_loss = 2.675, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 5776 (epoch 9), train_loss = 2.934, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 5777 (epoch 9), train_loss = 2.329, time/batch = 0.021
Read data: 9.894371032714844e-05
iter 5778 (epoch 9), train_loss = 2.726, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 5779 (epoch 9), train_loss = 2.968, time/batch = 0.034
Read data: 8.273124694824219e-05
iter 5780 (epoch 9), train_loss = 2.864, time/batch = 0.032
Read data: 0.00014162063598632812
iter 5781 (epoch 9), train_loss = 2.599, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 5782 (epoch 9), train_loss = 2.802, time/batch = 0.033
Read data: 0.00013113021850585938
iter 5783 (epoch 9), train_loss = 2.694, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 5784 (epoch 9), train_loss = 2.791, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 5785 (epoch 9), train_loss = 2.808, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 5786 (epoch 9), train_loss = 2.793, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 5787 (epoch 9), train_loss = 3.154, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 5788 (epoch 9), train_loss = 2.817, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 5789 (epoch 9), train_loss = 2.766, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 5790 (epoch 9), train_loss = 2.560, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 5791 (epoch 9), train_loss = 2.646, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 5792 (epoch 9), train_loss = 2.751, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5793 (epoch 9), train_loss = 2.335, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 5794 (epoch 9), train_loss = 2.724, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 5795 (epoch 9), train_loss = 2.794, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 5796 (epoch 9), train_loss = 2.827, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 5797 (epoch 9), train_loss = 3.071, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 5798 (epoch 9), train_loss = 2.534, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 5799 (epoch 9), train_loss = 2.782, time/batch = 0.035
Read data: 0.00034618377685546875
iter 5800 (epoch 9), train_loss = 2.480, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 5801 (epoch 9), train_loss = 2.404, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 5802 (epoch 9), train_loss = 2.417, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 5803 (epoch 9), train_loss = 3.086, time/batch = 0.024
Read data: 0.00013518333435058594
iter 5804 (epoch 9), train_loss = 2.643, time/batch = 0.026
Read data: 0.00016045570373535156
iter 5805 (epoch 9), train_loss = 2.785, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 5806 (epoch 9), train_loss = 2.938, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 5807 (epoch 9), train_loss = 2.492, time/batch = 0.024
Read data: 0.00013637542724609375
iter 5808 (epoch 9), train_loss = 2.756, time/batch = 0.022
Read data: 0.00014591217041015625
iter 5809 (epoch 9), train_loss = 2.805, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 5810 (epoch 9), train_loss = 2.738, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 5811 (epoch 9), train_loss = 2.788, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 5812 (epoch 9), train_loss = 2.122, time/batch = 0.024
Read data: 0.000179290771484375
iter 5813 (epoch 9), train_loss = 2.666, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 5814 (epoch 9), train_loss = 2.791, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 5815 (epoch 9), train_loss = 2.676, time/batch = 0.025
Read data: 0.00011348724365234375
iter 5816 (epoch 9), train_loss = 2.829, time/batch = 0.027
Read data: 0.00010991096496582031
iter 5817 (epoch 9), train_loss = 2.803, time/batch = 0.024
Read data: 0.0001125335693359375
iter 5818 (epoch 9), train_loss = 2.566, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 5819 (epoch 9), train_loss = 2.880, time/batch = 0.022
Read data: 0.0001862049102783203
iter 5820 (epoch 9), train_loss = 2.442, time/batch = 0.021
Read data: 0.00014495849609375
iter 5821 (epoch 9), train_loss = 3.061, time/batch = 0.033
Read data: 9.489059448242188e-05
iter 5822 (epoch 9), train_loss = 2.524, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 5823 (epoch 9), train_loss = 2.484, time/batch = 0.023
Read data: 0.00022745132446289062
iter 5824 (epoch 9), train_loss = 3.100, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5825 (epoch 9), train_loss = 2.121, time/batch = 0.020
Read data: 9.107589721679688e-05
iter 5826 (epoch 9), train_loss = 3.214, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 5827 (epoch 9), train_loss = 3.178, time/batch = 0.025
Read data: 0.00012612342834472656
iter 5828 (epoch 9), train_loss = 2.831, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 5829 (epoch 9), train_loss = 2.516, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 5830 (epoch 9), train_loss = 3.176, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 5831 (epoch 9), train_loss = 2.706, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 5832 (epoch 9), train_loss = 2.675, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 5833 (epoch 9), train_loss = 2.717, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 5834 (epoch 9), train_loss = 2.444, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 5835 (epoch 9), train_loss = 2.216, time/batch = 0.026
Read data: 0.0001354217529296875
iter 5836 (epoch 9), train_loss = 2.811, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 5837 (epoch 9), train_loss = 3.184, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 5838 (epoch 9), train_loss = 2.638, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 5839 (epoch 9), train_loss = 2.908, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 5840 (epoch 9), train_loss = 2.698, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 5841 (epoch 9), train_loss = 2.753, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 5842 (epoch 9), train_loss = 3.274, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 5843 (epoch 9), train_loss = 2.629, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 5844 (epoch 9), train_loss = 2.812, time/batch = 0.024
Read data: 0.0001423358917236328
iter 5845 (epoch 9), train_loss = 2.674, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 5846 (epoch 9), train_loss = 2.625, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 5847 (epoch 9), train_loss = 2.949, time/batch = 0.029
Read data: 0.00019788742065429688
iter 5848 (epoch 9), train_loss = 2.693, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 5849 (epoch 9), train_loss = 2.730, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 5850 (epoch 9), train_loss = 2.875, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 5851 (epoch 9), train_loss = 2.521, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 5852 (epoch 9), train_loss = 2.506, time/batch = 0.027
Read data: 0.00011301040649414062
iter 5853 (epoch 9), train_loss = 2.877, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 5854 (epoch 9), train_loss = 3.291, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 5855 (epoch 9), train_loss = 2.857, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 5856 (epoch 9), train_loss = 2.893, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 5857 (epoch 9), train_loss = 2.835, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 5858 (epoch 9), train_loss = 3.350, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 5859 (epoch 9), train_loss = 2.563, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 5860 (epoch 9), train_loss = 2.329, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 5861 (epoch 9), train_loss = 2.717, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 5862 (epoch 9), train_loss = 2.586, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 5863 (epoch 9), train_loss = 3.128, time/batch = 0.035
Read data: 8.487701416015625e-05
iter 5864 (epoch 9), train_loss = 2.565, time/batch = 0.028
Read data: 0.00011873245239257812
iter 5865 (epoch 9), train_loss = 2.790, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 5866 (epoch 9), train_loss = 2.956, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 5867 (epoch 9), train_loss = 2.660, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 5868 (epoch 9), train_loss = 2.958, time/batch = 0.026
Read data: 0.0001456737518310547
iter 5869 (epoch 9), train_loss = 2.677, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 5870 (epoch 9), train_loss = 2.576, time/batch = 0.025
Read data: 0.00018262863159179688
iter 5871 (epoch 9), train_loss = 3.101, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 5872 (epoch 9), train_loss = 2.930, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 5873 (epoch 9), train_loss = 2.677, time/batch = 0.025
Read data: 0.00010061264038085938
iter 5874 (epoch 9), train_loss = 2.706, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 5875 (epoch 9), train_loss = 2.231, time/batch = 0.021
Read data: 0.00012683868408203125
iter 5876 (epoch 9), train_loss = 3.240, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 5877 (epoch 9), train_loss = 2.864, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 5878 (epoch 9), train_loss = 2.656, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 5879 (epoch 9), train_loss = 2.715, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 5880 (epoch 9), train_loss = 2.666, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 5881 (epoch 9), train_loss = 2.429, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 5882 (epoch 9), train_loss = 2.580, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 5883 (epoch 9), train_loss = 2.858, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 5884 (epoch 9), train_loss = 2.553, time/batch = 0.020
Read data: 0.00014066696166992188
iter 5885 (epoch 9), train_loss = 2.907, time/batch = 0.022
Read data: 0.00010037422180175781
iter 5886 (epoch 9), train_loss = 2.653, time/batch = 0.025
Read data: 0.00013065338134765625
iter 5887 (epoch 9), train_loss = 2.133, time/batch = 0.028
Read data: 0.00013494491577148438
iter 5888 (epoch 9), train_loss = 2.746, time/batch = 0.024
Read data: 0.00014328956604003906
iter 5889 (epoch 9), train_loss = 2.580, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 5890 (epoch 9), train_loss = 3.090, time/batch = 0.030
Read data: 9.250640869140625e-05
iter 5891 (epoch 9), train_loss = 3.063, time/batch = 0.027
Read data: 0.00010061264038085938
iter 5892 (epoch 9), train_loss = 2.735, time/batch = 0.020
Read data: 8.344650268554688e-05
iter 5893 (epoch 9), train_loss = 2.914, time/batch = 0.024
Read data: 0.00013327598571777344
iter 5894 (epoch 9), train_loss = 2.617, time/batch = 0.030
Read data: 0.00010061264038085938
iter 5895 (epoch 9), train_loss = 3.107, time/batch = 0.024
Read data: 0.00010156631469726562
iter 5896 (epoch 9), train_loss = 2.978, time/batch = 0.037
Read data: 0.00013899803161621094
iter 5897 (epoch 9), train_loss = 2.804, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 5898 (epoch 9), train_loss = 2.463, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 5899 (epoch 9), train_loss = 3.258, time/batch = 0.036
Read data: 0.0002586841583251953
iter 5900 (epoch 9), train_loss = 2.404, time/batch = 0.026
Read data: 0.00015497207641601562
iter 5901 (epoch 9), train_loss = 2.587, time/batch = 0.023
Read data: 0.00017499923706054688
iter 5902 (epoch 9), train_loss = 2.860, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 5903 (epoch 9), train_loss = 2.729, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 5904 (epoch 9), train_loss = 2.720, time/batch = 0.030
Read data: 0.00011610984802246094
iter 5905 (epoch 9), train_loss = 3.154, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 5906 (epoch 9), train_loss = 2.643, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5907 (epoch 9), train_loss = 2.669, time/batch = 0.031
Read data: 0.0001251697540283203
iter 5908 (epoch 9), train_loss = 3.016, time/batch = 0.023
Read data: 0.00011372566223144531
iter 5909 (epoch 9), train_loss = 3.341, time/batch = 0.030
Read data: 0.000194549560546875
iter 5910 (epoch 9), train_loss = 2.807, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 5911 (epoch 9), train_loss = 3.232, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 5912 (epoch 9), train_loss = 2.794, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 5913 (epoch 9), train_loss = 2.455, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 5914 (epoch 9), train_loss = 2.659, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 5915 (epoch 9), train_loss = 2.174, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 5916 (epoch 9), train_loss = 2.817, time/batch = 0.022
Read data: 0.00010418891906738281
iter 5917 (epoch 9), train_loss = 2.857, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 5918 (epoch 9), train_loss = 2.722, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 5919 (epoch 9), train_loss = 2.897, time/batch = 0.027
Read data: 0.0001266002655029297
iter 5920 (epoch 9), train_loss = 2.709, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 5921 (epoch 9), train_loss = 3.079, time/batch = 0.021
Read data: 9.179115295410156e-05
iter 5922 (epoch 9), train_loss = 2.843, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 5923 (epoch 9), train_loss = 2.783, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 5924 (epoch 9), train_loss = 3.118, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 5925 (epoch 9), train_loss = 3.057, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 5926 (epoch 9), train_loss = 2.384, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 5927 (epoch 9), train_loss = 2.955, time/batch = 0.027
Read data: 0.00012540817260742188
iter 5928 (epoch 9), train_loss = 2.562, time/batch = 0.029
Read data: 0.00011444091796875
iter 5929 (epoch 9), train_loss = 2.944, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 5930 (epoch 9), train_loss = 2.696, time/batch = 0.029
Read data: 9.441375732421875e-05
iter 5931 (epoch 9), train_loss = 2.689, time/batch = 0.025
Read data: 0.0001239776611328125
iter 5932 (epoch 9), train_loss = 2.526, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 5933 (epoch 9), train_loss = 2.793, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 5934 (epoch 9), train_loss = 2.883, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 5935 (epoch 9), train_loss = 2.766, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 5936 (epoch 9), train_loss = 2.593, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 5937 (epoch 9), train_loss = 2.670, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 5938 (epoch 9), train_loss = 3.362, time/batch = 0.036
Read data: 8.153915405273438e-05
iter 5939 (epoch 9), train_loss = 2.735, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 5940 (epoch 9), train_loss = 3.007, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 5941 (epoch 9), train_loss = 2.388, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 5942 (epoch 9), train_loss = 2.531, time/batch = 0.031
Read data: 0.0001456737518310547
iter 5943 (epoch 9), train_loss = 3.135, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 5944 (epoch 9), train_loss = 2.839, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 5945 (epoch 9), train_loss = 2.554, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 5946 (epoch 9), train_loss = 3.205, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 5947 (epoch 9), train_loss = 2.582, time/batch = 0.027
Read data: 0.00011467933654785156
iter 5948 (epoch 9), train_loss = 3.094, time/batch = 0.037
Read data: 7.963180541992188e-05
iter 5949 (epoch 9), train_loss = 2.970, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 5950 (epoch 9), train_loss = 2.654, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 5951 (epoch 9), train_loss = 2.417, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 5952 (epoch 9), train_loss = 2.675, time/batch = 0.021
Read data: 9.989738464355469e-05
iter 5953 (epoch 9), train_loss = 2.677, time/batch = 0.024
Read data: 0.0001747608184814453
iter 5954 (epoch 9), train_loss = 2.850, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 5955 (epoch 9), train_loss = 2.564, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 5956 (epoch 9), train_loss = 3.060, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 5957 (epoch 9), train_loss = 2.790, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 5958 (epoch 9), train_loss = 2.752, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 5959 (epoch 9), train_loss = 3.213, time/batch = 0.035
Read data: 9.179115295410156e-05
iter 5960 (epoch 9), train_loss = 3.070, time/batch = 0.024
Read data: 0.0001373291015625
iter 5961 (epoch 9), train_loss = 3.108, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 5962 (epoch 9), train_loss = 2.695, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 5963 (epoch 9), train_loss = 2.693, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 5964 (epoch 9), train_loss = 2.799, time/batch = 0.025
Read data: 0.00011110305786132812
iter 5965 (epoch 9), train_loss = 3.056, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 5966 (epoch 9), train_loss = 2.969, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 5967 (epoch 9), train_loss = 2.684, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 5968 (epoch 9), train_loss = 2.657, time/batch = 0.025
Read data: 0.00010204315185546875
iter 5969 (epoch 9), train_loss = 2.523, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 5970 (epoch 9), train_loss = 2.626, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 5971 (epoch 9), train_loss = 2.481, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 5972 (epoch 9), train_loss = 2.342, time/batch = 0.041
Read data: 7.963180541992188e-05
iter 5973 (epoch 9), train_loss = 2.600, time/batch = 0.026
Read data: 0.00012683868408203125
iter 5974 (epoch 9), train_loss = 2.794, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 5975 (epoch 9), train_loss = 2.552, time/batch = 0.025
Read data: 0.00013065338134765625
iter 5976 (epoch 9), train_loss = 2.013, time/batch = 0.025
Read data: 0.0001163482666015625
iter 5977 (epoch 9), train_loss = 3.066, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 5978 (epoch 9), train_loss = 2.441, time/batch = 0.023
Read data: 0.00017523765563964844
iter 5979 (epoch 9), train_loss = 2.617, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 5980 (epoch 9), train_loss = 2.826, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 5981 (epoch 9), train_loss = 3.029, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 5982 (epoch 9), train_loss = 2.791, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 5983 (epoch 9), train_loss = 2.652, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 5984 (epoch 9), train_loss = 2.439, time/batch = 0.025
Read data: 0.0001456737518310547
iter 5985 (epoch 9), train_loss = 2.776, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 5986 (epoch 9), train_loss = 2.966, time/batch = 0.026
Read data: 0.00014781951904296875
iter 5987 (epoch 9), train_loss = 3.039, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 5988 (epoch 9), train_loss = 2.146, time/batch = 0.020
Read data: 0.00013589859008789062
iter 5989 (epoch 9), train_loss = 2.313, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 5990 (epoch 9), train_loss = 2.957, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 5991 (epoch 9), train_loss = 2.884, time/batch = 0.028
Read data: 0.0009362697601318359
iter 5992 (epoch 9), train_loss = 2.438, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 5993 (epoch 9), train_loss = 2.722, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 5994 (epoch 9), train_loss = 2.280, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 5995 (epoch 9), train_loss = 2.710, time/batch = 0.021
Read data: 9.942054748535156e-05
iter 5996 (epoch 9), train_loss = 2.542, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 5997 (epoch 9), train_loss = 2.627, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 5998 (epoch 9), train_loss = 2.982, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 5999 (epoch 9), train_loss = 3.407, time/batch = 0.027
image 976:     
image 5399:    
image 6910:      
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:    UNK
evaluating validation preformance... 10/1000 (2.799006)
image 2798:     
image 5884:    
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.401504)
image 6903:      
image 3301:    
image 2019:    UNK
image 5535:    
image 7680:     
image 5527:      
image 2568:    
image 160:     
image 8085:    
image 7670:      
evaluating validation preformance... 30/1000 (2.776984)
image 4604:     
image 5745:     
image 5288:    
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.986497)
image 2938:    
image 5183:     
image 2380:      
image 6973:     
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.674354)
image 4940:      
image 4905:    
image 469:     
image 102:    
image 6009:    
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.982076)
image 4389:     
image 4281:    
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.762245)
image 3258:     
image 6895:      
image 5296:     
image 4623:    
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.871244)
image 3276:      
image 3812:     
image 1400:    
image 3443:     
image 5027:     
image 7251:    
image 7305:     
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.233779)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (3.102519)
image 2800:    
image 7249:     
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (3.006677)
image 1122:     
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.546255)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:    UNK
image 4913:    
image 4589:    
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (3.002012)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:     
image 5542:     
image 8068:    UNK
image 4450:    
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.857696)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.082249)
image 1865:      
image 3830:      
image 360:      
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.936718)
image 4297:    
image 3315:     
image 1107:     
image 2051:     
image 4713:    
image 8036:     
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.721928)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:     
image 3000:    
image 1806:     
image 7761:     
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.792176)
image 2313:    
image 6289:    
image 8084:     
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.676046)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:      
image 8015:     
image 6565:     
image 6174:     
image 6894:     
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.476911)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:     
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.632965)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:     UNK
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.753696)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.464768)
image 1917:    
image 5844:      
image 1661:     
image 1510:     
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:     
image 5594:     
evaluating validation preformance... 240/1000 (2.364216)
image 7143:     
image 6019:     
image 885:     
image 2802:     
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.757079)
image 3028:    
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.636924)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.071874)
image 833:     
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.737276)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.682694)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.319504)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:    
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.967541)
image 3553:    
image 5971:     
image 122:    
image 3212:      
image 7223:    
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:     
image 6423:     
evaluating validation preformance... 320/1000 (2.534791)
image 489:     
image 5316:     
image 2613:      
image 7935:      
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:      
evaluating validation preformance... 330/1000 (2.886736)
image 5179:    
image 3754:    
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    
image 3972:     
evaluating validation preformance... 340/1000 (2.629244)
image 4542:      
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:     
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.770505)
image 6881:    
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.125690)
image 2905:    
image 7814:     
image 56:     
image 5034:    
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.749372)
image 4351:     
image 1054:    UNK
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.825149)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:     
image 6255:     
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (3.035935)
image 828:    
image 2733:    
image 791:      
image 5408:    UNK
image 7842:     
image 1117:      
image 5817:      
image 1231:     
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.402875)
image 2627:    
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:     
image 7546:      
evaluating validation preformance... 410/1000 (2.292157)
image 4359:     
image 2372:     
image 4472:     
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:    
evaluating validation preformance... 420/1000 (2.440704)
image 30:    
image 5540:    
image 2445:    
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:   
image 2408:    
image 7706:    
evaluating validation preformance... 430/1000 (2.960685)
image 385:     
image 6938:     
image 2381:    
image 5796:    UNK
image 4010:     
image 3452:    
image 2023:     
image 3052:    
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.963370)
image 1731:      
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:      
image 4790:    
image 5855:     
image 4245:      
image 973:    
evaluating validation preformance... 450/1000 (2.373772)
image 2241:     
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:    
image 3682:     
evaluating validation preformance... 460/1000 (2.943569)
image 7979:     
image 1618:    
image 7608:    
image 6393:    
image 5100:     
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.422950)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    UNK
image 6114:      
evaluating validation preformance... 480/1000 (3.079873)
image 358:     
image 4663:     
image 5541:    
image 4485:    
image 2727:      
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.481178)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.713861)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:      
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.154790)
image 3246:      
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:     
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.835199)
image 6806:     
image 6464:    
image 1872:     
image 1575:     
image 3045:      
image 303:     
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.596164)
image 5619:     
image 4391:    
image 891:     
image 3072:    
image 7781:      
image 6163:     
image 7376:      
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.726716)
image 5292:      
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:    
image 4696:     
image 1183:      
image 1961:      
evaluating validation preformance... 550/1000 (2.809530)
image 5439:     
image 7981:     
image 6012:     
image 4732:     
image 6630:    
image 994:    
image 5079:    
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.793550)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK
image 7893:     
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.796492)
image 7936:     
image 5433:    
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:     
evaluating validation preformance... 580/1000 (2.583909)
image 2135:      
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.760880)
image 4420:     
image 1734:    
image 7239:     
image 7447:    
image 8009:     
image 4510:    
image 7495:     
image 2530:      
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.776448)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:    
image 3253:    
image 1773:    
image 4823:    UNK
evaluating validation preformance... 610/1000 (2.919541)
image 69:     
image 3465:    
image 6179:     
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.638612)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:    UNK
evaluating validation preformance... 630/1000 (2.616279)
image 8074:    
image 1904:    
image 7917:      
image 2394:     
image 4406:    UNK
image 883:     
image 559:    
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.634316)
image 5313:      
image 2377:     
image 6058:    
image 4661:     
image 2955:     
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:     
evaluating validation preformance... 650/1000 (2.747225)
image 8065:    
image 3577:    
image 3254:    
image 4562:    
image 5462:     
image 2824:     
image 1639:     
image 1475:     
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.804088)
image 5701:     
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:      
image 1972:     
evaluating validation preformance... 670/1000 (3.077706)
image 7877:    
image 6761:     
image 6880:     
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:    
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.225682)
image 1445:     
image 6841:     
image 2896:    
image 6947:     
image 4782:    
image 7669:      
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (3.081009)
image 6860:    
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:     
image 6225:    
image 3669:     
image 980:     
image 5362:      
evaluating validation preformance... 700/1000 (3.090060)
image 5343:    
image 68:     
image 3184:     
image 5637:      
image 2041:    
image 650:     
image 4911:     
image 34:     
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.663756)
image 7368:     
image 709:     
image 3197:    
image 5214:    
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.759573)
image 5729:     
image 6395:     
image 516:    
image 1026:    
image 2972:      
image 3005:    
image 1241:    
image 2743:    
image 3665:     
image 1290:    
evaluating validation preformance... 730/1000 (2.464456)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:    
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.610461)
image 2239:      
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.950676)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.076825)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:     
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.349076)
image 6220:     
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:      
image 2329:     
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (2.911106)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:     
image 3312:     
image 7824:      
image 2032:    
evaluating validation preformance... 790/1000 (3.426224)
image 5047:      
image 325:     
image 7626:    UNK
image 4552:     
image 983:    UNK
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.409361)
image 7288:     
image 7302:    
image 3055:    
image 5250:     
image 1158:      
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.588324)
image 614:    
image 7295:     
image 4110:     
image 5402:    
image 3060:    
image 1317:      
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (2.156252)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:    UNK
image 7147:    
image 6348:     
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.563714)
image 5107:    
image 3973:    
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.534652)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:     
image 5534:    
evaluating validation preformance... 850/1000 (3.064633)
image 4404:    
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:      
image 6261:     
image 2166:     
evaluating validation preformance... 860/1000 (3.011982)
image 4254:    
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:     
image 4002:     
evaluating validation preformance... 870/1000 (2.474824)
image 4934:     
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:     
image 5681:      
image 1824:     
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.757815)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (3.050183)
image 7485:     
image 6102:    
image 1001:    
image 7167:     
image 4168:     
image 187:    
image 7798:     
image 4813:    UNK
image 7753:    UNK
image 210:    
evaluating validation preformance... 900/1000 (3.630274)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:    
image 2398:     
image 7205:     
evaluating validation preformance... 910/1000 (2.401271)
image 1368:     
image 1925:     
image 5870:    
image 4915:     
image 3879:     
image 1002:    
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.727701)
image 7152:    
image 4559:     
image 7233:      
image 1341:     
image 5337:      
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.641608)
image 5636:     
image 7799:    
image 6025:    
image 6907:    
image 2507:     
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.767130)
image 5860:     
image 3275:     
image 1935:     
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (3.237586)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.963321)
image 4935:     
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.524724)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.927781)
image 7352:     
image 5113:    
image 7822:     
image 4858:    
image 658:     
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.645322)
image 5789:      
image 5606:     
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:     
image 2483:    
image 2591:     
image 7615:    
evaluating validation preformance... 1000/1000 (2.544404)
average loss on validation: 2.772
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3469057083129883
Cider scores: 0.49559899782720984
Read data: 0.32708168029785156
Cider scores: 0.5013966292095664
Read data: 0.26909947395324707
Cider scores: 0.5636490238813372
Read data: 0.22799396514892578
Cider scores: 0.49414780128206376
Read data: 0.19631099700927734
Cider scores: 0.49156613007960565
Read data: 0.17490530014038086
Cider scores: 0.39993238966337036
Read data: 0.19855356216430664
Cider scores: 0.48786511152099726
Read data: 0.17868804931640625
Cider scores: 0.5146805518558644
Read data: 0.17834711074829102
Cider scores: 0.41945592551868505
Read data: 0.1784992218017578
Cider scores: 0.5998335342066097
Read data: 0.23883390426635742
Cider scores: 0.5726808966338583
Read data: 0.1765608787536621
Cider scores: 0.4792035031501691
Read data: 0.17534232139587402
Cider scores: 0.5133522200471444
Read data: 0.17615461349487305
Cider scores: 0.5127215844163171
Read data: 0.18103313446044922
Cider scores: 0.5190545920453891
Read data: 0.16670489311218262
Cider scores: 0.5720075740985523
Read data: 0.16109919548034668
Cider scores: 0.40426349724142535
Read data: 0.16181445121765137
Cider scores: 0.572765433072378
Read data: 0.16376018524169922
Cider scores: 0.44652371982969136
Read data: 0.16332769393920898
Cider scores: 0.6113511154956872
Average cider score on test set: 0.509
End calculating cider score on TEST data set
===============================================
Read data: 0.16472268104553223
iter 6000 (epoch 9), train_loss = 2.623, time/batch = 0.023
Read data: 0.00010561943054199219
iter 6001 (epoch 10), train_loss = 2.591, time/batch = 0.023
Read data: 0.00010776519775390625
iter 6002 (epoch 10), train_loss = 2.580, time/batch = 0.019
Read data: 0.0001068115234375
iter 6003 (epoch 10), train_loss = 2.936, time/batch = 0.024
Read data: 0.00012135505676269531
iter 6004 (epoch 10), train_loss = 2.939, time/batch = 0.037
Read data: 0.00011897087097167969
iter 6005 (epoch 10), train_loss = 2.778, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 6006 (epoch 10), train_loss = 3.026, time/batch = 0.025
Read data: 0.0001289844512939453
iter 6007 (epoch 10), train_loss = 2.568, time/batch = 0.021
Read data: 0.000102996826171875
iter 6008 (epoch 10), train_loss = 2.658, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 6009 (epoch 10), train_loss = 2.973, time/batch = 0.022
Read data: 9.655952453613281e-05
iter 6010 (epoch 10), train_loss = 2.611, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 6011 (epoch 10), train_loss = 2.740, time/batch = 0.025
Read data: 0.0001347064971923828
iter 6012 (epoch 10), train_loss = 2.667, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 6013 (epoch 10), train_loss = 2.865, time/batch = 0.022
Read data: 9.608268737792969e-05
iter 6014 (epoch 10), train_loss = 3.407, time/batch = 0.025
Read data: 0.00016045570373535156
iter 6015 (epoch 10), train_loss = 2.902, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 6016 (epoch 10), train_loss = 2.763, time/batch = 0.028
Read data: 9.632110595703125e-05
iter 6017 (epoch 10), train_loss = 2.498, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 6018 (epoch 10), train_loss = 2.915, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 6019 (epoch 10), train_loss = 2.851, time/batch = 0.032
Read data: 0.00011777877807617188
iter 6020 (epoch 10), train_loss = 3.127, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 6021 (epoch 10), train_loss = 2.690, time/batch = 0.021
Read data: 0.000102996826171875
iter 6022 (epoch 10), train_loss = 2.960, time/batch = 0.032
Read data: 7.486343383789062e-05
iter 6023 (epoch 10), train_loss = 2.503, time/batch = 0.031
Read data: 8.392333984375e-05
iter 6024 (epoch 10), train_loss = 2.962, time/batch = 0.022
Read data: 0.0002262592315673828
iter 6025 (epoch 10), train_loss = 3.006, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 6026 (epoch 10), train_loss = 2.606, time/batch = 0.022
Read data: 7.176399230957031e-05
iter 6027 (epoch 10), train_loss = 2.537, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 6028 (epoch 10), train_loss = 3.170, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 6029 (epoch 10), train_loss = 2.685, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 6030 (epoch 10), train_loss = 2.727, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 6031 (epoch 10), train_loss = 2.503, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 6032 (epoch 10), train_loss = 2.304, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 6033 (epoch 10), train_loss = 3.026, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 6034 (epoch 10), train_loss = 3.354, time/batch = 0.023
Read data: 7.271766662597656e-05
iter 6035 (epoch 10), train_loss = 3.015, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 6036 (epoch 10), train_loss = 3.004, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 6037 (epoch 10), train_loss = 2.762, time/batch = 0.024
Read data: 9.1552734375e-05
iter 6038 (epoch 10), train_loss = 2.627, time/batch = 0.032
Read data: 7.319450378417969e-05
iter 6039 (epoch 10), train_loss = 2.711, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 6040 (epoch 10), train_loss = 3.104, time/batch = 0.027
Read data: 0.00010395050048828125
iter 6041 (epoch 10), train_loss = 2.792, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 6042 (epoch 10), train_loss = 2.318, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 6043 (epoch 10), train_loss = 2.569, time/batch = 0.029
Read data: 9.1552734375e-05
iter 6044 (epoch 10), train_loss = 2.994, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 6045 (epoch 10), train_loss = 2.826, time/batch = 0.020
Read data: 8.0108642578125e-05
iter 6046 (epoch 10), train_loss = 2.962, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 6047 (epoch 10), train_loss = 2.638, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 6048 (epoch 10), train_loss = 2.995, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 6049 (epoch 10), train_loss = 2.425, time/batch = 0.025
Read data: 0.00021386146545410156
iter 6050 (epoch 10), train_loss = 3.090, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 6051 (epoch 10), train_loss = 2.701, time/batch = 0.022
Read data: 7.867813110351562e-05
iter 6052 (epoch 10), train_loss = 2.707, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 6053 (epoch 10), train_loss = 2.730, time/batch = 0.024
Read data: 0.00016570091247558594
iter 6054 (epoch 10), train_loss = 2.610, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 6055 (epoch 10), train_loss = 2.909, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 6056 (epoch 10), train_loss = 2.773, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 6057 (epoch 10), train_loss = 2.867, time/batch = 0.024
Read data: 0.0001595020294189453
iter 6058 (epoch 10), train_loss = 2.673, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 6059 (epoch 10), train_loss = 3.195, time/batch = 0.032
Read data: 9.465217590332031e-05
iter 6060 (epoch 10), train_loss = 2.959, time/batch = 0.025
Read data: 7.62939453125e-05
iter 6061 (epoch 10), train_loss = 2.888, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 6062 (epoch 10), train_loss = 2.437, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 6063 (epoch 10), train_loss = 2.598, time/batch = 0.022
Read data: 0.00017142295837402344
iter 6064 (epoch 10), train_loss = 2.584, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 6065 (epoch 10), train_loss = 2.946, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 6066 (epoch 10), train_loss = 3.160, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 6067 (epoch 10), train_loss = 3.185, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 6068 (epoch 10), train_loss = 2.516, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 6069 (epoch 10), train_loss = 2.786, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 6070 (epoch 10), train_loss = 2.935, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 6071 (epoch 10), train_loss = 2.581, time/batch = 0.027
Read data: 0.00010323524475097656
iter 6072 (epoch 10), train_loss = 3.070, time/batch = 0.036
Read data: 7.963180541992188e-05
iter 6073 (epoch 10), train_loss = 2.880, time/batch = 0.022
Read data: 7.843971252441406e-05
iter 6074 (epoch 10), train_loss = 2.716, time/batch = 0.028
Read data: 7.510185241699219e-05
iter 6075 (epoch 10), train_loss = 2.822, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 6076 (epoch 10), train_loss = 2.964, time/batch = 0.037
Read data: 0.00014853477478027344
iter 6077 (epoch 10), train_loss = 2.711, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 6078 (epoch 10), train_loss = 3.196, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 6079 (epoch 10), train_loss = 2.502, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 6080 (epoch 10), train_loss = 2.827, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 6081 (epoch 10), train_loss = 2.463, time/batch = 0.026
Read data: 0.00012946128845214844
iter 6082 (epoch 10), train_loss = 2.548, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 6083 (epoch 10), train_loss = 3.078, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 6084 (epoch 10), train_loss = 2.975, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 6085 (epoch 10), train_loss = 2.388, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 6086 (epoch 10), train_loss = 2.782, time/batch = 0.026
Read data: 7.390975952148438e-05
iter 6087 (epoch 10), train_loss = 2.562, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 6088 (epoch 10), train_loss = 3.205, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 6089 (epoch 10), train_loss = 2.689, time/batch = 0.024
Read data: 0.00014925003051757812
iter 6090 (epoch 10), train_loss = 2.812, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 6091 (epoch 10), train_loss = 2.634, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 6092 (epoch 10), train_loss = 3.143, time/batch = 0.036
Read data: 8.249282836914062e-05
iter 6093 (epoch 10), train_loss = 2.940, time/batch = 0.036
Read data: 8.368492126464844e-05
iter 6094 (epoch 10), train_loss = 3.009, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 6095 (epoch 10), train_loss = 3.263, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 6096 (epoch 10), train_loss = 2.666, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 6097 (epoch 10), train_loss = 3.155, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 6098 (epoch 10), train_loss = 2.607, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 6099 (epoch 10), train_loss = 2.442, time/batch = 0.022
Read data: 0.0002655982971191406
iter 6100 (epoch 10), train_loss = 2.869, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 6101 (epoch 10), train_loss = 2.921, time/batch = 0.031
Read data: 7.724761962890625e-05
iter 6102 (epoch 10), train_loss = 2.554, time/batch = 0.022
Read data: 0.00010251998901367188
iter 6103 (epoch 10), train_loss = 3.271, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 6104 (epoch 10), train_loss = 3.029, time/batch = 0.028
Read data: 9.393692016601562e-05
iter 6105 (epoch 10), train_loss = 2.857, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 6106 (epoch 10), train_loss = 2.654, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 6107 (epoch 10), train_loss = 2.963, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6108 (epoch 10), train_loss = 2.290, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 6109 (epoch 10), train_loss = 2.021, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 6110 (epoch 10), train_loss = 2.778, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 6111 (epoch 10), train_loss = 2.971, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 6112 (epoch 10), train_loss = 2.545, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 6113 (epoch 10), train_loss = 2.720, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 6114 (epoch 10), train_loss = 2.560, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 6115 (epoch 10), train_loss = 2.918, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 6116 (epoch 10), train_loss = 2.847, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 6117 (epoch 10), train_loss = 2.529, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6118 (epoch 10), train_loss = 2.321, time/batch = 0.023
Read data: 7.534027099609375e-05
iter 6119 (epoch 10), train_loss = 2.805, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 6120 (epoch 10), train_loss = 3.010, time/batch = 0.024
Read data: 7.557868957519531e-05
iter 6121 (epoch 10), train_loss = 2.473, time/batch = 0.020
Read data: 8.797645568847656e-05
iter 6122 (epoch 10), train_loss = 2.688, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 6123 (epoch 10), train_loss = 3.125, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 6124 (epoch 10), train_loss = 2.823, time/batch = 0.034
Read data: 0.0002484321594238281
iter 6125 (epoch 10), train_loss = 2.655, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 6126 (epoch 10), train_loss = 2.500, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 6127 (epoch 10), train_loss = 2.552, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 6128 (epoch 10), train_loss = 2.579, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 6129 (epoch 10), train_loss = 3.027, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 6130 (epoch 10), train_loss = 2.574, time/batch = 0.025
Read data: 7.414817810058594e-05
iter 6131 (epoch 10), train_loss = 2.686, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 6132 (epoch 10), train_loss = 2.333, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 6133 (epoch 10), train_loss = 2.967, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 6134 (epoch 10), train_loss = 2.688, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 6135 (epoch 10), train_loss = 2.904, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 6136 (epoch 10), train_loss = 2.891, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 6137 (epoch 10), train_loss = 2.514, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 6138 (epoch 10), train_loss = 2.789, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 6139 (epoch 10), train_loss = 3.343, time/batch = 0.032
Read data: 7.796287536621094e-05
iter 6140 (epoch 10), train_loss = 2.915, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 6141 (epoch 10), train_loss = 2.315, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6142 (epoch 10), train_loss = 2.582, time/batch = 0.028
Read data: 7.486343383789062e-05
iter 6143 (epoch 10), train_loss = 2.901, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 6144 (epoch 10), train_loss = 2.635, time/batch = 0.026
Read data: 0.00010037422180175781
iter 6145 (epoch 10), train_loss = 2.547, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 6146 (epoch 10), train_loss = 2.766, time/batch = 0.031
Read data: 7.677078247070312e-05
iter 6147 (epoch 10), train_loss = 2.737, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 6148 (epoch 10), train_loss = 2.789, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 6149 (epoch 10), train_loss = 2.245, time/batch = 0.033
Read data: 0.0002639293670654297
iter 6150 (epoch 10), train_loss = 2.848, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 6151 (epoch 10), train_loss = 2.430, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6152 (epoch 10), train_loss = 2.745, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 6153 (epoch 10), train_loss = 2.724, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 6154 (epoch 10), train_loss = 2.897, time/batch = 0.029
Read data: 8.916854858398438e-05
iter 6155 (epoch 10), train_loss = 2.610, time/batch = 0.031
Read data: 0.00010204315185546875
iter 6156 (epoch 10), train_loss = 3.182, time/batch = 0.024
Read data: 0.00012445449829101562
iter 6157 (epoch 10), train_loss = 2.806, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 6158 (epoch 10), train_loss = 2.949, time/batch = 0.030
Read data: 7.62939453125e-05
iter 6159 (epoch 10), train_loss = 2.566, time/batch = 0.020
Read data: 8.273124694824219e-05
iter 6160 (epoch 10), train_loss = 2.814, time/batch = 0.029
Read data: 9.632110595703125e-05
iter 6161 (epoch 10), train_loss = 2.522, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 6162 (epoch 10), train_loss = 2.740, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 6163 (epoch 10), train_loss = 2.940, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 6164 (epoch 10), train_loss = 2.398, time/batch = 0.024
Read data: 0.00014328956604003906
iter 6165 (epoch 10), train_loss = 2.857, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 6166 (epoch 10), train_loss = 2.761, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 6167 (epoch 10), train_loss = 2.691, time/batch = 0.032
Read data: 7.581710815429688e-05
iter 6168 (epoch 10), train_loss = 2.817, time/batch = 0.024
Read data: 9.72747802734375e-05
iter 6169 (epoch 10), train_loss = 2.578, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 6170 (epoch 10), train_loss = 2.552, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 6171 (epoch 10), train_loss = 2.732, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 6172 (epoch 10), train_loss = 2.761, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 6173 (epoch 10), train_loss = 3.119, time/batch = 0.028
Read data: 0.00012302398681640625
iter 6174 (epoch 10), train_loss = 2.984, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 6175 (epoch 10), train_loss = 2.967, time/batch = 0.020
Read data: 8.034706115722656e-05
iter 6176 (epoch 10), train_loss = 2.667, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 6177 (epoch 10), train_loss = 3.059, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 6178 (epoch 10), train_loss = 2.303, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 6179 (epoch 10), train_loss = 2.337, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 6180 (epoch 10), train_loss = 2.771, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 6181 (epoch 10), train_loss = 2.544, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 6182 (epoch 10), train_loss = 3.082, time/batch = 0.031
Read data: 9.632110595703125e-05
iter 6183 (epoch 10), train_loss = 3.039, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 6184 (epoch 10), train_loss = 2.846, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 6185 (epoch 10), train_loss = 2.548, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 6186 (epoch 10), train_loss = 2.873, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 6187 (epoch 10), train_loss = 2.999, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 6188 (epoch 10), train_loss = 3.080, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 6189 (epoch 10), train_loss = 2.241, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 6190 (epoch 10), train_loss = 3.023, time/batch = 0.032
Read data: 7.605552673339844e-05
iter 6191 (epoch 10), train_loss = 2.525, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 6192 (epoch 10), train_loss = 2.712, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 6193 (epoch 10), train_loss = 2.460, time/batch = 0.035
Read data: 8.034706115722656e-05
iter 6194 (epoch 10), train_loss = 2.807, time/batch = 0.030
Read data: 9.012222290039062e-05
iter 6195 (epoch 10), train_loss = 2.776, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 6196 (epoch 10), train_loss = 3.065, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 6197 (epoch 10), train_loss = 2.825, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 6198 (epoch 10), train_loss = 2.744, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 6199 (epoch 10), train_loss = 2.870, time/batch = 0.024
Read data: 0.00025081634521484375
iter 6200 (epoch 10), train_loss = 2.618, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 6201 (epoch 10), train_loss = 2.805, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 6202 (epoch 10), train_loss = 3.012, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 6203 (epoch 10), train_loss = 2.788, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 6204 (epoch 10), train_loss = 2.337, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 6205 (epoch 10), train_loss = 2.883, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 6206 (epoch 10), train_loss = 3.027, time/batch = 0.026
Read data: 9.1552734375e-05
iter 6207 (epoch 10), train_loss = 2.815, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 6208 (epoch 10), train_loss = 2.991, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 6209 (epoch 10), train_loss = 3.116, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 6210 (epoch 10), train_loss = 2.618, time/batch = 0.027
Read data: 0.0016329288482666016
iter 6211 (epoch 10), train_loss = 2.786, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 6212 (epoch 10), train_loss = 2.710, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 6213 (epoch 10), train_loss = 3.044, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 6214 (epoch 10), train_loss = 3.038, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 6215 (epoch 10), train_loss = 3.028, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 6216 (epoch 10), train_loss = 2.794, time/batch = 0.034
Read data: 8.344650268554688e-05
iter 6217 (epoch 10), train_loss = 2.759, time/batch = 0.028
Read data: 0.00017261505126953125
iter 6218 (epoch 10), train_loss = 3.177, time/batch = 0.025
Read data: 0.0001735687255859375
iter 6219 (epoch 10), train_loss = 2.582, time/batch = 0.033
Read data: 7.82012939453125e-05
iter 6220 (epoch 10), train_loss = 2.861, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 6221 (epoch 10), train_loss = 2.441, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 6222 (epoch 10), train_loss = 2.830, time/batch = 0.028
Read data: 0.00013256072998046875
iter 6223 (epoch 10), train_loss = 2.923, time/batch = 0.020
Read data: 8.106231689453125e-05
iter 6224 (epoch 10), train_loss = 3.147, time/batch = 0.022
Read data: 0.0002872943878173828
iter 6225 (epoch 10), train_loss = 3.050, time/batch = 0.035
Read data: 7.677078247070312e-05
iter 6226 (epoch 10), train_loss = 2.497, time/batch = 0.023
Read data: 9.1552734375e-05
iter 6227 (epoch 10), train_loss = 3.312, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 6228 (epoch 10), train_loss = 2.770, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 6229 (epoch 10), train_loss = 2.840, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 6230 (epoch 10), train_loss = 2.930, time/batch = 0.026
Read data: 0.000118255615234375
iter 6231 (epoch 10), train_loss = 2.961, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 6232 (epoch 10), train_loss = 2.671, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 6233 (epoch 10), train_loss = 2.671, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 6234 (epoch 10), train_loss = 2.915, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 6235 (epoch 10), train_loss = 2.971, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 6236 (epoch 10), train_loss = 2.633, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 6237 (epoch 10), train_loss = 2.720, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 6238 (epoch 10), train_loss = 2.550, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 6239 (epoch 10), train_loss = 2.649, time/batch = 0.026
Read data: 8.392333984375e-05
iter 6240 (epoch 10), train_loss = 3.428, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 6241 (epoch 10), train_loss = 2.762, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 6242 (epoch 10), train_loss = 2.921, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 6243 (epoch 10), train_loss = 2.729, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 6244 (epoch 10), train_loss = 2.881, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 6245 (epoch 10), train_loss = 3.295, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 6246 (epoch 10), train_loss = 2.675, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 6247 (epoch 10), train_loss = 2.760, time/batch = 0.022
Read data: 9.298324584960938e-05
iter 6248 (epoch 10), train_loss = 2.407, time/batch = 0.020
Read data: 9.322166442871094e-05
iter 6249 (epoch 10), train_loss = 2.986, time/batch = 0.020
Read data: 0.0002510547637939453
iter 6250 (epoch 10), train_loss = 2.526, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 6251 (epoch 10), train_loss = 2.966, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 6252 (epoch 10), train_loss = 2.999, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 6253 (epoch 10), train_loss = 2.678, time/batch = 0.024
Read data: 0.00015044212341308594
iter 6254 (epoch 10), train_loss = 2.660, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 6255 (epoch 10), train_loss = 2.863, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 6256 (epoch 10), train_loss = 2.402, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 6257 (epoch 10), train_loss = 2.791, time/batch = 0.026
Read data: 0.0021948814392089844
iter 6258 (epoch 10), train_loss = 2.297, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 6259 (epoch 10), train_loss = 2.817, time/batch = 0.034
Read data: 0.00012683868408203125
iter 6260 (epoch 10), train_loss = 2.863, time/batch = 0.027
Read data: 0.00013971328735351562
iter 6261 (epoch 10), train_loss = 2.939, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 6262 (epoch 10), train_loss = 2.875, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 6263 (epoch 10), train_loss = 2.657, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 6264 (epoch 10), train_loss = 3.044, time/batch = 0.028
Read data: 0.0001647472381591797
iter 6265 (epoch 10), train_loss = 2.904, time/batch = 0.026
Read data: 0.000156402587890625
iter 6266 (epoch 10), train_loss = 3.083, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 6267 (epoch 10), train_loss = 2.577, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 6268 (epoch 10), train_loss = 2.758, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 6269 (epoch 10), train_loss = 3.151, time/batch = 0.031
Read data: 0.00011229515075683594
iter 6270 (epoch 10), train_loss = 2.784, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 6271 (epoch 10), train_loss = 3.118, time/batch = 0.028
Read data: 8.392333984375e-05
iter 6272 (epoch 10), train_loss = 2.542, time/batch = 0.029
Read data: 0.00011110305786132812
iter 6273 (epoch 10), train_loss = 2.690, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6274 (epoch 10), train_loss = 3.031, time/batch = 0.024
Read data: 7.581710815429688e-05
iter 6275 (epoch 10), train_loss = 2.620, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 6276 (epoch 10), train_loss = 2.798, time/batch = 0.030
Read data: 0.0001537799835205078
iter 6277 (epoch 10), train_loss = 2.715, time/batch = 0.023
Read data: 0.00015020370483398438
iter 6278 (epoch 10), train_loss = 2.564, time/batch = 0.024
Read data: 0.0001277923583984375
iter 6279 (epoch 10), train_loss = 3.062, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 6280 (epoch 10), train_loss = 2.516, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 6281 (epoch 10), train_loss = 2.674, time/batch = 0.035
Read data: 7.677078247070312e-05
iter 6282 (epoch 10), train_loss = 3.325, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 6283 (epoch 10), train_loss = 2.984, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6284 (epoch 10), train_loss = 2.262, time/batch = 0.026
Read data: 0.00015354156494140625
iter 6285 (epoch 10), train_loss = 2.785, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 6286 (epoch 10), train_loss = 2.990, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 6287 (epoch 10), train_loss = 2.659, time/batch = 0.029
Read data: 7.581710815429688e-05
iter 6288 (epoch 10), train_loss = 2.747, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 6289 (epoch 10), train_loss = 2.879, time/batch = 0.020
Read data: 0.00021004676818847656
iter 6290 (epoch 10), train_loss = 3.284, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 6291 (epoch 10), train_loss = 2.532, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 6292 (epoch 10), train_loss = 3.254, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 6293 (epoch 10), train_loss = 2.415, time/batch = 0.027
Read data: 7.534027099609375e-05
iter 6294 (epoch 10), train_loss = 2.836, time/batch = 0.025
Read data: 7.43865966796875e-05
iter 6295 (epoch 10), train_loss = 2.774, time/batch = 0.023
Read data: 0.00016045570373535156
iter 6296 (epoch 10), train_loss = 2.954, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 6297 (epoch 10), train_loss = 2.839, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 6298 (epoch 10), train_loss = 2.289, time/batch = 0.032
Read data: 7.510185241699219e-05
iter 6299 (epoch 10), train_loss = 2.772, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 6300 (epoch 10), train_loss = 2.675, time/batch = 0.026
Read data: 0.00014257431030273438
iter 6301 (epoch 10), train_loss = 3.078, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 6302 (epoch 10), train_loss = 2.618, time/batch = 0.028
Read data: 7.557868957519531e-05
iter 6303 (epoch 10), train_loss = 3.113, time/batch = 0.028
Read data: 7.605552673339844e-05
iter 6304 (epoch 10), train_loss = 2.818, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 6305 (epoch 10), train_loss = 2.791, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6306 (epoch 10), train_loss = 3.068, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 6307 (epoch 10), train_loss = 2.856, time/batch = 0.033
Read data: 8.273124694824219e-05
iter 6308 (epoch 10), train_loss = 2.881, time/batch = 0.032
Read data: 0.00012111663818359375
iter 6309 (epoch 10), train_loss = 2.837, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 6310 (epoch 10), train_loss = 2.683, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6311 (epoch 10), train_loss = 2.813, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 6312 (epoch 10), train_loss = 2.518, time/batch = 0.022
Read data: 7.581710815429688e-05
iter 6313 (epoch 10), train_loss = 2.446, time/batch = 0.034
Read data: 7.557868957519531e-05
iter 6314 (epoch 10), train_loss = 3.053, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 6315 (epoch 10), train_loss = 2.764, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 6316 (epoch 10), train_loss = 2.704, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 6317 (epoch 10), train_loss = 2.316, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 6318 (epoch 10), train_loss = 2.915, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 6319 (epoch 10), train_loss = 2.953, time/batch = 0.027
Read data: 0.00016021728515625
iter 6320 (epoch 10), train_loss = 2.676, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 6321 (epoch 10), train_loss = 2.800, time/batch = 0.032
Read data: 7.557868957519531e-05
iter 6322 (epoch 10), train_loss = 2.397, time/batch = 0.024
Read data: 7.605552673339844e-05
iter 6323 (epoch 10), train_loss = 2.940, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 6324 (epoch 10), train_loss = 2.730, time/batch = 0.031
Read data: 0.00022220611572265625
iter 6325 (epoch 10), train_loss = 2.888, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 6326 (epoch 10), train_loss = 2.859, time/batch = 0.029
Read data: 7.486343383789062e-05
iter 6327 (epoch 10), train_loss = 3.519, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 6328 (epoch 10), train_loss = 2.853, time/batch = 0.030
Read data: 8.702278137207031e-05
iter 6329 (epoch 10), train_loss = 2.891, time/batch = 0.029
Read data: 0.00011181831359863281
iter 6330 (epoch 10), train_loss = 2.878, time/batch = 0.030
Read data: 0.00010728836059570312
iter 6331 (epoch 10), train_loss = 2.242, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 6332 (epoch 10), train_loss = 3.044, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 6333 (epoch 10), train_loss = 2.826, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 6334 (epoch 10), train_loss = 2.291, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 6335 (epoch 10), train_loss = 2.699, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6336 (epoch 10), train_loss = 2.720, time/batch = 0.025
Read data: 0.00015115737915039062
iter 6337 (epoch 10), train_loss = 2.503, time/batch = 0.025
Read data: 0.00020265579223632812
iter 6338 (epoch 10), train_loss = 3.256, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 6339 (epoch 10), train_loss = 3.216, time/batch = 0.033
Read data: 7.748603820800781e-05
iter 6340 (epoch 10), train_loss = 2.928, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 6341 (epoch 10), train_loss = 3.011, time/batch = 0.023
Read data: 7.557868957519531e-05
iter 6342 (epoch 10), train_loss = 2.942, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 6343 (epoch 10), train_loss = 2.771, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 6344 (epoch 10), train_loss = 2.945, time/batch = 0.031
Read data: 7.557868957519531e-05
iter 6345 (epoch 10), train_loss = 2.371, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 6346 (epoch 10), train_loss = 2.432, time/batch = 0.026
Read data: 8.392333984375e-05
iter 6347 (epoch 10), train_loss = 2.724, time/batch = 0.022
Read data: 0.00015354156494140625
iter 6348 (epoch 10), train_loss = 3.045, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 6349 (epoch 10), train_loss = 2.531, time/batch = 0.033
Read data: 0.00021767616271972656
iter 6350 (epoch 10), train_loss = 2.561, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 6351 (epoch 10), train_loss = 2.531, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 6352 (epoch 10), train_loss = 2.556, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 6353 (epoch 10), train_loss = 2.815, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 6354 (epoch 10), train_loss = 2.696, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 6355 (epoch 10), train_loss = 2.667, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 6356 (epoch 10), train_loss = 2.504, time/batch = 0.020
Read data: 9.131431579589844e-05
iter 6357 (epoch 10), train_loss = 3.185, time/batch = 0.029
Read data: 0.00015401840209960938
iter 6358 (epoch 10), train_loss = 2.871, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 6359 (epoch 10), train_loss = 2.761, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 6360 (epoch 10), train_loss = 3.022, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 6361 (epoch 10), train_loss = 2.954, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 6362 (epoch 10), train_loss = 3.116, time/batch = 0.028
Read data: 0.00010275840759277344
iter 6363 (epoch 10), train_loss = 2.954, time/batch = 0.024
Read data: 0.00015473365783691406
iter 6364 (epoch 10), train_loss = 2.488, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 6365 (epoch 10), train_loss = 2.861, time/batch = 0.026
Read data: 0.00010418891906738281
iter 6366 (epoch 10), train_loss = 2.842, time/batch = 0.026
Read data: 0.0001609325408935547
iter 6367 (epoch 10), train_loss = 2.795, time/batch = 0.020
Read data: 8.96453857421875e-05
iter 6368 (epoch 10), train_loss = 2.665, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 6369 (epoch 10), train_loss = 3.003, time/batch = 0.021
Read data: 7.534027099609375e-05
iter 6370 (epoch 10), train_loss = 2.933, time/batch = 0.027
Read data: 0.00015044212341308594
iter 6371 (epoch 10), train_loss = 2.315, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 6372 (epoch 10), train_loss = 3.118, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 6373 (epoch 10), train_loss = 2.599, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 6374 (epoch 10), train_loss = 2.971, time/batch = 0.030
Read data: 7.605552673339844e-05
iter 6375 (epoch 10), train_loss = 2.854, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 6376 (epoch 10), train_loss = 2.570, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 6377 (epoch 10), train_loss = 2.905, time/batch = 0.022
Read data: 7.677078247070312e-05
iter 6378 (epoch 10), train_loss = 2.461, time/batch = 0.027
Read data: 0.00014781951904296875
iter 6379 (epoch 10), train_loss = 2.970, time/batch = 0.027
Read data: 7.534027099609375e-05
iter 6380 (epoch 10), train_loss = 2.400, time/batch = 0.024
Read data: 0.0001583099365234375
iter 6381 (epoch 10), train_loss = 2.243, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 6382 (epoch 10), train_loss = 2.320, time/batch = 0.022
Read data: 7.510185241699219e-05
iter 6383 (epoch 10), train_loss = 2.779, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 6384 (epoch 10), train_loss = 3.013, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 6385 (epoch 10), train_loss = 2.746, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6386 (epoch 10), train_loss = 2.364, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 6387 (epoch 10), train_loss = 2.687, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 6388 (epoch 10), train_loss = 3.152, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 6389 (epoch 10), train_loss = 2.827, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 6390 (epoch 10), train_loss = 3.398, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 6391 (epoch 10), train_loss = 2.908, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 6392 (epoch 10), train_loss = 2.732, time/batch = 0.033
Read data: 7.581710815429688e-05
iter 6393 (epoch 10), train_loss = 2.754, time/batch = 0.024
Read data: 7.62939453125e-05
iter 6394 (epoch 10), train_loss = 2.500, time/batch = 0.023
Read data: 7.605552673339844e-05
iter 6395 (epoch 10), train_loss = 3.186, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 6396 (epoch 10), train_loss = 2.572, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 6397 (epoch 10), train_loss = 2.889, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 6398 (epoch 10), train_loss = 3.010, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 6399 (epoch 10), train_loss = 2.568, time/batch = 0.027
Read data: 0.0002129077911376953
iter 6400 (epoch 10), train_loss = 2.655, time/batch = 0.025
Read data: 0.00016021728515625
iter 6401 (epoch 10), train_loss = 2.742, time/batch = 0.025
Read data: 0.0001552104949951172
iter 6402 (epoch 10), train_loss = 2.861, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 6403 (epoch 10), train_loss = 2.807, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 6404 (epoch 10), train_loss = 2.744, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 6405 (epoch 10), train_loss = 2.877, time/batch = 0.026
Read data: 0.00011944770812988281
iter 6406 (epoch 10), train_loss = 2.740, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 6407 (epoch 10), train_loss = 2.873, time/batch = 0.023
Read data: 7.581710815429688e-05
iter 6408 (epoch 10), train_loss = 2.909, time/batch = 0.025
Read data: 0.0001575946807861328
iter 6409 (epoch 10), train_loss = 2.844, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 6410 (epoch 10), train_loss = 3.169, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 6411 (epoch 10), train_loss = 2.330, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 6412 (epoch 10), train_loss = 2.759, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 6413 (epoch 10), train_loss = 2.807, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 6414 (epoch 10), train_loss = 2.699, time/batch = 0.024
Read data: 0.00010704994201660156
iter 6415 (epoch 10), train_loss = 3.255, time/batch = 0.025
Read data: 7.486343383789062e-05
iter 6416 (epoch 10), train_loss = 3.077, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 6417 (epoch 10), train_loss = 3.348, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 6418 (epoch 10), train_loss = 2.687, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6419 (epoch 10), train_loss = 3.011, time/batch = 0.024
Read data: 0.00015211105346679688
iter 6420 (epoch 10), train_loss = 2.912, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 6421 (epoch 10), train_loss = 2.465, time/batch = 0.027
Read data: 7.557868957519531e-05
iter 6422 (epoch 10), train_loss = 3.129, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 6423 (epoch 10), train_loss = 3.061, time/batch = 0.024
Read data: 7.43865966796875e-05
iter 6424 (epoch 10), train_loss = 2.772, time/batch = 0.027
Read data: 0.0002200603485107422
iter 6425 (epoch 10), train_loss = 2.923, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 6426 (epoch 10), train_loss = 2.835, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 6427 (epoch 10), train_loss = 2.415, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 6428 (epoch 10), train_loss = 2.554, time/batch = 0.024
Read data: 7.62939453125e-05
iter 6429 (epoch 10), train_loss = 2.815, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 6430 (epoch 10), train_loss = 2.601, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 6431 (epoch 10), train_loss = 2.901, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6432 (epoch 10), train_loss = 2.788, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 6433 (epoch 10), train_loss = 2.652, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 6434 (epoch 10), train_loss = 2.968, time/batch = 0.020
Read data: 8.559226989746094e-05
iter 6435 (epoch 10), train_loss = 3.001, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6436 (epoch 10), train_loss = 2.987, time/batch = 0.031
Read data: 0.0001518726348876953
iter 6437 (epoch 10), train_loss = 3.114, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 6438 (epoch 10), train_loss = 2.920, time/batch = 0.024
Read data: 7.62939453125e-05
iter 6439 (epoch 10), train_loss = 3.150, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 6440 (epoch 10), train_loss = 2.490, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 6441 (epoch 10), train_loss = 2.745, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 6442 (epoch 10), train_loss = 2.719, time/batch = 0.027
Read data: 9.1552734375e-05
iter 6443 (epoch 10), train_loss = 2.618, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 6444 (epoch 10), train_loss = 3.146, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 6445 (epoch 10), train_loss = 2.788, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 6446 (epoch 10), train_loss = 2.942, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 6447 (epoch 10), train_loss = 3.051, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 6448 (epoch 10), train_loss = 2.826, time/batch = 0.021
Read data: 0.00012159347534179688
iter 6449 (epoch 10), train_loss = 2.809, time/batch = 0.032
Read data: 0.00021600723266601562
iter 6450 (epoch 10), train_loss = 2.854, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 6451 (epoch 10), train_loss = 2.866, time/batch = 0.024
Read data: 7.62939453125e-05
iter 6452 (epoch 10), train_loss = 2.550, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 6453 (epoch 10), train_loss = 2.542, time/batch = 0.020
Read data: 8.797645568847656e-05
iter 6454 (epoch 10), train_loss = 2.481, time/batch = 0.025
Read data: 0.00012373924255371094
iter 6455 (epoch 10), train_loss = 2.713, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 6456 (epoch 10), train_loss = 2.743, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 6457 (epoch 10), train_loss = 2.703, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 6458 (epoch 10), train_loss = 2.688, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 6459 (epoch 10), train_loss = 2.645, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 6460 (epoch 10), train_loss = 2.820, time/batch = 0.040
Read data: 8.058547973632812e-05
iter 6461 (epoch 10), train_loss = 2.491, time/batch = 0.022
Read data: 0.0001556873321533203
iter 6462 (epoch 10), train_loss = 3.053, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 6463 (epoch 10), train_loss = 2.818, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 6464 (epoch 10), train_loss = 2.707, time/batch = 0.020
Read data: 0.00011682510375976562
iter 6465 (epoch 10), train_loss = 2.891, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 6466 (epoch 10), train_loss = 2.492, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 6467 (epoch 10), train_loss = 2.668, time/batch = 0.034
Read data: 8.034706115722656e-05
iter 6468 (epoch 10), train_loss = 3.084, time/batch = 0.022
Read data: 0.00015592575073242188
iter 6469 (epoch 10), train_loss = 2.537, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 6470 (epoch 10), train_loss = 2.540, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 6471 (epoch 10), train_loss = 2.740, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 6472 (epoch 10), train_loss = 2.692, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 6473 (epoch 10), train_loss = 2.920, time/batch = 0.029
Read data: 7.605552673339844e-05
iter 6474 (epoch 10), train_loss = 3.010, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 6475 (epoch 10), train_loss = 2.843, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 6476 (epoch 10), train_loss = 2.987, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 6477 (epoch 10), train_loss = 2.833, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 6478 (epoch 10), train_loss = 2.888, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 6479 (epoch 10), train_loss = 2.879, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 6480 (epoch 10), train_loss = 2.877, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 6481 (epoch 10), train_loss = 2.307, time/batch = 0.022
Read data: 0.00015664100646972656
iter 6482 (epoch 10), train_loss = 2.728, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 6483 (epoch 10), train_loss = 2.451, time/batch = 0.030
Read data: 0.00014591217041015625
iter 6484 (epoch 10), train_loss = 2.581, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 6485 (epoch 10), train_loss = 2.677, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 6486 (epoch 10), train_loss = 2.710, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 6487 (epoch 10), train_loss = 2.751, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 6488 (epoch 10), train_loss = 2.599, time/batch = 0.031
Read data: 7.581710815429688e-05
iter 6489 (epoch 10), train_loss = 2.472, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 6490 (epoch 10), train_loss = 2.914, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 6491 (epoch 10), train_loss = 3.322, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 6492 (epoch 10), train_loss = 2.796, time/batch = 0.035
Read data: 0.00011730194091796875
iter 6493 (epoch 10), train_loss = 2.743, time/batch = 0.034
Read data: 0.00014472007751464844
iter 6494 (epoch 10), train_loss = 2.682, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 6495 (epoch 10), train_loss = 2.454, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 6496 (epoch 10), train_loss = 2.394, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 6497 (epoch 10), train_loss = 2.477, time/batch = 0.029
Read data: 0.00014591217041015625
iter 6498 (epoch 10), train_loss = 2.486, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 6499 (epoch 10), train_loss = 2.906, time/batch = 0.026
Read data: 0.00021719932556152344
iter 6500 (epoch 10), train_loss = 2.858, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 6501 (epoch 10), train_loss = 3.251, time/batch = 0.025
Read data: 0.00015735626220703125
iter 6502 (epoch 10), train_loss = 2.276, time/batch = 0.025
Read data: 0.0001659393310546875
iter 6503 (epoch 10), train_loss = 3.065, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 6504 (epoch 10), train_loss = 3.482, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 6505 (epoch 10), train_loss = 2.921, time/batch = 0.022
Read data: 7.62939453125e-05
iter 6506 (epoch 10), train_loss = 2.802, time/batch = 0.020
Read data: 7.748603820800781e-05
iter 6507 (epoch 10), train_loss = 2.869, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 6508 (epoch 10), train_loss = 2.610, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 6509 (epoch 10), train_loss = 3.067, time/batch = 0.037
Read data: 7.724761962890625e-05
iter 6510 (epoch 10), train_loss = 2.544, time/batch = 0.026
Read data: 7.486343383789062e-05
iter 6511 (epoch 10), train_loss = 2.810, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 6512 (epoch 10), train_loss = 2.475, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 6513 (epoch 10), train_loss = 2.493, time/batch = 0.022
Read data: 7.867813110351562e-05
iter 6514 (epoch 10), train_loss = 2.706, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 6515 (epoch 10), train_loss = 3.131, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 6516 (epoch 10), train_loss = 2.526, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 6517 (epoch 10), train_loss = 2.639, time/batch = 0.022
Read data: 7.724761962890625e-05
iter 6518 (epoch 10), train_loss = 2.585, time/batch = 0.025
Read data: 7.414817810058594e-05
iter 6519 (epoch 10), train_loss = 2.810, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 6520 (epoch 10), train_loss = 3.025, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6521 (epoch 10), train_loss = 2.832, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 6522 (epoch 10), train_loss = 2.836, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 6523 (epoch 10), train_loss = 3.044, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 6524 (epoch 10), train_loss = 3.092, time/batch = 0.027
Read data: 0.0003094673156738281
iter 6525 (epoch 10), train_loss = 2.802, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 6526 (epoch 10), train_loss = 2.817, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 6527 (epoch 10), train_loss = 2.454, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 6528 (epoch 10), train_loss = 2.586, time/batch = 0.025
Read data: 0.00010013580322265625
iter 6529 (epoch 10), train_loss = 3.004, time/batch = 0.027
Read data: 0.000102996826171875
iter 6530 (epoch 10), train_loss = 2.681, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 6531 (epoch 10), train_loss = 2.649, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 6532 (epoch 10), train_loss = 2.437, time/batch = 0.025
Read data: 8.392333984375e-05
iter 6533 (epoch 10), train_loss = 2.673, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 6534 (epoch 10), train_loss = 2.979, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 6535 (epoch 10), train_loss = 2.653, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 6536 (epoch 10), train_loss = 2.624, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 6537 (epoch 10), train_loss = 2.486, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 6538 (epoch 10), train_loss = 2.572, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 6539 (epoch 10), train_loss = 2.723, time/batch = 0.031
Read data: 8.749961853027344e-05
iter 6540 (epoch 10), train_loss = 3.214, time/batch = 0.024
Read data: 0.00011467933654785156
iter 6541 (epoch 10), train_loss = 2.558, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 6542 (epoch 10), train_loss = 2.750, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 6543 (epoch 10), train_loss = 2.731, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6544 (epoch 10), train_loss = 2.787, time/batch = 0.034
Read data: 8.20159912109375e-05
iter 6545 (epoch 10), train_loss = 2.508, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 6546 (epoch 10), train_loss = 2.902, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 6547 (epoch 10), train_loss = 2.599, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 6548 (epoch 10), train_loss = 2.349, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 6549 (epoch 10), train_loss = 2.656, time/batch = 0.029
Read data: 0.00020837783813476562
iter 6550 (epoch 10), train_loss = 2.612, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 6551 (epoch 10), train_loss = 2.669, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 6552 (epoch 10), train_loss = 3.076, time/batch = 0.039
Read data: 0.00012302398681640625
iter 6553 (epoch 10), train_loss = 2.778, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 6554 (epoch 10), train_loss = 2.573, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 6555 (epoch 10), train_loss = 2.759, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 6556 (epoch 10), train_loss = 2.923, time/batch = 0.031
Read data: 9.703636169433594e-05
iter 6557 (epoch 10), train_loss = 3.008, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 6558 (epoch 10), train_loss = 2.379, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 6559 (epoch 10), train_loss = 2.542, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 6560 (epoch 10), train_loss = 2.701, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 6561 (epoch 10), train_loss = 2.094, time/batch = 0.032
Read data: 0.00011539459228515625
iter 6562 (epoch 10), train_loss = 2.632, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 6563 (epoch 10), train_loss = 2.031, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 6564 (epoch 10), train_loss = 2.760, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 6565 (epoch 10), train_loss = 2.866, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 6566 (epoch 10), train_loss = 2.624, time/batch = 0.031
Read data: 9.131431579589844e-05
iter 6567 (epoch 10), train_loss = 2.701, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 6568 (epoch 10), train_loss = 2.443, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 6569 (epoch 10), train_loss = 2.416, time/batch = 0.029
Read data: 9.250640869140625e-05
iter 6570 (epoch 10), train_loss = 2.950, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 6571 (epoch 10), train_loss = 2.312, time/batch = 0.022
Read data: 7.62939453125e-05
iter 6572 (epoch 10), train_loss = 2.913, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 6573 (epoch 10), train_loss = 2.926, time/batch = 0.022
Read data: 0.00011992454528808594
iter 6574 (epoch 10), train_loss = 2.900, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 6575 (epoch 10), train_loss = 3.075, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 6576 (epoch 10), train_loss = 2.696, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 6577 (epoch 10), train_loss = 2.416, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 6578 (epoch 10), train_loss = 2.449, time/batch = 0.026
Read data: 0.00012826919555664062
iter 6579 (epoch 10), train_loss = 2.651, time/batch = 0.036
Read data: 9.250640869140625e-05
iter 6580 (epoch 10), train_loss = 2.917, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 6581 (epoch 10), train_loss = 2.795, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 6582 (epoch 10), train_loss = 2.601, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 6583 (epoch 10), train_loss = 2.766, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 6584 (epoch 10), train_loss = 2.920, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 6585 (epoch 10), train_loss = 2.647, time/batch = 0.020
Read data: 0.00013113021850585938
iter 6586 (epoch 10), train_loss = 2.564, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 6587 (epoch 10), train_loss = 2.839, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 6588 (epoch 10), train_loss = 2.783, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 6589 (epoch 10), train_loss = 3.002, time/batch = 0.026
Read data: 0.00012636184692382812
iter 6590 (epoch 10), train_loss = 3.016, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 6591 (epoch 10), train_loss = 2.717, time/batch = 0.031
Read data: 0.0010173320770263672
iter 6592 (epoch 10), train_loss = 2.345, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6593 (epoch 10), train_loss = 2.716, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 6594 (epoch 10), train_loss = 3.239, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 6595 (epoch 10), train_loss = 3.425, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 6596 (epoch 10), train_loss = 2.781, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 6597 (epoch 10), train_loss = 2.221, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 6598 (epoch 10), train_loss = 2.633, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 6599 (epoch 10), train_loss = 2.839, time/batch = 0.039
Read data: 0.00036215782165527344
iter 6600 (epoch 10), train_loss = 2.516, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 6601 (epoch 11), train_loss = 2.669, time/batch = 0.024
Read data: 0.0001544952392578125
iter 6602 (epoch 11), train_loss = 2.700, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 6603 (epoch 11), train_loss = 3.087, time/batch = 0.026
Read data: 7.343292236328125e-05
iter 6604 (epoch 11), train_loss = 2.756, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 6605 (epoch 11), train_loss = 2.532, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 6606 (epoch 11), train_loss = 2.925, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 6607 (epoch 11), train_loss = 2.426, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 6608 (epoch 11), train_loss = 2.833, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 6609 (epoch 11), train_loss = 2.659, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 6610 (epoch 11), train_loss = 2.650, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 6611 (epoch 11), train_loss = 2.347, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 6612 (epoch 11), train_loss = 2.655, time/batch = 0.020
Read data: 8.58306884765625e-05
iter 6613 (epoch 11), train_loss = 2.431, time/batch = 0.026
Read data: 0.00020170211791992188
iter 6614 (epoch 11), train_loss = 2.792, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 6615 (epoch 11), train_loss = 2.428, time/batch = 0.020
Read data: 8.749961853027344e-05
iter 6616 (epoch 11), train_loss = 3.005, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 6617 (epoch 11), train_loss = 2.778, time/batch = 0.022
Read data: 0.0001392364501953125
iter 6618 (epoch 11), train_loss = 2.865, time/batch = 0.028
Read data: 0.00012874603271484375
iter 6619 (epoch 11), train_loss = 2.785, time/batch = 0.026
Read data: 7.62939453125e-05
iter 6620 (epoch 11), train_loss = 2.600, time/batch = 0.018
Read data: 8.726119995117188e-05
iter 6621 (epoch 11), train_loss = 2.880, time/batch = 0.022
Read data: 0.0001614093780517578
iter 6622 (epoch 11), train_loss = 2.394, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 6623 (epoch 11), train_loss = 2.857, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 6624 (epoch 11), train_loss = 2.646, time/batch = 0.026
Read data: 0.00023555755615234375
iter 6625 (epoch 11), train_loss = 2.587, time/batch = 0.034
Read data: 9.870529174804688e-05
iter 6626 (epoch 11), train_loss = 2.532, time/batch = 0.026
Read data: 0.0001347064971923828
iter 6627 (epoch 11), train_loss = 2.681, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 6628 (epoch 11), train_loss = 2.107, time/batch = 0.020
Read data: 8.654594421386719e-05
iter 6629 (epoch 11), train_loss = 2.634, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 6630 (epoch 11), train_loss = 2.963, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 6631 (epoch 11), train_loss = 3.207, time/batch = 0.025
Read data: 8.392333984375e-05
iter 6632 (epoch 11), train_loss = 3.048, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 6633 (epoch 11), train_loss = 2.711, time/batch = 0.022
Read data: 0.00014400482177734375
iter 6634 (epoch 11), train_loss = 2.558, time/batch = 0.022
Read data: 0.00014901161193847656
iter 6635 (epoch 11), train_loss = 3.023, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 6636 (epoch 11), train_loss = 2.646, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 6637 (epoch 11), train_loss = 2.301, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 6638 (epoch 11), train_loss = 2.780, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 6639 (epoch 11), train_loss = 3.023, time/batch = 0.020
Read data: 8.940696716308594e-05
iter 6640 (epoch 11), train_loss = 3.003, time/batch = 0.034
Read data: 7.939338684082031e-05
iter 6641 (epoch 11), train_loss = 2.970, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 6642 (epoch 11), train_loss = 2.576, time/batch = 0.023
Read data: 0.00010013580322265625
iter 6643 (epoch 11), train_loss = 2.473, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 6644 (epoch 11), train_loss = 3.132, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 6645 (epoch 11), train_loss = 2.914, time/batch = 0.029
Read data: 0.0001239776611328125
iter 6646 (epoch 11), train_loss = 3.036, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 6647 (epoch 11), train_loss = 2.692, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 6648 (epoch 11), train_loss = 2.633, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 6649 (epoch 11), train_loss = 2.697, time/batch = 0.026
Read data: 0.00023937225341796875
iter 6650 (epoch 11), train_loss = 2.853, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 6651 (epoch 11), train_loss = 2.828, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 6652 (epoch 11), train_loss = 2.898, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 6653 (epoch 11), train_loss = 3.018, time/batch = 0.027
Read data: 0.00013637542724609375
iter 6654 (epoch 11), train_loss = 2.417, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 6655 (epoch 11), train_loss = 2.266, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6656 (epoch 11), train_loss = 2.852, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 6657 (epoch 11), train_loss = 2.585, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 6658 (epoch 11), train_loss = 2.472, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 6659 (epoch 11), train_loss = 2.809, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 6660 (epoch 11), train_loss = 2.501, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 6661 (epoch 11), train_loss = 2.268, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 6662 (epoch 11), train_loss = 2.815, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 6663 (epoch 11), train_loss = 2.989, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 6664 (epoch 11), train_loss = 2.538, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 6665 (epoch 11), train_loss = 3.017, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 6666 (epoch 11), train_loss = 3.012, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 6667 (epoch 11), train_loss = 2.750, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 6668 (epoch 11), train_loss = 2.810, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 6669 (epoch 11), train_loss = 2.498, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 6670 (epoch 11), train_loss = 2.499, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 6671 (epoch 11), train_loss = 2.987, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 6672 (epoch 11), train_loss = 2.683, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 6673 (epoch 11), train_loss = 2.704, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 6674 (epoch 11), train_loss = 2.918, time/batch = 0.035
Read data: 0.00016808509826660156
iter 6675 (epoch 11), train_loss = 2.435, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 6676 (epoch 11), train_loss = 2.998, time/batch = 0.025
Read data: 0.00014066696166992188
iter 6677 (epoch 11), train_loss = 2.866, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 6678 (epoch 11), train_loss = 2.701, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 6679 (epoch 11), train_loss = 3.059, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 6680 (epoch 11), train_loss = 2.219, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 6681 (epoch 11), train_loss = 2.205, time/batch = 0.022
Read data: 0.00013017654418945312
iter 6682 (epoch 11), train_loss = 2.792, time/batch = 0.034
Read data: 8.416175842285156e-05
iter 6683 (epoch 11), train_loss = 2.638, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 6684 (epoch 11), train_loss = 2.648, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 6685 (epoch 11), train_loss = 2.806, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 6686 (epoch 11), train_loss = 2.566, time/batch = 0.023
Read data: 9.918212890625e-05
iter 6687 (epoch 11), train_loss = 2.486, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 6688 (epoch 11), train_loss = 2.907, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 6689 (epoch 11), train_loss = 2.571, time/batch = 0.020
Read data: 0.0001316070556640625
iter 6690 (epoch 11), train_loss = 2.820, time/batch = 0.031
Read data: 8.869171142578125e-05
iter 6691 (epoch 11), train_loss = 2.918, time/batch = 0.032
Read data: 7.653236389160156e-05
iter 6692 (epoch 11), train_loss = 2.738, time/batch = 0.026
Read data: 0.0001285076141357422
iter 6693 (epoch 11), train_loss = 2.438, time/batch = 0.023
Read data: 8.392333984375e-05
iter 6694 (epoch 11), train_loss = 2.946, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 6695 (epoch 11), train_loss = 2.786, time/batch = 0.031
Read data: 8.630752563476562e-05
iter 6696 (epoch 11), train_loss = 2.718, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 6697 (epoch 11), train_loss = 2.706, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 6698 (epoch 11), train_loss = 2.208, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6699 (epoch 11), train_loss = 2.450, time/batch = 0.027
Read data: 0.00016021728515625
iter 6700 (epoch 11), train_loss = 2.839, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 6701 (epoch 11), train_loss = 2.734, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 6702 (epoch 11), train_loss = 2.517, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 6703 (epoch 11), train_loss = 3.050, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 6704 (epoch 11), train_loss = 2.335, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 6705 (epoch 11), train_loss = 2.781, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 6706 (epoch 11), train_loss = 2.721, time/batch = 0.035
Read data: 8.0108642578125e-05
iter 6707 (epoch 11), train_loss = 2.592, time/batch = 0.024
Read data: 0.0001399517059326172
iter 6708 (epoch 11), train_loss = 3.216, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 6709 (epoch 11), train_loss = 2.750, time/batch = 0.021
Read data: 7.915496826171875e-05
iter 6710 (epoch 11), train_loss = 2.198, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 6711 (epoch 11), train_loss = 2.685, time/batch = 0.033
Read data: 7.796287536621094e-05
iter 6712 (epoch 11), train_loss = 2.833, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 6713 (epoch 11), train_loss = 2.647, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 6714 (epoch 11), train_loss = 1.945, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6715 (epoch 11), train_loss = 2.642, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 6716 (epoch 11), train_loss = 2.767, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 6717 (epoch 11), train_loss = 2.659, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 6718 (epoch 11), train_loss = 2.582, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 6719 (epoch 11), train_loss = 2.203, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 6720 (epoch 11), train_loss = 2.934, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 6721 (epoch 11), train_loss = 2.489, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 6722 (epoch 11), train_loss = 2.786, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 6723 (epoch 11), train_loss = 2.527, time/batch = 0.032
Read data: 0.0001289844512939453
iter 6724 (epoch 11), train_loss = 3.088, time/batch = 0.027
Read data: 0.00024127960205078125
iter 6725 (epoch 11), train_loss = 2.600, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 6726 (epoch 11), train_loss = 2.672, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 6727 (epoch 11), train_loss = 2.483, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 6728 (epoch 11), train_loss = 2.364, time/batch = 0.023
Read data: 0.0001304149627685547
iter 6729 (epoch 11), train_loss = 2.928, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 6730 (epoch 11), train_loss = 3.048, time/batch = 0.029
Read data: 0.00013208389282226562
iter 6731 (epoch 11), train_loss = 3.028, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 6732 (epoch 11), train_loss = 2.715, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 6733 (epoch 11), train_loss = 2.909, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 6734 (epoch 11), train_loss = 2.699, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 6735 (epoch 11), train_loss = 2.932, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 6736 (epoch 11), train_loss = 2.437, time/batch = 0.021
Read data: 8.58306884765625e-05
iter 6737 (epoch 11), train_loss = 2.981, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 6738 (epoch 11), train_loss = 2.517, time/batch = 0.029
Read data: 9.226799011230469e-05
iter 6739 (epoch 11), train_loss = 2.724, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 6740 (epoch 11), train_loss = 2.360, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 6741 (epoch 11), train_loss = 2.489, time/batch = 0.024
Read data: 0.00013303756713867188
iter 6742 (epoch 11), train_loss = 2.670, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 6743 (epoch 11), train_loss = 2.677, time/batch = 0.033
Read data: 7.677078247070312e-05
iter 6744 (epoch 11), train_loss = 2.704, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 6745 (epoch 11), train_loss = 2.711, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 6746 (epoch 11), train_loss = 2.959, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6747 (epoch 11), train_loss = 2.447, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 6748 (epoch 11), train_loss = 2.677, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 6749 (epoch 11), train_loss = 2.909, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 6750 (epoch 11), train_loss = 2.928, time/batch = 0.024
Read data: 0.000141143798828125
iter 6751 (epoch 11), train_loss = 2.359, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 6752 (epoch 11), train_loss = 2.724, time/batch = 0.031
Read data: 7.891654968261719e-05
iter 6753 (epoch 11), train_loss = 2.885, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 6754 (epoch 11), train_loss = 2.910, time/batch = 0.020
Read data: 8.463859558105469e-05
iter 6755 (epoch 11), train_loss = 2.712, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 6756 (epoch 11), train_loss = 3.109, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 6757 (epoch 11), train_loss = 2.821, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 6758 (epoch 11), train_loss = 2.583, time/batch = 0.024
Read data: 0.00023627281188964844
iter 6759 (epoch 11), train_loss = 3.123, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 6760 (epoch 11), train_loss = 2.726, time/batch = 0.035
Read data: 8.058547973632812e-05
iter 6761 (epoch 11), train_loss = 2.543, time/batch = 0.022
Read data: 9.799003601074219e-05
iter 6762 (epoch 11), train_loss = 2.736, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 6763 (epoch 11), train_loss = 2.552, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 6764 (epoch 11), train_loss = 2.700, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 6765 (epoch 11), train_loss = 2.733, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 6766 (epoch 11), train_loss = 3.034, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 6767 (epoch 11), train_loss = 2.617, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 6768 (epoch 11), train_loss = 2.453, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 6769 (epoch 11), train_loss = 2.590, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 6770 (epoch 11), train_loss = 2.916, time/batch = 0.031
Read data: 8.988380432128906e-05
iter 6771 (epoch 11), train_loss = 2.554, time/batch = 0.030
Read data: 7.62939453125e-05
iter 6772 (epoch 11), train_loss = 2.123, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 6773 (epoch 11), train_loss = 2.728, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 6774 (epoch 11), train_loss = 2.512, time/batch = 0.023
Read data: 0.0002155303955078125
iter 6775 (epoch 11), train_loss = 2.595, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 6776 (epoch 11), train_loss = 2.612, time/batch = 0.038
Read data: 7.653236389160156e-05
iter 6777 (epoch 11), train_loss = 2.802, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 6778 (epoch 11), train_loss = 2.807, time/batch = 0.027
Read data: 0.00013208389282226562
iter 6779 (epoch 11), train_loss = 3.134, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 6780 (epoch 11), train_loss = 3.010, time/batch = 0.029
Read data: 7.653236389160156e-05
iter 6781 (epoch 11), train_loss = 2.902, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 6782 (epoch 11), train_loss = 2.912, time/batch = 0.029
Read data: 9.226799011230469e-05
iter 6783 (epoch 11), train_loss = 2.805, time/batch = 0.022
Read data: 6.747245788574219e-05
iter 6784 (epoch 11), train_loss = 2.772, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 6785 (epoch 11), train_loss = 2.648, time/batch = 0.020
Read data: 9.489059448242188e-05
iter 6786 (epoch 11), train_loss = 2.946, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 6787 (epoch 11), train_loss = 2.376, time/batch = 0.023
Read data: 7.557868957519531e-05
iter 6788 (epoch 11), train_loss = 2.619, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 6789 (epoch 11), train_loss = 2.899, time/batch = 0.037
Read data: 8.034706115722656e-05
iter 6790 (epoch 11), train_loss = 2.914, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 6791 (epoch 11), train_loss = 2.554, time/batch = 0.023
Read data: 6.747245788574219e-05
iter 6792 (epoch 11), train_loss = 2.679, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 6793 (epoch 11), train_loss = 2.901, time/batch = 0.036
Read data: 8.153915405273438e-05
iter 6794 (epoch 11), train_loss = 2.789, time/batch = 0.029
Read data: 9.107589721679688e-05
iter 6795 (epoch 11), train_loss = 2.620, time/batch = 0.037
Read data: 7.534027099609375e-05
iter 6796 (epoch 11), train_loss = 2.502, time/batch = 0.020
Read data: 0.00014495849609375
iter 6797 (epoch 11), train_loss = 2.680, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 6798 (epoch 11), train_loss = 2.858, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 6799 (epoch 11), train_loss = 2.952, time/batch = 0.025
Read data: 7.343292236328125e-05
iter 6800 (epoch 11), train_loss = 2.905, time/batch = 0.042
Read data: 7.939338684082031e-05
iter 6801 (epoch 11), train_loss = 2.848, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 6802 (epoch 11), train_loss = 2.949, time/batch = 0.022
Read data: 8.392333984375e-05
iter 6803 (epoch 11), train_loss = 2.586, time/batch = 0.024
Read data: 9.5367431640625e-05
iter 6804 (epoch 11), train_loss = 2.471, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 6805 (epoch 11), train_loss = 2.826, time/batch = 0.022
Read data: 9.72747802734375e-05
iter 6806 (epoch 11), train_loss = 2.901, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 6807 (epoch 11), train_loss = 2.572, time/batch = 0.031
Read data: 8.96453857421875e-05
iter 6808 (epoch 11), train_loss = 2.286, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 6809 (epoch 11), train_loss = 2.993, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 6810 (epoch 11), train_loss = 2.818, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 6811 (epoch 11), train_loss = 3.146, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 6812 (epoch 11), train_loss = 2.431, time/batch = 0.025
Read data: 0.0001583099365234375
iter 6813 (epoch 11), train_loss = 3.032, time/batch = 0.021
Read data: 0.00013184547424316406
iter 6814 (epoch 11), train_loss = 2.673, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 6815 (epoch 11), train_loss = 2.475, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 6816 (epoch 11), train_loss = 2.784, time/batch = 0.034
Read data: 0.00010633468627929688
iter 6817 (epoch 11), train_loss = 2.453, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 6818 (epoch 11), train_loss = 2.932, time/batch = 0.025
Read data: 0.00012803077697753906
iter 6819 (epoch 11), train_loss = 2.811, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 6820 (epoch 11), train_loss = 2.837, time/batch = 0.020
Read data: 8.58306884765625e-05
iter 6821 (epoch 11), train_loss = 2.766, time/batch = 0.024
Read data: 0.00014400482177734375
iter 6822 (epoch 11), train_loss = 2.644, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 6823 (epoch 11), train_loss = 2.715, time/batch = 0.027
Read data: 0.00010657310485839844
iter 6824 (epoch 11), train_loss = 2.690, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 6825 (epoch 11), train_loss = 2.967, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 6826 (epoch 11), train_loss = 2.424, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 6827 (epoch 11), train_loss = 3.021, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 6828 (epoch 11), train_loss = 2.831, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 6829 (epoch 11), train_loss = 2.597, time/batch = 0.019
Read data: 7.772445678710938e-05
iter 6830 (epoch 11), train_loss = 2.687, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 6831 (epoch 11), train_loss = 3.147, time/batch = 0.023
Read data: 0.00011134147644042969
iter 6832 (epoch 11), train_loss = 2.556, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 6833 (epoch 11), train_loss = 2.896, time/batch = 0.033
Read data: 8.130073547363281e-05
iter 6834 (epoch 11), train_loss = 2.619, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 6835 (epoch 11), train_loss = 2.667, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 6836 (epoch 11), train_loss = 2.706, time/batch = 0.020
Read data: 8.106231689453125e-05
iter 6837 (epoch 11), train_loss = 2.517, time/batch = 0.022
Read data: 0.00012993812561035156
iter 6838 (epoch 11), train_loss = 2.672, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 6839 (epoch 11), train_loss = 2.893, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 6840 (epoch 11), train_loss = 2.750, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 6841 (epoch 11), train_loss = 2.571, time/batch = 0.023
Read data: 0.00012969970703125
iter 6842 (epoch 11), train_loss = 2.695, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 6843 (epoch 11), train_loss = 2.891, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 6844 (epoch 11), train_loss = 2.882, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 6845 (epoch 11), train_loss = 3.147, time/batch = 0.026
Read data: 0.00014209747314453125
iter 6846 (epoch 11), train_loss = 2.887, time/batch = 0.041
Read data: 8.726119995117188e-05
iter 6847 (epoch 11), train_loss = 2.813, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 6848 (epoch 11), train_loss = 2.707, time/batch = 0.020
Read data: 9.036064147949219e-05
iter 6849 (epoch 11), train_loss = 2.270, time/batch = 0.026
Read data: 0.0001659393310546875
iter 6850 (epoch 11), train_loss = 2.681, time/batch = 0.031
Read data: 9.369850158691406e-05
iter 6851 (epoch 11), train_loss = 2.775, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 6852 (epoch 11), train_loss = 2.883, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 6853 (epoch 11), train_loss = 2.559, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 6854 (epoch 11), train_loss = 2.394, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 6855 (epoch 11), train_loss = 2.583, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 6856 (epoch 11), train_loss = 2.898, time/batch = 0.024
Read data: 7.581710815429688e-05
iter 6857 (epoch 11), train_loss = 2.567, time/batch = 0.035
Read data: 8.678436279296875e-05
iter 6858 (epoch 11), train_loss = 2.467, time/batch = 0.027
Read data: 0.00012564659118652344
iter 6859 (epoch 11), train_loss = 2.579, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 6860 (epoch 11), train_loss = 2.618, time/batch = 0.035
Read data: 8.130073547363281e-05
iter 6861 (epoch 11), train_loss = 2.615, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 6862 (epoch 11), train_loss = 2.703, time/batch = 0.030
Read data: 0.0001361370086669922
iter 6863 (epoch 11), train_loss = 2.686, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 6864 (epoch 11), train_loss = 2.871, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 6865 (epoch 11), train_loss = 2.401, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 6866 (epoch 11), train_loss = 2.761, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 6867 (epoch 11), train_loss = 2.394, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 6868 (epoch 11), train_loss = 2.592, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 6869 (epoch 11), train_loss = 3.432, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 6870 (epoch 11), train_loss = 2.509, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 6871 (epoch 11), train_loss = 2.138, time/batch = 0.019
Read data: 8.606910705566406e-05
iter 6872 (epoch 11), train_loss = 2.299, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 6873 (epoch 11), train_loss = 2.873, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 6874 (epoch 11), train_loss = 2.937, time/batch = 0.022
Read data: 8.416175842285156e-05
iter 6875 (epoch 11), train_loss = 2.570, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 6876 (epoch 11), train_loss = 2.629, time/batch = 0.027
Read data: 7.557868957519531e-05
iter 6877 (epoch 11), train_loss = 2.775, time/batch = 0.022
Read data: 9.1552734375e-05
iter 6878 (epoch 11), train_loss = 2.811, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 6879 (epoch 11), train_loss = 2.479, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 6880 (epoch 11), train_loss = 2.075, time/batch = 0.019
Read data: 8.487701416015625e-05
iter 6881 (epoch 11), train_loss = 2.619, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 6882 (epoch 11), train_loss = 3.224, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 6883 (epoch 11), train_loss = 2.453, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 6884 (epoch 11), train_loss = 2.778, time/batch = 0.031
Read data: 9.584426879882812e-05
iter 6885 (epoch 11), train_loss = 2.898, time/batch = 0.023
Read data: 9.1552734375e-05
iter 6886 (epoch 11), train_loss = 2.772, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 6887 (epoch 11), train_loss = 2.845, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 6888 (epoch 11), train_loss = 2.629, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 6889 (epoch 11), train_loss = 2.599, time/batch = 0.026
Read data: 9.441375732421875e-05
iter 6890 (epoch 11), train_loss = 2.581, time/batch = 0.021
Read data: 0.00013709068298339844
iter 6891 (epoch 11), train_loss = 2.775, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 6892 (epoch 11), train_loss = 3.141, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 6893 (epoch 11), train_loss = 2.670, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 6894 (epoch 11), train_loss = 2.761, time/batch = 0.024
Read data: 0.00014352798461914062
iter 6895 (epoch 11), train_loss = 2.749, time/batch = 0.029
Read data: 9.250640869140625e-05
iter 6896 (epoch 11), train_loss = 2.754, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 6897 (epoch 11), train_loss = 2.565, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 6898 (epoch 11), train_loss = 2.892, time/batch = 0.020
Read data: 8.606910705566406e-05
iter 6899 (epoch 11), train_loss = 2.213, time/batch = 0.019
Read data: 0.0003132820129394531
iter 6900 (epoch 11), train_loss = 2.823, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 6901 (epoch 11), train_loss = 2.938, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 6902 (epoch 11), train_loss = 2.981, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 6903 (epoch 11), train_loss = 3.271, time/batch = 0.027
Read data: 0.00011157989501953125
iter 6904 (epoch 11), train_loss = 2.629, time/batch = 0.029
Read data: 9.298324584960938e-05
iter 6905 (epoch 11), train_loss = 2.657, time/batch = 0.020
Read data: 0.0001327991485595703
iter 6906 (epoch 11), train_loss = 2.989, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 6907 (epoch 11), train_loss = 2.635, time/batch = 0.030
Read data: 8.7738037109375e-05
iter 6908 (epoch 11), train_loss = 2.922, time/batch = 0.030
Read data: 7.724761962890625e-05
iter 6909 (epoch 11), train_loss = 2.817, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 6910 (epoch 11), train_loss = 2.834, time/batch = 0.020
Read data: 0.00010442733764648438
iter 6911 (epoch 11), train_loss = 3.143, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 6912 (epoch 11), train_loss = 2.622, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 6913 (epoch 11), train_loss = 3.211, time/batch = 0.031
Read data: 0.00010657310485839844
iter 6914 (epoch 11), train_loss = 2.586, time/batch = 0.025
Read data: 0.00012946128845214844
iter 6915 (epoch 11), train_loss = 2.467, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 6916 (epoch 11), train_loss = 2.916, time/batch = 0.038
Read data: 7.867813110351562e-05
iter 6917 (epoch 11), train_loss = 2.457, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 6918 (epoch 11), train_loss = 3.019, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 6919 (epoch 11), train_loss = 3.047, time/batch = 0.032
Read data: 9.441375732421875e-05
iter 6920 (epoch 11), train_loss = 2.580, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 6921 (epoch 11), train_loss = 2.908, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 6922 (epoch 11), train_loss = 2.436, time/batch = 0.020
Read data: 8.96453857421875e-05
iter 6923 (epoch 11), train_loss = 3.107, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 6924 (epoch 11), train_loss = 2.799, time/batch = 0.034
Read data: 7.867813110351562e-05
iter 6925 (epoch 11), train_loss = 2.963, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 6926 (epoch 11), train_loss = 2.709, time/batch = 0.021
Read data: 9.679794311523438e-05
iter 6927 (epoch 11), train_loss = 2.907, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 6928 (epoch 11), train_loss = 3.213, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 6929 (epoch 11), train_loss = 2.435, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 6930 (epoch 11), train_loss = 2.623, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 6931 (epoch 11), train_loss = 2.523, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 6932 (epoch 11), train_loss = 2.572, time/batch = 0.024
Read data: 9.1552734375e-05
iter 6933 (epoch 11), train_loss = 2.848, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 6934 (epoch 11), train_loss = 2.950, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 6935 (epoch 11), train_loss = 2.744, time/batch = 0.025
Read data: 9.1552734375e-05
iter 6936 (epoch 11), train_loss = 2.178, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 6937 (epoch 11), train_loss = 3.098, time/batch = 0.027
Read data: 0.00013589859008789062
iter 6938 (epoch 11), train_loss = 2.854, time/batch = 0.035
Read data: 0.00013375282287597656
iter 6939 (epoch 11), train_loss = 2.995, time/batch = 0.022
Read data: 7.653236389160156e-05
iter 6940 (epoch 11), train_loss = 2.904, time/batch = 0.026
Read data: 7.62939453125e-05
iter 6941 (epoch 11), train_loss = 2.908, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 6942 (epoch 11), train_loss = 2.527, time/batch = 0.024
Read data: 0.00013589859008789062
iter 6943 (epoch 11), train_loss = 2.466, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 6944 (epoch 11), train_loss = 2.774, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 6945 (epoch 11), train_loss = 3.089, time/batch = 0.027
Read data: 0.00012969970703125
iter 6946 (epoch 11), train_loss = 2.897, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 6947 (epoch 11), train_loss = 2.893, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 6948 (epoch 11), train_loss = 2.803, time/batch = 0.030
Read data: 7.605552673339844e-05
iter 6949 (epoch 11), train_loss = 2.896, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 6950 (epoch 11), train_loss = 2.656, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 6951 (epoch 11), train_loss = 2.670, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 6952 (epoch 11), train_loss = 3.018, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 6953 (epoch 11), train_loss = 3.300, time/batch = 0.033
Read data: 0.00020384788513183594
iter 6954 (epoch 11), train_loss = 2.778, time/batch = 0.035
Read data: 0.00013780593872070312
iter 6955 (epoch 11), train_loss = 2.763, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 6956 (epoch 11), train_loss = 2.576, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 6957 (epoch 11), train_loss = 2.893, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 6958 (epoch 11), train_loss = 2.905, time/batch = 0.022
Read data: 0.00012540817260742188
iter 6959 (epoch 11), train_loss = 2.695, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 6960 (epoch 11), train_loss = 2.445, time/batch = 0.026
Read data: 0.000102996826171875
iter 6961 (epoch 11), train_loss = 2.774, time/batch = 0.022
Read data: 0.0001323223114013672
iter 6962 (epoch 11), train_loss = 2.821, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 6963 (epoch 11), train_loss = 2.479, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 6964 (epoch 11), train_loss = 3.157, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 6965 (epoch 11), train_loss = 2.649, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 6966 (epoch 11), train_loss = 3.134, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 6967 (epoch 11), train_loss = 2.499, time/batch = 0.028
Read data: 7.605552673339844e-05
iter 6968 (epoch 11), train_loss = 2.658, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 6969 (epoch 11), train_loss = 2.748, time/batch = 0.021
Read data: 9.298324584960938e-05
iter 6970 (epoch 11), train_loss = 2.768, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 6971 (epoch 11), train_loss = 2.177, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 6972 (epoch 11), train_loss = 2.534, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 6973 (epoch 11), train_loss = 2.844, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 6974 (epoch 11), train_loss = 2.770, time/batch = 0.022
Read data: 8.392333984375e-05
iter 6975 (epoch 11), train_loss = 2.889, time/batch = 0.029
Read data: 8.916854858398438e-05
iter 6976 (epoch 11), train_loss = 3.061, time/batch = 0.029
Read data: 9.012222290039062e-05
iter 6977 (epoch 11), train_loss = 2.607, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 6978 (epoch 11), train_loss = 2.685, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 6979 (epoch 11), train_loss = 2.495, time/batch = 0.038
Read data: 8.845329284667969e-05
iter 6980 (epoch 11), train_loss = 2.850, time/batch = 0.021
Read data: 0.00011658668518066406
iter 6981 (epoch 11), train_loss = 2.808, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 6982 (epoch 11), train_loss = 2.744, time/batch = 0.029
Read data: 8.654594421386719e-05
iter 6983 (epoch 11), train_loss = 2.660, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 6984 (epoch 11), train_loss = 2.438, time/batch = 0.037
Read data: 8.463859558105469e-05
iter 6985 (epoch 11), train_loss = 2.535, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 6986 (epoch 11), train_loss = 2.509, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 6987 (epoch 11), train_loss = 2.767, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 6988 (epoch 11), train_loss = 2.721, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 6989 (epoch 11), train_loss = 2.514, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 6990 (epoch 11), train_loss = 2.854, time/batch = 0.030
Read data: 0.000125885009765625
iter 6991 (epoch 11), train_loss = 2.740, time/batch = 0.032
Read data: 8.7738037109375e-05
iter 6992 (epoch 11), train_loss = 2.476, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 6993 (epoch 11), train_loss = 2.946, time/batch = 0.026
Read data: 0.00020360946655273438
iter 6994 (epoch 11), train_loss = 2.827, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 6995 (epoch 11), train_loss = 2.845, time/batch = 0.029
Read data: 7.677078247070312e-05
iter 6996 (epoch 11), train_loss = 2.853, time/batch = 0.023
Read data: 0.0001285076141357422
iter 6997 (epoch 11), train_loss = 2.908, time/batch = 0.024
Read data: 0.00013589859008789062
iter 6998 (epoch 11), train_loss = 3.020, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 6999 (epoch 11), train_loss = 2.767, time/batch = 0.030
image 976:     
image 5399:    
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.761455)
image 2798:     
image 5884:     
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.371027)
image 6903:      
image 3301:    
image 2019:    UNK
image 5535:    
image 7680:     
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.723688)
image 4604:     
image 5745:     
image 5288:    
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.985905)
image 2938:     
image 5183:     
image 2380:      
image 6973:     
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.626191)
image 4940:      
image 4905:    
image 469:     
image 102:    
image 6009:    
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.962964)
image 4389:     
image 4281:    
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.691703)
image 3258:     
image 6895:      
image 5296:     
image 4623:     
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.808600)
image 3276:      
image 3812:   
image 1400:    
image 3443:     
image 5027:     
image 7251:    
image 7305:     
image 1480:      
image 4806:      
image 766:    
evaluating validation preformance... 90/1000 (2.212647)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:     
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (3.066168)
image 2800:    
image 7249:    
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.926463)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.488657)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:    UNK
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (2.946696)
image 6214:     
image 429:     
image 7743:    
image 3657:    
image 4535:     
image 5542:     
image 8068:    UNK
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.811170)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (3.017658)
image 1865:      
image 3830:      
image 360:      
image 5097:     
image 4455:     
image 1153:    
image 1248:      
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.857967)
image 4297:    
image 3315:     
image 1107:    
image 2051:     
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.706760)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:     
image 3000:    
image 1806:    
image 7761:     
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.739565)
image 2313:    
image 6289:    
image 8084:     
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.609593)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:    
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.411359)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:     
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.547916)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:    UNK
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.720642)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:     
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.399842)
image 1917:     
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:     
image 5594:     
evaluating validation preformance... 240/1000 (2.336191)
image 7143:     
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.696524)
image 3028:    
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.605839)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:     
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.048595)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.690864)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:     
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.587420)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.264969)
image 2805:     
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.922025)
image 3553:    
image 5971:     
image 122:    
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:    
evaluating validation preformance... 320/1000 (2.470381)
image 489:     
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.825069)
image 5179:    
image 3754:    
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    
image 3972:     
evaluating validation preformance... 340/1000 (2.571849)
image 4542:      
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.693293)
image 6881:    
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.106508)
image 2905:    
image 7814:     
image 56:     
image 5034:    
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:      
evaluating validation preformance... 370/1000 (2.690953)
image 4351:     
image 1054:    UNK
image 129:     
image 2849:    
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.781527)
image 2458:     
image 1084:      
image 4835:    
image 867:    
image 723:     
image 6255:     
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (2.961380)
image 828:    
image 2733:    
image 791:      
image 5408:    UNK
image 7842:     
image 1117:      
image 5817:      
image 1231:     
image 1630:     
image 6886:    
evaluating validation preformance... 400/1000 (2.342186)
image 2627:    
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:    
image 2325:     
image 7546:      
evaluating validation preformance... 410/1000 (2.261878)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:     
image 7864:     
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.420397)
image 30:     
image 5540:     
image 2445:      
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.922065)
image 385:     
image 6938:     
image 2381:    
image 5796:    UNK
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.971393)
image 1731:      
image 978:      
image 6033:    
image 5080:     
image 7804:    
image 439:      
image 4790:    
image 5855:     
image 4245:      
image 973:    
evaluating validation preformance... 450/1000 (2.356946)
image 2241:      
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:    
image 3682:     
evaluating validation preformance... 460/1000 (2.902215)
image 7979:     
image 1618:    
image 7608:     
image 6393:    
image 5100:    
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.323805)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:     
image 7450:      
image 841:     
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (3.020352)
image 358:     
image 4663:    
image 5541:    
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.446884)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:    
image 606:      
image 6577:    
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.643980)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.117637)
image 3246:      
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:     
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.759983)
image 6806:     
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:    
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.565469)
image 5619:    
image 4391:     
image 891:     
image 3072:    
image 7781:    
image 6163:     
image 7376:      
image 6034:    
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.629091)
image 5292:      
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:      
evaluating validation preformance... 550/1000 (2.761929)
image 5439:     
image 7981:     
image 6012:     
image 4732:     
image 6630:    
image 994:    
image 5079:     
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.743681)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK
image 7893:     
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.699975)
image 7936:     
image 5433:    
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.580102)
image 2135:      
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.705991)
image 4420:     
image 1734:    
image 7239:     
image 7447:     
image 8009:     
image 4510:     
image 7495:    
image 2530:      
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.699373)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:    
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.836734)
image 69:     
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.563968)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.577406)
image 8074:    
image 1904:    
image 7917:      
image 2394:     
image 4406:    UNK
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.587036)
image 5313:      
image 2377:      
image 6058:     
image 4661:     
image 2955:      
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:      
evaluating validation preformance... 650/1000 (2.695869)
image 8065:    
image 3577:    
image 3254:    
image 4562:    
image 5462:     
image 2824:     
image 1639:     
image 1475:     
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.778831)
image 5701:      
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (3.014319)
image 7877:    
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.141229)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:      
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (3.017270)
image 6860:     
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:    
image 6225:    
image 3669:     
image 980:     
image 5362:      
evaluating validation preformance... 700/1000 (3.037653)
image 5343:    
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.649079)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.724097)
image 5729:     
image 6395:      
image 516:    
image 1026:    
image 2972:      
image 3005:    
image 1241:    
image 2743:    
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.429799)
image 2527:     
image 6266:     
image 4161:    
image 1139:     
image 3781:     
image 6081:    
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.573741)
image 2239:    
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:      
image 6197:     
evaluating validation preformance... 750/1000 (2.906332)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.082494)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:     
image 5400:    
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.329531)
image 6220:     
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:      
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.876347)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:     
image 3312:    UNK
image 7824:      
image 2032:    
evaluating validation preformance... 790/1000 (3.340236)
image 5047:      
image 325:     
image 7626:     
image 4552:     
image 983:    UNK
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.382301)
image 7288:      
image 7302:    
image 3055:     
image 5250:     
image 1158:      
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.548922)
image 614:    
image 7295:     
image 4110:     
image 5402:    
image 3060:    UNK
image 1317:    
image 3339:    
image 1052:      
image 3701:     
image 4194:    
evaluating validation preformance... 820/1000 (2.104835)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:    
image 7147:    
image 6348:      
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.521177)
image 5107:    
image 3973:    
image 4233:     
image 3593:      
image 5872:     
image 2074:      
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.541683)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:     
image 5534:    
evaluating validation preformance... 850/1000 (2.948442)
image 4404:    
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:      
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.950064)
image 4254:    
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:     
image 4927:     
image 3222:     
image 4002:     
evaluating validation preformance... 870/1000 (2.464737)
image 4934:     
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:      
image 5681:      
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.685447)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (3.019068)
image 7485:     
image 6102:    
image 1001:    
image 7167:    
image 4168:     
image 187:    
image 7798:     
image 4813:    UNK
image 7753:      
image 210:    
evaluating validation preformance... 900/1000 (3.554148)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:     
image 7205:     
evaluating validation preformance... 910/1000 (2.355871)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.693556)
image 7152:    
image 4559:     
image 7233:    
image 1341:     
image 5337:      
image 3189:    
image 6274:       
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.566787)
image 5636:    
image 7799:      
image 6025:     
image 6907:      
image 2507:      
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.731114)
image 5860:     
image 3275:     
image 1935:     
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (3.138504)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:     
image 1085:      
image 3923:    
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.887084)
image 4935:     
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.468256)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:    
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.852253)
image 7352:     
image 5113:    
image 7822:    
image 4858:    
image 658:     
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.625923)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:     
image 2483:    
image 2591:     
image 7615:     
evaluating validation preformance... 1000/1000 (2.468857)
average loss on validation: 2.722
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.4093539714813232
Cider scores: 0.5595252071902186
Read data: 0.33951759338378906
Cider scores: 0.5369906530534885
Read data: 0.24130773544311523
Cider scores: 0.5561647510309933
Read data: 0.23333406448364258
Cider scores: 0.46645480559781505
Read data: 0.19447731971740723
Cider scores: 0.4589134561991485
Read data: 0.1687173843383789
Cider scores: 0.40942479282462724
Read data: 0.20352840423583984
Cider scores: 0.46376157031481
Read data: 0.1804490089416504
Cider scores: 0.5607169887514997
Read data: 0.17045283317565918
Cider scores: 0.43505764370834643
Read data: 0.18489360809326172
Cider scores: 0.5592574617744042
Read data: 0.23802447319030762
Cider scores: 0.49593862793219234
Read data: 0.18154215812683105
Cider scores: 0.5176267128797511
Read data: 0.18098115921020508
Cider scores: 0.4919909841608658
Read data: 0.17578816413879395
Cider scores: 0.5290388485916256
Read data: 0.18159747123718262
Cider scores: 0.5318548176895473
Read data: 0.17125678062438965
Cider scores: 0.5938679738142965
Read data: 0.16168856620788574
Cider scores: 0.4420799366674036
Read data: 0.16713762283325195
Cider scores: 0.6295879180646204
Read data: 0.16716647148132324
Cider scores: 0.494285022049924
Read data: 0.16315960884094238
Cider scores: 0.5428850576104761
Average cider score on test set: 0.514
End calculating cider score on TEST data set
===============================================
Read data: 0.16750311851501465
iter 7000 (epoch 11), train_loss = 2.878, time/batch = 0.022
Read data: 9.703636169433594e-05
iter 7001 (epoch 11), train_loss = 2.895, time/batch = 0.021
Read data: 0.0001010894775390625
iter 7002 (epoch 11), train_loss = 2.104, time/batch = 0.022
Read data: 0.00011086463928222656
iter 7003 (epoch 11), train_loss = 2.603, time/batch = 0.022
Read data: 0.00012803077697753906
iter 7004 (epoch 11), train_loss = 2.719, time/batch = 0.024
Read data: 0.0002124309539794922
iter 7005 (epoch 11), train_loss = 2.401, time/batch = 0.034
Read data: 0.0001366138458251953
iter 7006 (epoch 11), train_loss = 2.733, time/batch = 0.030
Read data: 9.918212890625e-05
iter 7007 (epoch 11), train_loss = 2.869, time/batch = 0.027
Read data: 0.0001327991485595703
iter 7008 (epoch 11), train_loss = 3.239, time/batch = 0.027
Read data: 0.00010037422180175781
iter 7009 (epoch 11), train_loss = 2.766, time/batch = 0.031
Read data: 0.0001857280731201172
iter 7010 (epoch 11), train_loss = 2.732, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 7011 (epoch 11), train_loss = 3.072, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 7012 (epoch 11), train_loss = 2.212, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 7013 (epoch 11), train_loss = 2.648, time/batch = 0.029
Read data: 0.0001289844512939453
iter 7014 (epoch 11), train_loss = 2.825, time/batch = 0.035
Read data: 7.510185241699219e-05
iter 7015 (epoch 11), train_loss = 2.920, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 7016 (epoch 11), train_loss = 2.687, time/batch = 0.027
Read data: 0.0002846717834472656
iter 7017 (epoch 11), train_loss = 3.134, time/batch = 0.033
Read data: 6.866455078125e-05
iter 7018 (epoch 11), train_loss = 2.129, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 7019 (epoch 11), train_loss = 2.023, time/batch = 0.020
Read data: 8.344650268554688e-05
iter 7020 (epoch 11), train_loss = 3.309, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 7021 (epoch 11), train_loss = 2.838, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 7022 (epoch 11), train_loss = 2.505, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 7023 (epoch 11), train_loss = 2.556, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 7024 (epoch 11), train_loss = 2.731, time/batch = 0.025
Read data: 0.00021529197692871094
iter 7025 (epoch 11), train_loss = 2.389, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 7026 (epoch 11), train_loss = 2.449, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 7027 (epoch 11), train_loss = 2.745, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 7028 (epoch 11), train_loss = 3.059, time/batch = 0.037
Read data: 0.0001666545867919922
iter 7029 (epoch 11), train_loss = 2.714, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 7030 (epoch 11), train_loss = 2.797, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 7031 (epoch 11), train_loss = 2.910, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 7032 (epoch 11), train_loss = 2.875, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 7033 (epoch 11), train_loss = 2.870, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 7034 (epoch 11), train_loss = 2.830, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 7035 (epoch 11), train_loss = 2.699, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 7036 (epoch 11), train_loss = 2.653, time/batch = 0.023
Read data: 0.00010228157043457031
iter 7037 (epoch 11), train_loss = 3.240, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 7038 (epoch 11), train_loss = 2.662, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 7039 (epoch 11), train_loss = 3.203, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7040 (epoch 11), train_loss = 2.545, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7041 (epoch 11), train_loss = 3.116, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 7042 (epoch 11), train_loss = 2.528, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 7043 (epoch 11), train_loss = 2.704, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 7044 (epoch 11), train_loss = 2.573, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 7045 (epoch 11), train_loss = 2.371, time/batch = 0.036
Read data: 8.058547973632812e-05
iter 7046 (epoch 11), train_loss = 2.877, time/batch = 0.029
Read data: 0.00010704994201660156
iter 7047 (epoch 11), train_loss = 2.626, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 7048 (epoch 11), train_loss = 2.452, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 7049 (epoch 11), train_loss = 2.724, time/batch = 0.025
Read data: 0.00016355514526367188
iter 7050 (epoch 11), train_loss = 2.695, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 7051 (epoch 11), train_loss = 2.967, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 7052 (epoch 11), train_loss = 3.018, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 7053 (epoch 11), train_loss = 2.905, time/batch = 0.037
Read data: 8.320808410644531e-05
iter 7054 (epoch 11), train_loss = 2.824, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 7055 (epoch 11), train_loss = 2.822, time/batch = 0.029
Read data: 0.00011014938354492188
iter 7056 (epoch 11), train_loss = 2.748, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 7057 (epoch 11), train_loss = 2.770, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7058 (epoch 11), train_loss = 2.545, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 7059 (epoch 11), train_loss = 2.590, time/batch = 0.023
Read data: 0.00012612342834472656
iter 7060 (epoch 11), train_loss = 2.544, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 7061 (epoch 11), train_loss = 2.549, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 7062 (epoch 11), train_loss = 2.862, time/batch = 0.029
Read data: 0.00011491775512695312
iter 7063 (epoch 11), train_loss = 2.814, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 7064 (epoch 11), train_loss = 2.862, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 7065 (epoch 11), train_loss = 2.904, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 7066 (epoch 11), train_loss = 2.403, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7067 (epoch 11), train_loss = 2.772, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 7068 (epoch 11), train_loss = 2.816, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 7069 (epoch 11), train_loss = 2.671, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 7070 (epoch 11), train_loss = 2.579, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 7071 (epoch 11), train_loss = 2.656, time/batch = 0.022
Read data: 9.751319885253906e-05
iter 7072 (epoch 11), train_loss = 3.395, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 7073 (epoch 11), train_loss = 2.673, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 7074 (epoch 11), train_loss = 2.645, time/batch = 0.023
Read data: 0.00013327598571777344
iter 7075 (epoch 11), train_loss = 2.065, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 7076 (epoch 11), train_loss = 2.778, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 7077 (epoch 11), train_loss = 3.001, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 7078 (epoch 11), train_loss = 2.735, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7079 (epoch 11), train_loss = 2.467, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 7080 (epoch 11), train_loss = 2.896, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 7081 (epoch 11), train_loss = 2.519, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 7082 (epoch 11), train_loss = 3.177, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 7083 (epoch 11), train_loss = 3.012, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 7084 (epoch 11), train_loss = 3.084, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 7085 (epoch 11), train_loss = 2.894, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 7086 (epoch 11), train_loss = 2.180, time/batch = 0.021
Read data: 8.869171142578125e-05
iter 7087 (epoch 11), train_loss = 2.837, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 7088 (epoch 11), train_loss = 2.640, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 7089 (epoch 11), train_loss = 2.475, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 7090 (epoch 11), train_loss = 2.367, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 7091 (epoch 11), train_loss = 2.971, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 7092 (epoch 11), train_loss = 2.817, time/batch = 0.031
Read data: 9.942054748535156e-05
iter 7093 (epoch 11), train_loss = 2.561, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 7094 (epoch 11), train_loss = 2.742, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 7095 (epoch 11), train_loss = 2.590, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 7096 (epoch 11), train_loss = 2.658, time/batch = 0.024
Read data: 9.918212890625e-05
iter 7097 (epoch 11), train_loss = 2.874, time/batch = 0.029
Read data: 0.0001010894775390625
iter 7098 (epoch 11), train_loss = 2.883, time/batch = 0.031
Read data: 7.891654968261719e-05
iter 7099 (epoch 11), train_loss = 2.692, time/batch = 0.026
Read data: 0.00021696090698242188
iter 7100 (epoch 11), train_loss = 2.813, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 7101 (epoch 11), train_loss = 3.009, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 7102 (epoch 11), train_loss = 2.698, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 7103 (epoch 11), train_loss = 2.286, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 7104 (epoch 11), train_loss = 2.414, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 7105 (epoch 11), train_loss = 2.589, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 7106 (epoch 11), train_loss = 2.797, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 7107 (epoch 11), train_loss = 2.577, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7108 (epoch 11), train_loss = 2.621, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 7109 (epoch 11), train_loss = 2.596, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 7110 (epoch 11), train_loss = 2.535, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 7111 (epoch 11), train_loss = 2.727, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 7112 (epoch 11), train_loss = 2.791, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 7113 (epoch 11), train_loss = 2.735, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 7114 (epoch 11), train_loss = 2.489, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 7115 (epoch 11), train_loss = 2.709, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 7116 (epoch 11), train_loss = 3.219, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7117 (epoch 11), train_loss = 2.542, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 7118 (epoch 11), train_loss = 3.136, time/batch = 0.023
Read data: 0.00014925003051757812
iter 7119 (epoch 11), train_loss = 2.899, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 7120 (epoch 11), train_loss = 2.624, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 7121 (epoch 11), train_loss = 2.890, time/batch = 0.029
Read data: 0.0001342296600341797
iter 7122 (epoch 11), train_loss = 2.537, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 7123 (epoch 11), train_loss = 2.895, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 7124 (epoch 11), train_loss = 2.752, time/batch = 0.030
Read data: 0.00022220611572265625
iter 7125 (epoch 11), train_loss = 2.556, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 7126 (epoch 11), train_loss = 2.766, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 7127 (epoch 11), train_loss = 2.836, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 7128 (epoch 11), train_loss = 3.116, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 7129 (epoch 11), train_loss = 2.467, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 7130 (epoch 11), train_loss = 2.813, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 7131 (epoch 11), train_loss = 2.530, time/batch = 0.029
Read data: 0.00012063980102539062
iter 7132 (epoch 11), train_loss = 2.923, time/batch = 0.032
Read data: 0.0001380443572998047
iter 7133 (epoch 11), train_loss = 2.842, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 7134 (epoch 11), train_loss = 3.106, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 7135 (epoch 11), train_loss = 2.699, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 7136 (epoch 11), train_loss = 2.684, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 7137 (epoch 11), train_loss = 2.974, time/batch = 0.030
Read data: 0.00010418891906738281
iter 7138 (epoch 11), train_loss = 2.302, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 7139 (epoch 11), train_loss = 2.508, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 7140 (epoch 11), train_loss = 2.790, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 7141 (epoch 11), train_loss = 2.701, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 7142 (epoch 11), train_loss = 2.740, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 7143 (epoch 11), train_loss = 2.808, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 7144 (epoch 11), train_loss = 2.799, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 7145 (epoch 11), train_loss = 2.884, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 7146 (epoch 11), train_loss = 2.558, time/batch = 0.034
Read data: 0.00023317337036132812
iter 7147 (epoch 11), train_loss = 2.830, time/batch = 0.030
Read data: 9.083747863769531e-05
iter 7148 (epoch 11), train_loss = 2.465, time/batch = 0.026
Read data: 0.00011086463928222656
iter 7149 (epoch 11), train_loss = 2.560, time/batch = 0.028
Read data: 0.0002512931823730469
iter 7150 (epoch 11), train_loss = 2.614, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 7151 (epoch 11), train_loss = 2.909, time/batch = 0.027
Read data: 8.392333984375e-05
iter 7152 (epoch 11), train_loss = 2.873, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7153 (epoch 11), train_loss = 2.931, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 7154 (epoch 11), train_loss = 2.764, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 7155 (epoch 11), train_loss = 2.785, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 7156 (epoch 11), train_loss = 2.583, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 7157 (epoch 11), train_loss = 3.009, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 7158 (epoch 11), train_loss = 2.280, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 7159 (epoch 11), train_loss = 2.363, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 7160 (epoch 11), train_loss = 2.569, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7161 (epoch 11), train_loss = 2.382, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 7162 (epoch 11), train_loss = 3.309, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 7163 (epoch 11), train_loss = 2.431, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7164 (epoch 11), train_loss = 2.963, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 7165 (epoch 11), train_loss = 2.627, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 7166 (epoch 11), train_loss = 3.034, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 7167 (epoch 11), train_loss = 3.129, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7168 (epoch 11), train_loss = 2.661, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 7169 (epoch 11), train_loss = 3.084, time/batch = 0.031
Read data: 8.869171142578125e-05
iter 7170 (epoch 11), train_loss = 3.175, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 7171 (epoch 11), train_loss = 3.149, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 7172 (epoch 11), train_loss = 2.326, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 7173 (epoch 11), train_loss = 2.727, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 7174 (epoch 11), train_loss = 2.789, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 7175 (epoch 11), train_loss = 2.824, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 7176 (epoch 11), train_loss = 2.553, time/batch = 0.029
Read data: 0.00013947486877441406
iter 7177 (epoch 11), train_loss = 3.045, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 7178 (epoch 11), train_loss = 2.950, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7179 (epoch 11), train_loss = 2.670, time/batch = 0.023
Read data: 0.00013136863708496094
iter 7180 (epoch 11), train_loss = 2.454, time/batch = 0.026
Read data: 0.000102996826171875
iter 7181 (epoch 11), train_loss = 2.600, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 7182 (epoch 11), train_loss = 2.797, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 7183 (epoch 11), train_loss = 2.944, time/batch = 0.037
Read data: 8.58306884765625e-05
iter 7184 (epoch 11), train_loss = 2.865, time/batch = 0.027
Read data: 0.00013589859008789062
iter 7185 (epoch 11), train_loss = 2.447, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 7186 (epoch 11), train_loss = 2.753, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 7187 (epoch 11), train_loss = 2.821, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 7188 (epoch 11), train_loss = 2.682, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 7189 (epoch 11), train_loss = 2.807, time/batch = 0.027
Read data: 0.000102996826171875
iter 7190 (epoch 11), train_loss = 3.008, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 7191 (epoch 11), train_loss = 2.459, time/batch = 0.025
Read data: 0.0008876323699951172
iter 7192 (epoch 11), train_loss = 2.777, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 7193 (epoch 11), train_loss = 2.330, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 7194 (epoch 11), train_loss = 3.220, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 7195 (epoch 11), train_loss = 2.951, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7196 (epoch 11), train_loss = 2.714, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 7197 (epoch 11), train_loss = 3.005, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 7198 (epoch 11), train_loss = 2.355, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 7199 (epoch 11), train_loss = 2.889, time/batch = 0.027
Read data: 0.0002486705780029297
iter 7200 (epoch 11), train_loss = 2.333, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 7201 (epoch 12), train_loss = 2.733, time/batch = 0.037
Read data: 0.00011134147644042969
iter 7202 (epoch 12), train_loss = 2.469, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 7203 (epoch 12), train_loss = 2.437, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 7204 (epoch 12), train_loss = 2.664, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 7205 (epoch 12), train_loss = 2.207, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 7206 (epoch 12), train_loss = 2.542, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 7207 (epoch 12), train_loss = 2.777, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 7208 (epoch 12), train_loss = 2.441, time/batch = 0.037
Read data: 0.00011515617370605469
iter 7209 (epoch 12), train_loss = 3.054, time/batch = 0.032
Read data: 0.00011396408081054688
iter 7210 (epoch 12), train_loss = 2.450, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 7211 (epoch 12), train_loss = 2.559, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 7212 (epoch 12), train_loss = 2.914, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 7213 (epoch 12), train_loss = 2.389, time/batch = 0.023
Read data: 9.799003601074219e-05
iter 7214 (epoch 12), train_loss = 2.492, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 7215 (epoch 12), train_loss = 2.446, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 7216 (epoch 12), train_loss = 2.354, time/batch = 0.031
Read data: 7.748603820800781e-05
iter 7217 (epoch 12), train_loss = 2.784, time/batch = 0.034
Read data: 8.130073547363281e-05
iter 7218 (epoch 12), train_loss = 2.950, time/batch = 0.030
Read data: 0.00012445449829101562
iter 7219 (epoch 12), train_loss = 2.738, time/batch = 0.028
Read data: 0.00013208389282226562
iter 7220 (epoch 12), train_loss = 2.506, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 7221 (epoch 12), train_loss = 2.671, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 7222 (epoch 12), train_loss = 2.210, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 7223 (epoch 12), train_loss = 2.593, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 7224 (epoch 12), train_loss = 2.798, time/batch = 0.024
Read data: 0.0002942085266113281
iter 7225 (epoch 12), train_loss = 3.016, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 7226 (epoch 12), train_loss = 2.545, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 7227 (epoch 12), train_loss = 2.897, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 7228 (epoch 12), train_loss = 2.847, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 7229 (epoch 12), train_loss = 2.702, time/batch = 0.034
Read data: 0.00011396408081054688
iter 7230 (epoch 12), train_loss = 2.790, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 7231 (epoch 12), train_loss = 2.953, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 7232 (epoch 12), train_loss = 2.547, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 7233 (epoch 12), train_loss = 3.213, time/batch = 0.031
Read data: 7.939338684082031e-05
iter 7234 (epoch 12), train_loss = 2.664, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 7235 (epoch 12), train_loss = 2.596, time/batch = 0.028
Read data: 9.584426879882812e-05
iter 7236 (epoch 12), train_loss = 2.496, time/batch = 0.029
Read data: 0.0001690387725830078
iter 7237 (epoch 12), train_loss = 2.826, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 7238 (epoch 12), train_loss = 3.091, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 7239 (epoch 12), train_loss = 2.845, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 7240 (epoch 12), train_loss = 2.873, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 7241 (epoch 12), train_loss = 2.378, time/batch = 0.022
Read data: 0.0001709461212158203
iter 7242 (epoch 12), train_loss = 2.945, time/batch = 0.036
Read data: 7.939338684082031e-05
iter 7243 (epoch 12), train_loss = 3.214, time/batch = 0.028
Read data: 0.00017261505126953125
iter 7244 (epoch 12), train_loss = 2.832, time/batch = 0.032
Read data: 0.00016641616821289062
iter 7245 (epoch 12), train_loss = 3.053, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 7246 (epoch 12), train_loss = 2.601, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 7247 (epoch 12), train_loss = 3.079, time/batch = 0.024
Read data: 0.0001838207244873047
iter 7248 (epoch 12), train_loss = 2.804, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7249 (epoch 12), train_loss = 2.671, time/batch = 0.028
Read data: 0.00021147727966308594
iter 7250 (epoch 12), train_loss = 2.454, time/batch = 0.023
Read data: 0.00012111663818359375
iter 7251 (epoch 12), train_loss = 2.732, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 7252 (epoch 12), train_loss = 2.932, time/batch = 0.030
Read data: 7.724761962890625e-05
iter 7253 (epoch 12), train_loss = 2.734, time/batch = 0.030
Read data: 0.00013184547424316406
iter 7254 (epoch 12), train_loss = 2.838, time/batch = 0.028
Read data: 0.00011348724365234375
iter 7255 (epoch 12), train_loss = 2.363, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 7256 (epoch 12), train_loss = 3.004, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 7257 (epoch 12), train_loss = 2.915, time/batch = 0.022
Read data: 7.82012939453125e-05
iter 7258 (epoch 12), train_loss = 2.318, time/batch = 0.024
Read data: 0.0001583099365234375
iter 7259 (epoch 12), train_loss = 2.400, time/batch = 0.022
Read data: 0.00017523765563964844
iter 7260 (epoch 12), train_loss = 2.232, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 7261 (epoch 12), train_loss = 2.988, time/batch = 0.026
Read data: 0.0001430511474609375
iter 7262 (epoch 12), train_loss = 2.629, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 7263 (epoch 12), train_loss = 2.710, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 7264 (epoch 12), train_loss = 2.578, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 7265 (epoch 12), train_loss = 3.074, time/batch = 0.023
Read data: 7.700920104980469e-05
iter 7266 (epoch 12), train_loss = 2.913, time/batch = 0.024
Read data: 0.00015592575073242188
iter 7267 (epoch 12), train_loss = 2.601, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 7268 (epoch 12), train_loss = 2.449, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 7269 (epoch 12), train_loss = 2.791, time/batch = 0.028
Read data: 0.00014925003051757812
iter 7270 (epoch 12), train_loss = 2.603, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 7271 (epoch 12), train_loss = 2.442, time/batch = 0.024
Read data: 0.00015401840209960938
iter 7272 (epoch 12), train_loss = 2.900, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 7273 (epoch 12), train_loss = 2.902, time/batch = 0.034
Read data: 0.0001392364501953125
iter 7274 (epoch 12), train_loss = 2.452, time/batch = 0.037
Read data: 0.00011444091796875
iter 7275 (epoch 12), train_loss = 2.726, time/batch = 0.033
Read data: 0.00019216537475585938
iter 7276 (epoch 12), train_loss = 2.614, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 7277 (epoch 12), train_loss = 2.806, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7278 (epoch 12), train_loss = 2.779, time/batch = 0.024
Read data: 7.605552673339844e-05
iter 7279 (epoch 12), train_loss = 3.269, time/batch = 0.025
Read data: 0.00015282630920410156
iter 7280 (epoch 12), train_loss = 2.062, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 7281 (epoch 12), train_loss = 2.520, time/batch = 0.028
Read data: 0.00011801719665527344
iter 7282 (epoch 12), train_loss = 2.406, time/batch = 0.033
Read data: 8.130073547363281e-05
iter 7283 (epoch 12), train_loss = 2.847, time/batch = 0.047
Read data: 7.748603820800781e-05
iter 7284 (epoch 12), train_loss = 2.791, time/batch = 0.028
Read data: 9.1552734375e-05
iter 7285 (epoch 12), train_loss = 2.956, time/batch = 0.032
Read data: 7.343292236328125e-05
iter 7286 (epoch 12), train_loss = 3.136, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7287 (epoch 12), train_loss = 2.572, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 7288 (epoch 12), train_loss = 2.564, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 7289 (epoch 12), train_loss = 2.382, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 7290 (epoch 12), train_loss = 2.574, time/batch = 0.034
Read data: 8.702278137207031e-05
iter 7291 (epoch 12), train_loss = 2.924, time/batch = 0.038
Read data: 0.00017333030700683594
iter 7292 (epoch 12), train_loss = 2.587, time/batch = 0.027
Read data: 0.0001590251922607422
iter 7293 (epoch 12), train_loss = 2.986, time/batch = 0.036
Read data: 0.00013566017150878906
iter 7294 (epoch 12), train_loss = 2.595, time/batch = 0.035
Read data: 0.00022935867309570312
iter 7295 (epoch 12), train_loss = 2.642, time/batch = 0.030
Read data: 0.00014472007751464844
iter 7296 (epoch 12), train_loss = 2.620, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 7297 (epoch 12), train_loss = 2.626, time/batch = 0.022
Read data: 7.605552673339844e-05
iter 7298 (epoch 12), train_loss = 2.387, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 7299 (epoch 12), train_loss = 2.340, time/batch = 0.026
Read data: 7.534027099609375e-05
iter 7300 (epoch 12), train_loss = 2.969, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 7301 (epoch 12), train_loss = 2.857, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 7302 (epoch 12), train_loss = 3.167, time/batch = 0.034
Read data: 8.845329284667969e-05
iter 7303 (epoch 12), train_loss = 2.801, time/batch = 0.031
Read data: 0.00014257431030273438
iter 7304 (epoch 12), train_loss = 2.705, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 7305 (epoch 12), train_loss = 2.471, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 7306 (epoch 12), train_loss = 3.140, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 7307 (epoch 12), train_loss = 2.701, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 7308 (epoch 12), train_loss = 2.730, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 7309 (epoch 12), train_loss = 2.829, time/batch = 0.024
Read data: 0.00012493133544921875
iter 7310 (epoch 12), train_loss = 2.736, time/batch = 0.033
Read data: 7.796287536621094e-05
iter 7311 (epoch 12), train_loss = 2.550, time/batch = 0.028
Read data: 0.0001513957977294922
iter 7312 (epoch 12), train_loss = 2.378, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 7313 (epoch 12), train_loss = 2.822, time/batch = 0.032
Read data: 7.700920104980469e-05
iter 7314 (epoch 12), train_loss = 2.765, time/batch = 0.029
Read data: 0.0001418590545654297
iter 7315 (epoch 12), train_loss = 2.539, time/batch = 0.028
Read data: 0.0001404285430908203
iter 7316 (epoch 12), train_loss = 2.884, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 7317 (epoch 12), train_loss = 2.759, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7318 (epoch 12), train_loss = 2.256, time/batch = 0.028
Read data: 0.00013566017150878906
iter 7319 (epoch 12), train_loss = 2.655, time/batch = 0.042
Read data: 0.00013971328735351562
iter 7320 (epoch 12), train_loss = 2.457, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 7321 (epoch 12), train_loss = 2.810, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 7322 (epoch 12), train_loss = 2.494, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 7323 (epoch 12), train_loss = 2.409, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 7324 (epoch 12), train_loss = 2.504, time/batch = 0.032
Read data: 0.00021123886108398438
iter 7325 (epoch 12), train_loss = 3.147, time/batch = 0.028
Read data: 7.581710815429688e-05
iter 7326 (epoch 12), train_loss = 2.634, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 7327 (epoch 12), train_loss = 2.886, time/batch = 0.031
Read data: 0.00013303756713867188
iter 7328 (epoch 12), train_loss = 2.808, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 7329 (epoch 12), train_loss = 2.978, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 7330 (epoch 12), train_loss = 2.795, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 7331 (epoch 12), train_loss = 2.547, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 7332 (epoch 12), train_loss = 2.850, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 7333 (epoch 12), train_loss = 2.784, time/batch = 0.031
Read data: 9.179115295410156e-05
iter 7334 (epoch 12), train_loss = 2.423, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 7335 (epoch 12), train_loss = 2.795, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 7336 (epoch 12), train_loss = 2.693, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 7337 (epoch 12), train_loss = 2.161, time/batch = 0.028
Read data: 0.00012636184692382812
iter 7338 (epoch 12), train_loss = 2.707, time/batch = 0.030
Read data: 0.00015854835510253906
iter 7339 (epoch 12), train_loss = 2.658, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 7340 (epoch 12), train_loss = 2.231, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 7341 (epoch 12), train_loss = 2.571, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 7342 (epoch 12), train_loss = 2.668, time/batch = 0.031
Read data: 7.796287536621094e-05
iter 7343 (epoch 12), train_loss = 2.577, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 7344 (epoch 12), train_loss = 2.612, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 7345 (epoch 12), train_loss = 2.211, time/batch = 0.029
Read data: 0.0001590251922607422
iter 7346 (epoch 12), train_loss = 2.257, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 7347 (epoch 12), train_loss = 2.232, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 7348 (epoch 12), train_loss = 2.944, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 7349 (epoch 12), train_loss = 2.820, time/batch = 0.023
Read data: 0.00021839141845703125
iter 7350 (epoch 12), train_loss = 2.636, time/batch = 0.037
Read data: 8.296966552734375e-05
iter 7351 (epoch 12), train_loss = 2.809, time/batch = 0.029
Read data: 0.0001468658447265625
iter 7352 (epoch 12), train_loss = 2.996, time/batch = 0.033
Read data: 0.00012183189392089844
iter 7353 (epoch 12), train_loss = 2.305, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 7354 (epoch 12), train_loss = 2.588, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 7355 (epoch 12), train_loss = 2.386, time/batch = 0.030
Read data: 0.0001575946807861328
iter 7356 (epoch 12), train_loss = 2.856, time/batch = 0.033
Read data: 8.177757263183594e-05
iter 7357 (epoch 12), train_loss = 2.925, time/batch = 0.026
Read data: 7.62939453125e-05
iter 7358 (epoch 12), train_loss = 2.331, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 7359 (epoch 12), train_loss = 2.975, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 7360 (epoch 12), train_loss = 2.601, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 7361 (epoch 12), train_loss = 2.735, time/batch = 0.025
Read data: 0.00015473365783691406
iter 7362 (epoch 12), train_loss = 3.041, time/batch = 0.030
Read data: 0.00011110305786132812
iter 7363 (epoch 12), train_loss = 2.731, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 7364 (epoch 12), train_loss = 3.046, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 7365 (epoch 12), train_loss = 2.679, time/batch = 0.021
Read data: 0.00012636184692382812
iter 7366 (epoch 12), train_loss = 2.398, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 7367 (epoch 12), train_loss = 2.885, time/batch = 0.042
Read data: 7.867813110351562e-05
iter 7368 (epoch 12), train_loss = 3.061, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 7369 (epoch 12), train_loss = 2.545, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 7370 (epoch 12), train_loss = 2.630, time/batch = 0.035
Read data: 8.392333984375e-05
iter 7371 (epoch 12), train_loss = 2.876, time/batch = 0.034
Read data: 0.00013685226440429688
iter 7372 (epoch 12), train_loss = 2.854, time/batch = 0.028
Read data: 9.942054748535156e-05
iter 7373 (epoch 12), train_loss = 2.734, time/batch = 0.029
Read data: 0.00015783309936523438
iter 7374 (epoch 12), train_loss = 2.172, time/batch = 0.024
Read data: 0.00027489662170410156
iter 7375 (epoch 12), train_loss = 2.777, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 7376 (epoch 12), train_loss = 2.976, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 7377 (epoch 12), train_loss = 2.415, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 7378 (epoch 12), train_loss = 3.246, time/batch = 0.032
Read data: 0.00016236305236816406
iter 7379 (epoch 12), train_loss = 2.640, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 7380 (epoch 12), train_loss = 2.724, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 7381 (epoch 12), train_loss = 2.911, time/batch = 0.021
Read data: 7.748603820800781e-05
iter 7382 (epoch 12), train_loss = 3.016, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 7383 (epoch 12), train_loss = 2.803, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 7384 (epoch 12), train_loss = 2.867, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 7385 (epoch 12), train_loss = 2.303, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 7386 (epoch 12), train_loss = 2.540, time/batch = 0.026
Read data: 0.00016355514526367188
iter 7387 (epoch 12), train_loss = 2.143, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 7388 (epoch 12), train_loss = 2.672, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 7389 (epoch 12), train_loss = 2.791, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 7390 (epoch 12), train_loss = 2.431, time/batch = 0.046
Read data: 8.726119995117188e-05
iter 7391 (epoch 12), train_loss = 2.430, time/batch = 0.034
Read data: 7.486343383789062e-05
iter 7392 (epoch 12), train_loss = 2.855, time/batch = 0.034
Read data: 8.606910705566406e-05
iter 7393 (epoch 12), train_loss = 2.758, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 7394 (epoch 12), train_loss = 2.961, time/batch = 0.028
Read data: 0.00014519691467285156
iter 7395 (epoch 12), train_loss = 2.588, time/batch = 0.038
Read data: 9.322166442871094e-05
iter 7396 (epoch 12), train_loss = 2.632, time/batch = 0.035
Read data: 9.179115295410156e-05
iter 7397 (epoch 12), train_loss = 2.598, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 7398 (epoch 12), train_loss = 2.743, time/batch = 0.034
Read data: 0.00014162063598632812
iter 7399 (epoch 12), train_loss = 2.396, time/batch = 0.032
Read data: 0.00023818016052246094
iter 7400 (epoch 12), train_loss = 2.381, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 7401 (epoch 12), train_loss = 2.559, time/batch = 0.023
Read data: 7.653236389160156e-05
iter 7402 (epoch 12), train_loss = 2.748, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 7403 (epoch 12), train_loss = 3.028, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 7404 (epoch 12), train_loss = 2.948, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 7405 (epoch 12), train_loss = 3.016, time/batch = 0.027
Read data: 7.653236389160156e-05
iter 7406 (epoch 12), train_loss = 3.000, time/batch = 0.037
Read data: 0.00014328956604003906
iter 7407 (epoch 12), train_loss = 2.948, time/batch = 0.031
Read data: 0.00017142295837402344
iter 7408 (epoch 12), train_loss = 2.768, time/batch = 0.034
Read data: 8.606910705566406e-05
iter 7409 (epoch 12), train_loss = 3.093, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 7410 (epoch 12), train_loss = 2.420, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 7411 (epoch 12), train_loss = 3.006, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 7412 (epoch 12), train_loss = 2.607, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 7413 (epoch 12), train_loss = 2.653, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 7414 (epoch 12), train_loss = 2.877, time/batch = 0.042
Read data: 8.511543273925781e-05
iter 7415 (epoch 12), train_loss = 2.664, time/batch = 0.031
Read data: 0.00016999244689941406
iter 7416 (epoch 12), train_loss = 2.973, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 7417 (epoch 12), train_loss = 3.239, time/batch = 0.036
Read data: 9.012222290039062e-05
iter 7418 (epoch 12), train_loss = 2.676, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 7419 (epoch 12), train_loss = 2.515, time/batch = 0.028
Read data: 0.0001671314239501953
iter 7420 (epoch 12), train_loss = 2.676, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 7421 (epoch 12), train_loss = 2.673, time/batch = 0.027
Read data: 0.0001308917999267578
iter 7422 (epoch 12), train_loss = 2.652, time/batch = 0.030
Read data: 0.00011301040649414062
iter 7423 (epoch 12), train_loss = 2.569, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 7424 (epoch 12), train_loss = 2.466, time/batch = 0.028
Read data: 0.0002200603485107422
iter 7425 (epoch 12), train_loss = 2.712, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 7426 (epoch 12), train_loss = 2.842, time/batch = 0.034
Read data: 7.915496826171875e-05
iter 7427 (epoch 12), train_loss = 2.449, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 7428 (epoch 12), train_loss = 2.499, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 7429 (epoch 12), train_loss = 2.266, time/batch = 0.026
Read data: 0.000141143798828125
iter 7430 (epoch 12), train_loss = 3.040, time/batch = 0.035
Read data: 0.00015878677368164062
iter 7431 (epoch 12), train_loss = 2.828, time/batch = 0.028
Read data: 0.00010442733764648438
iter 7432 (epoch 12), train_loss = 2.422, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 7433 (epoch 12), train_loss = 2.678, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 7434 (epoch 12), train_loss = 2.413, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 7435 (epoch 12), train_loss = 2.857, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 7436 (epoch 12), train_loss = 2.350, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 7437 (epoch 12), train_loss = 2.709, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 7438 (epoch 12), train_loss = 2.564, time/batch = 0.022
Read data: 0.00015091896057128906
iter 7439 (epoch 12), train_loss = 2.840, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 7440 (epoch 12), train_loss = 2.613, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 7441 (epoch 12), train_loss = 2.780, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 7442 (epoch 12), train_loss = 2.575, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 7443 (epoch 12), train_loss = 2.573, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 7444 (epoch 12), train_loss = 2.763, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 7445 (epoch 12), train_loss = 2.186, time/batch = 0.025
Read data: 0.00017523765563964844
iter 7446 (epoch 12), train_loss = 2.700, time/batch = 0.030
Read data: 0.00012040138244628906
iter 7447 (epoch 12), train_loss = 2.502, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 7448 (epoch 12), train_loss = 2.800, time/batch = 0.040
Read data: 7.987022399902344e-05
iter 7449 (epoch 12), train_loss = 2.938, time/batch = 0.029
Read data: 0.00023698806762695312
iter 7450 (epoch 12), train_loss = 3.075, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 7451 (epoch 12), train_loss = 2.974, time/batch = 0.027
Read data: 9.1552734375e-05
iter 7452 (epoch 12), train_loss = 2.529, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 7453 (epoch 12), train_loss = 2.605, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 7454 (epoch 12), train_loss = 2.459, time/batch = 0.023
Read data: 0.0001304149627685547
iter 7455 (epoch 12), train_loss = 2.380, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 7456 (epoch 12), train_loss = 3.229, time/batch = 0.027
Read data: 0.00010013580322265625
iter 7457 (epoch 12), train_loss = 2.958, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 7458 (epoch 12), train_loss = 2.414, time/batch = 0.024
Read data: 0.00012993812561035156
iter 7459 (epoch 12), train_loss = 2.621, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 7460 (epoch 12), train_loss = 2.591, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 7461 (epoch 12), train_loss = 2.566, time/batch = 0.023
Read data: 0.00016617774963378906
iter 7462 (epoch 12), train_loss = 2.868, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 7463 (epoch 12), train_loss = 3.007, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 7464 (epoch 12), train_loss = 2.735, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 7465 (epoch 12), train_loss = 2.501, time/batch = 0.025
Read data: 0.00011396408081054688
iter 7466 (epoch 12), train_loss = 2.689, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 7467 (epoch 12), train_loss = 2.909, time/batch = 0.023
Read data: 0.00012135505676269531
iter 7468 (epoch 12), train_loss = 2.297, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 7469 (epoch 12), train_loss = 2.083, time/batch = 0.022
Read data: 0.00011444091796875
iter 7470 (epoch 12), train_loss = 3.114, time/batch = 0.035
Read data: 7.653236389160156e-05
iter 7471 (epoch 12), train_loss = 2.384, time/batch = 0.021
Read data: 7.843971252441406e-05
iter 7472 (epoch 12), train_loss = 2.140, time/batch = 0.023
Read data: 0.00020623207092285156
iter 7473 (epoch 12), train_loss = 2.722, time/batch = 0.024
Read data: 0.00016760826110839844
iter 7474 (epoch 12), train_loss = 3.017, time/batch = 0.026
Read data: 0.0003402233123779297
iter 7475 (epoch 12), train_loss = 2.754, time/batch = 0.026
Read data: 0.00017261505126953125
iter 7476 (epoch 12), train_loss = 2.753, time/batch = 0.027
Read data: 9.965896606445312e-05
iter 7477 (epoch 12), train_loss = 2.175, time/batch = 0.023
Read data: 0.00011706352233886719
iter 7478 (epoch 12), train_loss = 2.349, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 7479 (epoch 12), train_loss = 2.726, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 7480 (epoch 12), train_loss = 2.789, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 7481 (epoch 12), train_loss = 2.307, time/batch = 0.022
Read data: 0.00011420249938964844
iter 7482 (epoch 12), train_loss = 2.611, time/batch = 0.025
Read data: 0.00014209747314453125
iter 7483 (epoch 12), train_loss = 2.606, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 7484 (epoch 12), train_loss = 2.841, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 7485 (epoch 12), train_loss = 2.656, time/batch = 0.026
Read data: 0.00011157989501953125
iter 7486 (epoch 12), train_loss = 2.574, time/batch = 0.031
Read data: 7.867813110351562e-05
iter 7487 (epoch 12), train_loss = 3.248, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 7488 (epoch 12), train_loss = 2.561, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 7489 (epoch 12), train_loss = 2.487, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 7490 (epoch 12), train_loss = 2.282, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 7491 (epoch 12), train_loss = 2.727, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 7492 (epoch 12), train_loss = 2.777, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 7493 (epoch 12), train_loss = 2.845, time/batch = 0.023
Read data: 0.000102996826171875
iter 7494 (epoch 12), train_loss = 2.693, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 7495 (epoch 12), train_loss = 2.634, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 7496 (epoch 12), train_loss = 2.673, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 7497 (epoch 12), train_loss = 2.641, time/batch = 0.030
Read data: 0.0001289844512939453
iter 7498 (epoch 12), train_loss = 2.471, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 7499 (epoch 12), train_loss = 2.591, time/batch = 0.024
Read data: 0.00023651123046875
iter 7500 (epoch 12), train_loss = 2.683, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 7501 (epoch 12), train_loss = 2.366, time/batch = 0.023
Read data: 0.00011849403381347656
iter 7502 (epoch 12), train_loss = 2.525, time/batch = 0.033
Read data: 7.963180541992188e-05
iter 7503 (epoch 12), train_loss = 2.597, time/batch = 0.021
Read data: 7.772445678710938e-05
iter 7504 (epoch 12), train_loss = 2.688, time/batch = 0.020
Read data: 9.608268737792969e-05
iter 7505 (epoch 12), train_loss = 2.882, time/batch = 0.027
Read data: 0.00011420249938964844
iter 7506 (epoch 12), train_loss = 2.973, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 7507 (epoch 12), train_loss = 2.952, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 7508 (epoch 12), train_loss = 2.729, time/batch = 0.024
Read data: 0.0016672611236572266
iter 7509 (epoch 12), train_loss = 2.446, time/batch = 0.023
Read data: 0.00011682510375976562
iter 7510 (epoch 12), train_loss = 2.396, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 7511 (epoch 12), train_loss = 2.404, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 7512 (epoch 12), train_loss = 2.976, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 7513 (epoch 12), train_loss = 3.198, time/batch = 0.027
Read data: 0.0001595020294189453
iter 7514 (epoch 12), train_loss = 2.752, time/batch = 0.024
Read data: 0.00015854835510253906
iter 7515 (epoch 12), train_loss = 2.442, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 7516 (epoch 12), train_loss = 2.398, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 7517 (epoch 12), train_loss = 2.752, time/batch = 0.025
Read data: 0.00017309188842773438
iter 7518 (epoch 12), train_loss = 2.510, time/batch = 0.029
Read data: 8.797645568847656e-05
iter 7519 (epoch 12), train_loss = 2.808, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 7520 (epoch 12), train_loss = 2.540, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 7521 (epoch 12), train_loss = 2.702, time/batch = 0.026
Read data: 0.00015664100646972656
iter 7522 (epoch 12), train_loss = 2.675, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7523 (epoch 12), train_loss = 3.145, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 7524 (epoch 12), train_loss = 2.699, time/batch = 0.021
Read data: 0.0002105236053466797
iter 7525 (epoch 12), train_loss = 2.507, time/batch = 0.026
Read data: 0.00011920928955078125
iter 7526 (epoch 12), train_loss = 2.836, time/batch = 0.024
Read data: 0.0001571178436279297
iter 7527 (epoch 12), train_loss = 2.964, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 7528 (epoch 12), train_loss = 2.498, time/batch = 0.026
Read data: 0.00011992454528808594
iter 7529 (epoch 12), train_loss = 2.770, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 7530 (epoch 12), train_loss = 2.696, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 7531 (epoch 12), train_loss = 2.551, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 7532 (epoch 12), train_loss = 2.529, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 7533 (epoch 12), train_loss = 3.147, time/batch = 0.027
Read data: 0.00012087821960449219
iter 7534 (epoch 12), train_loss = 2.823, time/batch = 0.023
Read data: 0.00010085105895996094
iter 7535 (epoch 12), train_loss = 2.676, time/batch = 0.029
Read data: 7.700920104980469e-05
iter 7536 (epoch 12), train_loss = 2.704, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 7537 (epoch 12), train_loss = 2.245, time/batch = 0.026
Read data: 0.0001316070556640625
iter 7538 (epoch 12), train_loss = 2.519, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 7539 (epoch 12), train_loss = 2.996, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 7540 (epoch 12), train_loss = 2.662, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 7541 (epoch 12), train_loss = 2.638, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 7542 (epoch 12), train_loss = 2.784, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 7543 (epoch 12), train_loss = 2.644, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 7544 (epoch 12), train_loss = 2.701, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7545 (epoch 12), train_loss = 2.804, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 7546 (epoch 12), train_loss = 2.690, time/batch = 0.025
Read data: 0.0001518726348876953
iter 7547 (epoch 12), train_loss = 2.568, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 7548 (epoch 12), train_loss = 2.297, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 7549 (epoch 12), train_loss = 2.737, time/batch = 0.023
Read data: 0.00012087821960449219
iter 7550 (epoch 12), train_loss = 3.304, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 7551 (epoch 12), train_loss = 2.527, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 7552 (epoch 12), train_loss = 2.509, time/batch = 0.026
Read data: 0.00010275840759277344
iter 7553 (epoch 12), train_loss = 2.631, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 7554 (epoch 12), train_loss = 2.973, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 7555 (epoch 12), train_loss = 2.669, time/batch = 0.038
Read data: 8.559226989746094e-05
iter 7556 (epoch 12), train_loss = 2.585, time/batch = 0.041
Read data: 7.891654968261719e-05
iter 7557 (epoch 12), train_loss = 2.689, time/batch = 0.026
Read data: 7.62939453125e-05
iter 7558 (epoch 12), train_loss = 3.052, time/batch = 0.024
Read data: 0.00012159347534179688
iter 7559 (epoch 12), train_loss = 2.622, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 7560 (epoch 12), train_loss = 2.570, time/batch = 0.025
Read data: 7.62939453125e-05
iter 7561 (epoch 12), train_loss = 2.368, time/batch = 0.023
Read data: 0.000179290771484375
iter 7562 (epoch 12), train_loss = 2.533, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 7563 (epoch 12), train_loss = 2.793, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 7564 (epoch 12), train_loss = 2.789, time/batch = 0.026
Read data: 0.00011944770812988281
iter 7565 (epoch 12), train_loss = 2.719, time/batch = 0.030
Read data: 0.00012135505676269531
iter 7566 (epoch 12), train_loss = 3.238, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 7567 (epoch 12), train_loss = 2.491, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 7568 (epoch 12), train_loss = 3.190, time/batch = 0.033
Read data: 0.00011563301086425781
iter 7569 (epoch 12), train_loss = 2.632, time/batch = 0.032
Read data: 0.000171661376953125
iter 7570 (epoch 12), train_loss = 2.927, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 7571 (epoch 12), train_loss = 3.052, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 7572 (epoch 12), train_loss = 2.575, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 7573 (epoch 12), train_loss = 2.542, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7574 (epoch 12), train_loss = 2.518, time/batch = 0.030
Read data: 0.00021409988403320312
iter 7575 (epoch 12), train_loss = 2.524, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7576 (epoch 12), train_loss = 3.049, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 7577 (epoch 12), train_loss = 2.673, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 7578 (epoch 12), train_loss = 2.601, time/batch = 0.028
Read data: 0.00010323524475097656
iter 7579 (epoch 12), train_loss = 2.762, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 7580 (epoch 12), train_loss = 2.853, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 7581 (epoch 12), train_loss = 2.905, time/batch = 0.023
Read data: 0.00016570091247558594
iter 7582 (epoch 12), train_loss = 2.754, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 7583 (epoch 12), train_loss = 2.948, time/batch = 0.034
Read data: 8.344650268554688e-05
iter 7584 (epoch 12), train_loss = 2.203, time/batch = 0.021
Read data: 8.344650268554688e-05
iter 7585 (epoch 12), train_loss = 2.724, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7586 (epoch 12), train_loss = 2.994, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 7587 (epoch 12), train_loss = 2.494, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 7588 (epoch 12), train_loss = 2.718, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 7589 (epoch 12), train_loss = 2.887, time/batch = 0.032
Read data: 0.00013136863708496094
iter 7590 (epoch 12), train_loss = 2.990, time/batch = 0.023
Read data: 0.00020384788513183594
iter 7591 (epoch 12), train_loss = 2.441, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 7592 (epoch 12), train_loss = 2.901, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 7593 (epoch 12), train_loss = 2.870, time/batch = 0.025
Read data: 0.00014400482177734375
iter 7594 (epoch 12), train_loss = 2.478, time/batch = 0.026
Read data: 0.0001552104949951172
iter 7595 (epoch 12), train_loss = 2.902, time/batch = 0.036
Read data: 0.000171661376953125
iter 7596 (epoch 12), train_loss = 2.369, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 7597 (epoch 12), train_loss = 2.908, time/batch = 0.027
Read data: 0.00013947486877441406
iter 7598 (epoch 12), train_loss = 3.073, time/batch = 0.034
Read data: 0.00013494491577148438
iter 7599 (epoch 12), train_loss = 2.611, time/batch = 0.033
Read data: 0.0002598762512207031
iter 7600 (epoch 12), train_loss = 2.519, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 7601 (epoch 12), train_loss = 2.315, time/batch = 0.036
Read data: 8.678436279296875e-05
iter 7602 (epoch 12), train_loss = 2.733, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 7603 (epoch 12), train_loss = 2.418, time/batch = 0.028
Read data: 0.0001361370086669922
iter 7604 (epoch 12), train_loss = 2.719, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 7605 (epoch 12), train_loss = 2.628, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 7606 (epoch 12), train_loss = 2.736, time/batch = 0.025
Read data: 0.00010132789611816406
iter 7607 (epoch 12), train_loss = 2.229, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 7608 (epoch 12), train_loss = 2.601, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 7609 (epoch 12), train_loss = 2.459, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 7610 (epoch 12), train_loss = 2.522, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 7611 (epoch 12), train_loss = 3.210, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 7612 (epoch 12), train_loss = 3.020, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 7613 (epoch 12), train_loss = 2.754, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 7614 (epoch 12), train_loss = 2.722, time/batch = 0.023
Read data: 0.00012946128845214844
iter 7615 (epoch 12), train_loss = 2.533, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 7616 (epoch 12), train_loss = 2.983, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 7617 (epoch 12), train_loss = 2.327, time/batch = 0.021
Read data: 0.00010132789611816406
iter 7618 (epoch 12), train_loss = 2.629, time/batch = 0.028
Read data: 0.0001323223114013672
iter 7619 (epoch 12), train_loss = 2.169, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 7620 (epoch 12), train_loss = 3.131, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 7621 (epoch 12), train_loss = 2.431, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 7622 (epoch 12), train_loss = 2.519, time/batch = 0.025
Read data: 0.00012755393981933594
iter 7623 (epoch 12), train_loss = 2.805, time/batch = 0.029
Read data: 9.703636169433594e-05
iter 7624 (epoch 12), train_loss = 2.949, time/batch = 0.021
Read data: 0.0001976490020751953
iter 7625 (epoch 12), train_loss = 2.688, time/batch = 0.028
Read data: 9.775161743164062e-05
iter 7626 (epoch 12), train_loss = 2.890, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 7627 (epoch 12), train_loss = 2.521, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 7628 (epoch 12), train_loss = 2.674, time/batch = 0.024
Read data: 0.000102996826171875
iter 7629 (epoch 12), train_loss = 3.241, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 7630 (epoch 12), train_loss = 3.111, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 7631 (epoch 12), train_loss = 2.390, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 7632 (epoch 12), train_loss = 2.288, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 7633 (epoch 12), train_loss = 2.494, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 7634 (epoch 12), train_loss = 2.916, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 7635 (epoch 12), train_loss = 2.933, time/batch = 0.024
Read data: 0.0001461505889892578
iter 7636 (epoch 12), train_loss = 2.887, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 7637 (epoch 12), train_loss = 3.199, time/batch = 0.036
Read data: 8.153915405273438e-05
iter 7638 (epoch 12), train_loss = 2.422, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 7639 (epoch 12), train_loss = 2.585, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 7640 (epoch 12), train_loss = 3.096, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 7641 (epoch 12), train_loss = 2.707, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 7642 (epoch 12), train_loss = 2.911, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 7643 (epoch 12), train_loss = 2.569, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 7644 (epoch 12), train_loss = 2.990, time/batch = 0.026
Read data: 0.00010728836059570312
iter 7645 (epoch 12), train_loss = 2.645, time/batch = 0.023
Read data: 0.00015234947204589844
iter 7646 (epoch 12), train_loss = 2.492, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 7647 (epoch 12), train_loss = 2.207, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 7648 (epoch 12), train_loss = 2.661, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 7649 (epoch 12), train_loss = 2.695, time/batch = 0.023
Read data: 0.00019121170043945312
iter 7650 (epoch 12), train_loss = 2.432, time/batch = 0.030
Read data: 0.00015544891357421875
iter 7651 (epoch 12), train_loss = 2.710, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 7652 (epoch 12), train_loss = 3.099, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 7653 (epoch 12), train_loss = 2.469, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 7654 (epoch 12), train_loss = 2.732, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 7655 (epoch 12), train_loss = 2.885, time/batch = 0.025
Read data: 0.00017523765563964844
iter 7656 (epoch 12), train_loss = 2.994, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 7657 (epoch 12), train_loss = 2.752, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 7658 (epoch 12), train_loss = 2.529, time/batch = 0.023
Read data: 0.00015282630920410156
iter 7659 (epoch 12), train_loss = 2.666, time/batch = 0.026
Read data: 0.00014638900756835938
iter 7660 (epoch 12), train_loss = 2.917, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7661 (epoch 12), train_loss = 2.981, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 7662 (epoch 12), train_loss = 2.339, time/batch = 0.025
Read data: 0.00012731552124023438
iter 7663 (epoch 12), train_loss = 2.786, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 7664 (epoch 12), train_loss = 2.553, time/batch = 0.021
Read data: 9.274482727050781e-05
iter 7665 (epoch 12), train_loss = 2.541, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 7666 (epoch 12), train_loss = 2.335, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 7667 (epoch 12), train_loss = 2.669, time/batch = 0.025
Read data: 0.00017189979553222656
iter 7668 (epoch 12), train_loss = 2.542, time/batch = 0.029
Read data: 9.202957153320312e-05
iter 7669 (epoch 12), train_loss = 2.676, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 7670 (epoch 12), train_loss = 2.832, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7671 (epoch 12), train_loss = 2.816, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7672 (epoch 12), train_loss = 2.623, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 7673 (epoch 12), train_loss = 3.182, time/batch = 0.027
Read data: 0.0001342296600341797
iter 7674 (epoch 12), train_loss = 2.725, time/batch = 0.024
Read data: 0.00018739700317382812
iter 7675 (epoch 12), train_loss = 2.436, time/batch = 0.025
Read data: 0.00014972686767578125
iter 7676 (epoch 12), train_loss = 3.139, time/batch = 0.034
Read data: 8.392333984375e-05
iter 7677 (epoch 12), train_loss = 2.564, time/batch = 0.023
Read data: 0.0001857280731201172
iter 7678 (epoch 12), train_loss = 2.686, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 7679 (epoch 12), train_loss = 2.700, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 7680 (epoch 12), train_loss = 2.431, time/batch = 0.021
Read data: 8.678436279296875e-05
iter 7681 (epoch 12), train_loss = 2.649, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 7682 (epoch 12), train_loss = 2.820, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 7683 (epoch 12), train_loss = 2.623, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 7684 (epoch 12), train_loss = 2.947, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 7685 (epoch 12), train_loss = 2.846, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 7686 (epoch 12), train_loss = 2.769, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 7687 (epoch 12), train_loss = 2.696, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 7688 (epoch 12), train_loss = 2.805, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 7689 (epoch 12), train_loss = 2.433, time/batch = 0.019
Read data: 9.1552734375e-05
iter 7690 (epoch 12), train_loss = 2.508, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 7691 (epoch 12), train_loss = 3.070, time/batch = 0.027
Read data: 0.00014352798461914062
iter 7692 (epoch 12), train_loss = 2.153, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 7693 (epoch 12), train_loss = 2.801, time/batch = 0.027
Read data: 0.00010132789611816406
iter 7694 (epoch 12), train_loss = 2.813, time/batch = 0.029
Read data: 0.0001251697540283203
iter 7695 (epoch 12), train_loss = 2.674, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 7696 (epoch 12), train_loss = 2.382, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 7697 (epoch 12), train_loss = 2.927, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 7698 (epoch 12), train_loss = 2.364, time/batch = 0.025
Read data: 0.0001533031463623047
iter 7699 (epoch 12), train_loss = 2.336, time/batch = 0.025
Read data: 0.0001666545867919922
iter 7700 (epoch 12), train_loss = 3.086, time/batch = 0.036
Read data: 8.535385131835938e-05
iter 7701 (epoch 12), train_loss = 2.780, time/batch = 0.027
Read data: 0.00013184547424316406
iter 7702 (epoch 12), train_loss = 2.238, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 7703 (epoch 12), train_loss = 2.964, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 7704 (epoch 12), train_loss = 2.785, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 7705 (epoch 12), train_loss = 2.976, time/batch = 0.026
Read data: 0.00015425682067871094
iter 7706 (epoch 12), train_loss = 1.983, time/batch = 0.023
Read data: 0.0001552104949951172
iter 7707 (epoch 12), train_loss = 2.244, time/batch = 0.021
Read data: 0.0001735687255859375
iter 7708 (epoch 12), train_loss = 2.809, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 7709 (epoch 12), train_loss = 2.329, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 7710 (epoch 12), train_loss = 2.643, time/batch = 0.033
Read data: 0.0001289844512939453
iter 7711 (epoch 12), train_loss = 2.387, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 7712 (epoch 12), train_loss = 2.258, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 7713 (epoch 12), train_loss = 2.892, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 7714 (epoch 12), train_loss = 2.693, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 7715 (epoch 12), train_loss = 2.691, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 7716 (epoch 12), train_loss = 2.712, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 7717 (epoch 12), train_loss = 2.681, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 7718 (epoch 12), train_loss = 2.435, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 7719 (epoch 12), train_loss = 2.880, time/batch = 0.025
Read data: 0.00017690658569335938
iter 7720 (epoch 12), train_loss = 2.273, time/batch = 0.026
Read data: 9.417533874511719e-05
iter 7721 (epoch 12), train_loss = 2.983, time/batch = 0.021
Read data: 9.489059448242188e-05
iter 7722 (epoch 12), train_loss = 2.724, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 7723 (epoch 12), train_loss = 2.671, time/batch = 0.027
Read data: 0.0001442432403564453
iter 7724 (epoch 12), train_loss = 3.137, time/batch = 0.028
Read data: 0.00019168853759765625
iter 7725 (epoch 12), train_loss = 2.777, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 7726 (epoch 12), train_loss = 2.383, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 7727 (epoch 12), train_loss = 2.942, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 7728 (epoch 12), train_loss = 2.843, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 7729 (epoch 12), train_loss = 3.334, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 7730 (epoch 12), train_loss = 2.556, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7731 (epoch 12), train_loss = 2.681, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 7732 (epoch 12), train_loss = 2.512, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 7733 (epoch 12), train_loss = 2.776, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 7734 (epoch 12), train_loss = 2.709, time/batch = 0.024
Read data: 0.00010442733764648438
iter 7735 (epoch 12), train_loss = 2.649, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 7736 (epoch 12), train_loss = 2.450, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 7737 (epoch 12), train_loss = 2.491, time/batch = 0.022
Read data: 9.298324584960938e-05
iter 7738 (epoch 12), train_loss = 2.374, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 7739 (epoch 12), train_loss = 2.890, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 7740 (epoch 12), train_loss = 2.462, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 7741 (epoch 12), train_loss = 2.337, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 7742 (epoch 12), train_loss = 3.001, time/batch = 0.022
Read data: 0.00014853477478027344
iter 7743 (epoch 12), train_loss = 2.934, time/batch = 0.027
Read data: 0.00018286705017089844
iter 7744 (epoch 12), train_loss = 2.822, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 7745 (epoch 12), train_loss = 2.534, time/batch = 0.026
Read data: 0.0001556873321533203
iter 7746 (epoch 12), train_loss = 2.804, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 7747 (epoch 12), train_loss = 2.725, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7748 (epoch 12), train_loss = 2.779, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 7749 (epoch 12), train_loss = 2.583, time/batch = 0.026
Read data: 0.00019407272338867188
iter 7750 (epoch 12), train_loss = 3.213, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 7751 (epoch 12), train_loss = 3.079, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 7752 (epoch 12), train_loss = 3.286, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 7753 (epoch 12), train_loss = 2.919, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 7754 (epoch 12), train_loss = 3.195, time/batch = 0.038
Read data: 0.00011992454528808594
iter 7755 (epoch 12), train_loss = 2.387, time/batch = 0.030
Read data: 0.00018024444580078125
iter 7756 (epoch 12), train_loss = 2.510, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 7757 (epoch 12), train_loss = 2.779, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 7758 (epoch 12), train_loss = 3.160, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 7759 (epoch 12), train_loss = 2.521, time/batch = 0.023
Read data: 9.799003601074219e-05
iter 7760 (epoch 12), train_loss = 2.922, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 7761 (epoch 12), train_loss = 2.502, time/batch = 0.026
Read data: 0.00010156631469726562
iter 7762 (epoch 12), train_loss = 2.800, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 7763 (epoch 12), train_loss = 2.307, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 7764 (epoch 12), train_loss = 2.846, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 7765 (epoch 12), train_loss = 2.611, time/batch = 0.021
Read data: 9.799003601074219e-05
iter 7766 (epoch 12), train_loss = 2.420, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 7767 (epoch 12), train_loss = 3.039, time/batch = 0.036
Read data: 8.034706115722656e-05
iter 7768 (epoch 12), train_loss = 2.712, time/batch = 0.030
Read data: 0.00010776519775390625
iter 7769 (epoch 12), train_loss = 3.079, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 7770 (epoch 12), train_loss = 2.160, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 7771 (epoch 12), train_loss = 2.687, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 7772 (epoch 12), train_loss = 2.884, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 7773 (epoch 12), train_loss = 2.535, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 7774 (epoch 12), train_loss = 2.530, time/batch = 0.035
Read data: 0.0001690387725830078
iter 7775 (epoch 12), train_loss = 2.998, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 7776 (epoch 12), train_loss = 2.435, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 7777 (epoch 12), train_loss = 2.530, time/batch = 0.029
Read data: 0.00015854835510253906
iter 7778 (epoch 12), train_loss = 2.905, time/batch = 0.020
Read data: 0.00010037422180175781
iter 7779 (epoch 12), train_loss = 2.991, time/batch = 0.029
Read data: 9.679794311523438e-05
iter 7780 (epoch 12), train_loss = 2.819, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 7781 (epoch 12), train_loss = 2.333, time/batch = 0.025
Read data: 0.00015473365783691406
iter 7782 (epoch 12), train_loss = 2.877, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 7783 (epoch 12), train_loss = 2.587, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 7784 (epoch 12), train_loss = 2.619, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 7785 (epoch 12), train_loss = 2.026, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 7786 (epoch 12), train_loss = 2.811, time/batch = 0.028
Read data: 9.632110595703125e-05
iter 7787 (epoch 12), train_loss = 2.583, time/batch = 0.024
Read data: 0.00010442733764648438
iter 7788 (epoch 12), train_loss = 2.669, time/batch = 0.022
Read data: 0.00010132789611816406
iter 7789 (epoch 12), train_loss = 2.773, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 7790 (epoch 12), train_loss = 3.140, time/batch = 0.031
Read data: 0.0001354217529296875
iter 7791 (epoch 12), train_loss = 2.673, time/batch = 0.027
Read data: 0.0009303092956542969
iter 7792 (epoch 12), train_loss = 2.595, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 7793 (epoch 12), train_loss = 2.714, time/batch = 0.031
Read data: 0.0001347064971923828
iter 7794 (epoch 12), train_loss = 2.464, time/batch = 0.032
Read data: 0.00020432472229003906
iter 7795 (epoch 12), train_loss = 2.853, time/batch = 0.027
Read data: 0.00014400482177734375
iter 7796 (epoch 12), train_loss = 2.744, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 7797 (epoch 12), train_loss = 2.523, time/batch = 0.025
Read data: 0.0001277923583984375
iter 7798 (epoch 12), train_loss = 2.402, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 7799 (epoch 12), train_loss = 2.732, time/batch = 0.025
Read data: 0.0001709461212158203
iter 7800 (epoch 12), train_loss = 3.146, time/batch = 0.025
Read data: 0.00013899803161621094
iter 7801 (epoch 13), train_loss = 2.453, time/batch = 0.030
Read data: 0.0001270771026611328
iter 7802 (epoch 13), train_loss = 2.575, time/batch = 0.029
Read data: 0.000125885009765625
iter 7803 (epoch 13), train_loss = 2.094, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 7804 (epoch 13), train_loss = 2.781, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 7805 (epoch 13), train_loss = 2.895, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 7806 (epoch 13), train_loss = 2.403, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 7807 (epoch 13), train_loss = 2.302, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 7808 (epoch 13), train_loss = 2.850, time/batch = 0.036
Read data: 8.606910705566406e-05
iter 7809 (epoch 13), train_loss = 2.676, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 7810 (epoch 13), train_loss = 2.562, time/batch = 0.025
Read data: 0.00010776519775390625
iter 7811 (epoch 13), train_loss = 2.705, time/batch = 0.024
Read data: 9.918212890625e-05
iter 7812 (epoch 13), train_loss = 2.833, time/batch = 0.032
Read data: 7.891654968261719e-05
iter 7813 (epoch 13), train_loss = 3.124, time/batch = 0.023
Read data: 0.00012922286987304688
iter 7814 (epoch 13), train_loss = 2.330, time/batch = 0.029
Read data: 0.00012445449829101562
iter 7815 (epoch 13), train_loss = 3.124, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 7816 (epoch 13), train_loss = 2.584, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 7817 (epoch 13), train_loss = 2.197, time/batch = 0.030
Read data: 0.00015544891357421875
iter 7818 (epoch 13), train_loss = 2.962, time/batch = 0.030
Read data: 0.00016045570373535156
iter 7819 (epoch 13), train_loss = 3.013, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 7820 (epoch 13), train_loss = 3.094, time/batch = 0.038
Read data: 8.463859558105469e-05
iter 7821 (epoch 13), train_loss = 2.723, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 7822 (epoch 13), train_loss = 2.292, time/batch = 0.025
Read data: 0.00010776519775390625
iter 7823 (epoch 13), train_loss = 2.221, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 7824 (epoch 13), train_loss = 2.733, time/batch = 0.036
Read data: 0.00016999244689941406
iter 7825 (epoch 13), train_loss = 2.377, time/batch = 0.025
Read data: 0.00012993812561035156
iter 7826 (epoch 13), train_loss = 2.902, time/batch = 0.028
Read data: 0.0001804828643798828
iter 7827 (epoch 13), train_loss = 2.410, time/batch = 0.030
Read data: 0.00014400482177734375
iter 7828 (epoch 13), train_loss = 2.410, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 7829 (epoch 13), train_loss = 2.580, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 7830 (epoch 13), train_loss = 2.584, time/batch = 0.032
Read data: 0.00011181831359863281
iter 7831 (epoch 13), train_loss = 2.562, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 7832 (epoch 13), train_loss = 2.831, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 7833 (epoch 13), train_loss = 2.509, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 7834 (epoch 13), train_loss = 2.354, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 7835 (epoch 13), train_loss = 2.379, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 7836 (epoch 13), train_loss = 2.700, time/batch = 0.025
Read data: 0.00011396408081054688
iter 7837 (epoch 13), train_loss = 2.420, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 7838 (epoch 13), train_loss = 2.308, time/batch = 0.037
Read data: 8.893013000488281e-05
iter 7839 (epoch 13), train_loss = 2.205, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 7840 (epoch 13), train_loss = 2.528, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 7841 (epoch 13), train_loss = 2.597, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 7842 (epoch 13), train_loss = 3.070, time/batch = 0.027
Read data: 0.00012493133544921875
iter 7843 (epoch 13), train_loss = 2.470, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 7844 (epoch 13), train_loss = 2.769, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 7845 (epoch 13), train_loss = 2.667, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 7846 (epoch 13), train_loss = 2.619, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 7847 (epoch 13), train_loss = 2.393, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 7848 (epoch 13), train_loss = 2.567, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 7849 (epoch 13), train_loss = 2.406, time/batch = 0.025
Read data: 0.00016808509826660156
iter 7850 (epoch 13), train_loss = 2.963, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7851 (epoch 13), train_loss = 2.674, time/batch = 0.022
Read data: 7.82012939453125e-05
iter 7852 (epoch 13), train_loss = 2.942, time/batch = 0.038
Read data: 8.344650268554688e-05
iter 7853 (epoch 13), train_loss = 2.621, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 7854 (epoch 13), train_loss = 2.403, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 7855 (epoch 13), train_loss = 2.343, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 7856 (epoch 13), train_loss = 2.928, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 7857 (epoch 13), train_loss = 2.451, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7858 (epoch 13), train_loss = 2.684, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 7859 (epoch 13), train_loss = 2.902, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 7860 (epoch 13), train_loss = 2.752, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 7861 (epoch 13), train_loss = 2.636, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 7862 (epoch 13), train_loss = 2.439, time/batch = 0.032
Read data: 0.00013637542724609375
iter 7863 (epoch 13), train_loss = 2.660, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 7864 (epoch 13), train_loss = 2.371, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 7865 (epoch 13), train_loss = 2.474, time/batch = 0.021
Read data: 0.0001480579376220703
iter 7866 (epoch 13), train_loss = 2.826, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 7867 (epoch 13), train_loss = 2.173, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 7868 (epoch 13), train_loss = 2.816, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 7869 (epoch 13), train_loss = 2.510, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 7870 (epoch 13), train_loss = 2.755, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 7871 (epoch 13), train_loss = 2.409, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 7872 (epoch 13), train_loss = 2.593, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 7873 (epoch 13), train_loss = 2.647, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 7874 (epoch 13), train_loss = 2.365, time/batch = 0.027
Read data: 0.00012731552124023438
iter 7875 (epoch 13), train_loss = 2.469, time/batch = 0.026
Read data: 7.62939453125e-05
iter 7876 (epoch 13), train_loss = 3.002, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 7877 (epoch 13), train_loss = 2.481, time/batch = 0.020
Read data: 9.083747863769531e-05
iter 7878 (epoch 13), train_loss = 2.563, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 7879 (epoch 13), train_loss = 2.988, time/batch = 0.031
Read data: 9.489059448242188e-05
iter 7880 (epoch 13), train_loss = 2.311, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 7881 (epoch 13), train_loss = 2.185, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 7882 (epoch 13), train_loss = 2.610, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 7883 (epoch 13), train_loss = 2.229, time/batch = 0.024
Read data: 0.00011324882507324219
iter 7884 (epoch 13), train_loss = 2.601, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 7885 (epoch 13), train_loss = 2.890, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 7886 (epoch 13), train_loss = 2.803, time/batch = 0.036
Read data: 7.82012939453125e-05
iter 7887 (epoch 13), train_loss = 2.451, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7888 (epoch 13), train_loss = 2.246, time/batch = 0.021
Read data: 0.00015163421630859375
iter 7889 (epoch 13), train_loss = 2.711, time/batch = 0.023
Read data: 0.0001552104949951172
iter 7890 (epoch 13), train_loss = 2.712, time/batch = 0.037
Read data: 0.00016927719116210938
iter 7891 (epoch 13), train_loss = 2.749, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 7892 (epoch 13), train_loss = 2.510, time/batch = 0.029
Read data: 0.00012946128845214844
iter 7893 (epoch 13), train_loss = 3.025, time/batch = 0.030
Read data: 0.00013780593872070312
iter 7894 (epoch 13), train_loss = 3.198, time/batch = 0.029
Read data: 0.0001347064971923828
iter 7895 (epoch 13), train_loss = 2.537, time/batch = 0.031
Read data: 0.0001220703125
iter 7896 (epoch 13), train_loss = 2.718, time/batch = 0.037
Read data: 0.00016832351684570312
iter 7897 (epoch 13), train_loss = 2.647, time/batch = 0.023
Read data: 0.00012564659118652344
iter 7898 (epoch 13), train_loss = 2.630, time/batch = 0.031
Read data: 0.00011515617370605469
iter 7899 (epoch 13), train_loss = 2.494, time/batch = 0.029
Read data: 0.00020551681518554688
iter 7900 (epoch 13), train_loss = 2.896, time/batch = 0.029
Read data: 0.0001380443572998047
iter 7901 (epoch 13), train_loss = 2.779, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 7902 (epoch 13), train_loss = 2.432, time/batch = 0.029
Read data: 0.00013637542724609375
iter 7903 (epoch 13), train_loss = 2.543, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 7904 (epoch 13), train_loss = 2.635, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7905 (epoch 13), train_loss = 2.771, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7906 (epoch 13), train_loss = 2.261, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 7907 (epoch 13), train_loss = 2.252, time/batch = 0.023
Read data: 0.00013256072998046875
iter 7908 (epoch 13), train_loss = 3.398, time/batch = 0.033
Read data: 7.915496826171875e-05
iter 7909 (epoch 13), train_loss = 2.646, time/batch = 0.027
Read data: 0.0001571178436279297
iter 7910 (epoch 13), train_loss = 2.502, time/batch = 0.031
Read data: 0.00014066696166992188
iter 7911 (epoch 13), train_loss = 3.194, time/batch = 0.030
Read data: 0.00011539459228515625
iter 7912 (epoch 13), train_loss = 3.052, time/batch = 0.027
Read data: 0.00012874603271484375
iter 7913 (epoch 13), train_loss = 2.680, time/batch = 0.026
Read data: 0.00013327598571777344
iter 7914 (epoch 13), train_loss = 2.927, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 7915 (epoch 13), train_loss = 2.472, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 7916 (epoch 13), train_loss = 2.701, time/batch = 0.033
Read data: 0.00014090538024902344
iter 7917 (epoch 13), train_loss = 2.379, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 7918 (epoch 13), train_loss = 2.807, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 7919 (epoch 13), train_loss = 2.667, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 7920 (epoch 13), train_loss = 2.797, time/batch = 0.042
Read data: 8.893013000488281e-05
iter 7921 (epoch 13), train_loss = 3.054, time/batch = 0.026
Read data: 0.0001735687255859375
iter 7922 (epoch 13), train_loss = 2.511, time/batch = 0.028
Read data: 0.00017213821411132812
iter 7923 (epoch 13), train_loss = 2.723, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 7924 (epoch 13), train_loss = 2.446, time/batch = 0.023
Read data: 0.0001862049102783203
iter 7925 (epoch 13), train_loss = 2.908, time/batch = 0.027
Read data: 0.00013756752014160156
iter 7926 (epoch 13), train_loss = 3.141, time/batch = 0.026
Read data: 0.00010085105895996094
iter 7927 (epoch 13), train_loss = 2.977, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 7928 (epoch 13), train_loss = 2.193, time/batch = 0.023
Read data: 0.000118255615234375
iter 7929 (epoch 13), train_loss = 3.061, time/batch = 0.022
Read data: 0.00018644332885742188
iter 7930 (epoch 13), train_loss = 2.903, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 7931 (epoch 13), train_loss = 2.773, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 7932 (epoch 13), train_loss = 2.556, time/batch = 0.029
Read data: 9.655952453613281e-05
iter 7933 (epoch 13), train_loss = 2.611, time/batch = 0.028
Read data: 0.0001289844512939453
iter 7934 (epoch 13), train_loss = 2.390, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 7935 (epoch 13), train_loss = 2.800, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 7936 (epoch 13), train_loss = 2.549, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 7937 (epoch 13), train_loss = 2.654, time/batch = 0.030
Read data: 0.00014066696166992188
iter 7938 (epoch 13), train_loss = 2.293, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 7939 (epoch 13), train_loss = 2.750, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 7940 (epoch 13), train_loss = 2.421, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 7941 (epoch 13), train_loss = 2.469, time/batch = 0.025
Read data: 0.00012636184692382812
iter 7942 (epoch 13), train_loss = 2.431, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 7943 (epoch 13), train_loss = 2.538, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7944 (epoch 13), train_loss = 2.645, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 7945 (epoch 13), train_loss = 2.729, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 7946 (epoch 13), train_loss = 2.569, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 7947 (epoch 13), train_loss = 2.473, time/batch = 0.026
Read data: 0.00010919570922851562
iter 7948 (epoch 13), train_loss = 3.195, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 7949 (epoch 13), train_loss = 2.625, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 7950 (epoch 13), train_loss = 2.695, time/batch = 0.033
Read data: 7.82012939453125e-05
iter 7951 (epoch 13), train_loss = 2.693, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 7952 (epoch 13), train_loss = 2.415, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 7953 (epoch 13), train_loss = 2.191, time/batch = 0.025
Read data: 0.0001232624053955078
iter 7954 (epoch 13), train_loss = 2.570, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 7955 (epoch 13), train_loss = 2.352, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 7956 (epoch 13), train_loss = 2.692, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 7957 (epoch 13), train_loss = 3.142, time/batch = 0.025
Read data: 0.00012087821960449219
iter 7958 (epoch 13), train_loss = 2.987, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 7959 (epoch 13), train_loss = 2.351, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 7960 (epoch 13), train_loss = 2.538, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 7961 (epoch 13), train_loss = 2.887, time/batch = 0.027
Read data: 0.00012922286987304688
iter 7962 (epoch 13), train_loss = 2.627, time/batch = 0.019
Read data: 0.0001456737518310547
iter 7963 (epoch 13), train_loss = 2.868, time/batch = 0.025
Read data: 0.00011777877807617188
iter 7964 (epoch 13), train_loss = 2.728, time/batch = 0.030
Read data: 9.489059448242188e-05
iter 7965 (epoch 13), train_loss = 2.508, time/batch = 0.028
Read data: 0.0001513957977294922
iter 7966 (epoch 13), train_loss = 2.779, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 7967 (epoch 13), train_loss = 2.567, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 7968 (epoch 13), train_loss = 2.586, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 7969 (epoch 13), train_loss = 3.153, time/batch = 0.032
Read data: 8.7738037109375e-05
iter 7970 (epoch 13), train_loss = 2.670, time/batch = 0.026
Read data: 0.00014543533325195312
iter 7971 (epoch 13), train_loss = 2.741, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 7972 (epoch 13), train_loss = 2.672, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 7973 (epoch 13), train_loss = 2.675, time/batch = 0.029
Read data: 0.00012969970703125
iter 7974 (epoch 13), train_loss = 2.655, time/batch = 0.023
Read data: 0.00012922286987304688
iter 7975 (epoch 13), train_loss = 2.358, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 7976 (epoch 13), train_loss = 2.827, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 7977 (epoch 13), train_loss = 2.706, time/batch = 0.025
Read data: 0.0001316070556640625
iter 7978 (epoch 13), train_loss = 3.004, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 7979 (epoch 13), train_loss = 2.860, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 7980 (epoch 13), train_loss = 2.951, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 7981 (epoch 13), train_loss = 3.155, time/batch = 0.034
Read data: 0.00013494491577148438
iter 7982 (epoch 13), train_loss = 2.878, time/batch = 0.026
Read data: 0.00012183189392089844
iter 7983 (epoch 13), train_loss = 2.520, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 7984 (epoch 13), train_loss = 2.776, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 7985 (epoch 13), train_loss = 2.724, time/batch = 0.030
Read data: 0.0001327991485595703
iter 7986 (epoch 13), train_loss = 2.366, time/batch = 0.024
Read data: 0.00013065338134765625
iter 7987 (epoch 13), train_loss = 2.606, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 7988 (epoch 13), train_loss = 2.591, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 7989 (epoch 13), train_loss = 2.650, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 7990 (epoch 13), train_loss = 2.829, time/batch = 0.034
Read data: 0.00013184547424316406
iter 7991 (epoch 13), train_loss = 2.764, time/batch = 0.029
Read data: 0.00014448165893554688
iter 7992 (epoch 13), train_loss = 2.512, time/batch = 0.028
Read data: 0.0001399517059326172
iter 7993 (epoch 13), train_loss = 2.548, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 7994 (epoch 13), train_loss = 2.356, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 7995 (epoch 13), train_loss = 2.817, time/batch = 0.035
Read data: 7.987022399902344e-05
iter 7996 (epoch 13), train_loss = 2.669, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 7997 (epoch 13), train_loss = 2.559, time/batch = 0.023
Read data: 0.00012803077697753906
iter 7998 (epoch 13), train_loss = 2.445, time/batch = 0.029
Read data: 0.00013208389282226562
iter 7999 (epoch 13), train_loss = 2.598, time/batch = 0.025
image 976:     
image 5399:    
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.695786)
image 2798:     
image 5884:     
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.314164)
image 6903:      
image 3301:    
image 2019:    
image 5535:     
image 7680:     
image 5527:      
image 2568:      
image 160:   
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.655042)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.913050)
image 2938:    UNK
image 5183:     
image 2380:      
image 6973:   
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.600128)
image 4940:      
image 4905:    
image 469:     
image 102:    
image 6009:    UNK
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.862682)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.672535)
image 3258:     
image 6895:      
image 5296:     
image 4623:    
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.740758)
image 3276:      
image 3812:   
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.204139)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:      
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (3.011780)
image 2800:    
image 7249:     
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.894374)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:    
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.440376)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.976306)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:     
image 5542:     
image 8068:   
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.768440)
image 1738:     
image 1455:     
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (2.987198)
image 1865:      
image 3830:      
image 360:      
image 5097:     
image 4455:     
image 1153:    
image 1248:    
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.836138)
image 4297:    
image 3315:     
image 1107:    
image 2051:     
image 4713:    
image 8036:     
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.649668)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:     
image 3000:    
image 1806:    
image 7761:     
image 3014:    UNK
image 3687:    
evaluating validation preformance... 180/1000 (2.702135)
image 2313:    
image 6289:    
image 8084:   
image 2696:    
image 5830:     
image 6240:      
image 4541:     
image 2813:    
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.548123)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:    
image 8015:    
image 6565:     
image 6174:      
image 6894:     
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.372373)
image 5159:    
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.541000)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:    UNK
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.667181)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.339958)
image 1917:     
image 5844:      
image 1661:     
image 1510:     
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.283568)
image 7143:     
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (2.649548)
image 3028:     
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.572648)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.010330)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:     
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.655992)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.547900)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.238893)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.874915)
image 3553:    
image 5971:     
image 122:     
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:     
image 6423:     
evaluating validation preformance... 320/1000 (2.446877)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:    
evaluating validation preformance... 330/1000 (2.812521)
image 5179:    
image 3754:    
image 2911:    UNK
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.537929)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.647676)
image 6881:    UNK
image 942:     
image 2775:    
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.106519)
image 2905:    UNK
image 7814:     
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.659981)
image 4351:     
image 1054:    UNK
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.718812)
image 2458:     
image 1084:      
image 4835:    
image 867:    
image 723:     
image 6255:    
image 5255:    
image 3598:    
image 2997:    
image 60:     
evaluating validation preformance... 390/1000 (2.914011)
image 828:    
image 2733:    
image 791:      
image 5408:    UNK
image 7842:     
image 1117:    
image 5817:      
image 1231:    
image 1630:     
image 6886:    
evaluating validation preformance... 400/1000 (2.295738)
image 2627:    
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.219900)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.383029)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.860493)
image 385:     
image 6938:      
image 2381:    
image 5796:    UNK
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.943066)
image 1731:       
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:    
image 5855:     
image 4245:      
image 973:    
evaluating validation preformance... 450/1000 (2.270583)
image 2241:      
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:     
image 3682:     
evaluating validation preformance... 460/1000 (2.826884)
image 7979:     
image 1618:    
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.312480)
image 4503:    
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    UNK
image 6114:      
evaluating validation preformance... 480/1000 (2.960554)
image 358:     
image 4663:    
image 5541:    
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:     
image 205:    
evaluating validation preformance... 490/1000 (3.368727)
image 2044:    
image 4349:    
image 3855:      
image 1846:    UNK
image 3724:    
image 606:      
image 6577:    
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.618961)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.071156)
image 3246:    
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.735151)
image 6806:    
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:     
image 5552:    
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.533991)
image 5619:     
image 4391:    
image 891:     
image 3072:    
image 7781:    
image 6163:    
image 7376:      
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.582500)
image 5292:    
image 2901:    
image 3568:     
image 690:      
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:      
evaluating validation preformance... 550/1000 (2.685789)
image 5439:     
image 7981:     
image 6012:     
image 4732:     
image 6630:    
image 994:    
image 5079:     
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.683064)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.694862)
image 7936:     
image 5433:    
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:     
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.570547)
image 2135:      
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:    
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.635445)
image 4420:     
image 1734:    
image 7239:     
image 7447:    
image 8009:     
image 4510:    UNK
image 7495:    
image 2530:      
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.658645)
image 353:     
image 1095:     
image 3583:    
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.798098)
image 69:     
image 3465:    
image 6179:    
image 552:    
image 511:    
image 761:    
image 5742:    
image 359:      
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.513878)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:     
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.564563)
image 8074:    
image 1904:     
image 7917:      
image 2394:     
image 4406:    UNK
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.570992)
image 5313:      
image 2377:      
image 6058:     
image 4661:     
image 2955:   
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:      
evaluating validation preformance... 650/1000 (2.619034)
image 8065:    
image 3577:    
image 3254:    
image 4562:    
image 5462:      
image 2824:    
image 1639:     
image 1475:     
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.735059)
image 5701:      
image 1709:    
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (2.937564)
image 7877:    
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722:    UNK
image 7784:      
evaluating validation preformance... 680/1000 (3.081984)
image 1445:     
image 6841:     
image 2896:    
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (2.988494)
image 6860:     
image 576:    
image 6580:     
image 1497:   
image 3360:     
image 4939:     
image 6225:    
image 3669:     
image 980:    
image 5362:      
evaluating validation preformance... 700/1000 (3.016358)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.611828)
image 7368:     
image 709:     
image 3197:    
image 5214:    
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.692144)
image 5729:     
image 6395:      
image 516:    
image 1026:    
image 2972:      
image 3005:    
image 1241:    
image 2743:    
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.368464)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:    
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.530746)
image 2239:     
image 120:    
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.838139)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.038011)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:     
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.283954)
image 6220:    
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:       
image 2329:     
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (2.849308)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:     
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.273137)
image 5047:    
image 325:     
image 7626:     
image 4552:    
image 983:    
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.332635)
image 7288:     
image 7302:     
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.478461)
image 614:    
image 7295:    
image 4110:     
image 5402:    
image 3060:    UNK
image 1317:      
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (2.045000)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    UNK
image 5514:    
image 7147:    
image 6348:     
image 580:    
image 2531:     
evaluating validation preformance... 830/1000 (2.453687)
image 5107:    
image 3973:    
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.506147)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.926197)
image 4404:    
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:     
image 6261:     
image 2166:      
evaluating validation preformance... 860/1000 (2.893368)
image 4254:      
image 6842:     
image 1644:     
image 7371:    UNK
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:     
image 4002:     
evaluating validation preformance... 870/1000 (2.422814)
image 4934:    
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:      
image 5681:      
image 1824:   
image 2098:     
image 28:     
evaluating validation preformance... 880/1000 (2.682474)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:    
image 4530:    
evaluating validation preformance... 890/1000 (2.989654)
image 7485:    
image 6102:    
image 1001:    
image 7167:    
image 4168:     
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.522298)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:    
image 7205:     
evaluating validation preformance... 910/1000 (2.311645)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.669035)
image 7152:    
image 4559:      
image 7233:    
image 1341:     
image 5337:    
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.590475)
image 5636:     
image 7799:      
image 6025:     
image 6907:      
image 2507:     
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.690591)
image 5860:     
image 3275:     
image 1935:     
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (3.074004)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.825200)
image 4935:     
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.434615)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.815036)
image 7352:     
image 5113:     
image 7822:    
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.557784)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:     
image 2483:    
image 2591:     
image 7615:     
evaluating validation preformance... 1000/1000 (2.445894)
average loss on validation: 2.680
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3074531555175781
Cider scores: 0.5237426460900257
Read data: 0.3422377109527588
Cider scores: 0.49564745619003875
Read data: 0.24232697486877441
Cider scores: 0.5443735449799485
Read data: 0.24499058723449707
Cider scores: 0.4683585690678969
Read data: 0.2013554573059082
Cider scores: 0.45884628774958514
Read data: 0.1724698543548584
Cider scores: 0.5057009394813747
Read data: 0.19626522064208984
Cider scores: 0.43300623416579376
Read data: 0.18010330200195312
Cider scores: 0.5355098173507652
Read data: 0.18360137939453125
Cider scores: 0.4470983891274953
Read data: 0.17958664894104004
Cider scores: 0.5670360256646286
Read data: 0.23603415489196777
Cider scores: 0.5240325819976521
Read data: 0.17694354057312012
Cider scores: 0.5923298133268387
Read data: 0.1849842071533203
Cider scores: 0.4398772176357653
Read data: 0.1740574836730957
Cider scores: 0.4767609353164257
Read data: 0.17830204963684082
Cider scores: 0.5673403399372938
Read data: 0.17662739753723145
Cider scores: 0.5491359396122135
Read data: 0.1642765998840332
Cider scores: 0.4492740067041228
Read data: 0.16384100914001465
Cider scores: 0.575525870295774
Read data: 0.1662144660949707
Cider scores: 0.4666774761559782
Read data: 0.16585755348205566
Cider scores: 0.6637239760598473
Average cider score on test set: 0.514
End calculating cider score on TEST data set
===============================================
Read data: 0.17266321182250977
iter 8000 (epoch 13), train_loss = 2.516, time/batch = 0.023
Read data: 0.00010418891906738281
iter 8001 (epoch 13), train_loss = 2.501, time/batch = 0.023
Read data: 0.00010633468627929688
iter 8002 (epoch 13), train_loss = 2.961, time/batch = 0.029
Read data: 0.00012111663818359375
iter 8003 (epoch 13), train_loss = 2.653, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 8004 (epoch 13), train_loss = 2.798, time/batch = 0.030
Read data: 0.00010180473327636719
iter 8005 (epoch 13), train_loss = 2.704, time/batch = 0.029
Read data: 9.775161743164062e-05
iter 8006 (epoch 13), train_loss = 2.984, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 8007 (epoch 13), train_loss = 2.692, time/batch = 0.025
Read data: 0.00012731552124023438
iter 8008 (epoch 13), train_loss = 2.380, time/batch = 0.033
Read data: 9.560585021972656e-05
iter 8009 (epoch 13), train_loss = 2.764, time/batch = 0.030
Read data: 0.00016808509826660156
iter 8010 (epoch 13), train_loss = 2.505, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 8011 (epoch 13), train_loss = 2.868, time/batch = 0.030
Read data: 9.655952453613281e-05
iter 8012 (epoch 13), train_loss = 2.966, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 8013 (epoch 13), train_loss = 2.827, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 8014 (epoch 13), train_loss = 2.468, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 8015 (epoch 13), train_loss = 2.678, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8016 (epoch 13), train_loss = 2.698, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 8017 (epoch 13), train_loss = 2.930, time/batch = 0.022
Read data: 9.489059448242188e-05
iter 8018 (epoch 13), train_loss = 2.865, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 8019 (epoch 13), train_loss = 2.257, time/batch = 0.027
Read data: 0.000118255615234375
iter 8020 (epoch 13), train_loss = 2.552, time/batch = 0.026
Read data: 9.870529174804688e-05
iter 8021 (epoch 13), train_loss = 2.671, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 8022 (epoch 13), train_loss = 2.929, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 8023 (epoch 13), train_loss = 2.811, time/batch = 0.038
Read data: 9.512901306152344e-05
iter 8024 (epoch 13), train_loss = 2.437, time/batch = 0.022
Read data: 0.00011038780212402344
iter 8025 (epoch 13), train_loss = 3.025, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 8026 (epoch 13), train_loss = 2.321, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 8027 (epoch 13), train_loss = 2.466, time/batch = 0.021
Read data: 0.0001220703125
iter 8028 (epoch 13), train_loss = 2.435, time/batch = 0.028
Read data: 0.00010180473327636719
iter 8029 (epoch 13), train_loss = 3.122, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 8030 (epoch 13), train_loss = 2.316, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 8031 (epoch 13), train_loss = 2.660, time/batch = 0.021
Read data: 0.00011706352233886719
iter 8032 (epoch 13), train_loss = 2.284, time/batch = 0.030
Read data: 8.916854858398438e-05
iter 8033 (epoch 13), train_loss = 2.818, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 8034 (epoch 13), train_loss = 3.029, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 8035 (epoch 13), train_loss = 2.387, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 8036 (epoch 13), train_loss = 2.816, time/batch = 0.027
Read data: 0.0001308917999267578
iter 8037 (epoch 13), train_loss = 2.633, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 8038 (epoch 13), train_loss = 3.050, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 8039 (epoch 13), train_loss = 2.618, time/batch = 0.023
Read data: 0.00010013580322265625
iter 8040 (epoch 13), train_loss = 2.707, time/batch = 0.021
Read data: 0.00021266937255859375
iter 8041 (epoch 13), train_loss = 2.497, time/batch = 0.028
Read data: 8.392333984375e-05
iter 8042 (epoch 13), train_loss = 2.465, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 8043 (epoch 13), train_loss = 2.250, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 8044 (epoch 13), train_loss = 2.515, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 8045 (epoch 13), train_loss = 2.547, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 8046 (epoch 13), train_loss = 2.404, time/batch = 0.028
Read data: 7.62939453125e-05
iter 8047 (epoch 13), train_loss = 2.488, time/batch = 0.035
Read data: 8.249282836914062e-05
iter 8048 (epoch 13), train_loss = 2.484, time/batch = 0.029
Read data: 0.000110626220703125
iter 8049 (epoch 13), train_loss = 2.450, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 8050 (epoch 13), train_loss = 2.490, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 8051 (epoch 13), train_loss = 2.668, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 8052 (epoch 13), train_loss = 2.775, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 8053 (epoch 13), train_loss = 2.844, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 8054 (epoch 13), train_loss = 2.609, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 8055 (epoch 13), train_loss = 2.881, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 8056 (epoch 13), train_loss = 3.080, time/batch = 0.022
Read data: 0.00013518333435058594
iter 8057 (epoch 13), train_loss = 2.859, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 8058 (epoch 13), train_loss = 2.841, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 8059 (epoch 13), train_loss = 2.340, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 8060 (epoch 13), train_loss = 2.270, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 8061 (epoch 13), train_loss = 3.109, time/batch = 0.025
Read data: 9.1552734375e-05
iter 8062 (epoch 13), train_loss = 2.466, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 8063 (epoch 13), train_loss = 2.850, time/batch = 0.029
Read data: 8.96453857421875e-05
iter 8064 (epoch 13), train_loss = 2.501, time/batch = 0.025
Read data: 0.00014400482177734375
iter 8065 (epoch 13), train_loss = 2.563, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 8066 (epoch 13), train_loss = 2.316, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 8067 (epoch 13), train_loss = 2.813, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 8068 (epoch 13), train_loss = 2.564, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 8069 (epoch 13), train_loss = 2.785, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 8070 (epoch 13), train_loss = 2.516, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 8071 (epoch 13), train_loss = 2.612, time/batch = 0.026
Read data: 0.00012063980102539062
iter 8072 (epoch 13), train_loss = 2.572, time/batch = 0.036
Read data: 8.797645568847656e-05
iter 8073 (epoch 13), train_loss = 2.711, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 8074 (epoch 13), train_loss = 2.553, time/batch = 0.021
Read data: 0.0001842975616455078
iter 8075 (epoch 13), train_loss = 3.307, time/batch = 0.036
Read data: 8.416175842285156e-05
iter 8076 (epoch 13), train_loss = 2.095, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 8077 (epoch 13), train_loss = 2.501, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 8078 (epoch 13), train_loss = 2.407, time/batch = 0.022
Read data: 0.00010037422180175781
iter 8079 (epoch 13), train_loss = 2.518, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 8080 (epoch 13), train_loss = 2.448, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 8081 (epoch 13), train_loss = 2.924, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 8082 (epoch 13), train_loss = 2.303, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 8083 (epoch 13), train_loss = 2.880, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 8084 (epoch 13), train_loss = 2.659, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 8085 (epoch 13), train_loss = 2.794, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 8086 (epoch 13), train_loss = 3.143, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 8087 (epoch 13), train_loss = 2.376, time/batch = 0.040
Read data: 9.179115295410156e-05
iter 8088 (epoch 13), train_loss = 2.574, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 8089 (epoch 13), train_loss = 2.827, time/batch = 0.035
Read data: 8.702278137207031e-05
iter 8090 (epoch 13), train_loss = 2.460, time/batch = 0.029
Read data: 0.00011610984802246094
iter 8091 (epoch 13), train_loss = 2.489, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 8092 (epoch 13), train_loss = 2.563, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 8093 (epoch 13), train_loss = 2.809, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 8094 (epoch 13), train_loss = 2.999, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 8095 (epoch 13), train_loss = 2.793, time/batch = 0.036
Read data: 0.00013899803161621094
iter 8096 (epoch 13), train_loss = 2.612, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 8097 (epoch 13), train_loss = 2.507, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 8098 (epoch 13), train_loss = 2.641, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 8099 (epoch 13), train_loss = 2.753, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 8100 (epoch 13), train_loss = 2.283, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 8101 (epoch 13), train_loss = 2.353, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 8102 (epoch 13), train_loss = 2.731, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 8103 (epoch 13), train_loss = 2.979, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 8104 (epoch 13), train_loss = 2.584, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 8105 (epoch 13), train_loss = 2.813, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 8106 (epoch 13), train_loss = 2.714, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 8107 (epoch 13), train_loss = 2.726, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 8108 (epoch 13), train_loss = 2.798, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 8109 (epoch 13), train_loss = 2.662, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 8110 (epoch 13), train_loss = 2.896, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 8111 (epoch 13), train_loss = 3.290, time/batch = 0.028
Read data: 0.00011515617370605469
iter 8112 (epoch 13), train_loss = 1.952, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 8113 (epoch 13), train_loss = 2.631, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 8114 (epoch 13), train_loss = 2.503, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 8115 (epoch 13), train_loss = 2.774, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 8116 (epoch 13), train_loss = 2.880, time/batch = 0.022
Read data: 0.0001068115234375
iter 8117 (epoch 13), train_loss = 2.669, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 8118 (epoch 13), train_loss = 2.907, time/batch = 0.025
Read data: 0.00015926361083984375
iter 8119 (epoch 13), train_loss = 2.261, time/batch = 0.020
Read data: 0.00011491775512695312
iter 8120 (epoch 13), train_loss = 2.760, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 8121 (epoch 13), train_loss = 2.809, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 8122 (epoch 13), train_loss = 2.983, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 8123 (epoch 13), train_loss = 2.497, time/batch = 0.025
Read data: 0.00011229515075683594
iter 8124 (epoch 13), train_loss = 2.745, time/batch = 0.028
Read data: 0.0002503395080566406
iter 8125 (epoch 13), train_loss = 2.260, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 8126 (epoch 13), train_loss = 3.171, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 8127 (epoch 13), train_loss = 2.946, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 8128 (epoch 13), train_loss = 2.739, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 8129 (epoch 13), train_loss = 2.496, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 8130 (epoch 13), train_loss = 2.674, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 8131 (epoch 13), train_loss = 2.693, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 8132 (epoch 13), train_loss = 2.677, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 8133 (epoch 13), train_loss = 2.527, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 8134 (epoch 13), train_loss = 2.486, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 8135 (epoch 13), train_loss = 2.437, time/batch = 0.026
Read data: 0.00012493133544921875
iter 8136 (epoch 13), train_loss = 2.524, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 8137 (epoch 13), train_loss = 2.519, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 8138 (epoch 13), train_loss = 2.687, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 8139 (epoch 13), train_loss = 2.315, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 8140 (epoch 13), train_loss = 2.222, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 8141 (epoch 13), train_loss = 2.777, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 8142 (epoch 13), train_loss = 3.185, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 8143 (epoch 13), train_loss = 2.895, time/batch = 0.036
Read data: 8.654594421386719e-05
iter 8144 (epoch 13), train_loss = 2.608, time/batch = 0.025
Read data: 0.00012230873107910156
iter 8145 (epoch 13), train_loss = 2.520, time/batch = 0.033
Read data: 8.940696716308594e-05
iter 8146 (epoch 13), train_loss = 2.398, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 8147 (epoch 13), train_loss = 2.721, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 8148 (epoch 13), train_loss = 2.559, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 8149 (epoch 13), train_loss = 2.525, time/batch = 0.025
Read data: 0.0002281665802001953
iter 8150 (epoch 13), train_loss = 2.451, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 8151 (epoch 13), train_loss = 2.513, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 8152 (epoch 13), train_loss = 3.001, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 8153 (epoch 13), train_loss = 2.812, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 8154 (epoch 13), train_loss = 2.705, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 8155 (epoch 13), train_loss = 2.427, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 8156 (epoch 13), train_loss = 2.470, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8157 (epoch 13), train_loss = 2.842, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 8158 (epoch 13), train_loss = 2.849, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 8159 (epoch 13), train_loss = 2.820, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 8160 (epoch 13), train_loss = 2.758, time/batch = 0.029
Read data: 9.703636169433594e-05
iter 8161 (epoch 13), train_loss = 2.742, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 8162 (epoch 13), train_loss = 2.810, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 8163 (epoch 13), train_loss = 2.693, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 8164 (epoch 13), train_loss = 2.990, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 8165 (epoch 13), train_loss = 2.950, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 8166 (epoch 13), train_loss = 2.283, time/batch = 0.024
Read data: 0.0016341209411621094
iter 8167 (epoch 13), train_loss = 2.426, time/batch = 0.021
Read data: 0.00011873245239257812
iter 8168 (epoch 13), train_loss = 2.975, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 8169 (epoch 13), train_loss = 2.230, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 8170 (epoch 13), train_loss = 2.821, time/batch = 0.028
Read data: 0.00022125244140625
iter 8171 (epoch 13), train_loss = 2.569, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 8172 (epoch 13), train_loss = 3.128, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 8173 (epoch 13), train_loss = 2.766, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 8174 (epoch 13), train_loss = 2.810, time/batch = 0.030
Read data: 0.00033164024353027344
iter 8175 (epoch 13), train_loss = 2.682, time/batch = 0.032
Read data: 9.059906005859375e-05
iter 8176 (epoch 13), train_loss = 2.839, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 8177 (epoch 13), train_loss = 2.556, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 8178 (epoch 13), train_loss = 2.883, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 8179 (epoch 13), train_loss = 2.858, time/batch = 0.023
Read data: 0.00011467933654785156
iter 8180 (epoch 13), train_loss = 3.018, time/batch = 0.037
Read data: 8.368492126464844e-05
iter 8181 (epoch 13), train_loss = 2.382, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 8182 (epoch 13), train_loss = 2.787, time/batch = 0.023
Read data: 9.989738464355469e-05
iter 8183 (epoch 13), train_loss = 2.680, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 8184 (epoch 13), train_loss = 2.643, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 8185 (epoch 13), train_loss = 2.755, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 8186 (epoch 13), train_loss = 2.508, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 8187 (epoch 13), train_loss = 2.363, time/batch = 0.025
Read data: 0.00011610984802246094
iter 8188 (epoch 13), train_loss = 3.382, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 8189 (epoch 13), train_loss = 2.843, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 8190 (epoch 13), train_loss = 2.428, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 8191 (epoch 13), train_loss = 2.287, time/batch = 0.034
Read data: 8.0108642578125e-05
iter 8192 (epoch 13), train_loss = 2.851, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 8193 (epoch 13), train_loss = 2.480, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 8194 (epoch 13), train_loss = 2.493, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 8195 (epoch 13), train_loss = 2.580, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 8196 (epoch 13), train_loss = 2.389, time/batch = 0.033
Read data: 8.58306884765625e-05
iter 8197 (epoch 13), train_loss = 2.483, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 8198 (epoch 13), train_loss = 2.973, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 8199 (epoch 13), train_loss = 3.105, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 8200 (epoch 13), train_loss = 2.860, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 8201 (epoch 13), train_loss = 2.810, time/batch = 0.024
Read data: 9.822845458984375e-05
iter 8202 (epoch 13), train_loss = 2.785, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 8203 (epoch 13), train_loss = 2.983, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 8204 (epoch 13), train_loss = 2.823, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 8205 (epoch 13), train_loss = 2.408, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 8206 (epoch 13), train_loss = 2.678, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 8207 (epoch 13), train_loss = 2.197, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 8208 (epoch 13), train_loss = 3.005, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 8209 (epoch 13), train_loss = 2.643, time/batch = 0.035
Read data: 8.344650268554688e-05
iter 8210 (epoch 13), train_loss = 2.439, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 8211 (epoch 13), train_loss = 3.192, time/batch = 0.032
Read data: 8.702278137207031e-05
iter 8212 (epoch 13), train_loss = 2.443, time/batch = 0.024
Read data: 0.00012564659118652344
iter 8213 (epoch 13), train_loss = 2.929, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 8214 (epoch 13), train_loss = 2.227, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 8215 (epoch 13), train_loss = 2.598, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 8216 (epoch 13), train_loss = 2.362, time/batch = 0.023
Read data: 0.00013017654418945312
iter 8217 (epoch 13), train_loss = 2.490, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 8218 (epoch 13), train_loss = 2.679, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 8219 (epoch 13), train_loss = 3.088, time/batch = 0.038
Read data: 0.0001304149627685547
iter 8220 (epoch 13), train_loss = 2.630, time/batch = 0.026
Read data: 0.00015687942504882812
iter 8221 (epoch 13), train_loss = 2.463, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 8222 (epoch 13), train_loss = 2.649, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 8223 (epoch 13), train_loss = 2.589, time/batch = 0.025
Read data: 0.00010013580322265625
iter 8224 (epoch 13), train_loss = 2.772, time/batch = 0.028
Read data: 0.0002846717834472656
iter 8225 (epoch 13), train_loss = 2.741, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 8226 (epoch 13), train_loss = 2.552, time/batch = 0.021
Read data: 9.417533874511719e-05
iter 8227 (epoch 13), train_loss = 2.917, time/batch = 0.032
Read data: 8.702278137207031e-05
iter 8228 (epoch 13), train_loss = 2.655, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 8229 (epoch 13), train_loss = 2.348, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 8230 (epoch 13), train_loss = 2.331, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 8231 (epoch 13), train_loss = 2.693, time/batch = 0.025
Read data: 0.00010895729064941406
iter 8232 (epoch 13), train_loss = 3.010, time/batch = 0.022
Read data: 0.00010132789611816406
iter 8233 (epoch 13), train_loss = 2.894, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 8234 (epoch 13), train_loss = 2.704, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 8235 (epoch 13), train_loss = 3.159, time/batch = 0.037
Read data: 8.678436279296875e-05
iter 8236 (epoch 13), train_loss = 2.590, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 8237 (epoch 13), train_loss = 2.251, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 8238 (epoch 13), train_loss = 2.808, time/batch = 0.028
Read data: 8.392333984375e-05
iter 8239 (epoch 13), train_loss = 2.577, time/batch = 0.027
Read data: 0.00014662742614746094
iter 8240 (epoch 13), train_loss = 2.660, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 8241 (epoch 13), train_loss = 2.579, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 8242 (epoch 13), train_loss = 2.655, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 8243 (epoch 13), train_loss = 2.515, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 8244 (epoch 13), train_loss = 3.041, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 8245 (epoch 13), train_loss = 2.577, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 8246 (epoch 13), train_loss = 2.620, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 8247 (epoch 13), train_loss = 2.727, time/batch = 0.027
Read data: 0.00012063980102539062
iter 8248 (epoch 13), train_loss = 2.565, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 8249 (epoch 13), train_loss = 2.368, time/batch = 0.023
Read data: 0.00027179718017578125
iter 8250 (epoch 13), train_loss = 3.011, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 8251 (epoch 13), train_loss = 3.085, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 8252 (epoch 13), train_loss = 2.626, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 8253 (epoch 13), train_loss = 2.655, time/batch = 0.021
Read data: 0.00010728836059570312
iter 8254 (epoch 13), train_loss = 2.552, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 8255 (epoch 13), train_loss = 2.814, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 8256 (epoch 13), train_loss = 2.484, time/batch = 0.026
Read data: 8.392333984375e-05
iter 8257 (epoch 13), train_loss = 2.819, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 8258 (epoch 13), train_loss = 2.379, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 8259 (epoch 13), train_loss = 2.046, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 8260 (epoch 13), train_loss = 2.470, time/batch = 0.021
Read data: 9.775161743164062e-05
iter 8261 (epoch 13), train_loss = 2.450, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 8262 (epoch 13), train_loss = 2.750, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 8263 (epoch 13), train_loss = 2.908, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 8264 (epoch 13), train_loss = 2.377, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 8265 (epoch 13), train_loss = 2.612, time/batch = 0.022
Read data: 0.00010085105895996094
iter 8266 (epoch 13), train_loss = 3.029, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 8267 (epoch 13), train_loss = 2.626, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 8268 (epoch 13), train_loss = 2.513, time/batch = 0.023
Read data: 0.00010156631469726562
iter 8269 (epoch 13), train_loss = 2.946, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 8270 (epoch 13), train_loss = 2.774, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 8271 (epoch 13), train_loss = 2.787, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 8272 (epoch 13), train_loss = 2.367, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 8273 (epoch 13), train_loss = 2.567, time/batch = 0.020
Read data: 8.869171142578125e-05
iter 8274 (epoch 13), train_loss = 2.433, time/batch = 0.027
Read data: 0.0002338886260986328
iter 8275 (epoch 13), train_loss = 2.765, time/batch = 0.023
Read data: 0.00011730194091796875
iter 8276 (epoch 13), train_loss = 2.607, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 8277 (epoch 13), train_loss = 2.165, time/batch = 0.024
Read data: 9.822845458984375e-05
iter 8278 (epoch 13), train_loss = 3.003, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8279 (epoch 13), train_loss = 2.423, time/batch = 0.027
Read data: 0.00011515617370605469
iter 8280 (epoch 13), train_loss = 2.949, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 8281 (epoch 13), train_loss = 2.576, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 8282 (epoch 13), train_loss = 2.496, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 8283 (epoch 13), train_loss = 2.173, time/batch = 0.021
Read data: 0.0001163482666015625
iter 8284 (epoch 13), train_loss = 3.105, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 8285 (epoch 13), train_loss = 2.801, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 8286 (epoch 13), train_loss = 2.266, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 8287 (epoch 13), train_loss = 2.328, time/batch = 0.035
Read data: 9.34600830078125e-05
iter 8288 (epoch 13), train_loss = 2.512, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 8289 (epoch 13), train_loss = 2.606, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 8290 (epoch 13), train_loss = 2.424, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 8291 (epoch 13), train_loss = 2.684, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 8292 (epoch 13), train_loss = 2.346, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 8293 (epoch 13), train_loss = 2.669, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 8294 (epoch 13), train_loss = 2.792, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 8295 (epoch 13), train_loss = 2.412, time/batch = 0.023
Read data: 0.0016865730285644531
iter 8296 (epoch 13), train_loss = 3.005, time/batch = 0.024
Read data: 9.1552734375e-05
iter 8297 (epoch 13), train_loss = 2.880, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 8298 (epoch 13), train_loss = 2.966, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8299 (epoch 13), train_loss = 2.894, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 8300 (epoch 13), train_loss = 2.716, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 8301 (epoch 13), train_loss = 2.920, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 8302 (epoch 13), train_loss = 2.758, time/batch = 0.021
Read data: 9.703636169433594e-05
iter 8303 (epoch 13), train_loss = 2.686, time/batch = 0.029
Read data: 0.0001201629638671875
iter 8304 (epoch 13), train_loss = 2.803, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 8305 (epoch 13), train_loss = 2.657, time/batch = 0.025
Read data: 0.00010442733764648438
iter 8306 (epoch 13), train_loss = 2.581, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 8307 (epoch 13), train_loss = 2.679, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 8308 (epoch 13), train_loss = 2.548, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 8309 (epoch 13), train_loss = 2.795, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 8310 (epoch 13), train_loss = 2.473, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 8311 (epoch 13), train_loss = 2.260, time/batch = 0.025
Read data: 0.0001220703125
iter 8312 (epoch 13), train_loss = 2.851, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 8313 (epoch 13), train_loss = 2.789, time/batch = 0.030
Read data: 8.392333984375e-05
iter 8314 (epoch 13), train_loss = 2.967, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 8315 (epoch 13), train_loss = 2.812, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 8316 (epoch 13), train_loss = 2.608, time/batch = 0.020
Read data: 0.0001354217529296875
iter 8317 (epoch 13), train_loss = 2.507, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 8318 (epoch 13), train_loss = 2.560, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 8319 (epoch 13), train_loss = 2.183, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 8320 (epoch 13), train_loss = 2.577, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 8321 (epoch 13), train_loss = 2.595, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 8322 (epoch 13), train_loss = 2.391, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 8323 (epoch 13), train_loss = 2.486, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 8324 (epoch 13), train_loss = 2.472, time/batch = 0.023
Read data: 0.0002422332763671875
iter 8325 (epoch 13), train_loss = 2.452, time/batch = 0.029
Read data: 7.510185241699219e-05
iter 8326 (epoch 13), train_loss = 2.892, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 8327 (epoch 13), train_loss = 2.290, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 8328 (epoch 13), train_loss = 2.822, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 8329 (epoch 13), train_loss = 2.240, time/batch = 0.027
Read data: 0.000133514404296875
iter 8330 (epoch 13), train_loss = 2.653, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 8331 (epoch 13), train_loss = 2.156, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 8332 (epoch 13), train_loss = 2.512, time/batch = 0.030
Read data: 9.751319885253906e-05
iter 8333 (epoch 13), train_loss = 2.584, time/batch = 0.025
Read data: 9.799003601074219e-05
iter 8334 (epoch 13), train_loss = 2.251, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8335 (epoch 13), train_loss = 2.514, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 8336 (epoch 13), train_loss = 2.578, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 8337 (epoch 13), train_loss = 2.638, time/batch = 0.032
Read data: 7.843971252441406e-05
iter 8338 (epoch 13), train_loss = 2.432, time/batch = 0.036
Read data: 0.00011730194091796875
iter 8339 (epoch 13), train_loss = 2.716, time/batch = 0.025
Read data: 8.392333984375e-05
iter 8340 (epoch 13), train_loss = 2.624, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 8341 (epoch 13), train_loss = 2.394, time/batch = 0.028
Read data: 8.392333984375e-05
iter 8342 (epoch 13), train_loss = 2.442, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 8343 (epoch 13), train_loss = 2.584, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 8344 (epoch 13), train_loss = 2.778, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 8345 (epoch 13), train_loss = 2.942, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 8346 (epoch 13), train_loss = 2.349, time/batch = 0.025
Read data: 9.1552734375e-05
iter 8347 (epoch 13), train_loss = 3.091, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 8348 (epoch 13), train_loss = 3.002, time/batch = 0.021
Read data: 0.00010180473327636719
iter 8349 (epoch 13), train_loss = 3.299, time/batch = 0.026
Read data: 0.0002319812774658203
iter 8350 (epoch 13), train_loss = 2.272, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 8351 (epoch 13), train_loss = 2.901, time/batch = 0.023
Read data: 0.00011754035949707031
iter 8352 (epoch 13), train_loss = 2.289, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 8353 (epoch 13), train_loss = 2.509, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 8354 (epoch 13), train_loss = 2.484, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 8355 (epoch 13), train_loss = 2.857, time/batch = 0.035
Read data: 8.225440979003906e-05
iter 8356 (epoch 13), train_loss = 2.347, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 8357 (epoch 13), train_loss = 2.385, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 8358 (epoch 13), train_loss = 2.424, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 8359 (epoch 13), train_loss = 3.075, time/batch = 0.025
Read data: 0.00011706352233886719
iter 8360 (epoch 13), train_loss = 2.730, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 8361 (epoch 13), train_loss = 2.802, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 8362 (epoch 13), train_loss = 2.361, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 8363 (epoch 13), train_loss = 2.639, time/batch = 0.020
Read data: 0.00013113021850585938
iter 8364 (epoch 13), train_loss = 2.670, time/batch = 0.041
Read data: 8.225440979003906e-05
iter 8365 (epoch 13), train_loss = 2.354, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 8366 (epoch 13), train_loss = 2.976, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 8367 (epoch 13), train_loss = 2.452, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 8368 (epoch 13), train_loss = 2.708, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 8369 (epoch 13), train_loss = 2.614, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 8370 (epoch 13), train_loss = 2.582, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 8371 (epoch 13), train_loss = 2.591, time/batch = 0.023
Read data: 0.00011467933654785156
iter 8372 (epoch 13), train_loss = 2.466, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 8373 (epoch 13), train_loss = 2.482, time/batch = 0.030
Read data: 9.799003601074219e-05
iter 8374 (epoch 13), train_loss = 2.727, time/batch = 0.024
Read data: 0.00023818016052246094
iter 8375 (epoch 13), train_loss = 2.944, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 8376 (epoch 13), train_loss = 2.841, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 8377 (epoch 13), train_loss = 2.834, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 8378 (epoch 13), train_loss = 2.646, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 8379 (epoch 13), train_loss = 2.348, time/batch = 0.021
Read data: 0.00011587142944335938
iter 8380 (epoch 13), train_loss = 2.458, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 8381 (epoch 13), train_loss = 2.526, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 8382 (epoch 13), train_loss = 2.484, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 8383 (epoch 13), train_loss = 2.502, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 8384 (epoch 13), train_loss = 2.332, time/batch = 0.025
Read data: 0.00012111663818359375
iter 8385 (epoch 13), train_loss = 3.193, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 8386 (epoch 13), train_loss = 3.013, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 8387 (epoch 13), train_loss = 2.667, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 8388 (epoch 13), train_loss = 2.872, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 8389 (epoch 13), train_loss = 3.008, time/batch = 0.034
Read data: 7.915496826171875e-05
iter 8390 (epoch 13), train_loss = 2.270, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 8391 (epoch 13), train_loss = 2.800, time/batch = 0.021
Read data: 0.0010051727294921875
iter 8392 (epoch 13), train_loss = 2.785, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 8393 (epoch 13), train_loss = 2.335, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 8394 (epoch 13), train_loss = 2.296, time/batch = 0.024
Read data: 9.512901306152344e-05
iter 8395 (epoch 13), train_loss = 2.754, time/batch = 0.026
Read data: 0.00011682510375976562
iter 8396 (epoch 13), train_loss = 2.638, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 8397 (epoch 13), train_loss = 2.993, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 8398 (epoch 13), train_loss = 2.753, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 8399 (epoch 13), train_loss = 2.630, time/batch = 0.024
Read data: 0.00011610984802246094
iter 8400 (epoch 13), train_loss = 2.543, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 8401 (epoch 14), train_loss = 2.300, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 8402 (epoch 14), train_loss = 2.422, time/batch = 0.022
Read data: 8.392333984375e-05
iter 8403 (epoch 14), train_loss = 2.519, time/batch = 0.025
Read data: 0.00010657310485839844
iter 8404 (epoch 14), train_loss = 2.852, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 8405 (epoch 14), train_loss = 2.535, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 8406 (epoch 14), train_loss = 2.945, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 8407 (epoch 14), train_loss = 2.302, time/batch = 0.027
Read data: 7.510185241699219e-05
iter 8408 (epoch 14), train_loss = 3.106, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 8409 (epoch 14), train_loss = 2.302, time/batch = 0.021
Read data: 0.0001289844512939453
iter 8410 (epoch 14), train_loss = 2.475, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 8411 (epoch 14), train_loss = 2.479, time/batch = 0.029
Read data: 7.510185241699219e-05
iter 8412 (epoch 14), train_loss = 2.529, time/batch = 0.020
Read data: 8.893013000488281e-05
iter 8413 (epoch 14), train_loss = 2.846, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 8414 (epoch 14), train_loss = 2.618, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 8415 (epoch 14), train_loss = 2.675, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 8416 (epoch 14), train_loss = 2.413, time/batch = 0.020
Read data: 0.0001373291015625
iter 8417 (epoch 14), train_loss = 2.464, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 8418 (epoch 14), train_loss = 3.022, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 8419 (epoch 14), train_loss = 2.689, time/batch = 0.023
Read data: 0.00011706352233886719
iter 8420 (epoch 14), train_loss = 2.762, time/batch = 0.032
Read data: 0.00012493133544921875
iter 8421 (epoch 14), train_loss = 2.509, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 8422 (epoch 14), train_loss = 2.621, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 8423 (epoch 14), train_loss = 2.221, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 8424 (epoch 14), train_loss = 2.417, time/batch = 0.033
Read data: 0.0002155303955078125
iter 8425 (epoch 14), train_loss = 2.857, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 8426 (epoch 14), train_loss = 2.713, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 8427 (epoch 14), train_loss = 2.637, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 8428 (epoch 14), train_loss = 2.839, time/batch = 0.030
Read data: 9.012222290039062e-05
iter 8429 (epoch 14), train_loss = 2.686, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 8430 (epoch 14), train_loss = 2.951, time/batch = 0.021
Read data: 8.845329284667969e-05
iter 8431 (epoch 14), train_loss = 2.564, time/batch = 0.023
Read data: 0.0001125335693359375
iter 8432 (epoch 14), train_loss = 2.850, time/batch = 0.022
Read data: 0.00014638900756835938
iter 8433 (epoch 14), train_loss = 2.635, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 8434 (epoch 14), train_loss = 2.501, time/batch = 0.022
Read data: 0.00010514259338378906
iter 8435 (epoch 14), train_loss = 2.902, time/batch = 0.027
Read data: 0.00011777877807617188
iter 8436 (epoch 14), train_loss = 2.517, time/batch = 0.026
Read data: 0.0001430511474609375
iter 8437 (epoch 14), train_loss = 2.658, time/batch = 0.032
Read data: 7.772445678710938e-05
iter 8438 (epoch 14), train_loss = 2.747, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 8439 (epoch 14), train_loss = 2.603, time/batch = 0.023
Read data: 9.989738464355469e-05
iter 8440 (epoch 14), train_loss = 2.682, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 8441 (epoch 14), train_loss = 2.438, time/batch = 0.024
Read data: 9.5367431640625e-05
iter 8442 (epoch 14), train_loss = 2.770, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 8443 (epoch 14), train_loss = 2.546, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 8444 (epoch 14), train_loss = 2.606, time/batch = 0.023
Read data: 0.00013136863708496094
iter 8445 (epoch 14), train_loss = 2.591, time/batch = 0.031
Read data: 9.560585021972656e-05
iter 8446 (epoch 14), train_loss = 3.084, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 8447 (epoch 14), train_loss = 2.385, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8448 (epoch 14), train_loss = 2.682, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 8449 (epoch 14), train_loss = 2.602, time/batch = 0.024
Read data: 0.00023627281188964844
iter 8450 (epoch 14), train_loss = 2.382, time/batch = 0.027
Read data: 7.605552673339844e-05
iter 8451 (epoch 14), train_loss = 2.558, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 8452 (epoch 14), train_loss = 2.845, time/batch = 0.024
Read data: 0.00010704994201660156
iter 8453 (epoch 14), train_loss = 2.720, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 8454 (epoch 14), train_loss = 3.104, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 8455 (epoch 14), train_loss = 2.527, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 8456 (epoch 14), train_loss = 2.886, time/batch = 0.024
Read data: 0.00012731552124023438
iter 8457 (epoch 14), train_loss = 2.693, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 8458 (epoch 14), train_loss = 3.069, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8459 (epoch 14), train_loss = 2.579, time/batch = 0.025
Read data: 9.799003601074219e-05
iter 8460 (epoch 14), train_loss = 2.237, time/batch = 0.028
Read data: 8.392333984375e-05
iter 8461 (epoch 14), train_loss = 3.126, time/batch = 0.022
Read data: 7.605552673339844e-05
iter 8462 (epoch 14), train_loss = 3.233, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 8463 (epoch 14), train_loss = 2.925, time/batch = 0.023
Read data: 0.00010013580322265625
iter 8464 (epoch 14), train_loss = 2.339, time/batch = 0.025
Read data: 0.00010514259338378906
iter 8465 (epoch 14), train_loss = 2.460, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 8466 (epoch 14), train_loss = 2.408, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 8467 (epoch 14), train_loss = 2.374, time/batch = 0.027
Read data: 0.00010204315185546875
iter 8468 (epoch 14), train_loss = 2.724, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 8469 (epoch 14), train_loss = 2.615, time/batch = 0.023
Read data: 0.00012683868408203125
iter 8470 (epoch 14), train_loss = 2.426, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 8471 (epoch 14), train_loss = 2.417, time/batch = 0.031
Read data: 0.00011610984802246094
iter 8472 (epoch 14), train_loss = 2.805, time/batch = 0.025
Read data: 0.0001010894775390625
iter 8473 (epoch 14), train_loss = 2.497, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 8474 (epoch 14), train_loss = 2.637, time/batch = 0.027
Read data: 0.0002601146697998047
iter 8475 (epoch 14), train_loss = 2.928, time/batch = 0.034
Read data: 7.867813110351562e-05
iter 8476 (epoch 14), train_loss = 2.530, time/batch = 0.030
Read data: 9.036064147949219e-05
iter 8477 (epoch 14), train_loss = 2.676, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 8478 (epoch 14), train_loss = 2.772, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 8479 (epoch 14), train_loss = 2.888, time/batch = 0.034
Read data: 7.987022399902344e-05
iter 8480 (epoch 14), train_loss = 2.630, time/batch = 0.034
Read data: 9.417533874511719e-05
iter 8481 (epoch 14), train_loss = 2.517, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 8482 (epoch 14), train_loss = 2.607, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 8483 (epoch 14), train_loss = 2.816, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 8484 (epoch 14), train_loss = 2.810, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 8485 (epoch 14), train_loss = 2.904, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 8486 (epoch 14), train_loss = 2.890, time/batch = 0.028
Read data: 9.679794311523438e-05
iter 8487 (epoch 14), train_loss = 2.727, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 8488 (epoch 14), train_loss = 2.598, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 8489 (epoch 14), train_loss = 2.924, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 8490 (epoch 14), train_loss = 2.661, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 8491 (epoch 14), train_loss = 2.537, time/batch = 0.023
Read data: 0.00011181831359863281
iter 8492 (epoch 14), train_loss = 2.290, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 8493 (epoch 14), train_loss = 2.852, time/batch = 0.029
Read data: 9.250640869140625e-05
iter 8494 (epoch 14), train_loss = 2.304, time/batch = 0.027
Read data: 0.00010371208190917969
iter 8495 (epoch 14), train_loss = 2.529, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 8496 (epoch 14), train_loss = 2.896, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 8497 (epoch 14), train_loss = 2.817, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 8498 (epoch 14), train_loss = 2.584, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 8499 (epoch 14), train_loss = 2.330, time/batch = 0.023
Read data: 0.00011277198791503906
iter 8500 (epoch 14), train_loss = 2.342, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 8501 (epoch 14), train_loss = 2.501, time/batch = 0.023
Read data: 0.00010609626770019531
iter 8502 (epoch 14), train_loss = 2.889, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 8503 (epoch 14), train_loss = 2.628, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 8504 (epoch 14), train_loss = 2.634, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 8505 (epoch 14), train_loss = 2.493, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 8506 (epoch 14), train_loss = 2.631, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 8507 (epoch 14), train_loss = 2.325, time/batch = 0.021
Read data: 0.00011610984802246094
iter 8508 (epoch 14), train_loss = 2.814, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 8509 (epoch 14), train_loss = 2.567, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 8510 (epoch 14), train_loss = 2.488, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 8511 (epoch 14), train_loss = 2.337, time/batch = 0.025
Read data: 0.00011372566223144531
iter 8512 (epoch 14), train_loss = 2.676, time/batch = 0.030
Read data: 0.00013113021850585938
iter 8513 (epoch 14), train_loss = 2.602, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 8514 (epoch 14), train_loss = 3.132, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 8515 (epoch 14), train_loss = 2.652, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 8516 (epoch 14), train_loss = 2.517, time/batch = 0.024
Read data: 0.00013446807861328125
iter 8517 (epoch 14), train_loss = 2.722, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 8518 (epoch 14), train_loss = 2.757, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 8519 (epoch 14), train_loss = 2.583, time/batch = 0.026
Read data: 0.000125885009765625
iter 8520 (epoch 14), train_loss = 2.457, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 8521 (epoch 14), train_loss = 2.485, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 8522 (epoch 14), train_loss = 2.585, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 8523 (epoch 14), train_loss = 2.456, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 8524 (epoch 14), train_loss = 2.645, time/batch = 0.023
Read data: 0.0003108978271484375
iter 8525 (epoch 14), train_loss = 2.874, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 8526 (epoch 14), train_loss = 2.529, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 8527 (epoch 14), train_loss = 2.558, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 8528 (epoch 14), train_loss = 2.612, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 8529 (epoch 14), train_loss = 2.739, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 8530 (epoch 14), train_loss = 2.775, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 8531 (epoch 14), train_loss = 2.322, time/batch = 0.022
Read data: 0.00014495849609375
iter 8532 (epoch 14), train_loss = 2.412, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 8533 (epoch 14), train_loss = 2.314, time/batch = 0.026
Read data: 0.001712799072265625
iter 8534 (epoch 14), train_loss = 2.745, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 8535 (epoch 14), train_loss = 2.476, time/batch = 0.026
Read data: 0.0001201629638671875
iter 8536 (epoch 14), train_loss = 2.617, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 8537 (epoch 14), train_loss = 2.467, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 8538 (epoch 14), train_loss = 2.434, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 8539 (epoch 14), train_loss = 2.572, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 8540 (epoch 14), train_loss = 2.630, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 8541 (epoch 14), train_loss = 2.653, time/batch = 0.022
Read data: 9.417533874511719e-05
iter 8542 (epoch 14), train_loss = 2.522, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 8543 (epoch 14), train_loss = 2.362, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 8544 (epoch 14), train_loss = 2.340, time/batch = 0.025
Read data: 0.0001049041748046875
iter 8545 (epoch 14), train_loss = 2.829, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 8546 (epoch 14), train_loss = 2.747, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 8547 (epoch 14), train_loss = 2.923, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 8548 (epoch 14), train_loss = 2.764, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8549 (epoch 14), train_loss = 2.496, time/batch = 0.026
Read data: 0.00025010108947753906
iter 8550 (epoch 14), train_loss = 1.766, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 8551 (epoch 14), train_loss = 2.481, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 8552 (epoch 14), train_loss = 2.974, time/batch = 0.023
Read data: 0.0001659393310546875
iter 8553 (epoch 14), train_loss = 2.656, time/batch = 0.033
Read data: 8.249282836914062e-05
iter 8554 (epoch 14), train_loss = 2.334, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 8555 (epoch 14), train_loss = 3.131, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 8556 (epoch 14), train_loss = 2.637, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 8557 (epoch 14), train_loss = 2.597, time/batch = 0.024
Read data: 9.918212890625e-05
iter 8558 (epoch 14), train_loss = 2.867, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 8559 (epoch 14), train_loss = 2.401, time/batch = 0.023
Read data: 0.00011754035949707031
iter 8560 (epoch 14), train_loss = 2.636, time/batch = 0.024
Read data: 0.00017261505126953125
iter 8561 (epoch 14), train_loss = 2.660, time/batch = 0.028
Read data: 0.00012946128845214844
iter 8562 (epoch 14), train_loss = 2.222, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 8563 (epoch 14), train_loss = 2.692, time/batch = 0.029
Read data: 8.893013000488281e-05
iter 8564 (epoch 14), train_loss = 2.814, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 8565 (epoch 14), train_loss = 2.647, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 8566 (epoch 14), train_loss = 2.037, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 8567 (epoch 14), train_loss = 2.951, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 8568 (epoch 14), train_loss = 2.510, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 8569 (epoch 14), train_loss = 2.426, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 8570 (epoch 14), train_loss = 2.564, time/batch = 0.040
Read data: 9.393692016601562e-05
iter 8571 (epoch 14), train_loss = 2.916, time/batch = 0.025
Read data: 0.00014162063598632812
iter 8572 (epoch 14), train_loss = 3.104, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 8573 (epoch 14), train_loss = 2.763, time/batch = 0.032
Read data: 8.368492126464844e-05
iter 8574 (epoch 14), train_loss = 2.767, time/batch = 0.028
Read data: 0.0002117156982421875
iter 8575 (epoch 14), train_loss = 2.619, time/batch = 0.031
Read data: 9.560585021972656e-05
iter 8576 (epoch 14), train_loss = 2.625, time/batch = 0.044
Read data: 8.606910705566406e-05
iter 8577 (epoch 14), train_loss = 2.579, time/batch = 0.034
Read data: 7.724761962890625e-05
iter 8578 (epoch 14), train_loss = 2.763, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 8579 (epoch 14), train_loss = 2.716, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 8580 (epoch 14), train_loss = 2.859, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 8581 (epoch 14), train_loss = 2.532, time/batch = 0.031
Read data: 8.630752563476562e-05
iter 8582 (epoch 14), train_loss = 2.441, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 8583 (epoch 14), train_loss = 2.629, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 8584 (epoch 14), train_loss = 2.832, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 8585 (epoch 14), train_loss = 2.533, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 8586 (epoch 14), train_loss = 2.656, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 8587 (epoch 14), train_loss = 2.150, time/batch = 0.033
Read data: 8.273124694824219e-05
iter 8588 (epoch 14), train_loss = 2.299, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 8589 (epoch 14), train_loss = 2.755, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 8590 (epoch 14), train_loss = 2.564, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 8591 (epoch 14), train_loss = 2.484, time/batch = 0.030
Read data: 0.00011801719665527344
iter 8592 (epoch 14), train_loss = 2.659, time/batch = 0.036
Read data: 8.559226989746094e-05
iter 8593 (epoch 14), train_loss = 2.469, time/batch = 0.035
Read data: 8.630752563476562e-05
iter 8594 (epoch 14), train_loss = 2.539, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 8595 (epoch 14), train_loss = 2.286, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 8596 (epoch 14), train_loss = 2.690, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 8597 (epoch 14), train_loss = 2.379, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 8598 (epoch 14), train_loss = 2.697, time/batch = 0.029
Read data: 0.00013017654418945312
iter 8599 (epoch 14), train_loss = 2.464, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 8600 (epoch 14), train_loss = 2.516, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8601 (epoch 14), train_loss = 2.642, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 8602 (epoch 14), train_loss = 2.663, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 8603 (epoch 14), train_loss = 2.518, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8604 (epoch 14), train_loss = 2.328, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 8605 (epoch 14), train_loss = 2.855, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 8606 (epoch 14), train_loss = 3.038, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 8607 (epoch 14), train_loss = 2.445, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 8608 (epoch 14), train_loss = 2.180, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 8609 (epoch 14), train_loss = 2.296, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 8610 (epoch 14), train_loss = 2.583, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 8611 (epoch 14), train_loss = 2.157, time/batch = 0.024
Read data: 0.00012636184692382812
iter 8612 (epoch 14), train_loss = 2.178, time/batch = 0.022
Read data: 9.72747802734375e-05
iter 8613 (epoch 14), train_loss = 2.800, time/batch = 0.034
Read data: 9.799003601074219e-05
iter 8614 (epoch 14), train_loss = 2.536, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 8615 (epoch 14), train_loss = 2.286, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 8616 (epoch 14), train_loss = 2.444, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 8617 (epoch 14), train_loss = 2.592, time/batch = 0.028
Read data: 0.0001552104949951172
iter 8618 (epoch 14), train_loss = 2.627, time/batch = 0.025
Read data: 0.00011372566223144531
iter 8619 (epoch 14), train_loss = 2.763, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 8620 (epoch 14), train_loss = 2.367, time/batch = 0.026
Read data: 0.00011610984802246094
iter 8621 (epoch 14), train_loss = 2.470, time/batch = 0.033
Read data: 7.867813110351562e-05
iter 8622 (epoch 14), train_loss = 2.659, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 8623 (epoch 14), train_loss = 2.388, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 8624 (epoch 14), train_loss = 2.579, time/batch = 0.029
Read data: 0.0002570152282714844
iter 8625 (epoch 14), train_loss = 2.889, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 8626 (epoch 14), train_loss = 2.831, time/batch = 0.038
Read data: 0.00010752677917480469
iter 8627 (epoch 14), train_loss = 2.547, time/batch = 0.029
Read data: 0.000133514404296875
iter 8628 (epoch 14), train_loss = 2.529, time/batch = 0.032
Read data: 9.1552734375e-05
iter 8629 (epoch 14), train_loss = 2.603, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 8630 (epoch 14), train_loss = 2.571, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 8631 (epoch 14), train_loss = 2.983, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 8632 (epoch 14), train_loss = 2.823, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 8633 (epoch 14), train_loss = 1.961, time/batch = 0.031
Read data: 9.202957153320312e-05
iter 8634 (epoch 14), train_loss = 2.041, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 8635 (epoch 14), train_loss = 2.441, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 8636 (epoch 14), train_loss = 2.465, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 8637 (epoch 14), train_loss = 2.782, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 8638 (epoch 14), train_loss = 2.765, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 8639 (epoch 14), train_loss = 2.612, time/batch = 0.025
Read data: 0.0001583099365234375
iter 8640 (epoch 14), train_loss = 2.612, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 8641 (epoch 14), train_loss = 2.660, time/batch = 0.032
Read data: 8.630752563476562e-05
iter 8642 (epoch 14), train_loss = 2.562, time/batch = 0.038
Read data: 7.62939453125e-05
iter 8643 (epoch 14), train_loss = 2.580, time/batch = 0.025
Read data: 0.0001361370086669922
iter 8644 (epoch 14), train_loss = 2.339, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 8645 (epoch 14), train_loss = 2.560, time/batch = 0.028
Read data: 0.00012874603271484375
iter 8646 (epoch 14), train_loss = 2.962, time/batch = 0.040
Read data: 7.486343383789062e-05
iter 8647 (epoch 14), train_loss = 2.574, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 8648 (epoch 14), train_loss = 2.774, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 8649 (epoch 14), train_loss = 2.872, time/batch = 0.024
Read data: 0.0002124309539794922
iter 8650 (epoch 14), train_loss = 2.650, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 8651 (epoch 14), train_loss = 2.590, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 8652 (epoch 14), train_loss = 3.069, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 8653 (epoch 14), train_loss = 2.558, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 8654 (epoch 14), train_loss = 3.069, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 8655 (epoch 14), train_loss = 2.737, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 8656 (epoch 14), train_loss = 2.645, time/batch = 0.031
Read data: 7.62939453125e-05
iter 8657 (epoch 14), train_loss = 2.633, time/batch = 0.023
Read data: 0.00011444091796875
iter 8658 (epoch 14), train_loss = 2.799, time/batch = 0.028
Read data: 0.00012350082397460938
iter 8659 (epoch 14), train_loss = 2.186, time/batch = 0.026
Read data: 0.0001270771026611328
iter 8660 (epoch 14), train_loss = 2.851, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 8661 (epoch 14), train_loss = 2.550, time/batch = 0.028
Read data: 0.00019073486328125
iter 8662 (epoch 14), train_loss = 2.787, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 8663 (epoch 14), train_loss = 2.658, time/batch = 0.024
Read data: 0.00013184547424316406
iter 8664 (epoch 14), train_loss = 2.296, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 8665 (epoch 14), train_loss = 2.429, time/batch = 0.024
Read data: 0.000179290771484375
iter 8666 (epoch 14), train_loss = 2.210, time/batch = 0.024
Read data: 0.00019359588623046875
iter 8667 (epoch 14), train_loss = 2.498, time/batch = 0.025
Read data: 0.0001518726348876953
iter 8668 (epoch 14), train_loss = 2.686, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 8669 (epoch 14), train_loss = 2.489, time/batch = 0.029
Read data: 0.00020647048950195312
iter 8670 (epoch 14), train_loss = 2.557, time/batch = 0.022
Read data: 0.0001518726348876953
iter 8671 (epoch 14), train_loss = 2.295, time/batch = 0.029
Read data: 7.581710815429688e-05
iter 8672 (epoch 14), train_loss = 2.725, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 8673 (epoch 14), train_loss = 2.586, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 8674 (epoch 14), train_loss = 2.804, time/batch = 0.024
Read data: 0.000213623046875
iter 8675 (epoch 14), train_loss = 2.339, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 8676 (epoch 14), train_loss = 3.244, time/batch = 0.022
Read data: 0.0001518726348876953
iter 8677 (epoch 14), train_loss = 3.015, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 8678 (epoch 14), train_loss = 2.359, time/batch = 0.028
Read data: 0.00019216537475585938
iter 8679 (epoch 14), train_loss = 2.871, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 8680 (epoch 14), train_loss = 2.224, time/batch = 0.024
Read data: 0.0001544952392578125
iter 8681 (epoch 14), train_loss = 2.641, time/batch = 0.026
Read data: 9.846687316894531e-05
iter 8682 (epoch 14), train_loss = 2.694, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 8683 (epoch 14), train_loss = 2.896, time/batch = 0.028
Read data: 0.00013399124145507812
iter 8684 (epoch 14), train_loss = 2.079, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 8685 (epoch 14), train_loss = 2.895, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 8686 (epoch 14), train_loss = 2.618, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 8687 (epoch 14), train_loss = 2.391, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 8688 (epoch 14), train_loss = 2.467, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 8689 (epoch 14), train_loss = 2.931, time/batch = 0.031
Read data: 0.000118255615234375
iter 8690 (epoch 14), train_loss = 2.503, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 8691 (epoch 14), train_loss = 2.516, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 8692 (epoch 14), train_loss = 2.738, time/batch = 0.024
Read data: 0.00015997886657714844
iter 8693 (epoch 14), train_loss = 2.715, time/batch = 0.032
Read data: 0.000118255615234375
iter 8694 (epoch 14), train_loss = 2.960, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 8695 (epoch 14), train_loss = 2.769, time/batch = 0.026
Read data: 0.0001347064971923828
iter 8696 (epoch 14), train_loss = 2.224, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 8697 (epoch 14), train_loss = 2.876, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 8698 (epoch 14), train_loss = 2.543, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 8699 (epoch 14), train_loss = 2.265, time/batch = 0.025
Read data: 0.00012493133544921875
iter 8700 (epoch 14), train_loss = 2.833, time/batch = 0.034
Read data: 0.00011801719665527344
iter 8701 (epoch 14), train_loss = 2.453, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 8702 (epoch 14), train_loss = 2.363, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 8703 (epoch 14), train_loss = 2.377, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 8704 (epoch 14), train_loss = 2.928, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 8705 (epoch 14), train_loss = 2.405, time/batch = 0.023
Read data: 0.00011134147644042969
iter 8706 (epoch 14), train_loss = 2.849, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 8707 (epoch 14), train_loss = 2.664, time/batch = 0.022
Read data: 0.00014328956604003906
iter 8708 (epoch 14), train_loss = 2.520, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 8709 (epoch 14), train_loss = 2.947, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 8710 (epoch 14), train_loss = 2.702, time/batch = 0.026
Read data: 7.62939453125e-05
iter 8711 (epoch 14), train_loss = 3.162, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 8712 (epoch 14), train_loss = 2.876, time/batch = 0.024
Read data: 0.00015282630920410156
iter 8713 (epoch 14), train_loss = 2.316, time/batch = 0.026
Read data: 0.00018548965454101562
iter 8714 (epoch 14), train_loss = 2.405, time/batch = 0.026
Read data: 0.00015783309936523438
iter 8715 (epoch 14), train_loss = 2.486, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 8716 (epoch 14), train_loss = 2.800, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 8717 (epoch 14), train_loss = 2.906, time/batch = 0.030
Read data: 0.00011873245239257812
iter 8718 (epoch 14), train_loss = 2.204, time/batch = 0.025
Read data: 0.00011444091796875
iter 8719 (epoch 14), train_loss = 2.687, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 8720 (epoch 14), train_loss = 2.564, time/batch = 0.023
Read data: 0.00011229515075683594
iter 8721 (epoch 14), train_loss = 2.896, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 8722 (epoch 14), train_loss = 2.203, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 8723 (epoch 14), train_loss = 2.488, time/batch = 0.026
Read data: 0.00016832351684570312
iter 8724 (epoch 14), train_loss = 2.078, time/batch = 0.027
Read data: 0.00029778480529785156
iter 8725 (epoch 14), train_loss = 2.662, time/batch = 0.024
Read data: 0.00010013580322265625
iter 8726 (epoch 14), train_loss = 2.583, time/batch = 0.027
Read data: 0.00018477439880371094
iter 8727 (epoch 14), train_loss = 2.420, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 8728 (epoch 14), train_loss = 2.498, time/batch = 0.026
Read data: 7.62939453125e-05
iter 8729 (epoch 14), train_loss = 2.589, time/batch = 0.026
Read data: 0.00011467933654785156
iter 8730 (epoch 14), train_loss = 2.289, time/batch = 0.024
Read data: 0.00011467933654785156
iter 8731 (epoch 14), train_loss = 2.575, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 8732 (epoch 14), train_loss = 2.487, time/batch = 0.024
Read data: 0.00015044212341308594
iter 8733 (epoch 14), train_loss = 2.434, time/batch = 0.027
Read data: 0.00019860267639160156
iter 8734 (epoch 14), train_loss = 2.840, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 8735 (epoch 14), train_loss = 2.485, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 8736 (epoch 14), train_loss = 2.423, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 8737 (epoch 14), train_loss = 2.664, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 8738 (epoch 14), train_loss = 2.433, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 8739 (epoch 14), train_loss = 2.730, time/batch = 0.027
Read data: 0.000171661376953125
iter 8740 (epoch 14), train_loss = 2.881, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 8741 (epoch 14), train_loss = 2.465, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 8742 (epoch 14), train_loss = 2.597, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 8743 (epoch 14), train_loss = 2.641, time/batch = 0.025
Read data: 0.00012159347534179688
iter 8744 (epoch 14), train_loss = 3.113, time/batch = 0.026
Read data: 0.00016117095947265625
iter 8745 (epoch 14), train_loss = 2.895, time/batch = 0.027
Read data: 0.00011229515075683594
iter 8746 (epoch 14), train_loss = 2.426, time/batch = 0.021
Read data: 0.0001609325408935547
iter 8747 (epoch 14), train_loss = 2.585, time/batch = 0.027
Read data: 7.581710815429688e-05
iter 8748 (epoch 14), train_loss = 2.812, time/batch = 0.024
Read data: 0.00015783309936523438
iter 8749 (epoch 14), train_loss = 2.574, time/batch = 0.021
Read data: 0.0002334117889404297
iter 8750 (epoch 14), train_loss = 2.263, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 8751 (epoch 14), train_loss = 2.686, time/batch = 0.021
Read data: 0.00011134147644042969
iter 8752 (epoch 14), train_loss = 2.867, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 8753 (epoch 14), train_loss = 2.601, time/batch = 0.028
Read data: 0.00011515617370605469
iter 8754 (epoch 14), train_loss = 2.888, time/batch = 0.025
Read data: 7.62939453125e-05
iter 8755 (epoch 14), train_loss = 2.761, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 8756 (epoch 14), train_loss = 3.004, time/batch = 0.034
Read data: 8.368492126464844e-05
iter 8757 (epoch 14), train_loss = 2.442, time/batch = 0.026
Read data: 8.392333984375e-05
iter 8758 (epoch 14), train_loss = 2.400, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 8759 (epoch 14), train_loss = 2.605, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 8760 (epoch 14), train_loss = 2.566, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 8761 (epoch 14), train_loss = 2.409, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 8762 (epoch 14), train_loss = 2.706, time/batch = 0.022
Read data: 0.0002040863037109375
iter 8763 (epoch 14), train_loss = 3.073, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 8764 (epoch 14), train_loss = 2.389, time/batch = 0.030
Read data: 8.845329284667969e-05
iter 8765 (epoch 14), train_loss = 2.585, time/batch = 0.021
Read data: 9.5367431640625e-05
iter 8766 (epoch 14), train_loss = 2.570, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 8767 (epoch 14), train_loss = 2.638, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 8768 (epoch 14), train_loss = 2.898, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 8769 (epoch 14), train_loss = 2.680, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 8770 (epoch 14), train_loss = 2.804, time/batch = 0.032
Read data: 9.584426879882812e-05
iter 8771 (epoch 14), train_loss = 2.774, time/batch = 0.026
Read data: 0.00015091896057128906
iter 8772 (epoch 14), train_loss = 2.622, time/batch = 0.028
Read data: 0.0001423358917236328
iter 8773 (epoch 14), train_loss = 3.294, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 8774 (epoch 14), train_loss = 2.633, time/batch = 0.025
Read data: 0.00021696090698242188
iter 8775 (epoch 14), train_loss = 2.435, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 8776 (epoch 14), train_loss = 2.328, time/batch = 0.027
Read data: 7.43865966796875e-05
iter 8777 (epoch 14), train_loss = 2.855, time/batch = 0.027
Read data: 0.0001888275146484375
iter 8778 (epoch 14), train_loss = 2.534, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 8779 (epoch 14), train_loss = 2.669, time/batch = 0.024
Read data: 0.00012683868408203125
iter 8780 (epoch 14), train_loss = 2.023, time/batch = 0.022
Read data: 0.00015616416931152344
iter 8781 (epoch 14), train_loss = 2.431, time/batch = 0.033
Read data: 0.00020241737365722656
iter 8782 (epoch 14), train_loss = 2.747, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 8783 (epoch 14), train_loss = 2.547, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 8784 (epoch 14), train_loss = 2.914, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 8785 (epoch 14), train_loss = 2.784, time/batch = 0.024
Read data: 0.00011444091796875
iter 8786 (epoch 14), train_loss = 2.605, time/batch = 0.024
Read data: 0.0001533031463623047
iter 8787 (epoch 14), train_loss = 2.680, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 8788 (epoch 14), train_loss = 2.712, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 8789 (epoch 14), train_loss = 2.613, time/batch = 0.024
Read data: 0.00015807151794433594
iter 8790 (epoch 14), train_loss = 2.199, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 8791 (epoch 14), train_loss = 2.282, time/batch = 0.020
Read data: 9.250640869140625e-05
iter 8792 (epoch 14), train_loss = 2.691, time/batch = 0.028
Read data: 0.0001125335693359375
iter 8793 (epoch 14), train_loss = 2.389, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 8794 (epoch 14), train_loss = 2.832, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 8795 (epoch 14), train_loss = 2.752, time/batch = 0.024
Read data: 0.00012159347534179688
iter 8796 (epoch 14), train_loss = 2.274, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 8797 (epoch 14), train_loss = 2.788, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 8798 (epoch 14), train_loss = 2.963, time/batch = 0.028
Read data: 0.0001163482666015625
iter 8799 (epoch 14), train_loss = 2.379, time/batch = 0.022
Read data: 0.00014495849609375
iter 8800 (epoch 14), train_loss = 2.661, time/batch = 0.030
Read data: 9.5367431640625e-05
iter 8801 (epoch 14), train_loss = 2.472, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 8802 (epoch 14), train_loss = 2.885, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 8803 (epoch 14), train_loss = 2.386, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 8804 (epoch 14), train_loss = 3.252, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 8805 (epoch 14), train_loss = 3.014, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 8806 (epoch 14), train_loss = 2.388, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 8807 (epoch 14), train_loss = 2.259, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 8808 (epoch 14), train_loss = 3.103, time/batch = 0.024
Read data: 7.605552673339844e-05
iter 8809 (epoch 14), train_loss = 2.946, time/batch = 0.020
Read data: 8.702278137207031e-05
iter 8810 (epoch 14), train_loss = 3.018, time/batch = 0.033
Read data: 0.00016117095947265625
iter 8811 (epoch 14), train_loss = 2.646, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 8812 (epoch 14), train_loss = 2.987, time/batch = 0.042
Read data: 0.0001556873321533203
iter 8813 (epoch 14), train_loss = 2.523, time/batch = 0.027
Read data: 0.00014638900756835938
iter 8814 (epoch 14), train_loss = 2.312, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 8815 (epoch 14), train_loss = 2.459, time/batch = 0.026
Read data: 0.00016546249389648438
iter 8816 (epoch 14), train_loss = 2.789, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 8817 (epoch 14), train_loss = 2.939, time/batch = 0.032
Read data: 7.891654968261719e-05
iter 8818 (epoch 14), train_loss = 2.497, time/batch = 0.029
Read data: 0.00014519691467285156
iter 8819 (epoch 14), train_loss = 3.023, time/batch = 0.038
Read data: 0.0001494884490966797
iter 8820 (epoch 14), train_loss = 2.641, time/batch = 0.022
Read data: 0.00014066696166992188
iter 8821 (epoch 14), train_loss = 2.523, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 8822 (epoch 14), train_loss = 2.558, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 8823 (epoch 14), train_loss = 2.319, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 8824 (epoch 14), train_loss = 2.582, time/batch = 0.027
Read data: 0.0002238750457763672
iter 8825 (epoch 14), train_loss = 2.759, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 8826 (epoch 14), train_loss = 2.428, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 8827 (epoch 14), train_loss = 1.856, time/batch = 0.024
Read data: 0.00012302398681640625
iter 8828 (epoch 14), train_loss = 2.744, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 8829 (epoch 14), train_loss = 2.578, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 8830 (epoch 14), train_loss = 2.812, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 8831 (epoch 14), train_loss = 2.721, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 8832 (epoch 14), train_loss = 2.977, time/batch = 0.027
Read data: 0.00011396408081054688
iter 8833 (epoch 14), train_loss = 2.761, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 8834 (epoch 14), train_loss = 2.778, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 8835 (epoch 14), train_loss = 2.375, time/batch = 0.024
Read data: 0.00012040138244628906
iter 8836 (epoch 14), train_loss = 2.269, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 8837 (epoch 14), train_loss = 2.781, time/batch = 0.029
Read data: 0.00015664100646972656
iter 8838 (epoch 14), train_loss = 2.740, time/batch = 0.026
Read data: 0.0001614093780517578
iter 8839 (epoch 14), train_loss = 2.756, time/batch = 0.028
Read data: 0.00012373924255371094
iter 8840 (epoch 14), train_loss = 2.385, time/batch = 0.024
Read data: 0.0001590251922607422
iter 8841 (epoch 14), train_loss = 2.655, time/batch = 0.041
Read data: 8.487701416015625e-05
iter 8842 (epoch 14), train_loss = 2.430, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 8843 (epoch 14), train_loss = 2.487, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 8844 (epoch 14), train_loss = 2.230, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 8845 (epoch 14), train_loss = 2.470, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 8846 (epoch 14), train_loss = 2.442, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 8847 (epoch 14), train_loss = 2.422, time/batch = 0.024
Read data: 0.0001232624053955078
iter 8848 (epoch 14), train_loss = 2.685, time/batch = 0.023
Read data: 0.00016355514526367188
iter 8849 (epoch 14), train_loss = 2.362, time/batch = 0.028
Read data: 0.00022602081298828125
iter 8850 (epoch 14), train_loss = 2.513, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 8851 (epoch 14), train_loss = 2.676, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 8852 (epoch 14), train_loss = 2.416, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 8853 (epoch 14), train_loss = 3.087, time/batch = 0.038
Read data: 8.392333984375e-05
iter 8854 (epoch 14), train_loss = 2.413, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 8855 (epoch 14), train_loss = 2.302, time/batch = 0.030
Read data: 0.00017023086547851562
iter 8856 (epoch 14), train_loss = 2.392, time/batch = 0.029
Read data: 0.0001049041748046875
iter 8857 (epoch 14), train_loss = 3.015, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 8858 (epoch 14), train_loss = 2.829, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 8859 (epoch 14), train_loss = 2.904, time/batch = 0.033
Read data: 0.00016355514526367188
iter 8860 (epoch 14), train_loss = 2.513, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 8861 (epoch 14), train_loss = 2.727, time/batch = 0.038
Read data: 0.00010776519775390625
iter 8862 (epoch 14), train_loss = 2.759, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 8863 (epoch 14), train_loss = 2.692, time/batch = 0.030
Read data: 0.00017309188842773438
iter 8864 (epoch 14), train_loss = 2.497, time/batch = 0.030
Read data: 0.00014209747314453125
iter 8865 (epoch 14), train_loss = 3.085, time/batch = 0.041
Read data: 7.748603820800781e-05
iter 8866 (epoch 14), train_loss = 2.702, time/batch = 0.027
Read data: 0.0001461505889892578
iter 8867 (epoch 14), train_loss = 2.632, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 8868 (epoch 14), train_loss = 2.551, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 8869 (epoch 14), train_loss = 3.029, time/batch = 0.026
Read data: 0.0001437664031982422
iter 8870 (epoch 14), train_loss = 2.516, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 8871 (epoch 14), train_loss = 2.737, time/batch = 0.024
Read data: 0.0001404285430908203
iter 8872 (epoch 14), train_loss = 2.604, time/batch = 0.023
Read data: 0.0001163482666015625
iter 8873 (epoch 14), train_loss = 2.627, time/batch = 0.038
Read data: 8.249282836914062e-05
iter 8874 (epoch 14), train_loss = 2.254, time/batch = 0.029
Read data: 0.00028705596923828125
iter 8875 (epoch 14), train_loss = 2.678, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 8876 (epoch 14), train_loss = 2.888, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 8877 (epoch 14), train_loss = 2.665, time/batch = 0.026
Read data: 0.00014066696166992188
iter 8878 (epoch 14), train_loss = 2.784, time/batch = 0.028
Read data: 0.00016355514526367188
iter 8879 (epoch 14), train_loss = 2.212, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 8880 (epoch 14), train_loss = 2.307, time/batch = 0.027
Read data: 0.0001595020294189453
iter 8881 (epoch 14), train_loss = 2.567, time/batch = 0.026
Read data: 0.00015401840209960938
iter 8882 (epoch 14), train_loss = 2.474, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 8883 (epoch 14), train_loss = 2.564, time/batch = 0.024
Read data: 0.00015616416931152344
iter 8884 (epoch 14), train_loss = 2.232, time/batch = 0.022
Read data: 0.00015211105346679688
iter 8885 (epoch 14), train_loss = 2.507, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 8886 (epoch 14), train_loss = 2.837, time/batch = 0.027
Read data: 0.00015234947204589844
iter 8887 (epoch 14), train_loss = 2.551, time/batch = 0.028
Read data: 0.00012755393981933594
iter 8888 (epoch 14), train_loss = 2.755, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 8889 (epoch 14), train_loss = 2.277, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 8890 (epoch 14), train_loss = 2.330, time/batch = 0.021
Read data: 0.00017380714416503906
iter 8891 (epoch 14), train_loss = 2.544, time/batch = 0.023
Read data: 0.00017523765563964844
iter 8892 (epoch 14), train_loss = 2.749, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 8893 (epoch 14), train_loss = 2.592, time/batch = 0.041
Read data: 0.00013875961303710938
iter 8894 (epoch 14), train_loss = 2.878, time/batch = 0.025
Read data: 0.00014066696166992188
iter 8895 (epoch 14), train_loss = 2.919, time/batch = 0.037
Read data: 7.724761962890625e-05
iter 8896 (epoch 14), train_loss = 2.696, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 8897 (epoch 14), train_loss = 3.050, time/batch = 0.028
Read data: 9.632110595703125e-05
iter 8898 (epoch 14), train_loss = 2.364, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 8899 (epoch 14), train_loss = 2.682, time/batch = 0.025
Read data: 0.000164031982421875
iter 8900 (epoch 14), train_loss = 2.899, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 8901 (epoch 14), train_loss = 2.545, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 8902 (epoch 14), train_loss = 2.828, time/batch = 0.030
Read data: 0.00016951560974121094
iter 8903 (epoch 14), train_loss = 2.537, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 8904 (epoch 14), train_loss = 2.375, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 8905 (epoch 14), train_loss = 2.423, time/batch = 0.024
Read data: 0.00012135505676269531
iter 8906 (epoch 14), train_loss = 2.592, time/batch = 0.024
Read data: 0.0001475811004638672
iter 8907 (epoch 14), train_loss = 2.764, time/batch = 0.037
Read data: 7.963180541992188e-05
iter 8908 (epoch 14), train_loss = 2.287, time/batch = 0.021
Read data: 7.963180541992188e-05
iter 8909 (epoch 14), train_loss = 2.467, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 8910 (epoch 14), train_loss = 2.858, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 8911 (epoch 14), train_loss = 2.711, time/batch = 0.026
Read data: 7.62939453125e-05
iter 8912 (epoch 14), train_loss = 2.134, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 8913 (epoch 14), train_loss = 2.467, time/batch = 0.028
Read data: 0.0001285076141357422
iter 8914 (epoch 14), train_loss = 2.726, time/batch = 0.023
Read data: 8.392333984375e-05
iter 8915 (epoch 14), train_loss = 2.777, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 8916 (epoch 14), train_loss = 2.369, time/batch = 0.024
Read data: 0.00011539459228515625
iter 8917 (epoch 14), train_loss = 2.536, time/batch = 0.022
Read data: 0.00015664100646972656
iter 8918 (epoch 14), train_loss = 3.201, time/batch = 0.025
Read data: 0.00015234947204589844
iter 8919 (epoch 14), train_loss = 2.432, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 8920 (epoch 14), train_loss = 2.481, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 8921 (epoch 14), train_loss = 2.907, time/batch = 0.024
Read data: 0.00013518333435058594
iter 8922 (epoch 14), train_loss = 3.244, time/batch = 0.030
Read data: 0.00012803077697753906
iter 8923 (epoch 14), train_loss = 2.409, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 8924 (epoch 14), train_loss = 2.534, time/batch = 0.028
Read data: 0.00021076202392578125
iter 8925 (epoch 14), train_loss = 2.495, time/batch = 0.035
Read data: 0.00016355514526367188
iter 8926 (epoch 14), train_loss = 2.548, time/batch = 0.027
Read data: 0.0001552104949951172
iter 8927 (epoch 14), train_loss = 2.998, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 8928 (epoch 14), train_loss = 2.019, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 8929 (epoch 14), train_loss = 2.649, time/batch = 0.020
Read data: 0.00014209747314453125
iter 8930 (epoch 14), train_loss = 2.396, time/batch = 0.026
Read data: 0.00015282630920410156
iter 8931 (epoch 14), train_loss = 2.495, time/batch = 0.031
Read data: 0.00019979476928710938
iter 8932 (epoch 14), train_loss = 2.515, time/batch = 0.025
Read data: 0.00015878677368164062
iter 8933 (epoch 14), train_loss = 2.850, time/batch = 0.026
Read data: 0.00012493133544921875
iter 8934 (epoch 14), train_loss = 2.444, time/batch = 0.028
Read data: 0.00011992454528808594
iter 8935 (epoch 14), train_loss = 2.948, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 8936 (epoch 14), train_loss = 3.032, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 8937 (epoch 14), train_loss = 2.654, time/batch = 0.022
Read data: 0.0001266002655029297
iter 8938 (epoch 14), train_loss = 2.513, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 8939 (epoch 14), train_loss = 2.099, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 8940 (epoch 14), train_loss = 2.897, time/batch = 0.027
Read data: 0.00017452239990234375
iter 8941 (epoch 14), train_loss = 2.287, time/batch = 0.026
Read data: 0.00012183189392089844
iter 8942 (epoch 14), train_loss = 2.586, time/batch = 0.024
Read data: 0.0001270771026611328
iter 8943 (epoch 14), train_loss = 3.020, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 8944 (epoch 14), train_loss = 2.401, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 8945 (epoch 14), train_loss = 2.207, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 8946 (epoch 14), train_loss = 2.398, time/batch = 0.025
Read data: 0.0001723766326904297
iter 8947 (epoch 14), train_loss = 2.384, time/batch = 0.029
Read data: 0.00013113021850585938
iter 8948 (epoch 14), train_loss = 2.932, time/batch = 0.029
Read data: 0.00011420249938964844
iter 8949 (epoch 14), train_loss = 2.508, time/batch = 0.024
Read data: 0.00021791458129882812
iter 8950 (epoch 14), train_loss = 2.912, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 8951 (epoch 14), train_loss = 2.436, time/batch = 0.024
Read data: 0.00019812583923339844
iter 8952 (epoch 14), train_loss = 2.917, time/batch = 0.030
Read data: 0.0002002716064453125
iter 8953 (epoch 14), train_loss = 2.703, time/batch = 0.027
Read data: 0.0001308917999267578
iter 8954 (epoch 14), train_loss = 2.966, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 8955 (epoch 14), train_loss = 2.609, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 8956 (epoch 14), train_loss = 2.549, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 8957 (epoch 14), train_loss = 2.571, time/batch = 0.039
Read data: 0.0001666545867919922
iter 8958 (epoch 14), train_loss = 2.802, time/batch = 0.032
Read data: 0.00014281272888183594
iter 8959 (epoch 14), train_loss = 2.741, time/batch = 0.028
Read data: 0.00015282630920410156
iter 8960 (epoch 14), train_loss = 2.535, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 8961 (epoch 14), train_loss = 2.463, time/batch = 0.033
Read data: 8.96453857421875e-05
iter 8962 (epoch 14), train_loss = 2.579, time/batch = 0.026
Read data: 0.0001289844512939453
iter 8963 (epoch 14), train_loss = 2.812, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 8964 (epoch 14), train_loss = 2.398, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 8965 (epoch 14), train_loss = 2.637, time/batch = 0.031
Read data: 0.00015020370483398438
iter 8966 (epoch 14), train_loss = 2.951, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 8967 (epoch 14), train_loss = 2.544, time/batch = 0.031
Read data: 0.0001671314239501953
iter 8968 (epoch 14), train_loss = 2.603, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 8969 (epoch 14), train_loss = 2.539, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 8970 (epoch 14), train_loss = 2.743, time/batch = 0.024
Read data: 0.0001494884490966797
iter 8971 (epoch 14), train_loss = 2.398, time/batch = 0.032
Read data: 9.608268737792969e-05
iter 8972 (epoch 14), train_loss = 2.185, time/batch = 0.024
Read data: 0.00019097328186035156
iter 8973 (epoch 14), train_loss = 2.541, time/batch = 0.024
Read data: 0.00015401840209960938
iter 8974 (epoch 14), train_loss = 2.550, time/batch = 0.033
Read data: 0.00012803077697753906
iter 8975 (epoch 14), train_loss = 2.673, time/batch = 0.025
Read data: 0.00012087821960449219
iter 8976 (epoch 14), train_loss = 2.724, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 8977 (epoch 14), train_loss = 2.499, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 8978 (epoch 14), train_loss = 2.380, time/batch = 0.028
Read data: 0.00012612342834472656
iter 8979 (epoch 14), train_loss = 2.466, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 8980 (epoch 14), train_loss = 2.593, time/batch = 0.022
Read data: 0.00016021728515625
iter 8981 (epoch 14), train_loss = 2.609, time/batch = 0.030
Read data: 0.0001347064971923828
iter 8982 (epoch 14), train_loss = 2.461, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 8983 (epoch 14), train_loss = 2.557, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 8984 (epoch 14), train_loss = 2.536, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 8985 (epoch 14), train_loss = 2.418, time/batch = 0.026
Read data: 0.00015044212341308594
iter 8986 (epoch 14), train_loss = 2.050, time/batch = 0.024
Read data: 0.00012373924255371094
iter 8987 (epoch 14), train_loss = 2.520, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 8988 (epoch 14), train_loss = 2.226, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 8989 (epoch 14), train_loss = 2.954, time/batch = 0.024
Read data: 0.00013375282287597656
iter 8990 (epoch 14), train_loss = 2.320, time/batch = 0.028
Read data: 0.0001239776611328125
iter 8991 (epoch 14), train_loss = 2.267, time/batch = 0.024
Read data: 0.0009696483612060547
iter 8992 (epoch 14), train_loss = 2.583, time/batch = 0.035
Read data: 0.0001399517059326172
iter 8993 (epoch 14), train_loss = 2.782, time/batch = 0.030
Read data: 0.00013375282287597656
iter 8994 (epoch 14), train_loss = 2.628, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 8995 (epoch 14), train_loss = 2.609, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 8996 (epoch 14), train_loss = 2.390, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 8997 (epoch 14), train_loss = 2.897, time/batch = 0.033
Read data: 0.00012612342834472656
iter 8998 (epoch 14), train_loss = 2.722, time/batch = 0.030
Read data: 0.00012969970703125
iter 8999 (epoch 14), train_loss = 2.366, time/batch = 0.030
image 976:    
image 5399:    
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:      
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.667979)
image 2798:     
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:     
image 6767:     
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.277513)
image 6903:      
image 3301:    
image 2019:    
image 5535:     
image 7680:     
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.637155)
image 4604:    
image 5745:     
image 5288:   
image 1562:      
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.905131)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:     
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.550059)
image 4940:      
image 4905:     
image 469:     
image 102:    
image 6009:    UNK
image 4271:     
image 6329:     
image 1729:     
image 4444:     
image 6070:    UNK
evaluating validation preformance... 60/1000 (2.817708)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.606914)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.716674)
image 3276:      
image 3812:     
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:     
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.151406)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:     
image 6612:     
image 7701:     
image 7379:      
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (2.990431)
image 2800:    
image 7249:      
image 3211:     
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.868029)
image 1122:     
image 509:     
image 4091:     
image 5761:     
image 16:     
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.383067)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:      
evaluating validation preformance... 130/1000 (2.922368)
image 6214:     
image 429:     
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:   
image 4450:      
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.724931)
image 1738:     
image 1455:    
image 4198:      
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:    UNK
evaluating validation preformance... 150/1000 (2.954929)
image 1865:      
image 3830:      
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.846147)
image 4297:    
image 3315:     
image 1107:    
image 2051:     
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.633349)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:     
image 3000:    UNK
image 1806:      
image 7761:     
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.685026)
image 2313:    
image 6289:    
image 8084:      
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.521880)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:      
image 6894:     
image 4164:     
image 7049:      
evaluating validation preformance... 200/1000 (2.348285)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:     
image 2844:    
image 4023:     
evaluating validation preformance... 210/1000 (2.481923)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:    
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.600623)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:      
image 6582:     
evaluating validation preformance... 230/1000 (2.316162)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.244374)
image 7143:     
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.605263)
image 3028:     
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.537940)
image 492:    
image 5429:     
image 6968:      
image 2672:      
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.959064)
image 833:     
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:     
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.599378)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.521838)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.189226)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.828390)
image 3553:    
image 5971:     
image 122:     
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.380140)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.755144)
image 5179:    
image 3754:      
image 2911:    UNK
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.487886)
image 4542:      
image 1878:      
image 5329:      
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:     
image 2085:    
evaluating validation preformance... 350/1000 (2.581235)
image 6881:    UNK
image 942:     
image 2775:   
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.064513)
image 2905:    UNK
image 7814:     
image 56:     
image 5034:    
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:      
evaluating validation preformance... 370/1000 (2.606500)
image 4351:      
image 1054:    UNK
image 129:     
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.676596)
image 2458:     
image 1084:      
image 4835:     
image 867:    
image 723:     
image 6255:     
image 5255:    
image 3598:    
image 2997:      
image 60:     
evaluating validation preformance... 390/1000 (2.876893)
image 828:    
image 2733:    
image 791:      
image 5408:    UNK 
image 7842:     
image 1117:      
image 5817:      
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.289199)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:     
image 7546:      
evaluating validation preformance... 410/1000 (2.188358)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:     
image 7864:      
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.345347)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:    
image 6977:     
image 877:   
image 2408:    UNK
image 7706:      
evaluating validation preformance... 430/1000 (2.796334)
image 385:     
image 6938:      
image 2381:    
image 5796:     
image 4010:     
image 3452:    
image 2023:     
image 3052:     
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.929723)
image 1731:     
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:    
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.235544)
image 2241:      
image 2651:    
image 2315:     
image 4784:     
image 5160:      
image 2466:    
image 975:     
image 3818:     
image 6995:     
image 3682:     
evaluating validation preformance... 460/1000 (2.772048)
image 7979:    UNK
image 1618:    UNK
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:     
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.271838)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (2.944224)
image 358:      
image 4663:    
image 5541:    
image 4485:     
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.361553)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.579533)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:     
image 438:      
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.992508)
image 3246:       
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:     
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.705489)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.527706)
image 5619:     UNK
image 4391:    
image 891:     
image 3072:    
image 7781:    
image 6163:      
image 7376:      
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.540622)
image 5292:    
image 2901:    
image 3568:     
image 690:      
image 3345:     
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:      
evaluating validation preformance... 550/1000 (2.651669)
image 5439:     
image 7981:     
image 6012:     
image 4732:     
image 6630:    
image 994:    
image 5079:    UNK
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.618533)
image 6056:     
image 6419:    
image 275:     
image 7441:    UNK 
image 7893:    
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.627827)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:      
image 3267:     
evaluating validation preformance... 580/1000 (2.550048)
image 2135:      
image 3865:     
image 7837:     
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.595484)
image 4420:     
image 1734:      
image 7239:     
image 7447:     
image 8009:     
image 4510:    
image 7495:    
image 2530:      
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.594593)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:     
image 1773:    
image 4823:     
evaluating validation preformance... 610/1000 (2.725335)
image 69:     
image 3465:    
image 6179:     
image 552:     
image 511:     
image 761:    
image 5742:     
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.477842)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.509160)
image 8074:     
image 1904:     
image 7917:      
image 2394:     
image 4406:    UNK
image 883:      
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.533945)
image 5313:      
image 2377:      
image 6058:    
image 4661:     
image 2955:      
image 3333:     
image 7124:     
image 4278:      
image 953:    UNK
image 4037:      
evaluating validation preformance... 650/1000 (2.596604)
image 8065:    
image 3577:    
image 3254:    
image 4562:    
image 5462:      
image 2824:    
image 1639:     
image 1475:     
image 3991:     
image 1023:     
evaluating validation preformance... 660/1000 (2.666765)
image 5701:      
image 1709:    
image 4811:    
image 622:     
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (2.915777)
image 7877:    
image 6761:     
image 6880:    
image 4914:    UNK
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.041569)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (2.915808)
image 6860:     
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:      
image 6225:     
image 3669:     
image 980:     
image 5362:      
evaluating validation preformance... 700/1000 (2.988617)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.551141)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.668458)
image 5729:      
image 6395:      
image 516:    
image 1026:     
image 2972:      
image 3005:    
image 1241:      
image 2743:    
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.342938)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:    
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.503705)
image 2239:     
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:      
image 6197:     
evaluating validation preformance... 750/1000 (2.792591)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.989502)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:     UNK
image 2452:     
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.205730)
image 6220:     
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:     
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.798103)
image 6867:     
image 5525:     
image 4746:    
image 5531:    
image 5425:     
image 6978:     
image 3450:     
image 3312:     
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.228706)
image 5047:    
image 325:     
image 7626:    UNK
image 4552:     
image 983:    UNK
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.310991)
image 7288:     
image 7302:     
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:     
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.463652)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:     
image 4194:    
evaluating validation preformance... 820/1000 (1.991355)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    UNK
image 5514:    UNK
image 7147:    
image 6348:      
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.419018)
image 5107:     
image 3973:    UNK
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.449138)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:     
image 5534:    
evaluating validation preformance... 850/1000 (2.846277)
image 4404:      
image 5501:    
image 5765:     
image 1838:      
image 4354:     
image 336:      
image 3596:      
image 1921:     
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.852676)
image 4254:      
image 6842:     
image 1644:     
image 7371:    
image 4638:     
image 4031:     
image 2702:    UNK
image 4927:      
image 3222:    
image 4002:     
evaluating validation preformance... 870/1000 (2.366652)
image 4934:     
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:      
image 5681:      
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.638326)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.925139)
image 7485:     
image 6102:    
image 1001:    
image 7167:     
image 4168:     
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.533934)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:     
image 7205:      
evaluating validation preformance... 910/1000 (2.260430)
image 1368:     
image 1925:      
image 5870:    
image 4915:    UNK
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.624587)
image 7152:    
image 4559:     
image 7233:    
image 1341:     
image 5337:     
image 3189:      
image 6274:      
image 7102:      
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.517415)
image 5636:      
image 7799:    
image 6025:     
image 6907:      
image 2507:      
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.675238)
image 5860:     
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:      
evaluating validation preformance... 950/1000 (3.027115)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.824080)
image 4935:     
image 1930:      
image 6850:    
image 5310:      
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.392088)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.766248)
image 7352:     
image 5113:     
image 7822:     
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.525252)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:     
image 2483:    
image 2591:     
image 7615:     
evaluating validation preformance... 1000/1000 (2.418426)
average loss on validation: 2.639
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3115229606628418
Cider scores: 0.5058175804189285
Read data: 0.3384678363800049
Cider scores: 0.546197313507927
Read data: 0.2764303684234619
Cider scores: 0.5981751167389016
Read data: 0.23349571228027344
Cider scores: 0.49518533622834343
Read data: 0.21178698539733887
Cider scores: 0.5975413136284125
Read data: 0.17571544647216797
Cider scores: 0.4872010301158547
Read data: 0.198716402053833
Cider scores: 0.5224739911805307
Read data: 0.18165373802185059
Cider scores: 0.5409815195890995
Read data: 0.18020963668823242
Cider scores: 0.494425056366206
Read data: 0.19253873825073242
Cider scores: 0.6515549522928407
Read data: 0.24637794494628906
Cider scores: 0.5701094530876317
Read data: 0.1837902069091797
Cider scores: 0.5996270705876199
Read data: 0.18099594116210938
Cider scores: 0.5252445897818466
Read data: 0.17870426177978516
Cider scores: 0.5735230148771868
Read data: 0.18285036087036133
Cider scores: 0.5675575136808019
Read data: 0.17297029495239258
Cider scores: 0.6036429965277041
Read data: 0.16881608963012695
Cider scores: 0.48655216149358305
Read data: 0.17146086692810059
Cider scores: 0.6408626750061263
Read data: 0.16477632522583008
Cider scores: 0.5389216473618753
Read data: 0.16719317436218262
Cider scores: 0.7055925414770815
Average cider score on test set: 0.563
End calculating cider score on TEST data set
===============================================
Read data: 0.1690988540649414
iter 9000 (epoch 14), train_loss = 2.576, time/batch = 0.024
Read data: 0.00011038780212402344
iter 9001 (epoch 15), train_loss = 2.720, time/batch = 0.027
Read data: 0.000156402587890625
iter 9002 (epoch 15), train_loss = 2.695, time/batch = 0.023
Read data: 0.00014328956604003906
iter 9003 (epoch 15), train_loss = 2.641, time/batch = 0.027
Read data: 0.00011801719665527344
iter 9004 (epoch 15), train_loss = 2.980, time/batch = 0.021
Read data: 0.000217437744140625
iter 9005 (epoch 15), train_loss = 2.335, time/batch = 0.032
Read data: 0.00019073486328125
iter 9006 (epoch 15), train_loss = 2.639, time/batch = 0.031
Read data: 0.00012421607971191406
iter 9007 (epoch 15), train_loss = 2.813, time/batch = 0.025
Read data: 0.00016951560974121094
iter 9008 (epoch 15), train_loss = 2.547, time/batch = 0.033
Read data: 0.00010514259338378906
iter 9009 (epoch 15), train_loss = 2.683, time/batch = 0.030
Read data: 0.00011920928955078125
iter 9010 (epoch 15), train_loss = 2.438, time/batch = 0.035
Read data: 9.131431579589844e-05
iter 9011 (epoch 15), train_loss = 2.606, time/batch = 0.025
Read data: 0.0001647472381591797
iter 9012 (epoch 15), train_loss = 2.730, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 9013 (epoch 15), train_loss = 2.748, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9014 (epoch 15), train_loss = 2.304, time/batch = 0.026
Read data: 9.846687316894531e-05
iter 9015 (epoch 15), train_loss = 2.972, time/batch = 0.035
Read data: 8.249282836914062e-05
iter 9016 (epoch 15), train_loss = 2.623, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 9017 (epoch 15), train_loss = 2.069, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 9018 (epoch 15), train_loss = 2.523, time/batch = 0.023
Read data: 0.00010156631469726562
iter 9019 (epoch 15), train_loss = 2.552, time/batch = 0.031
Read data: 0.000125885009765625
iter 9020 (epoch 15), train_loss = 2.563, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 9021 (epoch 15), train_loss = 2.802, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9022 (epoch 15), train_loss = 3.306, time/batch = 0.030
Read data: 9.942054748535156e-05
iter 9023 (epoch 15), train_loss = 2.561, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 9024 (epoch 15), train_loss = 2.567, time/batch = 0.037
Read data: 0.00025391578674316406
iter 9025 (epoch 15), train_loss = 3.204, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 9026 (epoch 15), train_loss = 2.342, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 9027 (epoch 15), train_loss = 2.788, time/batch = 0.030
Read data: 0.00010514259338378906
iter 9028 (epoch 15), train_loss = 2.826, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 9029 (epoch 15), train_loss = 2.793, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 9030 (epoch 15), train_loss = 2.623, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 9031 (epoch 15), train_loss = 2.639, time/batch = 0.024
Read data: 0.00016069412231445312
iter 9032 (epoch 15), train_loss = 2.761, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 9033 (epoch 15), train_loss = 2.273, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9034 (epoch 15), train_loss = 2.727, time/batch = 0.029
Read data: 9.822845458984375e-05
iter 9035 (epoch 15), train_loss = 2.688, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 9036 (epoch 15), train_loss = 2.627, time/batch = 0.031
Read data: 0.00012230873107910156
iter 9037 (epoch 15), train_loss = 2.596, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 9038 (epoch 15), train_loss = 2.875, time/batch = 0.026
Read data: 0.00012922286987304688
iter 9039 (epoch 15), train_loss = 3.048, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 9040 (epoch 15), train_loss = 2.343, time/batch = 0.037
Read data: 0.00014472007751464844
iter 9041 (epoch 15), train_loss = 2.851, time/batch = 0.030
Read data: 8.702278137207031e-05
iter 9042 (epoch 15), train_loss = 2.419, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 9043 (epoch 15), train_loss = 2.885, time/batch = 0.027
Read data: 0.0001342296600341797
iter 9044 (epoch 15), train_loss = 2.017, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 9045 (epoch 15), train_loss = 2.374, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 9046 (epoch 15), train_loss = 3.190, time/batch = 0.038
Read data: 8.20159912109375e-05
iter 9047 (epoch 15), train_loss = 2.794, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 9048 (epoch 15), train_loss = 2.883, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 9049 (epoch 15), train_loss = 2.670, time/batch = 0.024
Read data: 0.00021409988403320312
iter 9050 (epoch 15), train_loss = 2.323, time/batch = 0.028
Read data: 9.489059448242188e-05
iter 9051 (epoch 15), train_loss = 2.639, time/batch = 0.031
Read data: 0.00013113021850585938
iter 9052 (epoch 15), train_loss = 2.593, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 9053 (epoch 15), train_loss = 2.601, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 9054 (epoch 15), train_loss = 2.418, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 9055 (epoch 15), train_loss = 2.340, time/batch = 0.035
Read data: 0.00016260147094726562
iter 9056 (epoch 15), train_loss = 2.666, time/batch = 0.029
Read data: 8.869171142578125e-05
iter 9057 (epoch 15), train_loss = 2.803, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 9058 (epoch 15), train_loss = 2.743, time/batch = 0.023
Read data: 8.392333984375e-05
iter 9059 (epoch 15), train_loss = 2.537, time/batch = 0.030
Read data: 0.00013685226440429688
iter 9060 (epoch 15), train_loss = 2.738, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 9061 (epoch 15), train_loss = 2.954, time/batch = 0.039
Read data: 0.00012993812561035156
iter 9062 (epoch 15), train_loss = 2.695, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 9063 (epoch 15), train_loss = 2.998, time/batch = 0.030
Read data: 8.893013000488281e-05
iter 9064 (epoch 15), train_loss = 2.464, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 9065 (epoch 15), train_loss = 2.290, time/batch = 0.032
Read data: 0.00014281272888183594
iter 9066 (epoch 15), train_loss = 2.761, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 9067 (epoch 15), train_loss = 2.850, time/batch = 0.024
Read data: 8.392333984375e-05
iter 9068 (epoch 15), train_loss = 2.608, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 9069 (epoch 15), train_loss = 2.550, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 9070 (epoch 15), train_loss = 2.581, time/batch = 0.031
Read data: 9.608268737792969e-05
iter 9071 (epoch 15), train_loss = 2.382, time/batch = 0.028
Read data: 0.0001289844512939453
iter 9072 (epoch 15), train_loss = 3.193, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 9073 (epoch 15), train_loss = 2.554, time/batch = 0.040
Read data: 8.893013000488281e-05
iter 9074 (epoch 15), train_loss = 2.539, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 9075 (epoch 15), train_loss = 2.758, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 9076 (epoch 15), train_loss = 2.436, time/batch = 0.026
Read data: 8.392333984375e-05
iter 9077 (epoch 15), train_loss = 2.707, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 9078 (epoch 15), train_loss = 2.655, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 9079 (epoch 15), train_loss = 2.380, time/batch = 0.028
Read data: 0.00015354156494140625
iter 9080 (epoch 15), train_loss = 2.596, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 9081 (epoch 15), train_loss = 2.990, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 9082 (epoch 15), train_loss = 2.415, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 9083 (epoch 15), train_loss = 2.384, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 9084 (epoch 15), train_loss = 2.372, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 9085 (epoch 15), train_loss = 2.884, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9086 (epoch 15), train_loss = 2.516, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 9087 (epoch 15), train_loss = 2.660, time/batch = 0.033
Read data: 0.00019741058349609375
iter 9088 (epoch 15), train_loss = 2.544, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 9089 (epoch 15), train_loss = 2.628, time/batch = 0.030
Read data: 9.012222290039062e-05
iter 9090 (epoch 15), train_loss = 2.942, time/batch = 0.036
Read data: 9.1552734375e-05
iter 9091 (epoch 15), train_loss = 2.672, time/batch = 0.025
Read data: 0.00011515617370605469
iter 9092 (epoch 15), train_loss = 2.839, time/batch = 0.026
Read data: 0.00016069412231445312
iter 9093 (epoch 15), train_loss = 2.886, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 9094 (epoch 15), train_loss = 2.856, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 9095 (epoch 15), train_loss = 2.663, time/batch = 0.027
Read data: 8.392333984375e-05
iter 9096 (epoch 15), train_loss = 2.760, time/batch = 0.023
Read data: 8.392333984375e-05
iter 9097 (epoch 15), train_loss = 3.017, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 9098 (epoch 15), train_loss = 2.962, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 9099 (epoch 15), train_loss = 2.806, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 9100 (epoch 15), train_loss = 2.706, time/batch = 0.021
Read data: 8.392333984375e-05
iter 9101 (epoch 15), train_loss = 2.696, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 9102 (epoch 15), train_loss = 2.564, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 9103 (epoch 15), train_loss = 2.242, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 9104 (epoch 15), train_loss = 2.521, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 9105 (epoch 15), train_loss = 2.864, time/batch = 0.031
Read data: 8.392333984375e-05
iter 9106 (epoch 15), train_loss = 2.829, time/batch = 0.035
Read data: 8.96453857421875e-05
iter 9107 (epoch 15), train_loss = 3.120, time/batch = 0.037
Read data: 8.153915405273438e-05
iter 9108 (epoch 15), train_loss = 2.617, time/batch = 0.028
Read data: 9.393692016601562e-05
iter 9109 (epoch 15), train_loss = 2.839, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 9110 (epoch 15), train_loss = 2.890, time/batch = 0.031
Read data: 8.96453857421875e-05
iter 9111 (epoch 15), train_loss = 2.703, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 9112 (epoch 15), train_loss = 2.309, time/batch = 0.042
Read data: 7.843971252441406e-05
iter 9113 (epoch 15), train_loss = 2.495, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 9114 (epoch 15), train_loss = 2.564, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 9115 (epoch 15), train_loss = 2.736, time/batch = 0.029
Read data: 0.00016808509826660156
iter 9116 (epoch 15), train_loss = 2.987, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 9117 (epoch 15), train_loss = 2.637, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9118 (epoch 15), train_loss = 2.459, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 9119 (epoch 15), train_loss = 2.792, time/batch = 0.031
Read data: 0.0001010894775390625
iter 9120 (epoch 15), train_loss = 2.874, time/batch = 0.030
Read data: 0.00014591217041015625
iter 9121 (epoch 15), train_loss = 2.585, time/batch = 0.034
Read data: 0.0001461505889892578
iter 9122 (epoch 15), train_loss = 2.139, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 9123 (epoch 15), train_loss = 2.768, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 9124 (epoch 15), train_loss = 2.569, time/batch = 0.026
Read data: 0.00021386146545410156
iter 9125 (epoch 15), train_loss = 2.529, time/batch = 0.026
Read data: 0.00014448165893554688
iter 9126 (epoch 15), train_loss = 2.531, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 9127 (epoch 15), train_loss = 2.272, time/batch = 0.030
Read data: 0.000133514404296875
iter 9128 (epoch 15), train_loss = 2.848, time/batch = 0.026
Read data: 0.00012683868408203125
iter 9129 (epoch 15), train_loss = 2.666, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 9130 (epoch 15), train_loss = 2.884, time/batch = 0.032
Read data: 0.00011706352233886719
iter 9131 (epoch 15), train_loss = 2.635, time/batch = 0.040
Read data: 9.918212890625e-05
iter 9132 (epoch 15), train_loss = 2.512, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 9133 (epoch 15), train_loss = 2.453, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 9134 (epoch 15), train_loss = 2.471, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 9135 (epoch 15), train_loss = 2.843, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 9136 (epoch 15), train_loss = 2.438, time/batch = 0.029
Read data: 0.0001323223114013672
iter 9137 (epoch 15), train_loss = 2.334, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 9138 (epoch 15), train_loss = 2.239, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 9139 (epoch 15), train_loss = 2.378, time/batch = 0.026
Read data: 0.00013971328735351562
iter 9140 (epoch 15), train_loss = 2.658, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 9141 (epoch 15), train_loss = 2.432, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 9142 (epoch 15), train_loss = 2.682, time/batch = 0.029
Read data: 9.870529174804688e-05
iter 9143 (epoch 15), train_loss = 2.483, time/batch = 0.030
Read data: 0.0001342296600341797
iter 9144 (epoch 15), train_loss = 2.693, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9145 (epoch 15), train_loss = 2.655, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 9146 (epoch 15), train_loss = 2.726, time/batch = 0.028
Read data: 0.00011849403381347656
iter 9147 (epoch 15), train_loss = 2.430, time/batch = 0.027
Read data: 0.00013113021850585938
iter 9148 (epoch 15), train_loss = 2.659, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 9149 (epoch 15), train_loss = 2.538, time/batch = 0.030
Read data: 0.0002129077911376953
iter 9150 (epoch 15), train_loss = 2.738, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 9151 (epoch 15), train_loss = 2.499, time/batch = 0.024
Read data: 0.00013065338134765625
iter 9152 (epoch 15), train_loss = 3.065, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 9153 (epoch 15), train_loss = 2.707, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 9154 (epoch 15), train_loss = 2.987, time/batch = 0.031
Read data: 9.393692016601562e-05
iter 9155 (epoch 15), train_loss = 2.460, time/batch = 0.035
Read data: 0.00013518333435058594
iter 9156 (epoch 15), train_loss = 2.914, time/batch = 0.033
Read data: 9.107589721679688e-05
iter 9157 (epoch 15), train_loss = 2.654, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 9158 (epoch 15), train_loss = 2.686, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 9159 (epoch 15), train_loss = 2.621, time/batch = 0.034
Read data: 8.988380432128906e-05
iter 9160 (epoch 15), train_loss = 2.236, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 9161 (epoch 15), train_loss = 2.442, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 9162 (epoch 15), train_loss = 2.584, time/batch = 0.021
Read data: 8.320808410644531e-05
iter 9163 (epoch 15), train_loss = 2.916, time/batch = 0.042
Read data: 8.702278137207031e-05
iter 9164 (epoch 15), train_loss = 2.631, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 9165 (epoch 15), train_loss = 2.908, time/batch = 0.033
Read data: 0.0016062259674072266
iter 9166 (epoch 15), train_loss = 2.679, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 9167 (epoch 15), train_loss = 2.807, time/batch = 0.027
Read data: 0.00014710426330566406
iter 9168 (epoch 15), train_loss = 2.793, time/batch = 0.034
Read data: 0.00013566017150878906
iter 9169 (epoch 15), train_loss = 2.964, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9170 (epoch 15), train_loss = 3.005, time/batch = 0.037
Read data: 8.702278137207031e-05
iter 9171 (epoch 15), train_loss = 2.577, time/batch = 0.032
Read data: 8.7738037109375e-05
iter 9172 (epoch 15), train_loss = 3.138, time/batch = 0.034
Read data: 7.915496826171875e-05
iter 9173 (epoch 15), train_loss = 2.163, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 9174 (epoch 15), train_loss = 2.816, time/batch = 0.029
Read data: 0.0002675056457519531
iter 9175 (epoch 15), train_loss = 3.110, time/batch = 0.028
Read data: 0.000133514404296875
iter 9176 (epoch 15), train_loss = 2.831, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 9177 (epoch 15), train_loss = 2.709, time/batch = 0.024
Read data: 8.392333984375e-05
iter 9178 (epoch 15), train_loss = 2.334, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 9179 (epoch 15), train_loss = 2.890, time/batch = 0.035
Read data: 8.487701416015625e-05
iter 9180 (epoch 15), train_loss = 2.914, time/batch = 0.031
Read data: 8.392333984375e-05
iter 9181 (epoch 15), train_loss = 3.120, time/batch = 0.034
Read data: 8.940696716308594e-05
iter 9182 (epoch 15), train_loss = 2.662, time/batch = 0.023
Read data: 0.00010251998901367188
iter 9183 (epoch 15), train_loss = 2.913, time/batch = 0.037
Read data: 9.107589721679688e-05
iter 9184 (epoch 15), train_loss = 2.458, time/batch = 0.034
Read data: 9.012222290039062e-05
iter 9185 (epoch 15), train_loss = 2.638, time/batch = 0.030
Read data: 8.869171142578125e-05
iter 9186 (epoch 15), train_loss = 2.691, time/batch = 0.035
Read data: 9.465217590332031e-05
iter 9187 (epoch 15), train_loss = 2.291, time/batch = 0.031
Read data: 9.036064147949219e-05
iter 9188 (epoch 15), train_loss = 2.555, time/batch = 0.037
Read data: 8.153915405273438e-05
iter 9189 (epoch 15), train_loss = 2.900, time/batch = 0.035
Read data: 9.298324584960938e-05
iter 9190 (epoch 15), train_loss = 2.776, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 9191 (epoch 15), train_loss = 2.562, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 9192 (epoch 15), train_loss = 2.851, time/batch = 0.029
Read data: 8.392333984375e-05
iter 9193 (epoch 15), train_loss = 3.161, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 9194 (epoch 15), train_loss = 2.750, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 9195 (epoch 15), train_loss = 2.781, time/batch = 0.037
Read data: 8.821487426757812e-05
iter 9196 (epoch 15), train_loss = 2.117, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 9197 (epoch 15), train_loss = 3.066, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 9198 (epoch 15), train_loss = 2.433, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 9199 (epoch 15), train_loss = 2.725, time/batch = 0.026
Read data: 0.00012373924255371094
iter 9200 (epoch 15), train_loss = 2.540, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 9201 (epoch 15), train_loss = 2.841, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 9202 (epoch 15), train_loss = 2.574, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9203 (epoch 15), train_loss = 2.515, time/batch = 0.033
Read data: 9.036064147949219e-05
iter 9204 (epoch 15), train_loss = 2.042, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 9205 (epoch 15), train_loss = 2.703, time/batch = 0.036
Read data: 8.535385131835938e-05
iter 9206 (epoch 15), train_loss = 2.789, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 9207 (epoch 15), train_loss = 2.472, time/batch = 0.024
Read data: 0.0001277923583984375
iter 9208 (epoch 15), train_loss = 2.286, time/batch = 0.031
Read data: 9.059906005859375e-05
iter 9209 (epoch 15), train_loss = 3.062, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9210 (epoch 15), train_loss = 2.951, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 9211 (epoch 15), train_loss = 2.285, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 9212 (epoch 15), train_loss = 2.335, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9213 (epoch 15), train_loss = 2.913, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 9214 (epoch 15), train_loss = 2.988, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 9215 (epoch 15), train_loss = 2.431, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 9216 (epoch 15), train_loss = 2.937, time/batch = 0.030
Read data: 8.678436279296875e-05
iter 9217 (epoch 15), train_loss = 2.516, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 9218 (epoch 15), train_loss = 2.804, time/batch = 0.025
Read data: 0.00011444091796875
iter 9219 (epoch 15), train_loss = 2.611, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 9220 (epoch 15), train_loss = 2.645, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9221 (epoch 15), train_loss = 2.347, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 9222 (epoch 15), train_loss = 2.757, time/batch = 0.028
Read data: 0.00014209747314453125
iter 9223 (epoch 15), train_loss = 2.435, time/batch = 0.029
Read data: 0.00013136863708496094
iter 9224 (epoch 15), train_loss = 2.259, time/batch = 0.028
Read data: 0.00021314620971679688
iter 9225 (epoch 15), train_loss = 2.342, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 9226 (epoch 15), train_loss = 2.660, time/batch = 0.027
Read data: 0.00011205673217773438
iter 9227 (epoch 15), train_loss = 2.696, time/batch = 0.044
Read data: 0.00010132789611816406
iter 9228 (epoch 15), train_loss = 2.476, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 9229 (epoch 15), train_loss = 2.705, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 9230 (epoch 15), train_loss = 2.414, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 9231 (epoch 15), train_loss = 2.660, time/batch = 0.037
Read data: 9.059906005859375e-05
iter 9232 (epoch 15), train_loss = 2.811, time/batch = 0.034
Read data: 0.00014781951904296875
iter 9233 (epoch 15), train_loss = 2.596, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 9234 (epoch 15), train_loss = 2.865, time/batch = 0.027
Read data: 0.00010752677917480469
iter 9235 (epoch 15), train_loss = 2.653, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 9236 (epoch 15), train_loss = 2.789, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 9237 (epoch 15), train_loss = 2.678, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 9238 (epoch 15), train_loss = 2.958, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 9239 (epoch 15), train_loss = 2.812, time/batch = 0.029
Read data: 8.988380432128906e-05
iter 9240 (epoch 15), train_loss = 2.517, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 9241 (epoch 15), train_loss = 2.483, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 9242 (epoch 15), train_loss = 2.484, time/batch = 0.023
Read data: 0.0001392364501953125
iter 9243 (epoch 15), train_loss = 2.846, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 9244 (epoch 15), train_loss = 2.735, time/batch = 0.027
Read data: 0.00010824203491210938
iter 9245 (epoch 15), train_loss = 2.529, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 9246 (epoch 15), train_loss = 2.593, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 9247 (epoch 15), train_loss = 2.653, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 9248 (epoch 15), train_loss = 2.797, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 9249 (epoch 15), train_loss = 2.468, time/batch = 0.025
Read data: 0.0003101825714111328
iter 9250 (epoch 15), train_loss = 2.421, time/batch = 0.024
Read data: 0.0001010894775390625
iter 9251 (epoch 15), train_loss = 2.849, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 9252 (epoch 15), train_loss = 2.664, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 9253 (epoch 15), train_loss = 2.241, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 9254 (epoch 15), train_loss = 2.503, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 9255 (epoch 15), train_loss = 2.731, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 9256 (epoch 15), train_loss = 2.727, time/batch = 0.025
Read data: 0.00011539459228515625
iter 9257 (epoch 15), train_loss = 2.805, time/batch = 0.032
Read data: 8.392333984375e-05
iter 9258 (epoch 15), train_loss = 2.505, time/batch = 0.035
Read data: 8.7738037109375e-05
iter 9259 (epoch 15), train_loss = 2.810, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 9260 (epoch 15), train_loss = 2.411, time/batch = 0.025
Read data: 0.0001220703125
iter 9261 (epoch 15), train_loss = 2.536, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9262 (epoch 15), train_loss = 2.238, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 9263 (epoch 15), train_loss = 2.654, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9264 (epoch 15), train_loss = 2.592, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 9265 (epoch 15), train_loss = 2.913, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 9266 (epoch 15), train_loss = 2.708, time/batch = 0.031
Read data: 9.5367431640625e-05
iter 9267 (epoch 15), train_loss = 2.821, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 9268 (epoch 15), train_loss = 2.963, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 9269 (epoch 15), train_loss = 2.780, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 9270 (epoch 15), train_loss = 2.126, time/batch = 0.030
Read data: 0.00012111663818359375
iter 9271 (epoch 15), train_loss = 2.604, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 9272 (epoch 15), train_loss = 3.131, time/batch = 0.031
Read data: 0.00013780593872070312
iter 9273 (epoch 15), train_loss = 2.814, time/batch = 0.039
Read data: 8.0108642578125e-05
iter 9274 (epoch 15), train_loss = 2.931, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 9275 (epoch 15), train_loss = 2.501, time/batch = 0.029
Read data: 0.0001418590545654297
iter 9276 (epoch 15), train_loss = 2.487, time/batch = 0.025
Read data: 0.0001556873321533203
iter 9277 (epoch 15), train_loss = 2.565, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 9278 (epoch 15), train_loss = 2.284, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 9279 (epoch 15), train_loss = 2.996, time/batch = 0.031
Read data: 0.0002300739288330078
iter 9280 (epoch 15), train_loss = 2.481, time/batch = 0.020
Read data: 9.72747802734375e-05
iter 9281 (epoch 15), train_loss = 2.730, time/batch = 0.038
Read data: 0.0001289844512939453
iter 9282 (epoch 15), train_loss = 2.728, time/batch = 0.030
Read data: 0.00011587142944335938
iter 9283 (epoch 15), train_loss = 2.391, time/batch = 0.026
Read data: 0.00014400482177734375
iter 9284 (epoch 15), train_loss = 2.649, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 9285 (epoch 15), train_loss = 2.826, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 9286 (epoch 15), train_loss = 2.972, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 9287 (epoch 15), train_loss = 2.087, time/batch = 0.024
Read data: 0.0001270771026611328
iter 9288 (epoch 15), train_loss = 2.294, time/batch = 0.026
Read data: 0.00014090538024902344
iter 9289 (epoch 15), train_loss = 2.711, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 9290 (epoch 15), train_loss = 2.560, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 9291 (epoch 15), train_loss = 2.593, time/batch = 0.024
Read data: 0.00013184547424316406
iter 9292 (epoch 15), train_loss = 2.525, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 9293 (epoch 15), train_loss = 2.985, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 9294 (epoch 15), train_loss = 2.454, time/batch = 0.026
Read data: 0.0001366138458251953
iter 9295 (epoch 15), train_loss = 2.723, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 9296 (epoch 15), train_loss = 2.384, time/batch = 0.021
Read data: 0.00010228157043457031
iter 9297 (epoch 15), train_loss = 2.311, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 9298 (epoch 15), train_loss = 2.395, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 9299 (epoch 15), train_loss = 2.800, time/batch = 0.028
Read data: 0.0003039836883544922
iter 9300 (epoch 15), train_loss = 2.345, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 9301 (epoch 15), train_loss = 2.805, time/batch = 0.035
Read data: 0.00013136863708496094
iter 9302 (epoch 15), train_loss = 2.538, time/batch = 0.033
Read data: 9.489059448242188e-05
iter 9303 (epoch 15), train_loss = 3.012, time/batch = 0.026
Read data: 0.00013756752014160156
iter 9304 (epoch 15), train_loss = 2.840, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 9305 (epoch 15), train_loss = 2.419, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 9306 (epoch 15), train_loss = 2.501, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 9307 (epoch 15), train_loss = 2.315, time/batch = 0.037
Read data: 8.702278137207031e-05
iter 9308 (epoch 15), train_loss = 2.081, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 9309 (epoch 15), train_loss = 3.027, time/batch = 0.032
Read data: 8.797645568847656e-05
iter 9310 (epoch 15), train_loss = 2.614, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 9311 (epoch 15), train_loss = 2.269, time/batch = 0.030
Read data: 0.00013971328735351562
iter 9312 (epoch 15), train_loss = 2.121, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 9313 (epoch 15), train_loss = 2.536, time/batch = 0.028
Read data: 0.0002167224884033203
iter 9314 (epoch 15), train_loss = 2.293, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9315 (epoch 15), train_loss = 2.702, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 9316 (epoch 15), train_loss = 2.751, time/batch = 0.035
Read data: 8.7738037109375e-05
iter 9317 (epoch 15), train_loss = 2.562, time/batch = 0.031
Read data: 9.417533874511719e-05
iter 9318 (epoch 15), train_loss = 2.799, time/batch = 0.031
Read data: 8.940696716308594e-05
iter 9319 (epoch 15), train_loss = 2.428, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 9320 (epoch 15), train_loss = 2.828, time/batch = 0.027
Read data: 0.00016832351684570312
iter 9321 (epoch 15), train_loss = 2.493, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 9322 (epoch 15), train_loss = 2.915, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 9323 (epoch 15), train_loss = 2.202, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 9324 (epoch 15), train_loss = 2.236, time/batch = 0.031
Read data: 0.0002636909484863281
iter 9325 (epoch 15), train_loss = 2.582, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 9326 (epoch 15), train_loss = 2.557, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 9327 (epoch 15), train_loss = 2.454, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 9328 (epoch 15), train_loss = 2.353, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 9329 (epoch 15), train_loss = 2.659, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 9330 (epoch 15), train_loss = 2.631, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 9331 (epoch 15), train_loss = 2.578, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 9332 (epoch 15), train_loss = 2.609, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 9333 (epoch 15), train_loss = 2.982, time/batch = 0.039
Read data: 8.821487426757812e-05
iter 9334 (epoch 15), train_loss = 2.369, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 9335 (epoch 15), train_loss = 2.457, time/batch = 0.032
Read data: 0.00013446807861328125
iter 9336 (epoch 15), train_loss = 2.731, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 9337 (epoch 15), train_loss = 2.973, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 9338 (epoch 15), train_loss = 3.202, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9339 (epoch 15), train_loss = 2.569, time/batch = 0.035
Read data: 8.511543273925781e-05
iter 9340 (epoch 15), train_loss = 2.758, time/batch = 0.031
Read data: 9.298324584960938e-05
iter 9341 (epoch 15), train_loss = 2.907, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 9342 (epoch 15), train_loss = 2.668, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 9343 (epoch 15), train_loss = 2.396, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 9344 (epoch 15), train_loss = 2.505, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 9345 (epoch 15), train_loss = 3.271, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9346 (epoch 15), train_loss = 2.648, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9347 (epoch 15), train_loss = 2.750, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 9348 (epoch 15), train_loss = 3.000, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 9349 (epoch 15), train_loss = 2.445, time/batch = 0.026
Read data: 0.0002117156982421875
iter 9350 (epoch 15), train_loss = 2.688, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 9351 (epoch 15), train_loss = 2.127, time/batch = 0.026
Read data: 8.392333984375e-05
iter 9352 (epoch 15), train_loss = 2.491, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 9353 (epoch 15), train_loss = 2.972, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 9354 (epoch 15), train_loss = 2.729, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 9355 (epoch 15), train_loss = 2.839, time/batch = 0.041
Read data: 8.416175842285156e-05
iter 9356 (epoch 15), train_loss = 2.915, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 9357 (epoch 15), train_loss = 2.348, time/batch = 0.032
Read data: 9.202957153320312e-05
iter 9358 (epoch 15), train_loss = 2.904, time/batch = 0.045
Read data: 7.581710815429688e-05
iter 9359 (epoch 15), train_loss = 2.779, time/batch = 0.033
Read data: 9.417533874511719e-05
iter 9360 (epoch 15), train_loss = 2.432, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 9361 (epoch 15), train_loss = 2.859, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 9362 (epoch 15), train_loss = 2.881, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 9363 (epoch 15), train_loss = 2.920, time/batch = 0.032
Read data: 8.559226989746094e-05
iter 9364 (epoch 15), train_loss = 2.672, time/batch = 0.027
Read data: 0.0001270771026611328
iter 9365 (epoch 15), train_loss = 2.700, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 9366 (epoch 15), train_loss = 2.735, time/batch = 0.037
Read data: 8.726119995117188e-05
iter 9367 (epoch 15), train_loss = 2.837, time/batch = 0.032
Read data: 0.0001614093780517578
iter 9368 (epoch 15), train_loss = 2.621, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 9369 (epoch 15), train_loss = 2.406, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 9370 (epoch 15), train_loss = 2.436, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 9371 (epoch 15), train_loss = 2.954, time/batch = 0.026
Read data: 0.00017786026000976562
iter 9372 (epoch 15), train_loss = 2.756, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 9373 (epoch 15), train_loss = 2.591, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 9374 (epoch 15), train_loss = 2.667, time/batch = 0.047
Read data: 7.510185241699219e-05
iter 9375 (epoch 15), train_loss = 2.654, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 9376 (epoch 15), train_loss = 3.293, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 9377 (epoch 15), train_loss = 2.428, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 9378 (epoch 15), train_loss = 2.538, time/batch = 0.033
Read data: 8.96453857421875e-05
iter 9379 (epoch 15), train_loss = 2.792, time/batch = 0.029
Read data: 8.726119995117188e-05
iter 9380 (epoch 15), train_loss = 2.818, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 9381 (epoch 15), train_loss = 2.825, time/batch = 0.044
Read data: 8.654594421386719e-05
iter 9382 (epoch 15), train_loss = 2.239, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 9383 (epoch 15), train_loss = 2.727, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 9384 (epoch 15), train_loss = 2.223, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 9385 (epoch 15), train_loss = 2.289, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 9386 (epoch 15), train_loss = 2.634, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 9387 (epoch 15), train_loss = 2.693, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 9388 (epoch 15), train_loss = 2.254, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 9389 (epoch 15), train_loss = 2.599, time/batch = 0.032
Read data: 9.393692016601562e-05
iter 9390 (epoch 15), train_loss = 2.284, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 9391 (epoch 15), train_loss = 2.456, time/batch = 0.033
Read data: 0.00018787384033203125
iter 9392 (epoch 15), train_loss = 2.394, time/batch = 0.027
Read data: 0.0001232624053955078
iter 9393 (epoch 15), train_loss = 2.632, time/batch = 0.032
Read data: 0.00013566017150878906
iter 9394 (epoch 15), train_loss = 2.497, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 9395 (epoch 15), train_loss = 2.448, time/batch = 0.026
Read data: 0.00013637542724609375
iter 9396 (epoch 15), train_loss = 2.204, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 9397 (epoch 15), train_loss = 2.459, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 9398 (epoch 15), train_loss = 2.768, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 9399 (epoch 15), train_loss = 2.847, time/batch = 0.030
Read data: 0.00022077560424804688
iter 9400 (epoch 15), train_loss = 3.064, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 9401 (epoch 15), train_loss = 3.138, time/batch = 0.033
Read data: 8.940696716308594e-05
iter 9402 (epoch 15), train_loss = 2.275, time/batch = 0.028
Read data: 0.00015473365783691406
iter 9403 (epoch 15), train_loss = 2.688, time/batch = 0.032
Read data: 0.00011348724365234375
iter 9404 (epoch 15), train_loss = 2.348, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 9405 (epoch 15), train_loss = 2.489, time/batch = 0.027
Read data: 0.00014209747314453125
iter 9406 (epoch 15), train_loss = 2.527, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 9407 (epoch 15), train_loss = 2.564, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 9408 (epoch 15), train_loss = 2.462, time/batch = 0.035
Read data: 8.749961853027344e-05
iter 9409 (epoch 15), train_loss = 2.828, time/batch = 0.033
Read data: 0.0001201629638671875
iter 9410 (epoch 15), train_loss = 2.135, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 9411 (epoch 15), train_loss = 2.173, time/batch = 0.025
Read data: 0.0001671314239501953
iter 9412 (epoch 15), train_loss = 2.390, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 9413 (epoch 15), train_loss = 2.695, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 9414 (epoch 15), train_loss = 2.839, time/batch = 0.033
Read data: 0.0001323223114013672
iter 9415 (epoch 15), train_loss = 2.583, time/batch = 0.028
Read data: 0.00017189979553222656
iter 9416 (epoch 15), train_loss = 2.619, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 9417 (epoch 15), train_loss = 2.646, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9418 (epoch 15), train_loss = 2.881, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 9419 (epoch 15), train_loss = 2.572, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 9420 (epoch 15), train_loss = 2.636, time/batch = 0.022
Read data: 9.489059448242188e-05
iter 9421 (epoch 15), train_loss = 2.942, time/batch = 0.035
Read data: 0.00010657310485839844
iter 9422 (epoch 15), train_loss = 2.693, time/batch = 0.030
Read data: 0.00014519691467285156
iter 9423 (epoch 15), train_loss = 2.378, time/batch = 0.030
Read data: 0.0001659393310546875
iter 9424 (epoch 15), train_loss = 2.314, time/batch = 0.022
Read data: 0.0002493858337402344
iter 9425 (epoch 15), train_loss = 2.567, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 9426 (epoch 15), train_loss = 2.223, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 9427 (epoch 15), train_loss = 2.926, time/batch = 0.028
Read data: 0.00014281272888183594
iter 9428 (epoch 15), train_loss = 2.491, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 9429 (epoch 15), train_loss = 2.769, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 9430 (epoch 15), train_loss = 2.374, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9431 (epoch 15), train_loss = 2.827, time/batch = 0.030
Read data: 0.00013446807861328125
iter 9432 (epoch 15), train_loss = 2.642, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 9433 (epoch 15), train_loss = 2.802, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 9434 (epoch 15), train_loss = 2.740, time/batch = 0.044
Read data: 8.916854858398438e-05
iter 9435 (epoch 15), train_loss = 2.694, time/batch = 0.025
Read data: 0.00013446807861328125
iter 9436 (epoch 15), train_loss = 2.798, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 9437 (epoch 15), train_loss = 2.649, time/batch = 0.034
Read data: 8.58306884765625e-05
iter 9438 (epoch 15), train_loss = 2.914, time/batch = 0.042
Read data: 7.772445678710938e-05
iter 9439 (epoch 15), train_loss = 2.804, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 9440 (epoch 15), train_loss = 2.419, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 9441 (epoch 15), train_loss = 2.984, time/batch = 0.029
Read data: 8.916854858398438e-05
iter 9442 (epoch 15), train_loss = 2.430, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9443 (epoch 15), train_loss = 2.982, time/batch = 0.037
Read data: 0.0001266002655029297
iter 9444 (epoch 15), train_loss = 3.279, time/batch = 0.027
Read data: 9.417533874511719e-05
iter 9445 (epoch 15), train_loss = 2.304, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 9446 (epoch 15), train_loss = 3.049, time/batch = 0.034
Read data: 8.58306884765625e-05
iter 9447 (epoch 15), train_loss = 3.040, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 9448 (epoch 15), train_loss = 2.462, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 9449 (epoch 15), train_loss = 2.930, time/batch = 0.025
Read data: 0.00021409988403320312
iter 9450 (epoch 15), train_loss = 2.482, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 9451 (epoch 15), train_loss = 2.639, time/batch = 0.028
Read data: 0.0001251697540283203
iter 9452 (epoch 15), train_loss = 2.497, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 9453 (epoch 15), train_loss = 3.073, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 9454 (epoch 15), train_loss = 2.407, time/batch = 0.031
Read data: 8.392333984375e-05
iter 9455 (epoch 15), train_loss = 2.601, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 9456 (epoch 15), train_loss = 2.225, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 9457 (epoch 15), train_loss = 3.226, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 9458 (epoch 15), train_loss = 2.612, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 9459 (epoch 15), train_loss = 2.432, time/batch = 0.033
Read data: 8.416175842285156e-05
iter 9460 (epoch 15), train_loss = 2.943, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 9461 (epoch 15), train_loss = 2.809, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 9462 (epoch 15), train_loss = 2.674, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 9463 (epoch 15), train_loss = 2.874, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 9464 (epoch 15), train_loss = 2.482, time/batch = 0.025
Read data: 0.00011134147644042969
iter 9465 (epoch 15), train_loss = 2.736, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 9466 (epoch 15), train_loss = 2.623, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 9467 (epoch 15), train_loss = 2.445, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9468 (epoch 15), train_loss = 2.411, time/batch = 0.025
Read data: 0.0001590251922607422
iter 9469 (epoch 15), train_loss = 2.643, time/batch = 0.039
Read data: 8.797645568847656e-05
iter 9470 (epoch 15), train_loss = 3.230, time/batch = 0.039
Read data: 7.772445678710938e-05
iter 9471 (epoch 15), train_loss = 2.092, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 9472 (epoch 15), train_loss = 2.580, time/batch = 0.026
Read data: 0.0001232624053955078
iter 9473 (epoch 15), train_loss = 2.576, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 9474 (epoch 15), train_loss = 2.263, time/batch = 0.033
Read data: 0.00024175643920898438
iter 9475 (epoch 15), train_loss = 2.886, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 9476 (epoch 15), train_loss = 2.409, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 9477 (epoch 15), train_loss = 2.056, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 9478 (epoch 15), train_loss = 2.942, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 9479 (epoch 15), train_loss = 3.028, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 9480 (epoch 15), train_loss = 2.772, time/batch = 0.021
Read data: 9.298324584960938e-05
iter 9481 (epoch 15), train_loss = 2.296, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 9482 (epoch 15), train_loss = 2.704, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9483 (epoch 15), train_loss = 2.761, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 9484 (epoch 15), train_loss = 3.037, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9485 (epoch 15), train_loss = 2.665, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 9486 (epoch 15), train_loss = 3.165, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9487 (epoch 15), train_loss = 2.707, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 9488 (epoch 15), train_loss = 2.365, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 9489 (epoch 15), train_loss = 2.591, time/batch = 0.032
Read data: 8.726119995117188e-05
iter 9490 (epoch 15), train_loss = 2.716, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 9491 (epoch 15), train_loss = 2.750, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 9492 (epoch 15), train_loss = 2.863, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 9493 (epoch 15), train_loss = 2.625, time/batch = 0.036
Read data: 9.369850158691406e-05
iter 9494 (epoch 15), train_loss = 2.535, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 9495 (epoch 15), train_loss = 2.515, time/batch = 0.035
Read data: 8.749961853027344e-05
iter 9496 (epoch 15), train_loss = 2.746, time/batch = 0.030
Read data: 8.916854858398438e-05
iter 9497 (epoch 15), train_loss = 2.544, time/batch = 0.027
Read data: 9.417533874511719e-05
iter 9498 (epoch 15), train_loss = 2.292, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 9499 (epoch 15), train_loss = 2.534, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 9500 (epoch 15), train_loss = 2.444, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 9501 (epoch 15), train_loss = 2.316, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 9502 (epoch 15), train_loss = 2.264, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 9503 (epoch 15), train_loss = 2.658, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 9504 (epoch 15), train_loss = 2.816, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 9505 (epoch 15), train_loss = 2.577, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9506 (epoch 15), train_loss = 2.788, time/batch = 0.033
Read data: 8.606910705566406e-05
iter 9507 (epoch 15), train_loss = 2.501, time/batch = 0.035
Read data: 8.630752563476562e-05
iter 9508 (epoch 15), train_loss = 2.957, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 9509 (epoch 15), train_loss = 2.927, time/batch = 0.029
Read data: 0.00014734268188476562
iter 9510 (epoch 15), train_loss = 2.652, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 9511 (epoch 15), train_loss = 2.761, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 9512 (epoch 15), train_loss = 2.338, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 9513 (epoch 15), train_loss = 2.668, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 9514 (epoch 15), train_loss = 2.713, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 9515 (epoch 15), train_loss = 2.410, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 9516 (epoch 15), train_loss = 2.698, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 9517 (epoch 15), train_loss = 2.422, time/batch = 0.038
Read data: 9.036064147949219e-05
iter 9518 (epoch 15), train_loss = 2.905, time/batch = 0.041
Read data: 7.891654968261719e-05
iter 9519 (epoch 15), train_loss = 2.939, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 9520 (epoch 15), train_loss = 2.251, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 9521 (epoch 15), train_loss = 2.447, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 9522 (epoch 15), train_loss = 2.746, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 9523 (epoch 15), train_loss = 2.883, time/batch = 0.033
Read data: 8.487701416015625e-05
iter 9524 (epoch 15), train_loss = 2.574, time/batch = 0.025
Read data: 0.000247955322265625
iter 9525 (epoch 15), train_loss = 2.574, time/batch = 0.030
Read data: 0.00016379356384277344
iter 9526 (epoch 15), train_loss = 2.558, time/batch = 0.030
Read data: 0.00013899803161621094
iter 9527 (epoch 15), train_loss = 2.688, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 9528 (epoch 15), train_loss = 3.096, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 9529 (epoch 15), train_loss = 2.589, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 9530 (epoch 15), train_loss = 3.073, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 9531 (epoch 15), train_loss = 2.472, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 9532 (epoch 15), train_loss = 2.434, time/batch = 0.025
Read data: 9.918212890625e-05
iter 9533 (epoch 15), train_loss = 2.636, time/batch = 0.025
Read data: 8.392333984375e-05
iter 9534 (epoch 15), train_loss = 2.611, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 9535 (epoch 15), train_loss = 2.590, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 9536 (epoch 15), train_loss = 2.495, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 9537 (epoch 15), train_loss = 2.834, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 9538 (epoch 15), train_loss = 2.567, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 9539 (epoch 15), train_loss = 1.947, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9540 (epoch 15), train_loss = 2.190, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 9541 (epoch 15), train_loss = 2.311, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 9542 (epoch 15), train_loss = 3.098, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 9543 (epoch 15), train_loss = 2.286, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 9544 (epoch 15), train_loss = 2.669, time/batch = 0.027
Read data: 0.00013589859008789062
iter 9545 (epoch 15), train_loss = 2.845, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 9546 (epoch 15), train_loss = 2.587, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 9547 (epoch 15), train_loss = 2.703, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 9548 (epoch 15), train_loss = 2.494, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 9549 (epoch 15), train_loss = 2.935, time/batch = 0.034
Read data: 0.00021600723266601562
iter 9550 (epoch 15), train_loss = 2.384, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 9551 (epoch 15), train_loss = 2.975, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 9552 (epoch 15), train_loss = 2.377, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 9553 (epoch 15), train_loss = 2.665, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9554 (epoch 15), train_loss = 2.896, time/batch = 0.040
Read data: 8.821487426757812e-05
iter 9555 (epoch 15), train_loss = 2.982, time/batch = 0.027
Read data: 0.00010323524475097656
iter 9556 (epoch 15), train_loss = 2.675, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 9557 (epoch 15), train_loss = 3.102, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 9558 (epoch 15), train_loss = 2.808, time/batch = 0.035
Read data: 0.0001392364501953125
iter 9559 (epoch 15), train_loss = 2.840, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 9560 (epoch 15), train_loss = 2.471, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 9561 (epoch 15), train_loss = 2.982, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 9562 (epoch 15), train_loss = 2.468, time/batch = 0.024
Read data: 8.392333984375e-05
iter 9563 (epoch 15), train_loss = 2.405, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 9564 (epoch 15), train_loss = 2.572, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 9565 (epoch 15), train_loss = 2.852, time/batch = 0.040
Read data: 9.083747863769531e-05
iter 9566 (epoch 15), train_loss = 2.258, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 9567 (epoch 15), train_loss = 2.477, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 9568 (epoch 15), train_loss = 2.822, time/batch = 0.023
Read data: 9.751319885253906e-05
iter 9569 (epoch 15), train_loss = 2.305, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9570 (epoch 15), train_loss = 2.624, time/batch = 0.021
Read data: 9.465217590332031e-05
iter 9571 (epoch 15), train_loss = 2.723, time/batch = 0.032
Read data: 7.772445678710938e-05
iter 9572 (epoch 15), train_loss = 2.560, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 9573 (epoch 15), train_loss = 2.886, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 9574 (epoch 15), train_loss = 2.852, time/batch = 0.045
Read data: 0.00022292137145996094
iter 9575 (epoch 15), train_loss = 3.075, time/batch = 0.032
Read data: 8.702278137207031e-05
iter 9576 (epoch 15), train_loss = 2.573, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 9577 (epoch 15), train_loss = 2.264, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 9578 (epoch 15), train_loss = 2.614, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 9579 (epoch 15), train_loss = 2.448, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 9580 (epoch 15), train_loss = 2.697, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 9581 (epoch 15), train_loss = 2.936, time/batch = 0.037
Read data: 9.369850158691406e-05
iter 9582 (epoch 15), train_loss = 2.767, time/batch = 0.035
Read data: 9.274482727050781e-05
iter 9583 (epoch 15), train_loss = 2.460, time/batch = 0.032
Read data: 8.7738037109375e-05
iter 9584 (epoch 15), train_loss = 2.798, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 9585 (epoch 15), train_loss = 2.687, time/batch = 0.030
Read data: 9.107589721679688e-05
iter 9586 (epoch 15), train_loss = 2.240, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 9587 (epoch 15), train_loss = 2.834, time/batch = 0.030
Read data: 8.96453857421875e-05
iter 9588 (epoch 15), train_loss = 2.322, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 9589 (epoch 15), train_loss = 2.719, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 9590 (epoch 15), train_loss = 2.743, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 9591 (epoch 15), train_loss = 2.380, time/batch = 0.024
Read data: 0.0009315013885498047
iter 9592 (epoch 15), train_loss = 2.818, time/batch = 0.023
Read data: 0.00010013580322265625
iter 9593 (epoch 15), train_loss = 2.611, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 9594 (epoch 15), train_loss = 2.744, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 9595 (epoch 15), train_loss = 2.671, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 9596 (epoch 15), train_loss = 2.269, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 9597 (epoch 15), train_loss = 3.115, time/batch = 0.037
Read data: 8.487701416015625e-05
iter 9598 (epoch 15), train_loss = 2.654, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 9599 (epoch 15), train_loss = 2.223, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 9600 (epoch 15), train_loss = 2.723, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 9601 (epoch 16), train_loss = 2.507, time/batch = 0.032
Read data: 9.441375732421875e-05
iter 9602 (epoch 16), train_loss = 3.091, time/batch = 0.025
Read data: 0.000133514404296875
iter 9603 (epoch 16), train_loss = 2.362, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 9604 (epoch 16), train_loss = 2.926, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 9605 (epoch 16), train_loss = 2.371, time/batch = 0.037
Read data: 0.00015687942504882812
iter 9606 (epoch 16), train_loss = 2.361, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 9607 (epoch 16), train_loss = 2.557, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 9608 (epoch 16), train_loss = 2.444, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9609 (epoch 16), train_loss = 2.435, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 9610 (epoch 16), train_loss = 2.796, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9611 (epoch 16), train_loss = 2.819, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 9612 (epoch 16), train_loss = 2.921, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 9613 (epoch 16), train_loss = 2.423, time/batch = 0.033
Read data: 9.465217590332031e-05
iter 9614 (epoch 16), train_loss = 2.517, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9615 (epoch 16), train_loss = 3.039, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 9616 (epoch 16), train_loss = 2.878, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 9617 (epoch 16), train_loss = 2.455, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 9618 (epoch 16), train_loss = 2.875, time/batch = 0.044
Read data: 9.226799011230469e-05
iter 9619 (epoch 16), train_loss = 2.662, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 9620 (epoch 16), train_loss = 2.609, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 9621 (epoch 16), train_loss = 2.599, time/batch = 0.040
Read data: 8.749961853027344e-05
iter 9622 (epoch 16), train_loss = 2.728, time/batch = 0.045
Read data: 7.963180541992188e-05
iter 9623 (epoch 16), train_loss = 2.527, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 9624 (epoch 16), train_loss = 2.785, time/batch = 0.024
Read data: 0.00024390220642089844
iter 9625 (epoch 16), train_loss = 2.930, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 9626 (epoch 16), train_loss = 3.005, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 9627 (epoch 16), train_loss = 2.862, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9628 (epoch 16), train_loss = 2.336, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 9629 (epoch 16), train_loss = 2.516, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 9630 (epoch 16), train_loss = 2.396, time/batch = 0.029
Read data: 0.00010418891906738281
iter 9631 (epoch 16), train_loss = 2.833, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 9632 (epoch 16), train_loss = 2.515, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 9633 (epoch 16), train_loss = 2.275, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 9634 (epoch 16), train_loss = 2.565, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 9635 (epoch 16), train_loss = 3.128, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9636 (epoch 16), train_loss = 2.570, time/batch = 0.030
Read data: 0.00017404556274414062
iter 9637 (epoch 16), train_loss = 2.697, time/batch = 0.037
Read data: 9.131431579589844e-05
iter 9638 (epoch 16), train_loss = 2.515, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 9639 (epoch 16), train_loss = 2.436, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 9640 (epoch 16), train_loss = 3.020, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 9641 (epoch 16), train_loss = 2.826, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 9642 (epoch 16), train_loss = 2.726, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9643 (epoch 16), train_loss = 2.501, time/batch = 0.033
Read data: 8.392333984375e-05
iter 9644 (epoch 16), train_loss = 2.224, time/batch = 0.027
Read data: 0.00014901161193847656
iter 9645 (epoch 16), train_loss = 2.660, time/batch = 0.031
Read data: 0.0001304149627685547
iter 9646 (epoch 16), train_loss = 2.305, time/batch = 0.028
Read data: 0.0001418590545654297
iter 9647 (epoch 16), train_loss = 2.494, time/batch = 0.032
Read data: 8.678436279296875e-05
iter 9648 (epoch 16), train_loss = 2.750, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 9649 (epoch 16), train_loss = 2.436, time/batch = 0.033
Read data: 0.00021505355834960938
iter 9650 (epoch 16), train_loss = 2.429, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 9651 (epoch 16), train_loss = 2.404, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 9652 (epoch 16), train_loss = 2.314, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 9653 (epoch 16), train_loss = 2.658, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 9654 (epoch 16), train_loss = 2.748, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 9655 (epoch 16), train_loss = 2.231, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 9656 (epoch 16), train_loss = 2.054, time/batch = 0.021
Read data: 8.678436279296875e-05
iter 9657 (epoch 16), train_loss = 2.567, time/batch = 0.026
Read data: 0.00010275840759277344
iter 9658 (epoch 16), train_loss = 3.111, time/batch = 0.039
Read data: 8.344650268554688e-05
iter 9659 (epoch 16), train_loss = 2.400, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 9660 (epoch 16), train_loss = 2.605, time/batch = 0.021
Read data: 9.489059448242188e-05
iter 9661 (epoch 16), train_loss = 2.500, time/batch = 0.034
Read data: 8.630752563476562e-05
iter 9662 (epoch 16), train_loss = 2.612, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 9663 (epoch 16), train_loss = 2.519, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9664 (epoch 16), train_loss = 2.072, time/batch = 0.021
Read data: 0.00010180473327636719
iter 9665 (epoch 16), train_loss = 2.450, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 9666 (epoch 16), train_loss = 2.625, time/batch = 0.030
Read data: 8.392333984375e-05
iter 9667 (epoch 16), train_loss = 2.776, time/batch = 0.035
Read data: 8.893013000488281e-05
iter 9668 (epoch 16), train_loss = 2.456, time/batch = 0.035
Read data: 7.724761962890625e-05
iter 9669 (epoch 16), train_loss = 2.380, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 9670 (epoch 16), train_loss = 2.407, time/batch = 0.035
Read data: 9.036064147949219e-05
iter 9671 (epoch 16), train_loss = 2.692, time/batch = 0.029
Read data: 8.726119995117188e-05
iter 9672 (epoch 16), train_loss = 2.432, time/batch = 0.029
Read data: 8.797645568847656e-05
iter 9673 (epoch 16), train_loss = 2.452, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 9674 (epoch 16), train_loss = 2.410, time/batch = 0.027
Read data: 0.0002219676971435547
iter 9675 (epoch 16), train_loss = 2.861, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 9676 (epoch 16), train_loss = 2.589, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 9677 (epoch 16), train_loss = 2.425, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 9678 (epoch 16), train_loss = 2.501, time/batch = 0.021
Read data: 9.608268737792969e-05
iter 9679 (epoch 16), train_loss = 2.502, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 9680 (epoch 16), train_loss = 2.792, time/batch = 0.035
Read data: 8.368492126464844e-05
iter 9681 (epoch 16), train_loss = 2.521, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 9682 (epoch 16), train_loss = 3.246, time/batch = 0.041
Read data: 7.653236389160156e-05
iter 9683 (epoch 16), train_loss = 3.068, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 9684 (epoch 16), train_loss = 2.404, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 9685 (epoch 16), train_loss = 2.540, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 9686 (epoch 16), train_loss = 2.603, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 9687 (epoch 16), train_loss = 2.441, time/batch = 0.026
Read data: 0.00012826919555664062
iter 9688 (epoch 16), train_loss = 2.601, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 9689 (epoch 16), train_loss = 2.724, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 9690 (epoch 16), train_loss = 2.419, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9691 (epoch 16), train_loss = 2.570, time/batch = 0.033
Read data: 0.00013017654418945312
iter 9692 (epoch 16), train_loss = 2.406, time/batch = 0.027
Read data: 0.00010895729064941406
iter 9693 (epoch 16), train_loss = 2.667, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 9694 (epoch 16), train_loss = 2.417, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 9695 (epoch 16), train_loss = 2.688, time/batch = 0.028
Read data: 0.0001270771026611328
iter 9696 (epoch 16), train_loss = 2.568, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 9697 (epoch 16), train_loss = 2.377, time/batch = 0.030
Read data: 9.226799011230469e-05
iter 9698 (epoch 16), train_loss = 2.746, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 9699 (epoch 16), train_loss = 2.251, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 9700 (epoch 16), train_loss = 2.589, time/batch = 0.030
Read data: 9.322166442871094e-05
iter 9701 (epoch 16), train_loss = 2.627, time/batch = 0.032
Read data: 0.00012087821960449219
iter 9702 (epoch 16), train_loss = 2.907, time/batch = 0.032
Read data: 8.726119995117188e-05
iter 9703 (epoch 16), train_loss = 2.508, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 9704 (epoch 16), train_loss = 2.896, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 9705 (epoch 16), train_loss = 2.457, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 9706 (epoch 16), train_loss = 2.763, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 9707 (epoch 16), train_loss = 2.736, time/batch = 0.038
Read data: 9.107589721679688e-05
iter 9708 (epoch 16), train_loss = 2.579, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 9709 (epoch 16), train_loss = 2.243, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 9710 (epoch 16), train_loss = 2.516, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 9711 (epoch 16), train_loss = 2.809, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 9712 (epoch 16), train_loss = 3.056, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 9713 (epoch 16), train_loss = 2.663, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 9714 (epoch 16), train_loss = 2.397, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 9715 (epoch 16), train_loss = 2.613, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 9716 (epoch 16), train_loss = 2.614, time/batch = 0.030
Read data: 8.392333984375e-05
iter 9717 (epoch 16), train_loss = 2.891, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 9718 (epoch 16), train_loss = 2.867, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 9719 (epoch 16), train_loss = 2.481, time/batch = 0.031
Read data: 0.00013327598571777344
iter 9720 (epoch 16), train_loss = 2.625, time/batch = 0.031
Read data: 0.00011444091796875
iter 9721 (epoch 16), train_loss = 2.521, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 9722 (epoch 16), train_loss = 2.571, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 9723 (epoch 16), train_loss = 2.226, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 9724 (epoch 16), train_loss = 2.477, time/batch = 0.024
Read data: 0.0002605915069580078
iter 9725 (epoch 16), train_loss = 2.467, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 9726 (epoch 16), train_loss = 2.927, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 9727 (epoch 16), train_loss = 2.400, time/batch = 0.030
Read data: 0.0001480579376220703
iter 9728 (epoch 16), train_loss = 2.664, time/batch = 0.032
Read data: 9.107589721679688e-05
iter 9729 (epoch 16), train_loss = 2.519, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 9730 (epoch 16), train_loss = 2.009, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 9731 (epoch 16), train_loss = 2.784, time/batch = 0.033
Read data: 0.0001506805419921875
iter 9732 (epoch 16), train_loss = 2.718, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 9733 (epoch 16), train_loss = 2.515, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9734 (epoch 16), train_loss = 2.673, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 9735 (epoch 16), train_loss = 2.215, time/batch = 0.030
Read data: 0.000133514404296875
iter 9736 (epoch 16), train_loss = 2.567, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 9737 (epoch 16), train_loss = 2.476, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 9738 (epoch 16), train_loss = 3.028, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 9739 (epoch 16), train_loss = 2.792, time/batch = 0.028
Read data: 0.00013589859008789062
iter 9740 (epoch 16), train_loss = 2.634, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 9741 (epoch 16), train_loss = 3.126, time/batch = 0.039
Read data: 8.344650268554688e-05
iter 9742 (epoch 16), train_loss = 2.683, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 9743 (epoch 16), train_loss = 2.528, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 9744 (epoch 16), train_loss = 2.769, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 9745 (epoch 16), train_loss = 2.794, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 9746 (epoch 16), train_loss = 2.555, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 9747 (epoch 16), train_loss = 2.752, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 9748 (epoch 16), train_loss = 2.645, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9749 (epoch 16), train_loss = 2.120, time/batch = 0.028
Read data: 0.00022840499877929688
iter 9750 (epoch 16), train_loss = 2.708, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 9751 (epoch 16), train_loss = 2.708, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 9752 (epoch 16), train_loss = 2.429, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 9753 (epoch 16), train_loss = 2.530, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 9754 (epoch 16), train_loss = 2.825, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 9755 (epoch 16), train_loss = 2.312, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 9756 (epoch 16), train_loss = 2.689, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 9757 (epoch 16), train_loss = 2.459, time/batch = 0.028
Read data: 8.392333984375e-05
iter 9758 (epoch 16), train_loss = 3.105, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 9759 (epoch 16), train_loss = 2.737, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 9760 (epoch 16), train_loss = 2.793, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 9761 (epoch 16), train_loss = 2.595, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 9762 (epoch 16), train_loss = 2.817, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 9763 (epoch 16), train_loss = 2.577, time/batch = 0.024
Read data: 0.00014925003051757812
iter 9764 (epoch 16), train_loss = 2.337, time/batch = 0.033
Read data: 8.153915405273438e-05
iter 9765 (epoch 16), train_loss = 2.188, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9766 (epoch 16), train_loss = 2.544, time/batch = 0.027
Read data: 0.0001513957977294922
iter 9767 (epoch 16), train_loss = 2.842, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 9768 (epoch 16), train_loss = 2.166, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 9769 (epoch 16), train_loss = 1.977, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 9770 (epoch 16), train_loss = 2.703, time/batch = 0.027
Read data: 0.00010156631469726562
iter 9771 (epoch 16), train_loss = 2.400, time/batch = 0.028
Read data: 0.00012350082397460938
iter 9772 (epoch 16), train_loss = 2.803, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 9773 (epoch 16), train_loss = 2.868, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 9774 (epoch 16), train_loss = 3.111, time/batch = 0.027
Read data: 0.00020813941955566406
iter 9775 (epoch 16), train_loss = 2.123, time/batch = 0.028
Read data: 0.0001277923583984375
iter 9776 (epoch 16), train_loss = 2.769, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 9777 (epoch 16), train_loss = 2.537, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 9778 (epoch 16), train_loss = 2.283, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 9779 (epoch 16), train_loss = 2.356, time/batch = 0.024
Read data: 0.000133514404296875
iter 9780 (epoch 16), train_loss = 2.430, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 9781 (epoch 16), train_loss = 1.998, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 9782 (epoch 16), train_loss = 2.314, time/batch = 0.030
Read data: 9.655952453613281e-05
iter 9783 (epoch 16), train_loss = 2.013, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 9784 (epoch 16), train_loss = 2.030, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 9785 (epoch 16), train_loss = 2.941, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 9786 (epoch 16), train_loss = 2.301, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 9787 (epoch 16), train_loss = 2.658, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 9788 (epoch 16), train_loss = 2.684, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 9789 (epoch 16), train_loss = 2.858, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 9790 (epoch 16), train_loss = 2.409, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 9791 (epoch 16), train_loss = 2.737, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 9792 (epoch 16), train_loss = 2.239, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 9793 (epoch 16), train_loss = 2.744, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 9794 (epoch 16), train_loss = 2.772, time/batch = 0.025
Read data: 0.0001163482666015625
iter 9795 (epoch 16), train_loss = 2.276, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 9796 (epoch 16), train_loss = 2.776, time/batch = 0.043
Read data: 9.1552734375e-05
iter 9797 (epoch 16), train_loss = 2.745, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 9798 (epoch 16), train_loss = 2.609, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 9799 (epoch 16), train_loss = 2.553, time/batch = 0.029
Read data: 0.00016880035400390625
iter 9800 (epoch 16), train_loss = 2.652, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 9801 (epoch 16), train_loss = 2.623, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 9802 (epoch 16), train_loss = 2.600, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 9803 (epoch 16), train_loss = 2.366, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 9804 (epoch 16), train_loss = 2.560, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 9805 (epoch 16), train_loss = 2.684, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 9806 (epoch 16), train_loss = 2.832, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 9807 (epoch 16), train_loss = 2.762, time/batch = 0.028
Read data: 0.0001285076141357422
iter 9808 (epoch 16), train_loss = 2.692, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 9809 (epoch 16), train_loss = 2.847, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 9810 (epoch 16), train_loss = 2.848, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 9811 (epoch 16), train_loss = 2.988, time/batch = 0.024
Read data: 0.0001361370086669922
iter 9812 (epoch 16), train_loss = 2.539, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 9813 (epoch 16), train_loss = 2.739, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 9814 (epoch 16), train_loss = 3.152, time/batch = 0.024
Read data: 0.00012946128845214844
iter 9815 (epoch 16), train_loss = 2.646, time/batch = 0.033
Read data: 0.0001628398895263672
iter 9816 (epoch 16), train_loss = 2.485, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 9817 (epoch 16), train_loss = 2.335, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 9818 (epoch 16), train_loss = 2.495, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 9819 (epoch 16), train_loss = 2.510, time/batch = 0.035
Read data: 0.00017452239990234375
iter 9820 (epoch 16), train_loss = 2.650, time/batch = 0.038
Read data: 8.7738037109375e-05
iter 9821 (epoch 16), train_loss = 2.961, time/batch = 0.027
Read data: 9.632110595703125e-05
iter 9822 (epoch 16), train_loss = 2.792, time/batch = 0.029
Read data: 9.441375732421875e-05
iter 9823 (epoch 16), train_loss = 2.812, time/batch = 0.032
Read data: 0.0001316070556640625
iter 9824 (epoch 16), train_loss = 2.699, time/batch = 0.036
Read data: 0.00022149085998535156
iter 9825 (epoch 16), train_loss = 3.134, time/batch = 0.033
Read data: 8.749961853027344e-05
iter 9826 (epoch 16), train_loss = 2.726, time/batch = 0.025
Read data: 0.00010561943054199219
iter 9827 (epoch 16), train_loss = 2.410, time/batch = 0.030
Read data: 0.00015354156494140625
iter 9828 (epoch 16), train_loss = 2.259, time/batch = 0.026
Read data: 0.00010275840759277344
iter 9829 (epoch 16), train_loss = 2.525, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 9830 (epoch 16), train_loss = 2.794, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 9831 (epoch 16), train_loss = 2.467, time/batch = 0.026
Read data: 0.0001575946807861328
iter 9832 (epoch 16), train_loss = 2.733, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 9833 (epoch 16), train_loss = 2.783, time/batch = 0.035
Read data: 9.083747863769531e-05
iter 9834 (epoch 16), train_loss = 2.380, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 9835 (epoch 16), train_loss = 2.518, time/batch = 0.034
Read data: 9.894371032714844e-05
iter 9836 (epoch 16), train_loss = 2.898, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 9837 (epoch 16), train_loss = 2.988, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 9838 (epoch 16), train_loss = 2.653, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 9839 (epoch 16), train_loss = 2.417, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 9840 (epoch 16), train_loss = 2.865, time/batch = 0.031
Read data: 0.00014472007751464844
iter 9841 (epoch 16), train_loss = 3.152, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 9842 (epoch 16), train_loss = 2.342, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 9843 (epoch 16), train_loss = 3.055, time/batch = 0.030
Read data: 0.00013709068298339844
iter 9844 (epoch 16), train_loss = 3.008, time/batch = 0.028
Read data: 0.00015616416931152344
iter 9845 (epoch 16), train_loss = 2.669, time/batch = 0.037
Read data: 0.00014472007751464844
iter 9846 (epoch 16), train_loss = 2.473, time/batch = 0.035
Read data: 7.772445678710938e-05
iter 9847 (epoch 16), train_loss = 2.758, time/batch = 0.041
Read data: 8.153915405273438e-05
iter 9848 (epoch 16), train_loss = 2.534, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 9849 (epoch 16), train_loss = 2.546, time/batch = 0.027
Read data: 0.0002181529998779297
iter 9850 (epoch 16), train_loss = 2.899, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 9851 (epoch 16), train_loss = 2.713, time/batch = 0.030
Read data: 0.00013375282287597656
iter 9852 (epoch 16), train_loss = 2.689, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 9853 (epoch 16), train_loss = 2.744, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 9854 (epoch 16), train_loss = 3.031, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 9855 (epoch 16), train_loss = 2.856, time/batch = 0.031
Read data: 8.630752563476562e-05
iter 9856 (epoch 16), train_loss = 2.873, time/batch = 0.030
Read data: 0.00011587142944335938
iter 9857 (epoch 16), train_loss = 2.915, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 9858 (epoch 16), train_loss = 2.711, time/batch = 0.040
Read data: 9.059906005859375e-05
iter 9859 (epoch 16), train_loss = 2.409, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 9860 (epoch 16), train_loss = 2.322, time/batch = 0.031
Read data: 7.724761962890625e-05
iter 9861 (epoch 16), train_loss = 2.715, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 9862 (epoch 16), train_loss = 2.706, time/batch = 0.023
Read data: 8.392333984375e-05
iter 9863 (epoch 16), train_loss = 2.480, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 9864 (epoch 16), train_loss = 2.576, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 9865 (epoch 16), train_loss = 2.513, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 9866 (epoch 16), train_loss = 2.498, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 9867 (epoch 16), train_loss = 3.220, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 9868 (epoch 16), train_loss = 2.429, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 9869 (epoch 16), train_loss = 2.910, time/batch = 0.026
Read data: 0.00010395050048828125
iter 9870 (epoch 16), train_loss = 2.187, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 9871 (epoch 16), train_loss = 2.763, time/batch = 0.031
Read data: 0.00016641616821289062
iter 9872 (epoch 16), train_loss = 2.422, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 9873 (epoch 16), train_loss = 2.959, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 9874 (epoch 16), train_loss = 3.071, time/batch = 0.026
Read data: 0.00025391578674316406
iter 9875 (epoch 16), train_loss = 2.589, time/batch = 0.033
Read data: 8.845329284667969e-05
iter 9876 (epoch 16), train_loss = 2.908, time/batch = 0.037
Read data: 9.107589721679688e-05
iter 9877 (epoch 16), train_loss = 2.407, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 9878 (epoch 16), train_loss = 2.731, time/batch = 0.037
Read data: 9.846687316894531e-05
iter 9879 (epoch 16), train_loss = 2.538, time/batch = 0.027
Read data: 0.00011801719665527344
iter 9880 (epoch 16), train_loss = 2.734, time/batch = 0.028
Read data: 9.107589721679688e-05
iter 9881 (epoch 16), train_loss = 2.406, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 9882 (epoch 16), train_loss = 2.416, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 9883 (epoch 16), train_loss = 2.388, time/batch = 0.033
Read data: 8.606910705566406e-05
iter 9884 (epoch 16), train_loss = 2.573, time/batch = 0.029
Read data: 9.1552734375e-05
iter 9885 (epoch 16), train_loss = 2.591, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 9886 (epoch 16), train_loss = 2.675, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 9887 (epoch 16), train_loss = 2.156, time/batch = 0.026
Read data: 0.0001266002655029297
iter 9888 (epoch 16), train_loss = 2.544, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 9889 (epoch 16), train_loss = 2.740, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 9890 (epoch 16), train_loss = 2.496, time/batch = 0.027
Read data: 0.00010013580322265625
iter 9891 (epoch 16), train_loss = 2.479, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 9892 (epoch 16), train_loss = 2.506, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 9893 (epoch 16), train_loss = 2.846, time/batch = 0.028
Read data: 9.417533874511719e-05
iter 9894 (epoch 16), train_loss = 2.104, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 9895 (epoch 16), train_loss = 3.121, time/batch = 0.033
Read data: 0.0001361370086669922
iter 9896 (epoch 16), train_loss = 2.739, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 9897 (epoch 16), train_loss = 2.949, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 9898 (epoch 16), train_loss = 2.591, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 9899 (epoch 16), train_loss = 2.638, time/batch = 0.032
Read data: 8.893013000488281e-05
iter 9900 (epoch 16), train_loss = 2.498, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 9901 (epoch 16), train_loss = 2.333, time/batch = 0.034
Read data: 8.821487426757812e-05
iter 9902 (epoch 16), train_loss = 2.648, time/batch = 0.026
Read data: 0.00011491775512695312
iter 9903 (epoch 16), train_loss = 2.686, time/batch = 0.035
Read data: 8.988380432128906e-05
iter 9904 (epoch 16), train_loss = 2.263, time/batch = 0.030
Read data: 8.869171142578125e-05
iter 9905 (epoch 16), train_loss = 2.842, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 9906 (epoch 16), train_loss = 2.724, time/batch = 0.029
Read data: 9.179115295410156e-05
iter 9907 (epoch 16), train_loss = 2.645, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 9908 (epoch 16), train_loss = 2.883, time/batch = 0.032
Read data: 0.0001614093780517578
iter 9909 (epoch 16), train_loss = 2.968, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 9910 (epoch 16), train_loss = 2.472, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 9911 (epoch 16), train_loss = 2.595, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 9912 (epoch 16), train_loss = 2.227, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 9913 (epoch 16), train_loss = 2.633, time/batch = 0.040
Read data: 0.0001404285430908203
iter 9914 (epoch 16), train_loss = 2.610, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 9915 (epoch 16), train_loss = 2.463, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 9916 (epoch 16), train_loss = 2.479, time/batch = 0.032
Read data: 8.559226989746094e-05
iter 9917 (epoch 16), train_loss = 3.049, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 9918 (epoch 16), train_loss = 2.589, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 9919 (epoch 16), train_loss = 2.312, time/batch = 0.037
Read data: 8.821487426757812e-05
iter 9920 (epoch 16), train_loss = 2.613, time/batch = 0.037
Read data: 9.059906005859375e-05
iter 9921 (epoch 16), train_loss = 2.807, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 9922 (epoch 16), train_loss = 2.660, time/batch = 0.031
Read data: 9.632110595703125e-05
iter 9923 (epoch 16), train_loss = 2.424, time/batch = 0.029
Read data: 8.869171142578125e-05
iter 9924 (epoch 16), train_loss = 2.679, time/batch = 0.030
Read data: 0.0003228187561035156
iter 9925 (epoch 16), train_loss = 2.111, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 9926 (epoch 16), train_loss = 2.686, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 9927 (epoch 16), train_loss = 2.344, time/batch = 0.026
Read data: 0.000133514404296875
iter 9928 (epoch 16), train_loss = 2.560, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 9929 (epoch 16), train_loss = 2.540, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 9930 (epoch 16), train_loss = 2.565, time/batch = 0.024
Read data: 0.0001366138458251953
iter 9931 (epoch 16), train_loss = 2.921, time/batch = 0.037
Read data: 8.702278137207031e-05
iter 9932 (epoch 16), train_loss = 2.510, time/batch = 0.030
Read data: 0.0001480579376220703
iter 9933 (epoch 16), train_loss = 2.363, time/batch = 0.036
Read data: 8.916854858398438e-05
iter 9934 (epoch 16), train_loss = 1.978, time/batch = 0.025
Read data: 0.00010085105895996094
iter 9935 (epoch 16), train_loss = 2.658, time/batch = 0.041
Read data: 9.179115295410156e-05
iter 9936 (epoch 16), train_loss = 2.660, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 9937 (epoch 16), train_loss = 2.555, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 9938 (epoch 16), train_loss = 3.053, time/batch = 0.028
Read data: 9.274482727050781e-05
iter 9939 (epoch 16), train_loss = 2.941, time/batch = 0.032
Read data: 8.630752563476562e-05
iter 9940 (epoch 16), train_loss = 2.656, time/batch = 0.039
Read data: 9.965896606445312e-05
iter 9941 (epoch 16), train_loss = 2.271, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 9942 (epoch 16), train_loss = 2.873, time/batch = 0.036
Read data: 8.0108642578125e-05
iter 9943 (epoch 16), train_loss = 2.153, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 9944 (epoch 16), train_loss = 2.810, time/batch = 0.028
Read data: 0.00010347366333007812
iter 9945 (epoch 16), train_loss = 2.682, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 9946 (epoch 16), train_loss = 2.659, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 9947 (epoch 16), train_loss = 2.965, time/batch = 0.026
Read data: 0.00013375282287597656
iter 9948 (epoch 16), train_loss = 2.544, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 9949 (epoch 16), train_loss = 2.415, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 9950 (epoch 16), train_loss = 2.677, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 9951 (epoch 16), train_loss = 2.893, time/batch = 0.031
Read data: 0.00015306472778320312
iter 9952 (epoch 16), train_loss = 2.365, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 9953 (epoch 16), train_loss = 2.186, time/batch = 0.032
Read data: 8.392333984375e-05
iter 9954 (epoch 16), train_loss = 2.722, time/batch = 0.033
Read data: 8.7738037109375e-05
iter 9955 (epoch 16), train_loss = 2.344, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 9956 (epoch 16), train_loss = 2.648, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 9957 (epoch 16), train_loss = 2.099, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 9958 (epoch 16), train_loss = 2.751, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 9959 (epoch 16), train_loss = 2.253, time/batch = 0.028
Read data: 0.0001354217529296875
iter 9960 (epoch 16), train_loss = 2.142, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 9961 (epoch 16), train_loss = 2.453, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 9962 (epoch 16), train_loss = 2.210, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 9963 (epoch 16), train_loss = 2.706, time/batch = 0.026
Read data: 0.00012969970703125
iter 9964 (epoch 16), train_loss = 2.711, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 9965 (epoch 16), train_loss = 2.812, time/batch = 0.034
Read data: 8.296966552734375e-05
iter 9966 (epoch 16), train_loss = 2.703, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 9967 (epoch 16), train_loss = 2.528, time/batch = 0.032
Read data: 0.00013780593872070312
iter 9968 (epoch 16), train_loss = 2.689, time/batch = 0.026
Read data: 8.392333984375e-05
iter 9969 (epoch 16), train_loss = 2.696, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 9970 (epoch 16), train_loss = 2.426, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 9971 (epoch 16), train_loss = 2.561, time/batch = 0.029
Read data: 8.869171142578125e-05
iter 9972 (epoch 16), train_loss = 2.727, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 9973 (epoch 16), train_loss = 2.759, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 9974 (epoch 16), train_loss = 2.488, time/batch = 0.023
Read data: 0.00021147727966308594
iter 9975 (epoch 16), train_loss = 2.679, time/batch = 0.024
Read data: 0.00013136863708496094
iter 9976 (epoch 16), train_loss = 2.564, time/batch = 0.037
Read data: 8.344650268554688e-05
iter 9977 (epoch 16), train_loss = 2.700, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 9978 (epoch 16), train_loss = 2.536, time/batch = 0.023
Read data: 0.0001430511474609375
iter 9979 (epoch 16), train_loss = 2.446, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 9980 (epoch 16), train_loss = 2.757, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 9981 (epoch 16), train_loss = 2.675, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 9982 (epoch 16), train_loss = 3.073, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 9983 (epoch 16), train_loss = 2.805, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 9984 (epoch 16), train_loss = 2.406, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 9985 (epoch 16), train_loss = 2.696, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 9986 (epoch 16), train_loss = 2.939, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 9987 (epoch 16), train_loss = 2.816, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 9988 (epoch 16), train_loss = 2.598, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 9989 (epoch 16), train_loss = 2.808, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 9990 (epoch 16), train_loss = 2.973, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 9991 (epoch 16), train_loss = 2.623, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 9992 (epoch 16), train_loss = 2.942, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 9993 (epoch 16), train_loss = 2.979, time/batch = 0.043
Read data: 8.344650268554688e-05
iter 9994 (epoch 16), train_loss = 2.579, time/batch = 0.029
Read data: 9.1552734375e-05
iter 9995 (epoch 16), train_loss = 2.720, time/batch = 0.033
Read data: 9.083747863769531e-05
iter 9996 (epoch 16), train_loss = 2.496, time/batch = 0.023
Read data: 8.702278137207031e-05
iter 9997 (epoch 16), train_loss = 2.750, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 9998 (epoch 16), train_loss = 2.692, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 9999 (epoch 16), train_loss = 2.541, time/batch = 0.028
image 976:     
image 5399:    
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.661267)
image 2798:    
image 5884:     
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.274873)
image 6903:    
image 3301:    
image 2019:    
image 5535:     
image 7680:     
image 5527:      
image 2568:    
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.616841)
image 4604:    
image 5745:     
image 5288:   
image 1562:      
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.915122)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:    
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.530491)
image 4940:      
image 4905:    
image 469:    
image 102:    
image 6009:    UNK
image 4271:     
image 6329:    
image 1729:     
image 4444:      
image 6070:     
evaluating validation preformance... 60/1000 (2.851832)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.617133)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.693119)
image 3276:      
image 3812:   
image 1400:     
image 3443:    
image 5027:     
image 7251:    
image 7305:     
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.153857)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:    
evaluating validation preformance... 100/1000 (2.957960)
image 2800:    
image 7249:    
image 3211:    
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.836926)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:    UNK
evaluating validation preformance... 120/1000 (2.402515)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.952053)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:   
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.731850)
image 1738:     
image 1455:    
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (2.944339)
image 1865:      
image 3830:      
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:    
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.839444)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.595613)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:    
image 3000:    
image 1806:      
image 7761:     
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.681920)
image 2313:    
image 6289:    
image 8084:   
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.488838)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:    
image 8015:    
image 6565:     
image 6174:      
image 6894:     
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.317700)
image 5159:    
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.474499)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:    
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.590596)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.286224)
image 1917:     
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.233589)
image 7143:     
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.596301)
image 3028:     
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.536350)
image 492:    
image 5429:     
image 6968:      
image 2672:      
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.994219)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.593412)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.481604)
image 6835:     
image 4698:    
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.178425)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.801777)
image 3553:    
image 5971:     
image 122:     
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.389306)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    UNK
image 2203:     
image 5727:     
image 1159:    
evaluating validation preformance... 330/1000 (2.768830)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.461742)
image 4542:      
image 1878:      
image 5329:     
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.581635)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:     
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.075520)
image 2905:    
image 7814:     
image 56:    
image 5034:    
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:      
evaluating validation preformance... 370/1000 (2.610016)
image 4351:     
image 1054:     
image 129:     
image 2849:     
image 725:   
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.650289)
image 2458:     
image 1084:      
image 4835:     
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (2.850059)
image 828:    
image 2733:    
image 791:      
image 5408:     
image 7842:     
image 1117:      
image 5817:      
image 1231:    
image 1630:    
image 6886:    
evaluating validation preformance... 400/1000 (2.279155)
image 2627:    
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.147559)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:     
image 7864:     
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.355640)
image 30:     
image 5540:     
image 2445:      
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.798706)
image 385:    
image 6938:       
image 2381:    
image 5796:     
image 4010:     
image 3452:    
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.914751)
image 1731:     
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:      
image 4790:    
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.224854)
image 2241:      
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:    
image 3682:    
evaluating validation preformance... 460/1000 (2.756399)
image 7979:    
image 1618:    
image 7608:     
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.262177)
image 4503:     
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:      
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.927769)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.294387)
image 2044:    
image 4349:    
image 3855:      
image 1846:    UNK
image 3724:     
image 606:      
image 6577:    
image 6820:     
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.551072)
image 1797:    
image 4670:     
image 4846:     
image 5907:    
image 3321:    
image 1700:    
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.997273)
image 3246:    
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.717547)
image 6806:      
image 6464:    
image 1872:     
image 1575:     
image 3045:      
image 303:   
image 5552:    
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.516185)
image 5619:     
image 4391:    
image 891:     
image 3072:    
image 7781:    
image 6163:    
image 7376:      
image 6034:    
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.547183)
image 5292:    
image 2901:    
image 3568:     
image 690:     
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.602894)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:     
image 5079:     
image 6169:     
image 4340:    
image 2134:     
evaluating validation preformance... 560/1000 (2.609314)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:      
image 4778:     
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.619315)
image 7936:     
image 5433:    
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:      
image 317:     
image 329:     
image 3267:     
evaluating validation preformance... 580/1000 (2.555007)
image 2135:    
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.610700)
image 4420:     
image 1734:    
image 7239:     
image 7447:     
image 8009:     
image 4510:    
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.559100)
image 353:     
image 1095:    
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.710772)
image 69:     
image 3465:    
image 6179:    
image 552:     
image 511:     
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.457333)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:    
image 989:     
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.521378)
image 8074:    
image 1904:     
image 7917:      
image 2394:     
image 4406:    UNK
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.517798)
image 5313:      
image 2377:      
image 6058:    
image 4661:     
image 2955:    
image 3333:     
image 7124:    UNK
image 4278:      
image 953:     
image 4037:      
evaluating validation preformance... 650/1000 (2.608833)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:     
image 1475:     
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.651858)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (2.871598)
image 7877:    
image 6761:     
image 6880:    
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.033607)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (2.902641)
image 6860:     
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:     
image 6225:     
image 3669:     
image 980:    
image 5362:      
evaluating validation preformance... 700/1000 (2.958459)
image 5343:    
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.540041)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.658529)
image 5729:     
image 6395:      
image 516:      
image 1026:    
image 2972:      
image 3005:    
image 1241:      
image 2743:      
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.322277)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:     
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.471273)
image 2239:     
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.782645)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.980410)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:     
image 5400:    
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.219239)
image 6220:    
image 6238:     
image 4534:     
image 2732:    
image 7003:     
image 1739:     
image 5503:     
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.813936)
image 6867:    
image 5525:     
image 4746:    
image 5531:    
image 5425:     
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.200321)
image 5047:    
image 325:     
image 7626:    
image 4552:    
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.274034)
image 7288:     
image 7302:     
image 3055:     
image 5250:     
image 1158:      
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.444134)
image 614:    
image 7295:     
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.988502)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:    UNK
image 5514:     
image 7147:    
image 6348:     
image 580:    
image 2531:     
evaluating validation preformance... 830/1000 (2.424693)
image 5107:    
image 3973:     
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.449113)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.831927)
image 4404:      
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:       
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.814109)
image 4254:      
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:      
image 3222:     
image 4002:     
evaluating validation preformance... 870/1000 (2.376447)
image 4934:    
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:     
image 5681:      
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.637868)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.934949)
image 7485:     
image 6102:    
image 1001:    
image 7167:    
image 4168:     
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.533830)
image 5664:     
image 4985:    
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.262689)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.636981)
image 7152:    
image 4559:      
image 7233:    
image 1341:     
image 5337:     
image 3189:     
image 6274:       
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.528552)
image 5636:     
image 7799:      
image 6025:    
image 6907:    
image 2507:      
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.665891)
image 5860:     
image 3275:     
image 1935:     
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (3.029419)
image 1081:    
image 1179:     
image 4316:      
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.794872)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.378816)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.750539)
image 7352:     
image 5113:     
image 7822:    
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.511602)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:    
image 5901:     
image 1163:    
image 2483:     
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.388170)
average loss on validation: 2.629
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.316889762878418
Cider scores: 0.537930360645033
Read data: 0.31633639335632324
Cider scores: 0.5687740240770031
Read data: 0.23850297927856445
Cider scores: 0.6158498488791501
Read data: 0.23619437217712402
Cider scores: 0.5012592155364242
Read data: 0.19841814041137695
Cider scores: 0.5572338642696436
Read data: 0.1700758934020996
Cider scores: 0.4235792301610798
Read data: 0.19679784774780273
Cider scores: 0.4899723247011476
Read data: 0.17832112312316895
Cider scores: 0.6003105581954774
Read data: 0.16984319686889648
Cider scores: 0.46306459413845874
Read data: 0.18670129776000977
Cider scores: 0.6979289168878227
Read data: 0.24065232276916504
Cider scores: 0.4972974832081981
Read data: 0.17688679695129395
Cider scores: 0.6356578135343018
Read data: 0.1864159107208252
Cider scores: 0.5235152443374889
Read data: 0.1768050193786621
Cider scores: 0.5534046693594327
Read data: 0.1814262866973877
Cider scores: 0.5671517228689742
Read data: 0.16708874702453613
Cider scores: 0.5487799122284739
Read data: 0.15863418579101562
Cider scores: 0.44002783712726756
Read data: 0.1613316535949707
Cider scores: 0.624818654851908
Read data: 0.16382193565368652
Cider scores: 0.5774429576705491
Read data: 0.16074085235595703
Cider scores: 0.6961123940600784
Average cider score on test set: 0.556
End calculating cider score on TEST data set
===============================================
Read data: 0.16268444061279297
iter 10000 (epoch 16), train_loss = 3.018, time/batch = 0.027
Read data: 9.775161743164062e-05
iter 10001 (epoch 16), train_loss = 2.640, time/batch = 0.024
Read data: 0.0001163482666015625
iter 10002 (epoch 16), train_loss = 2.782, time/batch = 0.026
Read data: 0.0001285076141357422
iter 10003 (epoch 16), train_loss = 2.472, time/batch = 0.026
Read data: 0.00010609626770019531
iter 10004 (epoch 16), train_loss = 2.812, time/batch = 0.025
Read data: 0.00012612342834472656
iter 10005 (epoch 16), train_loss = 2.873, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 10006 (epoch 16), train_loss = 2.921, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 10007 (epoch 16), train_loss = 2.524, time/batch = 0.037
Read data: 0.00010251998901367188
iter 10008 (epoch 16), train_loss = 2.727, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 10009 (epoch 16), train_loss = 2.746, time/batch = 0.037
Read data: 9.131431579589844e-05
iter 10010 (epoch 16), train_loss = 2.832, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 10011 (epoch 16), train_loss = 2.509, time/batch = 0.034
Read data: 8.96453857421875e-05
iter 10012 (epoch 16), train_loss = 2.573, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 10013 (epoch 16), train_loss = 2.882, time/batch = 0.031
Read data: 9.965896606445312e-05
iter 10014 (epoch 16), train_loss = 2.617, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 10015 (epoch 16), train_loss = 2.878, time/batch = 0.032
Read data: 0.00013685226440429688
iter 10016 (epoch 16), train_loss = 2.356, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 10017 (epoch 16), train_loss = 2.631, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 10018 (epoch 16), train_loss = 2.028, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 10019 (epoch 16), train_loss = 2.750, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 10020 (epoch 16), train_loss = 3.072, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 10021 (epoch 16), train_loss = 2.701, time/batch = 0.030
Read data: 7.534027099609375e-05
iter 10022 (epoch 16), train_loss = 2.970, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 10023 (epoch 16), train_loss = 2.300, time/batch = 0.026
Read data: 0.0001266002655029297
iter 10024 (epoch 16), train_loss = 2.853, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 10025 (epoch 16), train_loss = 2.288, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 10026 (epoch 16), train_loss = 2.487, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 10027 (epoch 16), train_loss = 2.695, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 10028 (epoch 16), train_loss = 2.888, time/batch = 0.036
Read data: 8.0108642578125e-05
iter 10029 (epoch 16), train_loss = 2.750, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 10030 (epoch 16), train_loss = 2.412, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 10031 (epoch 16), train_loss = 2.914, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 10032 (epoch 16), train_loss = 2.735, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 10033 (epoch 16), train_loss = 2.764, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 10034 (epoch 16), train_loss = 2.314, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 10035 (epoch 16), train_loss = 2.444, time/batch = 0.028
Read data: 0.00012874603271484375
iter 10036 (epoch 16), train_loss = 2.216, time/batch = 0.022
Read data: 7.557868957519531e-05
iter 10037 (epoch 16), train_loss = 2.426, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 10038 (epoch 16), train_loss = 2.832, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 10039 (epoch 16), train_loss = 2.487, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 10040 (epoch 16), train_loss = 2.613, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 10041 (epoch 16), train_loss = 2.250, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 10042 (epoch 16), train_loss = 2.583, time/batch = 0.032
Read data: 8.893013000488281e-05
iter 10043 (epoch 16), train_loss = 2.776, time/batch = 0.026
Read data: 0.0001289844512939453
iter 10044 (epoch 16), train_loss = 2.457, time/batch = 0.032
Read data: 8.606910705566406e-05
iter 10045 (epoch 16), train_loss = 2.877, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 10046 (epoch 16), train_loss = 2.838, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 10047 (epoch 16), train_loss = 2.565, time/batch = 0.024
Read data: 0.00012969970703125
iter 10048 (epoch 16), train_loss = 2.534, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 10049 (epoch 16), train_loss = 3.265, time/batch = 0.025
Read data: 0.00024056434631347656
iter 10050 (epoch 16), train_loss = 2.877, time/batch = 0.026
Read data: 0.00014829635620117188
iter 10051 (epoch 16), train_loss = 2.747, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 10052 (epoch 16), train_loss = 2.669, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 10053 (epoch 16), train_loss = 2.742, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 10054 (epoch 16), train_loss = 3.089, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 10055 (epoch 16), train_loss = 2.445, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 10056 (epoch 16), train_loss = 2.528, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 10057 (epoch 16), train_loss = 2.584, time/batch = 0.022
Read data: 7.700920104980469e-05
iter 10058 (epoch 16), train_loss = 2.528, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 10059 (epoch 16), train_loss = 2.677, time/batch = 0.026
Read data: 0.00017833709716796875
iter 10060 (epoch 16), train_loss = 2.890, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 10061 (epoch 16), train_loss = 2.384, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 10062 (epoch 16), train_loss = 2.770, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 10063 (epoch 16), train_loss = 2.410, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 10064 (epoch 16), train_loss = 2.747, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 10065 (epoch 16), train_loss = 2.356, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 10066 (epoch 16), train_loss = 2.353, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 10067 (epoch 16), train_loss = 2.248, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 10068 (epoch 16), train_loss = 2.569, time/batch = 0.032
Read data: 7.796287536621094e-05
iter 10069 (epoch 16), train_loss = 2.457, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 10070 (epoch 16), train_loss = 2.797, time/batch = 0.033
Read data: 0.00011730194091796875
iter 10071 (epoch 16), train_loss = 2.421, time/batch = 0.031
Read data: 0.0001423358917236328
iter 10072 (epoch 16), train_loss = 2.682, time/batch = 0.035
Read data: 0.0001506805419921875
iter 10073 (epoch 16), train_loss = 2.811, time/batch = 0.033
Read data: 8.654594421386719e-05
iter 10074 (epoch 16), train_loss = 2.661, time/batch = 0.027
Read data: 0.00014448165893554688
iter 10075 (epoch 16), train_loss = 2.783, time/batch = 0.025
Read data: 9.1552734375e-05
iter 10076 (epoch 16), train_loss = 2.703, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 10077 (epoch 16), train_loss = 2.381, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 10078 (epoch 16), train_loss = 2.581, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 10079 (epoch 16), train_loss = 2.583, time/batch = 0.040
Read data: 8.58306884765625e-05
iter 10080 (epoch 16), train_loss = 2.326, time/batch = 0.032
Read data: 0.00014901161193847656
iter 10081 (epoch 16), train_loss = 2.512, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 10082 (epoch 16), train_loss = 2.610, time/batch = 0.036
Read data: 0.00014853477478027344
iter 10083 (epoch 16), train_loss = 2.204, time/batch = 0.038
Read data: 7.915496826171875e-05
iter 10084 (epoch 16), train_loss = 2.460, time/batch = 0.025
Read data: 7.43865966796875e-05
iter 10085 (epoch 16), train_loss = 2.876, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 10086 (epoch 16), train_loss = 2.713, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 10087 (epoch 16), train_loss = 2.398, time/batch = 0.034
Read data: 9.369850158691406e-05
iter 10088 (epoch 16), train_loss = 2.470, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 10089 (epoch 16), train_loss = 2.624, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 10090 (epoch 16), train_loss = 2.628, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 10091 (epoch 16), train_loss = 2.368, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 10092 (epoch 16), train_loss = 2.669, time/batch = 0.032
Read data: 7.843971252441406e-05
iter 10093 (epoch 16), train_loss = 2.978, time/batch = 0.034
Read data: 0.00023412704467773438
iter 10094 (epoch 16), train_loss = 2.801, time/batch = 0.031
Read data: 7.43865966796875e-05
iter 10095 (epoch 16), train_loss = 2.410, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 10096 (epoch 16), train_loss = 2.671, time/batch = 0.033
Read data: 9.894371032714844e-05
iter 10097 (epoch 16), train_loss = 2.325, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 10098 (epoch 16), train_loss = 2.950, time/batch = 0.024
Read data: 0.00014972686767578125
iter 10099 (epoch 16), train_loss = 2.754, time/batch = 0.037
Read data: 8.082389831542969e-05
iter 10100 (epoch 16), train_loss = 2.535, time/batch = 0.033
Read data: 9.202957153320312e-05
iter 10101 (epoch 16), train_loss = 2.168, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 10102 (epoch 16), train_loss = 3.261, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 10103 (epoch 16), train_loss = 3.127, time/batch = 0.043
Read data: 0.0001552104949951172
iter 10104 (epoch 16), train_loss = 2.442, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 10105 (epoch 16), train_loss = 2.760, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 10106 (epoch 16), train_loss = 2.653, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 10107 (epoch 16), train_loss = 2.307, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 10108 (epoch 16), train_loss = 2.880, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 10109 (epoch 16), train_loss = 2.352, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 10110 (epoch 16), train_loss = 2.539, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 10111 (epoch 16), train_loss = 2.522, time/batch = 0.026
Read data: 0.00012683868408203125
iter 10112 (epoch 16), train_loss = 2.890, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 10113 (epoch 16), train_loss = 2.586, time/batch = 0.045
Read data: 8.58306884765625e-05
iter 10114 (epoch 16), train_loss = 2.444, time/batch = 0.028
Read data: 0.00015401840209960938
iter 10115 (epoch 16), train_loss = 2.459, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 10116 (epoch 16), train_loss = 2.484, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 10117 (epoch 16), train_loss = 3.055, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 10118 (epoch 16), train_loss = 2.666, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 10119 (epoch 16), train_loss = 2.508, time/batch = 0.032
Read data: 8.916854858398438e-05
iter 10120 (epoch 16), train_loss = 2.877, time/batch = 0.031
Read data: 8.893013000488281e-05
iter 10121 (epoch 16), train_loss = 2.445, time/batch = 0.035
Read data: 9.584426879882812e-05
iter 10122 (epoch 16), train_loss = 2.717, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 10123 (epoch 16), train_loss = 2.584, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 10124 (epoch 16), train_loss = 3.038, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 10125 (epoch 16), train_loss = 2.384, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 10126 (epoch 16), train_loss = 2.825, time/batch = 0.022
Read data: 0.0001552104949951172
iter 10127 (epoch 16), train_loss = 2.553, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 10128 (epoch 16), train_loss = 2.686, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 10129 (epoch 16), train_loss = 2.946, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 10130 (epoch 16), train_loss = 2.426, time/batch = 0.023
Read data: 0.00014638900756835938
iter 10131 (epoch 16), train_loss = 2.600, time/batch = 0.034
Read data: 0.00014495849609375
iter 10132 (epoch 16), train_loss = 2.515, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 10133 (epoch 16), train_loss = 2.396, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 10134 (epoch 16), train_loss = 2.473, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 10135 (epoch 16), train_loss = 2.666, time/batch = 0.028
Read data: 0.0001316070556640625
iter 10136 (epoch 16), train_loss = 2.403, time/batch = 0.025
Read data: 0.00011467933654785156
iter 10137 (epoch 16), train_loss = 3.055, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 10138 (epoch 16), train_loss = 2.600, time/batch = 0.034
Read data: 8.96453857421875e-05
iter 10139 (epoch 16), train_loss = 2.550, time/batch = 0.027
Read data: 0.0002200603485107422
iter 10140 (epoch 16), train_loss = 2.404, time/batch = 0.034
Read data: 8.96453857421875e-05
iter 10141 (epoch 16), train_loss = 3.034, time/batch = 0.032
Read data: 8.368492126464844e-05
iter 10142 (epoch 16), train_loss = 2.554, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 10143 (epoch 16), train_loss = 2.975, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 10144 (epoch 16), train_loss = 2.710, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 10145 (epoch 16), train_loss = 2.874, time/batch = 0.027
Read data: 0.00013875961303710938
iter 10146 (epoch 16), train_loss = 2.629, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 10147 (epoch 16), train_loss = 2.858, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 10148 (epoch 16), train_loss = 2.756, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 10149 (epoch 16), train_loss = 2.714, time/batch = 0.033
Read data: 0.00016617774963378906
iter 10150 (epoch 16), train_loss = 2.442, time/batch = 0.021
Read data: 8.606910705566406e-05
iter 10151 (epoch 16), train_loss = 2.379, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 10152 (epoch 16), train_loss = 2.522, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 10153 (epoch 16), train_loss = 2.296, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 10154 (epoch 16), train_loss = 2.577, time/batch = 0.024
Read data: 0.00010514259338378906
iter 10155 (epoch 16), train_loss = 2.616, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 10156 (epoch 16), train_loss = 2.624, time/batch = 0.031
Read data: 7.891654968261719e-05
iter 10157 (epoch 16), train_loss = 2.466, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 10158 (epoch 16), train_loss = 2.472, time/batch = 0.022
Read data: 0.00014352798461914062
iter 10159 (epoch 16), train_loss = 2.591, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 10160 (epoch 16), train_loss = 2.551, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 10161 (epoch 16), train_loss = 2.847, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 10162 (epoch 16), train_loss = 2.293, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 10163 (epoch 16), train_loss = 2.482, time/batch = 0.037
Read data: 8.130073547363281e-05
iter 10164 (epoch 16), train_loss = 2.605, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 10165 (epoch 16), train_loss = 2.482, time/batch = 0.023
Read data: 0.00012826919555664062
iter 10166 (epoch 16), train_loss = 2.766, time/batch = 0.024
Read data: 0.00013375282287597656
iter 10167 (epoch 16), train_loss = 2.339, time/batch = 0.029
Read data: 9.226799011230469e-05
iter 10168 (epoch 16), train_loss = 2.533, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 10169 (epoch 16), train_loss = 2.879, time/batch = 0.029
Read data: 0.00014781951904296875
iter 10170 (epoch 16), train_loss = 2.420, time/batch = 0.028
Read data: 9.822845458984375e-05
iter 10171 (epoch 16), train_loss = 2.623, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 10172 (epoch 16), train_loss = 2.617, time/batch = 0.024
Read data: 9.1552734375e-05
iter 10173 (epoch 16), train_loss = 2.555, time/batch = 0.026
Read data: 0.00013017654418945312
iter 10174 (epoch 16), train_loss = 2.060, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 10175 (epoch 16), train_loss = 3.038, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 10176 (epoch 16), train_loss = 2.857, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 10177 (epoch 16), train_loss = 2.509, time/batch = 0.043
Read data: 8.606910705566406e-05
iter 10178 (epoch 16), train_loss = 2.457, time/batch = 0.023
Read data: 0.00011134147644042969
iter 10179 (epoch 16), train_loss = 2.608, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 10180 (epoch 16), train_loss = 2.815, time/batch = 0.021
Read data: 8.249282836914062e-05
iter 10181 (epoch 16), train_loss = 2.641, time/batch = 0.024
Read data: 0.00014853477478027344
iter 10182 (epoch 16), train_loss = 2.943, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 10183 (epoch 16), train_loss = 2.634, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 10184 (epoch 16), train_loss = 2.495, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 10185 (epoch 16), train_loss = 2.782, time/batch = 0.024
Read data: 0.000125885009765625
iter 10186 (epoch 16), train_loss = 2.277, time/batch = 0.021
Read data: 9.655952453613281e-05
iter 10187 (epoch 16), train_loss = 3.019, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 10188 (epoch 16), train_loss = 2.613, time/batch = 0.029
Read data: 9.632110595703125e-05
iter 10189 (epoch 16), train_loss = 2.912, time/batch = 0.022
Read data: 0.00015687942504882812
iter 10190 (epoch 16), train_loss = 2.668, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 10191 (epoch 16), train_loss = 2.601, time/batch = 0.023
Read data: 0.0009589195251464844
iter 10192 (epoch 16), train_loss = 2.380, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 10193 (epoch 16), train_loss = 2.604, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 10194 (epoch 16), train_loss = 2.484, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 10195 (epoch 16), train_loss = 3.028, time/batch = 0.028
Read data: 0.00010323524475097656
iter 10196 (epoch 16), train_loss = 3.111, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 10197 (epoch 16), train_loss = 2.829, time/batch = 0.026
Read data: 0.00016832351684570312
iter 10198 (epoch 16), train_loss = 2.642, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 10199 (epoch 16), train_loss = 2.859, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 10200 (epoch 16), train_loss = 2.478, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 10201 (epoch 17), train_loss = 2.583, time/batch = 0.025
Read data: 0.0001533031463623047
iter 10202 (epoch 17), train_loss = 2.821, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 10203 (epoch 17), train_loss = 2.698, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 10204 (epoch 17), train_loss = 2.342, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 10205 (epoch 17), train_loss = 2.383, time/batch = 0.024
Read data: 0.0001728534698486328
iter 10206 (epoch 17), train_loss = 2.087, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 10207 (epoch 17), train_loss = 2.301, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 10208 (epoch 17), train_loss = 2.631, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 10209 (epoch 17), train_loss = 2.901, time/batch = 0.032
Read data: 0.0001614093780517578
iter 10210 (epoch 17), train_loss = 2.641, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 10211 (epoch 17), train_loss = 2.574, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 10212 (epoch 17), train_loss = 2.619, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 10213 (epoch 17), train_loss = 2.561, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 10214 (epoch 17), train_loss = 2.872, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 10215 (epoch 17), train_loss = 2.309, time/batch = 0.023
Read data: 0.00011324882507324219
iter 10216 (epoch 17), train_loss = 2.460, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 10217 (epoch 17), train_loss = 2.279, time/batch = 0.023
Read data: 0.00013327598571777344
iter 10218 (epoch 17), train_loss = 2.631, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 10219 (epoch 17), train_loss = 2.626, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 10220 (epoch 17), train_loss = 2.500, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 10221 (epoch 17), train_loss = 2.495, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 10222 (epoch 17), train_loss = 2.709, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 10223 (epoch 17), train_loss = 2.982, time/batch = 0.024
Read data: 0.00011539459228515625
iter 10224 (epoch 17), train_loss = 2.436, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 10225 (epoch 17), train_loss = 2.747, time/batch = 0.029
Read data: 0.0001590251922607422
iter 10226 (epoch 17), train_loss = 2.592, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 10227 (epoch 17), train_loss = 2.473, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 10228 (epoch 17), train_loss = 2.587, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 10229 (epoch 17), train_loss = 2.535, time/batch = 0.028
Read data: 0.0001614093780517578
iter 10230 (epoch 17), train_loss = 2.592, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 10231 (epoch 17), train_loss = 2.719, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 10232 (epoch 17), train_loss = 2.825, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 10233 (epoch 17), train_loss = 2.514, time/batch = 0.026
Read data: 0.0001678466796875
iter 10234 (epoch 17), train_loss = 2.808, time/batch = 0.022
Read data: 9.465217590332031e-05
iter 10235 (epoch 17), train_loss = 2.894, time/batch = 0.024
Read data: 0.0001163482666015625
iter 10236 (epoch 17), train_loss = 2.437, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 10237 (epoch 17), train_loss = 2.593, time/batch = 0.028
Read data: 0.00016188621520996094
iter 10238 (epoch 17), train_loss = 2.532, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 10239 (epoch 17), train_loss = 2.268, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 10240 (epoch 17), train_loss = 3.089, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 10241 (epoch 17), train_loss = 2.577, time/batch = 0.022
Read data: 0.0001780986785888672
iter 10242 (epoch 17), train_loss = 2.803, time/batch = 0.029
Read data: 8.96453857421875e-05
iter 10243 (epoch 17), train_loss = 3.079, time/batch = 0.034
Read data: 8.20159912109375e-05
iter 10244 (epoch 17), train_loss = 2.539, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 10245 (epoch 17), train_loss = 2.639, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 10246 (epoch 17), train_loss = 2.941, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 10247 (epoch 17), train_loss = 2.168, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 10248 (epoch 17), train_loss = 2.448, time/batch = 0.023
Read data: 0.00010013580322265625
iter 10249 (epoch 17), train_loss = 2.567, time/batch = 0.025
Read data: 0.0001327991485595703
iter 10250 (epoch 17), train_loss = 2.496, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 10251 (epoch 17), train_loss = 2.644, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 10252 (epoch 17), train_loss = 2.321, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 10253 (epoch 17), train_loss = 2.793, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 10254 (epoch 17), train_loss = 2.572, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 10255 (epoch 17), train_loss = 2.803, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 10256 (epoch 17), train_loss = 2.415, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 10257 (epoch 17), train_loss = 2.419, time/batch = 0.025
Read data: 0.0001380443572998047
iter 10258 (epoch 17), train_loss = 2.482, time/batch = 0.025
Read data: 9.846687316894531e-05
iter 10259 (epoch 17), train_loss = 2.554, time/batch = 0.025
Read data: 0.00011348724365234375
iter 10260 (epoch 17), train_loss = 2.031, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 10261 (epoch 17), train_loss = 2.385, time/batch = 0.026
Read data: 0.00016069412231445312
iter 10262 (epoch 17), train_loss = 3.001, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 10263 (epoch 17), train_loss = 2.864, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 10264 (epoch 17), train_loss = 2.148, time/batch = 0.022
Read data: 0.00013494491577148438
iter 10265 (epoch 17), train_loss = 2.324, time/batch = 0.026
Read data: 9.393692016601562e-05
iter 10266 (epoch 17), train_loss = 2.475, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 10267 (epoch 17), train_loss = 2.697, time/batch = 0.025
Read data: 0.00011968612670898438
iter 10268 (epoch 17), train_loss = 2.695, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 10269 (epoch 17), train_loss = 2.580, time/batch = 0.034
Read data: 0.000125885009765625
iter 10270 (epoch 17), train_loss = 3.041, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 10271 (epoch 17), train_loss = 2.663, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 10272 (epoch 17), train_loss = 2.404, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 10273 (epoch 17), train_loss = 2.514, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 10274 (epoch 17), train_loss = 2.832, time/batch = 0.028
Read data: 0.0002148151397705078
iter 10275 (epoch 17), train_loss = 2.754, time/batch = 0.035
Read data: 8.821487426757812e-05
iter 10276 (epoch 17), train_loss = 2.515, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 10277 (epoch 17), train_loss = 2.674, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 10278 (epoch 17), train_loss = 2.478, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 10279 (epoch 17), train_loss = 2.871, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 10280 (epoch 17), train_loss = 2.931, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 10281 (epoch 17), train_loss = 3.108, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 10282 (epoch 17), train_loss = 2.361, time/batch = 0.019
Read data: 9.870529174804688e-05
iter 10283 (epoch 17), train_loss = 2.385, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 10284 (epoch 17), train_loss = 2.870, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 10285 (epoch 17), train_loss = 3.011, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 10286 (epoch 17), train_loss = 2.814, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 10287 (epoch 17), train_loss = 2.882, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 10288 (epoch 17), train_loss = 2.520, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 10289 (epoch 17), train_loss = 2.591, time/batch = 0.028
Read data: 0.0001347064971923828
iter 10290 (epoch 17), train_loss = 2.631, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 10291 (epoch 17), train_loss = 2.750, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 10292 (epoch 17), train_loss = 2.771, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 10293 (epoch 17), train_loss = 2.589, time/batch = 0.023
Read data: 0.00016021728515625
iter 10294 (epoch 17), train_loss = 2.104, time/batch = 0.026
Read data: 0.0001285076141357422
iter 10295 (epoch 17), train_loss = 2.578, time/batch = 0.025
Read data: 0.00011968612670898438
iter 10296 (epoch 17), train_loss = 2.820, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 10297 (epoch 17), train_loss = 2.949, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 10298 (epoch 17), train_loss = 2.563, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 10299 (epoch 17), train_loss = 2.603, time/batch = 0.024
Read data: 0.00018358230590820312
iter 10300 (epoch 17), train_loss = 2.628, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 10301 (epoch 17), train_loss = 2.973, time/batch = 0.029
Read data: 0.00012493133544921875
iter 10302 (epoch 17), train_loss = 2.698, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 10303 (epoch 17), train_loss = 2.329, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 10304 (epoch 17), train_loss = 2.524, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 10305 (epoch 17), train_loss = 2.820, time/batch = 0.026
Read data: 0.0001239776611328125
iter 10306 (epoch 17), train_loss = 2.198, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 10307 (epoch 17), train_loss = 2.813, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 10308 (epoch 17), train_loss = 2.392, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 10309 (epoch 17), train_loss = 2.496, time/batch = 0.025
Read data: 0.00014209747314453125
iter 10310 (epoch 17), train_loss = 2.242, time/batch = 0.024
Read data: 0.00010275840759277344
iter 10311 (epoch 17), train_loss = 2.448, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 10312 (epoch 17), train_loss = 2.445, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 10313 (epoch 17), train_loss = 2.696, time/batch = 0.025
Read data: 0.00013971328735351562
iter 10314 (epoch 17), train_loss = 2.339, time/batch = 0.025
Read data: 0.00010347366333007812
iter 10315 (epoch 17), train_loss = 2.676, time/batch = 0.023
Read data: 0.00010633468627929688
iter 10316 (epoch 17), train_loss = 2.599, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 10317 (epoch 17), train_loss = 2.971, time/batch = 0.026
Read data: 0.00015044212341308594
iter 10318 (epoch 17), train_loss = 2.529, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 10319 (epoch 17), train_loss = 2.740, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 10320 (epoch 17), train_loss = 2.538, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 10321 (epoch 17), train_loss = 2.451, time/batch = 0.034
Read data: 0.00016260147094726562
iter 10322 (epoch 17), train_loss = 2.477, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 10323 (epoch 17), train_loss = 2.820, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 10324 (epoch 17), train_loss = 2.880, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 10325 (epoch 17), train_loss = 2.383, time/batch = 0.027
Read data: 0.00013017654418945312
iter 10326 (epoch 17), train_loss = 2.368, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 10327 (epoch 17), train_loss = 2.490, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 10328 (epoch 17), train_loss = 2.555, time/batch = 0.027
Read data: 0.00011301040649414062
iter 10329 (epoch 17), train_loss = 2.559, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 10330 (epoch 17), train_loss = 2.819, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 10331 (epoch 17), train_loss = 2.600, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 10332 (epoch 17), train_loss = 2.238, time/batch = 0.021
Read data: 9.202957153320312e-05
iter 10333 (epoch 17), train_loss = 3.154, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 10334 (epoch 17), train_loss = 2.638, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 10335 (epoch 17), train_loss = 2.398, time/batch = 0.024
Read data: 0.00011682510375976562
iter 10336 (epoch 17), train_loss = 3.030, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 10337 (epoch 17), train_loss = 2.355, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 10338 (epoch 17), train_loss = 2.811, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 10339 (epoch 17), train_loss = 2.554, time/batch = 0.035
Read data: 8.988380432128906e-05
iter 10340 (epoch 17), train_loss = 2.618, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 10341 (epoch 17), train_loss = 2.684, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 10342 (epoch 17), train_loss = 2.394, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 10343 (epoch 17), train_loss = 2.865, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 10344 (epoch 17), train_loss = 2.488, time/batch = 0.035
Read data: 7.963180541992188e-05
iter 10345 (epoch 17), train_loss = 2.947, time/batch = 0.026
Read data: 0.0001442432403564453
iter 10346 (epoch 17), train_loss = 2.880, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 10347 (epoch 17), train_loss = 2.463, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 10348 (epoch 17), train_loss = 2.824, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 10349 (epoch 17), train_loss = 2.777, time/batch = 0.028
Read data: 0.00012874603271484375
iter 10350 (epoch 17), train_loss = 2.256, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 10351 (epoch 17), train_loss = 1.900, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 10352 (epoch 17), train_loss = 2.301, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 10353 (epoch 17), train_loss = 2.850, time/batch = 0.028
Read data: 0.0001621246337890625
iter 10354 (epoch 17), train_loss = 2.193, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 10355 (epoch 17), train_loss = 2.949, time/batch = 0.043
Read data: 8.630752563476562e-05
iter 10356 (epoch 17), train_loss = 2.449, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 10357 (epoch 17), train_loss = 2.770, time/batch = 0.030
Read data: 0.0001919269561767578
iter 10358 (epoch 17), train_loss = 2.554, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 10359 (epoch 17), train_loss = 2.241, time/batch = 0.037
Read data: 9.393692016601562e-05
iter 10360 (epoch 17), train_loss = 2.926, time/batch = 0.035
Read data: 8.726119995117188e-05
iter 10361 (epoch 17), train_loss = 2.464, time/batch = 0.025
Read data: 0.00011992454528808594
iter 10362 (epoch 17), train_loss = 2.337, time/batch = 0.028
Read data: 0.0001983642578125
iter 10363 (epoch 17), train_loss = 2.505, time/batch = 0.032
Read data: 9.131431579589844e-05
iter 10364 (epoch 17), train_loss = 2.728, time/batch = 0.030
Read data: 0.00015807151794433594
iter 10365 (epoch 17), train_loss = 2.723, time/batch = 0.034
Read data: 0.00016498565673828125
iter 10366 (epoch 17), train_loss = 2.364, time/batch = 0.024
Read data: 0.00011372566223144531
iter 10367 (epoch 17), train_loss = 2.339, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 10368 (epoch 17), train_loss = 2.584, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 10369 (epoch 17), train_loss = 2.097, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 10370 (epoch 17), train_loss = 2.457, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 10371 (epoch 17), train_loss = 2.492, time/batch = 0.027
Read data: 0.00010895729064941406
iter 10372 (epoch 17), train_loss = 2.580, time/batch = 0.031
Read data: 8.893013000488281e-05
iter 10373 (epoch 17), train_loss = 2.960, time/batch = 0.024
Read data: 0.00015354156494140625
iter 10374 (epoch 17), train_loss = 2.605, time/batch = 0.026
Read data: 7.62939453125e-05
iter 10375 (epoch 17), train_loss = 2.889, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 10376 (epoch 17), train_loss = 2.647, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 10377 (epoch 17), train_loss = 2.617, time/batch = 0.023
Read data: 0.00013828277587890625
iter 10378 (epoch 17), train_loss = 2.437, time/batch = 0.026
Read data: 0.00010395050048828125
iter 10379 (epoch 17), train_loss = 2.911, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 10380 (epoch 17), train_loss = 2.987, time/batch = 0.027
Read data: 0.00012421607971191406
iter 10381 (epoch 17), train_loss = 2.502, time/batch = 0.025
Read data: 0.0001270771026611328
iter 10382 (epoch 17), train_loss = 2.341, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 10383 (epoch 17), train_loss = 2.141, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 10384 (epoch 17), train_loss = 2.461, time/batch = 0.023
Read data: 0.000118255615234375
iter 10385 (epoch 17), train_loss = 2.771, time/batch = 0.032
Read data: 0.0001533031463623047
iter 10386 (epoch 17), train_loss = 2.795, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 10387 (epoch 17), train_loss = 2.175, time/batch = 0.027
Read data: 0.00013971328735351562
iter 10388 (epoch 17), train_loss = 2.185, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 10389 (epoch 17), train_loss = 2.549, time/batch = 0.024
Read data: 0.00013208389282226562
iter 10390 (epoch 17), train_loss = 2.217, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 10391 (epoch 17), train_loss = 2.429, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 10392 (epoch 17), train_loss = 2.573, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 10393 (epoch 17), train_loss = 2.664, time/batch = 0.026
Read data: 0.0001323223114013672
iter 10394 (epoch 17), train_loss = 3.188, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 10395 (epoch 17), train_loss = 2.593, time/batch = 0.029
Read data: 0.00013971328735351562
iter 10396 (epoch 17), train_loss = 1.797, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 10397 (epoch 17), train_loss = 2.228, time/batch = 0.021
Read data: 0.0001552104949951172
iter 10398 (epoch 17), train_loss = 2.671, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 10399 (epoch 17), train_loss = 2.570, time/batch = 0.033
Read data: 9.369850158691406e-05
iter 10400 (epoch 17), train_loss = 2.841, time/batch = 0.022
Read data: 0.00015020370483398438
iter 10401 (epoch 17), train_loss = 2.488, time/batch = 0.021
Read data: 0.00013494491577148438
iter 10402 (epoch 17), train_loss = 2.061, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 10403 (epoch 17), train_loss = 2.982, time/batch = 0.024
Read data: 0.00014710426330566406
iter 10404 (epoch 17), train_loss = 2.899, time/batch = 0.021
Read data: 0.00014495849609375
iter 10405 (epoch 17), train_loss = 3.044, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 10406 (epoch 17), train_loss = 2.432, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 10407 (epoch 17), train_loss = 2.303, time/batch = 0.023
Read data: 0.00013637542724609375
iter 10408 (epoch 17), train_loss = 2.685, time/batch = 0.034
Read data: 7.987022399902344e-05
iter 10409 (epoch 17), train_loss = 2.355, time/batch = 0.027
Read data: 0.0001633167266845703
iter 10410 (epoch 17), train_loss = 2.199, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 10411 (epoch 17), train_loss = 2.494, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 10412 (epoch 17), train_loss = 2.803, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 10413 (epoch 17), train_loss = 2.562, time/batch = 0.024
Read data: 0.00012421607971191406
iter 10414 (epoch 17), train_loss = 2.548, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 10415 (epoch 17), train_loss = 2.311, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 10416 (epoch 17), train_loss = 2.381, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 10417 (epoch 17), train_loss = 2.439, time/batch = 0.024
Read data: 0.00015091896057128906
iter 10418 (epoch 17), train_loss = 2.521, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 10419 (epoch 17), train_loss = 2.638, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 10420 (epoch 17), train_loss = 2.860, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 10421 (epoch 17), train_loss = 2.900, time/batch = 0.021
Read data: 0.00013256072998046875
iter 10422 (epoch 17), train_loss = 2.280, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 10423 (epoch 17), train_loss = 2.289, time/batch = 0.026
Read data: 0.00010013580322265625
iter 10424 (epoch 17), train_loss = 2.357, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 10425 (epoch 17), train_loss = 2.416, time/batch = 0.026
Read data: 0.0001537799835205078
iter 10426 (epoch 17), train_loss = 2.581, time/batch = 0.023
Read data: 0.00012874603271484375
iter 10427 (epoch 17), train_loss = 2.377, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 10428 (epoch 17), train_loss = 2.035, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 10429 (epoch 17), train_loss = 2.356, time/batch = 0.022
Read data: 0.00017690658569335938
iter 10430 (epoch 17), train_loss = 2.620, time/batch = 0.032
Read data: 7.843971252441406e-05
iter 10431 (epoch 17), train_loss = 2.494, time/batch = 0.025
Read data: 0.000133514404296875
iter 10432 (epoch 17), train_loss = 2.622, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 10433 (epoch 17), train_loss = 2.723, time/batch = 0.024
Read data: 0.0001590251922607422
iter 10434 (epoch 17), train_loss = 2.634, time/batch = 0.035
Read data: 8.869171142578125e-05
iter 10435 (epoch 17), train_loss = 2.124, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 10436 (epoch 17), train_loss = 2.825, time/batch = 0.037
Read data: 8.726119995117188e-05
iter 10437 (epoch 17), train_loss = 2.837, time/batch = 0.022
Read data: 0.00016188621520996094
iter 10438 (epoch 17), train_loss = 3.091, time/batch = 0.034
Read data: 0.00010395050048828125
iter 10439 (epoch 17), train_loss = 2.649, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 10440 (epoch 17), train_loss = 2.748, time/batch = 0.027
Read data: 0.00013113021850585938
iter 10441 (epoch 17), train_loss = 2.630, time/batch = 0.040
Read data: 8.654594421386719e-05
iter 10442 (epoch 17), train_loss = 3.115, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 10443 (epoch 17), train_loss = 2.626, time/batch = 0.029
Read data: 0.00013637542724609375
iter 10444 (epoch 17), train_loss = 2.815, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 10445 (epoch 17), train_loss = 2.933, time/batch = 0.024
Read data: 0.00012612342834472656
iter 10446 (epoch 17), train_loss = 2.934, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 10447 (epoch 17), train_loss = 2.717, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 10448 (epoch 17), train_loss = 2.387, time/batch = 0.028
Read data: 0.00010418891906738281
iter 10449 (epoch 17), train_loss = 2.509, time/batch = 0.027
Read data: 0.00012445449829101562
iter 10450 (epoch 17), train_loss = 2.197, time/batch = 0.027
Read data: 0.00010228157043457031
iter 10451 (epoch 17), train_loss = 2.520, time/batch = 0.028
Read data: 0.00012969970703125
iter 10452 (epoch 17), train_loss = 2.860, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 10453 (epoch 17), train_loss = 2.693, time/batch = 0.024
Read data: 0.0001220703125
iter 10454 (epoch 17), train_loss = 2.819, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 10455 (epoch 17), train_loss = 2.825, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 10456 (epoch 17), train_loss = 2.224, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 10457 (epoch 17), train_loss = 2.679, time/batch = 0.031
Read data: 0.00013566017150878906
iter 10458 (epoch 17), train_loss = 2.493, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 10459 (epoch 17), train_loss = 2.506, time/batch = 0.028
Read data: 8.392333984375e-05
iter 10460 (epoch 17), train_loss = 2.535, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 10461 (epoch 17), train_loss = 2.237, time/batch = 0.026
Read data: 0.00012803077697753906
iter 10462 (epoch 17), train_loss = 2.227, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 10463 (epoch 17), train_loss = 2.711, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 10464 (epoch 17), train_loss = 2.361, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 10465 (epoch 17), train_loss = 2.393, time/batch = 0.024
Read data: 0.000156402587890625
iter 10466 (epoch 17), train_loss = 2.694, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 10467 (epoch 17), train_loss = 2.735, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 10468 (epoch 17), train_loss = 2.574, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 10469 (epoch 17), train_loss = 2.682, time/batch = 0.025
Read data: 0.0001304149627685547
iter 10470 (epoch 17), train_loss = 2.411, time/batch = 0.025
Read data: 0.0001246929168701172
iter 10471 (epoch 17), train_loss = 2.926, time/batch = 0.028
Read data: 8.392333984375e-05
iter 10472 (epoch 17), train_loss = 2.723, time/batch = 0.026
Read data: 0.0001010894775390625
iter 10473 (epoch 17), train_loss = 2.691, time/batch = 0.026
Read data: 0.00012564659118652344
iter 10474 (epoch 17), train_loss = 2.475, time/batch = 0.027
Read data: 7.534027099609375e-05
iter 10475 (epoch 17), train_loss = 2.780, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 10476 (epoch 17), train_loss = 2.228, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 10477 (epoch 17), train_loss = 2.194, time/batch = 0.023
Read data: 0.00012969970703125
iter 10478 (epoch 17), train_loss = 2.466, time/batch = 0.026
Read data: 0.00010347366333007812
iter 10479 (epoch 17), train_loss = 2.169, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 10480 (epoch 17), train_loss = 2.330, time/batch = 0.022
Read data: 9.489059448242188e-05
iter 10481 (epoch 17), train_loss = 2.671, time/batch = 0.030
Read data: 9.655952453613281e-05
iter 10482 (epoch 17), train_loss = 2.804, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 10483 (epoch 17), train_loss = 2.332, time/batch = 0.026
Read data: 0.0001220703125
iter 10484 (epoch 17), train_loss = 2.267, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 10485 (epoch 17), train_loss = 2.518, time/batch = 0.026
Read data: 0.00015163421630859375
iter 10486 (epoch 17), train_loss = 2.661, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 10487 (epoch 17), train_loss = 1.978, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 10488 (epoch 17), train_loss = 3.188, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 10489 (epoch 17), train_loss = 2.484, time/batch = 0.025
Read data: 0.00015544891357421875
iter 10490 (epoch 17), train_loss = 2.441, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 10491 (epoch 17), train_loss = 2.762, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 10492 (epoch 17), train_loss = 2.588, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 10493 (epoch 17), train_loss = 2.715, time/batch = 0.024
Read data: 0.0001590251922607422
iter 10494 (epoch 17), train_loss = 2.579, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 10495 (epoch 17), train_loss = 2.605, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 10496 (epoch 17), train_loss = 2.778, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 10497 (epoch 17), train_loss = 2.484, time/batch = 0.024
Read data: 0.0001583099365234375
iter 10498 (epoch 17), train_loss = 2.939, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 10499 (epoch 17), train_loss = 2.496, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 10500 (epoch 17), train_loss = 2.690, time/batch = 0.028
Read data: 0.0001404285430908203
iter 10501 (epoch 17), train_loss = 2.455, time/batch = 0.021
Read data: 0.00013375282287597656
iter 10502 (epoch 17), train_loss = 2.369, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 10503 (epoch 17), train_loss = 2.633, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 10504 (epoch 17), train_loss = 2.785, time/batch = 0.027
Read data: 0.00010037422180175781
iter 10505 (epoch 17), train_loss = 2.009, time/batch = 0.025
Read data: 0.0001571178436279297
iter 10506 (epoch 17), train_loss = 2.172, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 10507 (epoch 17), train_loss = 2.711, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 10508 (epoch 17), train_loss = 2.624, time/batch = 0.035
Read data: 7.915496826171875e-05
iter 10509 (epoch 17), train_loss = 2.423, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 10510 (epoch 17), train_loss = 2.614, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 10511 (epoch 17), train_loss = 2.950, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 10512 (epoch 17), train_loss = 2.778, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 10513 (epoch 17), train_loss = 2.768, time/batch = 0.024
Read data: 0.00012159347534179688
iter 10514 (epoch 17), train_loss = 2.196, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 10515 (epoch 17), train_loss = 2.850, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 10516 (epoch 17), train_loss = 2.707, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 10517 (epoch 17), train_loss = 2.452, time/batch = 0.028
Read data: 0.00012636184692382812
iter 10518 (epoch 17), train_loss = 2.442, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 10519 (epoch 17), train_loss = 2.700, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 10520 (epoch 17), train_loss = 2.767, time/batch = 0.035
Read data: 8.606910705566406e-05
iter 10521 (epoch 17), train_loss = 2.550, time/batch = 0.026
Read data: 0.00011849403381347656
iter 10522 (epoch 17), train_loss = 3.155, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 10523 (epoch 17), train_loss = 2.171, time/batch = 0.021
Read data: 0.00012302398681640625
iter 10524 (epoch 17), train_loss = 2.647, time/batch = 0.027
Read data: 9.918212890625e-05
iter 10525 (epoch 17), train_loss = 2.156, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 10526 (epoch 17), train_loss = 2.548, time/batch = 0.029
Read data: 0.00012350082397460938
iter 10527 (epoch 17), train_loss = 2.691, time/batch = 0.028
Read data: 0.00011920928955078125
iter 10528 (epoch 17), train_loss = 3.068, time/batch = 0.024
Read data: 0.000125885009765625
iter 10529 (epoch 17), train_loss = 2.456, time/batch = 0.021
Read data: 0.0001380443572998047
iter 10530 (epoch 17), train_loss = 2.803, time/batch = 0.036
Read data: 7.581710815429688e-05
iter 10531 (epoch 17), train_loss = 2.572, time/batch = 0.028
Read data: 0.00020694732666015625
iter 10532 (epoch 17), train_loss = 2.768, time/batch = 0.037
Read data: 8.797645568847656e-05
iter 10533 (epoch 17), train_loss = 2.706, time/batch = 0.034
Read data: 8.749961853027344e-05
iter 10534 (epoch 17), train_loss = 2.679, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 10535 (epoch 17), train_loss = 2.487, time/batch = 0.025
Read data: 0.0001811981201171875
iter 10536 (epoch 17), train_loss = 2.444, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 10537 (epoch 17), train_loss = 2.345, time/batch = 0.022
Read data: 0.0001533031463623047
iter 10538 (epoch 17), train_loss = 2.472, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 10539 (epoch 17), train_loss = 2.575, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 10540 (epoch 17), train_loss = 2.916, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 10541 (epoch 17), train_loss = 2.562, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 10542 (epoch 17), train_loss = 2.507, time/batch = 0.029
Read data: 7.462501525878906e-05
iter 10543 (epoch 17), train_loss = 2.948, time/batch = 0.026
Read data: 8.392333984375e-05
iter 10544 (epoch 17), train_loss = 2.325, time/batch = 0.030
Read data: 0.00014972686767578125
iter 10545 (epoch 17), train_loss = 2.418, time/batch = 0.025
Read data: 0.00012755393981933594
iter 10546 (epoch 17), train_loss = 2.777, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 10547 (epoch 17), train_loss = 2.480, time/batch = 0.023
Read data: 0.00011587142944335938
iter 10548 (epoch 17), train_loss = 3.034, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 10549 (epoch 17), train_loss = 2.560, time/batch = 0.021
Read data: 0.0001270771026611328
iter 10550 (epoch 17), train_loss = 2.777, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 10551 (epoch 17), train_loss = 2.550, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 10552 (epoch 17), train_loss = 2.449, time/batch = 0.025
Read data: 0.00011849403381347656
iter 10553 (epoch 17), train_loss = 2.770, time/batch = 0.023
Read data: 0.00012969970703125
iter 10554 (epoch 17), train_loss = 2.734, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 10555 (epoch 17), train_loss = 2.433, time/batch = 0.024
Read data: 0.00012636184692382812
iter 10556 (epoch 17), train_loss = 2.462, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 10557 (epoch 17), train_loss = 2.490, time/batch = 0.027
Read data: 0.00012564659118652344
iter 10558 (epoch 17), train_loss = 2.969, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 10559 (epoch 17), train_loss = 2.587, time/batch = 0.024
Read data: 0.0001373291015625
iter 10560 (epoch 17), train_loss = 2.534, time/batch = 0.026
Read data: 0.0001380443572998047
iter 10561 (epoch 17), train_loss = 2.437, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 10562 (epoch 17), train_loss = 2.833, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 10563 (epoch 17), train_loss = 2.465, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 10564 (epoch 17), train_loss = 2.599, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 10565 (epoch 17), train_loss = 2.434, time/batch = 0.024
Read data: 0.0001571178436279297
iter 10566 (epoch 17), train_loss = 2.811, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 10567 (epoch 17), train_loss = 2.268, time/batch = 0.025
Read data: 0.00012254714965820312
iter 10568 (epoch 17), train_loss = 2.973, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 10569 (epoch 17), train_loss = 2.275, time/batch = 0.026
Read data: 0.0001316070556640625
iter 10570 (epoch 17), train_loss = 2.586, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 10571 (epoch 17), train_loss = 2.205, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 10572 (epoch 17), train_loss = 3.027, time/batch = 0.037
Read data: 8.0108642578125e-05
iter 10573 (epoch 17), train_loss = 2.296, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 10574 (epoch 17), train_loss = 2.735, time/batch = 0.029
Read data: 9.226799011230469e-05
iter 10575 (epoch 17), train_loss = 2.746, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 10576 (epoch 17), train_loss = 2.790, time/batch = 0.027
Read data: 0.000110626220703125
iter 10577 (epoch 17), train_loss = 2.491, time/batch = 0.025
Read data: 0.00011849403381347656
iter 10578 (epoch 17), train_loss = 2.195, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 10579 (epoch 17), train_loss = 2.516, time/batch = 0.026
Read data: 0.00012159347534179688
iter 10580 (epoch 17), train_loss = 2.231, time/batch = 0.029
Read data: 0.00011968612670898438
iter 10581 (epoch 17), train_loss = 2.165, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 10582 (epoch 17), train_loss = 2.283, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 10583 (epoch 17), train_loss = 2.407, time/batch = 0.028
Read data: 0.00010538101196289062
iter 10584 (epoch 17), train_loss = 2.692, time/batch = 0.031
Read data: 0.00011515617370605469
iter 10585 (epoch 17), train_loss = 2.694, time/batch = 0.025
Read data: 0.0001316070556640625
iter 10586 (epoch 17), train_loss = 2.576, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 10587 (epoch 17), train_loss = 2.558, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 10588 (epoch 17), train_loss = 2.923, time/batch = 0.027
Read data: 0.00013399124145507812
iter 10589 (epoch 17), train_loss = 2.441, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 10590 (epoch 17), train_loss = 2.348, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 10591 (epoch 17), train_loss = 2.622, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 10592 (epoch 17), train_loss = 2.995, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 10593 (epoch 17), train_loss = 2.711, time/batch = 0.026
Read data: 0.0001327991485595703
iter 10594 (epoch 17), train_loss = 2.446, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 10595 (epoch 17), train_loss = 2.072, time/batch = 0.024
Read data: 0.0001201629638671875
iter 10596 (epoch 17), train_loss = 2.776, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 10597 (epoch 17), train_loss = 2.762, time/batch = 0.024
Read data: 0.000148773193359375
iter 10598 (epoch 17), train_loss = 2.698, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 10599 (epoch 17), train_loss = 2.703, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 10600 (epoch 17), train_loss = 2.873, time/batch = 0.029
Read data: 0.0001468658447265625
iter 10601 (epoch 17), train_loss = 2.464, time/batch = 0.023
Read data: 0.0001327991485595703
iter 10602 (epoch 17), train_loss = 2.365, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 10603 (epoch 17), train_loss = 2.416, time/batch = 0.027
Read data: 0.00013828277587890625
iter 10604 (epoch 17), train_loss = 2.731, time/batch = 0.036
Read data: 8.7738037109375e-05
iter 10605 (epoch 17), train_loss = 2.190, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 10606 (epoch 17), train_loss = 2.550, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 10607 (epoch 17), train_loss = 2.621, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 10608 (epoch 17), train_loss = 2.697, time/batch = 0.028
Read data: 0.00011372566223144531
iter 10609 (epoch 17), train_loss = 2.399, time/batch = 0.021
Read data: 0.0001277923583984375
iter 10610 (epoch 17), train_loss = 2.693, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 10611 (epoch 17), train_loss = 2.294, time/batch = 0.022
Read data: 0.00013256072998046875
iter 10612 (epoch 17), train_loss = 2.660, time/batch = 0.023
Read data: 0.00015115737915039062
iter 10613 (epoch 17), train_loss = 2.578, time/batch = 0.028
Read data: 0.00012683868408203125
iter 10614 (epoch 17), train_loss = 2.205, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 10615 (epoch 17), train_loss = 2.253, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 10616 (epoch 17), train_loss = 2.348, time/batch = 0.027
Read data: 0.00011944770812988281
iter 10617 (epoch 17), train_loss = 2.365, time/batch = 0.021
Read data: 0.00013375282287597656
iter 10618 (epoch 17), train_loss = 2.089, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 10619 (epoch 17), train_loss = 2.706, time/batch = 0.024
Read data: 0.00014066696166992188
iter 10620 (epoch 17), train_loss = 2.621, time/batch = 0.022
Read data: 0.0001575946807861328
iter 10621 (epoch 17), train_loss = 2.245, time/batch = 0.030
Read data: 0.00013446807861328125
iter 10622 (epoch 17), train_loss = 2.562, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 10623 (epoch 17), train_loss = 2.843, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 10624 (epoch 17), train_loss = 2.482, time/batch = 0.023
Read data: 0.0002276897430419922
iter 10625 (epoch 17), train_loss = 2.387, time/batch = 0.024
Read data: 0.00017333030700683594
iter 10626 (epoch 17), train_loss = 2.895, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 10627 (epoch 17), train_loss = 2.557, time/batch = 0.023
Read data: 0.00013256072998046875
iter 10628 (epoch 17), train_loss = 2.530, time/batch = 0.031
Read data: 0.00013017654418945312
iter 10629 (epoch 17), train_loss = 2.687, time/batch = 0.023
Read data: 0.00012373924255371094
iter 10630 (epoch 17), train_loss = 2.341, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 10631 (epoch 17), train_loss = 2.409, time/batch = 0.026
Read data: 0.0001316070556640625
iter 10632 (epoch 17), train_loss = 2.514, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 10633 (epoch 17), train_loss = 2.397, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 10634 (epoch 17), train_loss = 2.424, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 10635 (epoch 17), train_loss = 2.613, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 10636 (epoch 17), train_loss = 2.570, time/batch = 0.033
Read data: 0.00014781951904296875
iter 10637 (epoch 17), train_loss = 2.349, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 10638 (epoch 17), train_loss = 2.658, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 10639 (epoch 17), train_loss = 2.720, time/batch = 0.035
Read data: 8.487701416015625e-05
iter 10640 (epoch 17), train_loss = 2.425, time/batch = 0.031
Read data: 8.940696716308594e-05
iter 10641 (epoch 17), train_loss = 2.488, time/batch = 0.028
Read data: 0.0001430511474609375
iter 10642 (epoch 17), train_loss = 2.414, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 10643 (epoch 17), train_loss = 2.842, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 10644 (epoch 17), train_loss = 2.405, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 10645 (epoch 17), train_loss = 2.982, time/batch = 0.030
Read data: 0.00017380714416503906
iter 10646 (epoch 17), train_loss = 2.366, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 10647 (epoch 17), train_loss = 2.523, time/batch = 0.022
Read data: 0.00012183189392089844
iter 10648 (epoch 17), train_loss = 2.170, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 10649 (epoch 17), train_loss = 3.191, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 10650 (epoch 17), train_loss = 2.370, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 10651 (epoch 17), train_loss = 2.762, time/batch = 0.023
Read data: 7.724761962890625e-05
iter 10652 (epoch 17), train_loss = 2.919, time/batch = 0.025
Read data: 0.00011682510375976562
iter 10653 (epoch 17), train_loss = 2.983, time/batch = 0.023
Read data: 0.00011014938354492188
iter 10654 (epoch 17), train_loss = 2.619, time/batch = 0.039
Read data: 8.106231689453125e-05
iter 10655 (epoch 17), train_loss = 2.411, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 10656 (epoch 17), train_loss = 2.590, time/batch = 0.024
Read data: 0.0001361370086669922
iter 10657 (epoch 17), train_loss = 2.557, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 10658 (epoch 17), train_loss = 2.212, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 10659 (epoch 17), train_loss = 2.575, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 10660 (epoch 17), train_loss = 2.408, time/batch = 0.026
Read data: 0.00014352798461914062
iter 10661 (epoch 17), train_loss = 3.174, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 10662 (epoch 17), train_loss = 2.611, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 10663 (epoch 17), train_loss = 2.383, time/batch = 0.036
Read data: 0.00011324882507324219
iter 10664 (epoch 17), train_loss = 2.279, time/batch = 0.029
Read data: 0.0001456737518310547
iter 10665 (epoch 17), train_loss = 2.335, time/batch = 0.022
Read data: 0.0001285076141357422
iter 10666 (epoch 17), train_loss = 2.893, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 10667 (epoch 17), train_loss = 2.438, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 10668 (epoch 17), train_loss = 2.851, time/batch = 0.026
Read data: 0.00013327598571777344
iter 10669 (epoch 17), train_loss = 2.623, time/batch = 0.025
Read data: 0.00012540817260742188
iter 10670 (epoch 17), train_loss = 2.519, time/batch = 0.032
Read data: 7.724761962890625e-05
iter 10671 (epoch 17), train_loss = 2.678, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 10672 (epoch 17), train_loss = 2.779, time/batch = 0.024
Read data: 0.00011658668518066406
iter 10673 (epoch 17), train_loss = 2.201, time/batch = 0.020
Read data: 0.0016889572143554688
iter 10674 (epoch 17), train_loss = 2.797, time/batch = 0.024
Read data: 0.00019931793212890625
iter 10675 (epoch 17), train_loss = 2.830, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 10676 (epoch 17), train_loss = 2.470, time/batch = 0.023
Read data: 0.00011610984802246094
iter 10677 (epoch 17), train_loss = 3.014, time/batch = 0.033
Read data: 0.00012445449829101562
iter 10678 (epoch 17), train_loss = 2.422, time/batch = 0.021
Read data: 0.00011348724365234375
iter 10679 (epoch 17), train_loss = 2.515, time/batch = 0.021
Read data: 8.869171142578125e-05
iter 10680 (epoch 17), train_loss = 2.411, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 10681 (epoch 17), train_loss = 2.619, time/batch = 0.031
Read data: 0.00014734268188476562
iter 10682 (epoch 17), train_loss = 2.746, time/batch = 0.027
Read data: 0.00011301040649414062
iter 10683 (epoch 17), train_loss = 2.768, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 10684 (epoch 17), train_loss = 2.332, time/batch = 0.024
Read data: 0.00011754035949707031
iter 10685 (epoch 17), train_loss = 2.247, time/batch = 0.028
Read data: 0.00012755393981933594
iter 10686 (epoch 17), train_loss = 2.110, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 10687 (epoch 17), train_loss = 2.408, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 10688 (epoch 17), train_loss = 2.494, time/batch = 0.031
Read data: 0.00014495849609375
iter 10689 (epoch 17), train_loss = 2.626, time/batch = 0.024
Read data: 0.0001590251922607422
iter 10690 (epoch 17), train_loss = 2.752, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 10691 (epoch 17), train_loss = 3.059, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 10692 (epoch 17), train_loss = 2.278, time/batch = 0.021
Read data: 9.465217590332031e-05
iter 10693 (epoch 17), train_loss = 2.442, time/batch = 0.024
Read data: 0.0001461505889892578
iter 10694 (epoch 17), train_loss = 2.139, time/batch = 0.026
Read data: 0.00013303756713867188
iter 10695 (epoch 17), train_loss = 2.581, time/batch = 0.028
Read data: 9.393692016601562e-05
iter 10696 (epoch 17), train_loss = 2.608, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 10697 (epoch 17), train_loss = 2.427, time/batch = 0.024
Read data: 0.00017952919006347656
iter 10698 (epoch 17), train_loss = 2.187, time/batch = 0.026
Read data: 0.00011491775512695312
iter 10699 (epoch 17), train_loss = 2.854, time/batch = 0.032
Read data: 0.00019693374633789062
iter 10700 (epoch 17), train_loss = 2.556, time/batch = 0.023
Read data: 0.00016355514526367188
iter 10701 (epoch 17), train_loss = 2.357, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 10702 (epoch 17), train_loss = 2.531, time/batch = 0.032
Read data: 7.772445678710938e-05
iter 10703 (epoch 17), train_loss = 2.441, time/batch = 0.021
Read data: 9.822845458984375e-05
iter 10704 (epoch 17), train_loss = 2.912, time/batch = 0.027
Read data: 0.00011849403381347656
iter 10705 (epoch 17), train_loss = 2.211, time/batch = 0.022
Read data: 0.00013065338134765625
iter 10706 (epoch 17), train_loss = 2.340, time/batch = 0.024
Read data: 0.00011539459228515625
iter 10707 (epoch 17), train_loss = 2.539, time/batch = 0.027
Read data: 0.00010800361633300781
iter 10708 (epoch 17), train_loss = 3.032, time/batch = 0.030
Read data: 0.00011682510375976562
iter 10709 (epoch 17), train_loss = 2.426, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 10710 (epoch 17), train_loss = 2.401, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 10711 (epoch 17), train_loss = 2.630, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 10712 (epoch 17), train_loss = 2.886, time/batch = 0.027
Read data: 0.0001437664031982422
iter 10713 (epoch 17), train_loss = 2.552, time/batch = 0.020
Read data: 0.00018906593322753906
iter 10714 (epoch 17), train_loss = 2.976, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 10715 (epoch 17), train_loss = 2.908, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 10716 (epoch 17), train_loss = 2.396, time/batch = 0.030
Read data: 0.00011897087097167969
iter 10717 (epoch 17), train_loss = 2.572, time/batch = 0.030
Read data: 0.00013589859008789062
iter 10718 (epoch 17), train_loss = 3.051, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 10719 (epoch 17), train_loss = 2.465, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 10720 (epoch 17), train_loss = 2.585, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 10721 (epoch 17), train_loss = 2.846, time/batch = 0.028
Read data: 0.00012731552124023438
iter 10722 (epoch 17), train_loss = 2.554, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 10723 (epoch 17), train_loss = 2.581, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 10724 (epoch 17), train_loss = 2.643, time/batch = 0.026
Read data: 0.0002663135528564453
iter 10725 (epoch 17), train_loss = 2.471, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 10726 (epoch 17), train_loss = 2.582, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 10727 (epoch 17), train_loss = 2.530, time/batch = 0.022
Read data: 9.775161743164062e-05
iter 10728 (epoch 17), train_loss = 2.782, time/batch = 0.028
Read data: 0.00012350082397460938
iter 10729 (epoch 17), train_loss = 2.199, time/batch = 0.038
Read data: 9.083747863769531e-05
iter 10730 (epoch 17), train_loss = 2.514, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 10731 (epoch 17), train_loss = 2.922, time/batch = 0.028
Read data: 0.000110626220703125
iter 10732 (epoch 17), train_loss = 2.287, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 10733 (epoch 17), train_loss = 2.293, time/batch = 0.024
Read data: 0.00012803077697753906
iter 10734 (epoch 17), train_loss = 2.777, time/batch = 0.024
Read data: 0.00010776519775390625
iter 10735 (epoch 17), train_loss = 2.368, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 10736 (epoch 17), train_loss = 2.742, time/batch = 0.030
Read data: 0.00014734268188476562
iter 10737 (epoch 17), train_loss = 2.919, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 10738 (epoch 17), train_loss = 2.114, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 10739 (epoch 17), train_loss = 2.418, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 10740 (epoch 17), train_loss = 2.799, time/batch = 0.036
Read data: 7.987022399902344e-05
iter 10741 (epoch 17), train_loss = 2.546, time/batch = 0.023
Read data: 0.0001304149627685547
iter 10742 (epoch 17), train_loss = 2.298, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 10743 (epoch 17), train_loss = 2.462, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 10744 (epoch 17), train_loss = 3.046, time/batch = 0.030
Read data: 0.00011372566223144531
iter 10745 (epoch 17), train_loss = 2.856, time/batch = 0.035
Read data: 0.00011277198791503906
iter 10746 (epoch 17), train_loss = 2.686, time/batch = 0.026
Read data: 0.00012135505676269531
iter 10747 (epoch 17), train_loss = 3.185, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 10748 (epoch 17), train_loss = 2.801, time/batch = 0.027
Read data: 0.00011730194091796875
iter 10749 (epoch 17), train_loss = 2.835, time/batch = 0.026
Read data: 0.00021266937255859375
iter 10750 (epoch 17), train_loss = 2.868, time/batch = 0.021
Read data: 9.799003601074219e-05
iter 10751 (epoch 17), train_loss = 2.236, time/batch = 0.020
Read data: 9.393692016601562e-05
iter 10752 (epoch 17), train_loss = 2.517, time/batch = 0.027
Read data: 0.0001163482666015625
iter 10753 (epoch 17), train_loss = 2.663, time/batch = 0.025
Read data: 0.0001437664031982422
iter 10754 (epoch 17), train_loss = 2.701, time/batch = 0.033
Read data: 7.772445678710938e-05
iter 10755 (epoch 17), train_loss = 3.066, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 10756 (epoch 17), train_loss = 2.941, time/batch = 0.032
Read data: 0.00011110305786132812
iter 10757 (epoch 17), train_loss = 2.469, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 10758 (epoch 17), train_loss = 2.617, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 10759 (epoch 17), train_loss = 2.688, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 10760 (epoch 17), train_loss = 2.472, time/batch = 0.026
Read data: 0.00011706352233886719
iter 10761 (epoch 17), train_loss = 2.590, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 10762 (epoch 17), train_loss = 2.689, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 10763 (epoch 17), train_loss = 2.757, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 10764 (epoch 17), train_loss = 2.810, time/batch = 0.023
Read data: 0.00011730194091796875
iter 10765 (epoch 17), train_loss = 2.537, time/batch = 0.027
Read data: 0.00013184547424316406
iter 10766 (epoch 17), train_loss = 2.497, time/batch = 0.023
Read data: 0.00011110305786132812
iter 10767 (epoch 17), train_loss = 2.369, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 10768 (epoch 17), train_loss = 2.617, time/batch = 0.025
Read data: 0.00011968612670898438
iter 10769 (epoch 17), train_loss = 2.500, time/batch = 0.025
Read data: 0.0001423358917236328
iter 10770 (epoch 17), train_loss = 2.490, time/batch = 0.024
Read data: 0.000110626220703125
iter 10771 (epoch 17), train_loss = 2.390, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 10772 (epoch 17), train_loss = 2.507, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 10773 (epoch 17), train_loss = 2.633, time/batch = 0.028
Read data: 0.00014138221740722656
iter 10774 (epoch 17), train_loss = 2.615, time/batch = 0.027
Read data: 0.00010991096496582031
iter 10775 (epoch 17), train_loss = 2.874, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 10776 (epoch 17), train_loss = 3.042, time/batch = 0.026
Read data: 0.00011277198791503906
iter 10777 (epoch 17), train_loss = 2.595, time/batch = 0.032
Read data: 0.00013303756713867188
iter 10778 (epoch 17), train_loss = 2.750, time/batch = 0.036
Read data: 0.0001430511474609375
iter 10779 (epoch 17), train_loss = 2.653, time/batch = 0.033
Read data: 0.00012159347534179688
iter 10780 (epoch 17), train_loss = 2.238, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 10781 (epoch 17), train_loss = 2.827, time/batch = 0.024
Read data: 0.0001323223114013672
iter 10782 (epoch 17), train_loss = 2.684, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 10783 (epoch 17), train_loss = 2.688, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 10784 (epoch 17), train_loss = 2.354, time/batch = 0.024
Read data: 0.00011467933654785156
iter 10785 (epoch 17), train_loss = 2.934, time/batch = 0.035
Read data: 0.0001583099365234375
iter 10786 (epoch 17), train_loss = 2.574, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 10787 (epoch 17), train_loss = 2.184, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 10788 (epoch 17), train_loss = 2.531, time/batch = 0.032
Read data: 0.00012230873107910156
iter 10789 (epoch 17), train_loss = 2.556, time/batch = 0.026
Read data: 0.0001552104949951172
iter 10790 (epoch 17), train_loss = 2.671, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 10791 (epoch 17), train_loss = 2.673, time/batch = 0.030
Read data: 0.0009725093841552734
iter 10792 (epoch 17), train_loss = 2.652, time/batch = 0.037
Read data: 8.368492126464844e-05
iter 10793 (epoch 17), train_loss = 2.810, time/batch = 0.027
Read data: 0.00011587142944335938
iter 10794 (epoch 17), train_loss = 2.289, time/batch = 0.028
Read data: 0.0001423358917236328
iter 10795 (epoch 17), train_loss = 2.383, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 10796 (epoch 17), train_loss = 2.776, time/batch = 0.031
Read data: 0.00014972686767578125
iter 10797 (epoch 17), train_loss = 2.421, time/batch = 0.022
Read data: 0.0001609325408935547
iter 10798 (epoch 17), train_loss = 2.353, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 10799 (epoch 17), train_loss = 2.380, time/batch = 0.035
Read data: 0.00012135505676269531
iter 10800 (epoch 17), train_loss = 2.353, time/batch = 0.025
Read data: 0.00012946128845214844
iter 10801 (epoch 18), train_loss = 2.171, time/batch = 0.021
Read data: 0.0001323223114013672
iter 10802 (epoch 18), train_loss = 2.652, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 10803 (epoch 18), train_loss = 2.399, time/batch = 0.021
Read data: 9.179115295410156e-05
iter 10804 (epoch 18), train_loss = 2.101, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 10805 (epoch 18), train_loss = 2.585, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 10806 (epoch 18), train_loss = 2.111, time/batch = 0.021
Read data: 0.00011563301086425781
iter 10807 (epoch 18), train_loss = 2.006, time/batch = 0.024
Read data: 7.62939453125e-05
iter 10808 (epoch 18), train_loss = 2.965, time/batch = 0.021
Read data: 9.465217590332031e-05
iter 10809 (epoch 18), train_loss = 2.578, time/batch = 0.024
Read data: 0.0001468658447265625
iter 10810 (epoch 18), train_loss = 2.395, time/batch = 0.027
Read data: 0.00011777877807617188
iter 10811 (epoch 18), train_loss = 2.307, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 10812 (epoch 18), train_loss = 2.267, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 10813 (epoch 18), train_loss = 2.664, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 10814 (epoch 18), train_loss = 2.343, time/batch = 0.027
Read data: 0.00011086463928222656
iter 10815 (epoch 18), train_loss = 2.137, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 10816 (epoch 18), train_loss = 2.636, time/batch = 0.024
Read data: 0.00010156631469726562
iter 10817 (epoch 18), train_loss = 2.585, time/batch = 0.026
Read data: 0.00014209747314453125
iter 10818 (epoch 18), train_loss = 2.499, time/batch = 0.026
Read data: 0.00011849403381347656
iter 10819 (epoch 18), train_loss = 2.377, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 10820 (epoch 18), train_loss = 2.329, time/batch = 0.023
Read data: 0.0016639232635498047
iter 10821 (epoch 18), train_loss = 2.439, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 10822 (epoch 18), train_loss = 2.453, time/batch = 0.021
Read data: 0.00011754035949707031
iter 10823 (epoch 18), train_loss = 2.345, time/batch = 0.026
Read data: 0.00012755393981933594
iter 10824 (epoch 18), train_loss = 2.222, time/batch = 0.025
Read data: 0.0002346038818359375
iter 10825 (epoch 18), train_loss = 2.649, time/batch = 0.026
Read data: 0.00017714500427246094
iter 10826 (epoch 18), train_loss = 2.453, time/batch = 0.025
Read data: 0.00011229515075683594
iter 10827 (epoch 18), train_loss = 2.686, time/batch = 0.032
Read data: 8.249282836914062e-05
iter 10828 (epoch 18), train_loss = 3.102, time/batch = 0.033
Read data: 8.463859558105469e-05
iter 10829 (epoch 18), train_loss = 2.484, time/batch = 0.026
Read data: 0.0001327991485595703
iter 10830 (epoch 18), train_loss = 2.618, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 10831 (epoch 18), train_loss = 2.858, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 10832 (epoch 18), train_loss = 2.545, time/batch = 0.021
Read data: 0.00016880035400390625
iter 10833 (epoch 18), train_loss = 2.396, time/batch = 0.024
Read data: 0.00014734268188476562
iter 10834 (epoch 18), train_loss = 2.626, time/batch = 0.025
Read data: 0.00012302398681640625
iter 10835 (epoch 18), train_loss = 2.629, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 10836 (epoch 18), train_loss = 2.272, time/batch = 0.027
Read data: 0.00010180473327636719
iter 10837 (epoch 18), train_loss = 2.646, time/batch = 0.032
Read data: 0.00012493133544921875
iter 10838 (epoch 18), train_loss = 2.261, time/batch = 0.027
Read data: 0.00011157989501953125
iter 10839 (epoch 18), train_loss = 2.537, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 10840 (epoch 18), train_loss = 2.549, time/batch = 0.034
Read data: 8.082389831542969e-05
iter 10841 (epoch 18), train_loss = 2.531, time/batch = 0.025
Read data: 0.0001621246337890625
iter 10842 (epoch 18), train_loss = 3.017, time/batch = 0.027
Read data: 0.0001480579376220703
iter 10843 (epoch 18), train_loss = 2.339, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 10844 (epoch 18), train_loss = 2.341, time/batch = 0.023
Read data: 0.00010156631469726562
iter 10845 (epoch 18), train_loss = 2.521, time/batch = 0.031
Read data: 8.392333984375e-05
iter 10846 (epoch 18), train_loss = 2.673, time/batch = 0.024
Read data: 0.00010061264038085938
iter 10847 (epoch 18), train_loss = 2.715, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 10848 (epoch 18), train_loss = 2.395, time/batch = 0.023
Read data: 0.00016498565673828125
iter 10849 (epoch 18), train_loss = 2.410, time/batch = 0.031
Read data: 0.00022554397583007812
iter 10850 (epoch 18), train_loss = 2.707, time/batch = 0.028
Read data: 0.00011539459228515625
iter 10851 (epoch 18), train_loss = 2.634, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 10852 (epoch 18), train_loss = 2.702, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 10853 (epoch 18), train_loss = 2.387, time/batch = 0.022
Read data: 9.1552734375e-05
iter 10854 (epoch 18), train_loss = 2.167, time/batch = 0.025
Read data: 0.00014662742614746094
iter 10855 (epoch 18), train_loss = 2.338, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 10856 (epoch 18), train_loss = 2.554, time/batch = 0.025
Read data: 0.0001773834228515625
iter 10857 (epoch 18), train_loss = 3.081, time/batch = 0.036
Read data: 0.000133514404296875
iter 10858 (epoch 18), train_loss = 2.616, time/batch = 0.024
Read data: 0.00011491775512695312
iter 10859 (epoch 18), train_loss = 2.952, time/batch = 0.021
Read data: 8.344650268554688e-05
iter 10860 (epoch 18), train_loss = 3.094, time/batch = 0.023
Read data: 0.00011610984802246094
iter 10861 (epoch 18), train_loss = 2.428, time/batch = 0.026
Read data: 0.00014352798461914062
iter 10862 (epoch 18), train_loss = 2.487, time/batch = 0.029
Read data: 9.584426879882812e-05
iter 10863 (epoch 18), train_loss = 2.220, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 10864 (epoch 18), train_loss = 2.971, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 10865 (epoch 18), train_loss = 2.281, time/batch = 0.021
Read data: 0.00010323524475097656
iter 10866 (epoch 18), train_loss = 2.891, time/batch = 0.031
Read data: 0.000110626220703125
iter 10867 (epoch 18), train_loss = 2.706, time/batch = 0.024
Read data: 9.1552734375e-05
iter 10868 (epoch 18), train_loss = 2.689, time/batch = 0.032
Read data: 0.00013494491577148438
iter 10869 (epoch 18), train_loss = 2.680, time/batch = 0.035
Read data: 0.0001404285430908203
iter 10870 (epoch 18), train_loss = 2.120, time/batch = 0.031
Read data: 8.726119995117188e-05
iter 10871 (epoch 18), train_loss = 2.546, time/batch = 0.028
Read data: 0.0001163482666015625
iter 10872 (epoch 18), train_loss = 2.579, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 10873 (epoch 18), train_loss = 2.334, time/batch = 0.022
Read data: 0.00012731552124023438
iter 10874 (epoch 18), train_loss = 2.289, time/batch = 0.028
Read data: 0.0002052783966064453
iter 10875 (epoch 18), train_loss = 2.665, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 10876 (epoch 18), train_loss = 2.835, time/batch = 0.022
Read data: 0.00019359588623046875
iter 10877 (epoch 18), train_loss = 2.657, time/batch = 0.030
Read data: 0.00012636184692382812
iter 10878 (epoch 18), train_loss = 2.514, time/batch = 0.023
Read data: 0.00011897087097167969
iter 10879 (epoch 18), train_loss = 2.779, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 10880 (epoch 18), train_loss = 2.366, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 10881 (epoch 18), train_loss = 2.556, time/batch = 0.026
Read data: 0.00013113021850585938
iter 10882 (epoch 18), train_loss = 2.893, time/batch = 0.030
Read data: 0.00012111663818359375
iter 10883 (epoch 18), train_loss = 2.493, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 10884 (epoch 18), train_loss = 3.124, time/batch = 0.027
Read data: 0.00011873245239257812
iter 10885 (epoch 18), train_loss = 2.561, time/batch = 0.024
Read data: 0.00012373924255371094
iter 10886 (epoch 18), train_loss = 2.902, time/batch = 0.024
Read data: 0.00011205673217773438
iter 10887 (epoch 18), train_loss = 2.284, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 10888 (epoch 18), train_loss = 2.395, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 10889 (epoch 18), train_loss = 2.378, time/batch = 0.023
Read data: 0.00010633468627929688
iter 10890 (epoch 18), train_loss = 2.356, time/batch = 0.029
Read data: 0.00014710426330566406
iter 10891 (epoch 18), train_loss = 2.792, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 10892 (epoch 18), train_loss = 2.725, time/batch = 0.033
Read data: 0.00014901161193847656
iter 10893 (epoch 18), train_loss = 2.528, time/batch = 0.022
Read data: 0.00016427040100097656
iter 10894 (epoch 18), train_loss = 2.769, time/batch = 0.026
Read data: 0.00014257431030273438
iter 10895 (epoch 18), train_loss = 2.710, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 10896 (epoch 18), train_loss = 2.271, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 10897 (epoch 18), train_loss = 2.297, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 10898 (epoch 18), train_loss = 2.694, time/batch = 0.026
Read data: 0.00011944770812988281
iter 10899 (epoch 18), train_loss = 2.558, time/batch = 0.024
Read data: 0.00017690658569335938
iter 10900 (epoch 18), train_loss = 2.820, time/batch = 0.025
Read data: 0.00011706352233886719
iter 10901 (epoch 18), train_loss = 2.416, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 10902 (epoch 18), train_loss = 2.522, time/batch = 0.028
Read data: 9.608268737792969e-05
iter 10903 (epoch 18), train_loss = 3.062, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 10904 (epoch 18), train_loss = 2.418, time/batch = 0.023
Read data: 0.00010824203491210938
iter 10905 (epoch 18), train_loss = 2.493, time/batch = 0.024
Read data: 0.00014710426330566406
iter 10906 (epoch 18), train_loss = 2.391, time/batch = 0.025
Read data: 0.00011658668518066406
iter 10907 (epoch 18), train_loss = 2.777, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 10908 (epoch 18), train_loss = 2.922, time/batch = 0.031
Read data: 9.34600830078125e-05
iter 10909 (epoch 18), train_loss = 2.488, time/batch = 0.030
Read data: 0.0001583099365234375
iter 10910 (epoch 18), train_loss = 2.603, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 10911 (epoch 18), train_loss = 2.611, time/batch = 0.026
Read data: 0.00010371208190917969
iter 10912 (epoch 18), train_loss = 2.420, time/batch = 0.036
Read data: 0.00015425682067871094
iter 10913 (epoch 18), train_loss = 2.563, time/batch = 0.023
Read data: 0.00010418891906738281
iter 10914 (epoch 18), train_loss = 3.099, time/batch = 0.036
Read data: 8.678436279296875e-05
iter 10915 (epoch 18), train_loss = 2.846, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 10916 (epoch 18), train_loss = 2.399, time/batch = 0.037
Read data: 9.489059448242188e-05
iter 10917 (epoch 18), train_loss = 2.460, time/batch = 0.027
Read data: 0.0001418590545654297
iter 10918 (epoch 18), train_loss = 2.552, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 10919 (epoch 18), train_loss = 2.553, time/batch = 0.019
Read data: 8.96453857421875e-05
iter 10920 (epoch 18), train_loss = 2.182, time/batch = 0.029
Read data: 0.00011348724365234375
iter 10921 (epoch 18), train_loss = 2.652, time/batch = 0.026
Read data: 0.0001277923583984375
iter 10922 (epoch 18), train_loss = 2.297, time/batch = 0.023
Read data: 0.00011420249938964844
iter 10923 (epoch 18), train_loss = 2.394, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 10924 (epoch 18), train_loss = 2.913, time/batch = 0.021
Read data: 0.00011157989501953125
iter 10925 (epoch 18), train_loss = 2.805, time/batch = 0.025
Read data: 0.0001747608184814453
iter 10926 (epoch 18), train_loss = 2.562, time/batch = 0.027
Read data: 0.00011515617370605469
iter 10927 (epoch 18), train_loss = 2.674, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 10928 (epoch 18), train_loss = 2.882, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 10929 (epoch 18), train_loss = 2.299, time/batch = 0.025
Read data: 0.00013113021850585938
iter 10930 (epoch 18), train_loss = 2.374, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 10931 (epoch 18), train_loss = 2.315, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 10932 (epoch 18), train_loss = 2.333, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 10933 (epoch 18), train_loss = 2.839, time/batch = 0.022
Read data: 9.298324584960938e-05
iter 10934 (epoch 18), train_loss = 2.558, time/batch = 0.025
Read data: 0.00011491775512695312
iter 10935 (epoch 18), train_loss = 1.968, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 10936 (epoch 18), train_loss = 2.603, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 10937 (epoch 18), train_loss = 2.780, time/batch = 0.026
Read data: 0.0001347064971923828
iter 10938 (epoch 18), train_loss = 2.036, time/batch = 0.023
Read data: 0.00010585784912109375
iter 10939 (epoch 18), train_loss = 2.506, time/batch = 0.023
Read data: 0.0001220703125
iter 10940 (epoch 18), train_loss = 2.513, time/batch = 0.024
Read data: 0.00012111663818359375
iter 10941 (epoch 18), train_loss = 2.879, time/batch = 0.029
Read data: 9.274482727050781e-05
iter 10942 (epoch 18), train_loss = 2.378, time/batch = 0.027
Read data: 0.0001430511474609375
iter 10943 (epoch 18), train_loss = 2.684, time/batch = 0.022
Read data: 7.82012939453125e-05
iter 10944 (epoch 18), train_loss = 1.870, time/batch = 0.025
Read data: 0.000110626220703125
iter 10945 (epoch 18), train_loss = 2.579, time/batch = 0.035
Read data: 0.00015234947204589844
iter 10946 (epoch 18), train_loss = 2.689, time/batch = 0.023
Read data: 0.00020170211791992188
iter 10947 (epoch 18), train_loss = 2.321, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 10948 (epoch 18), train_loss = 2.545, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 10949 (epoch 18), train_loss = 2.420, time/batch = 0.026
Read data: 0.00020623207092285156
iter 10950 (epoch 18), train_loss = 2.769, time/batch = 0.035
Read data: 8.869171142578125e-05
iter 10951 (epoch 18), train_loss = 2.533, time/batch = 0.028
Read data: 0.00012445449829101562
iter 10952 (epoch 18), train_loss = 2.058, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 10953 (epoch 18), train_loss = 2.594, time/batch = 0.024
Read data: 0.00012874603271484375
iter 10954 (epoch 18), train_loss = 2.588, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 10955 (epoch 18), train_loss = 2.205, time/batch = 0.020
Read data: 8.821487426757812e-05
iter 10956 (epoch 18), train_loss = 2.502, time/batch = 0.025
Read data: 0.0001201629638671875
iter 10957 (epoch 18), train_loss = 2.516, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 10958 (epoch 18), train_loss = 2.567, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 10959 (epoch 18), train_loss = 2.457, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 10960 (epoch 18), train_loss = 2.486, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 10961 (epoch 18), train_loss = 2.666, time/batch = 0.028
Read data: 0.00012636184692382812
iter 10962 (epoch 18), train_loss = 2.804, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 10963 (epoch 18), train_loss = 2.437, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 10964 (epoch 18), train_loss = 2.729, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 10965 (epoch 18), train_loss = 2.693, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 10966 (epoch 18), train_loss = 2.911, time/batch = 0.033
Read data: 8.153915405273438e-05
iter 10967 (epoch 18), train_loss = 2.273, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 10968 (epoch 18), train_loss = 2.368, time/batch = 0.027
Read data: 0.00011897087097167969
iter 10969 (epoch 18), train_loss = 2.757, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 10970 (epoch 18), train_loss = 2.649, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 10971 (epoch 18), train_loss = 2.474, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 10972 (epoch 18), train_loss = 2.467, time/batch = 0.031
Read data: 0.0001201629638671875
iter 10973 (epoch 18), train_loss = 2.468, time/batch = 0.024
Read data: 0.0001304149627685547
iter 10974 (epoch 18), train_loss = 2.069, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 10975 (epoch 18), train_loss = 2.137, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 10976 (epoch 18), train_loss = 2.460, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 10977 (epoch 18), train_loss = 2.341, time/batch = 0.025
Read data: 0.00012874603271484375
iter 10978 (epoch 18), train_loss = 2.526, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 10979 (epoch 18), train_loss = 2.140, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 10980 (epoch 18), train_loss = 2.599, time/batch = 0.023
Read data: 0.00010466575622558594
iter 10981 (epoch 18), train_loss = 2.423, time/batch = 0.024
Read data: 0.00013971328735351562
iter 10982 (epoch 18), train_loss = 2.596, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 10983 (epoch 18), train_loss = 2.523, time/batch = 0.020
Read data: 0.0001652240753173828
iter 10984 (epoch 18), train_loss = 2.810, time/batch = 0.025
Read data: 0.00011610984802246094
iter 10985 (epoch 18), train_loss = 2.507, time/batch = 0.027
Read data: 0.00013327598571777344
iter 10986 (epoch 18), train_loss = 2.739, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 10987 (epoch 18), train_loss = 2.144, time/batch = 0.024
Read data: 0.0001652240753173828
iter 10988 (epoch 18), train_loss = 2.431, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 10989 (epoch 18), train_loss = 2.513, time/batch = 0.020
Read data: 0.00015163421630859375
iter 10990 (epoch 18), train_loss = 2.600, time/batch = 0.024
Read data: 0.000141143798828125
iter 10991 (epoch 18), train_loss = 2.498, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 10992 (epoch 18), train_loss = 2.602, time/batch = 0.029
Read data: 0.00010037422180175781
iter 10993 (epoch 18), train_loss = 2.604, time/batch = 0.025
Read data: 0.00017404556274414062
iter 10994 (epoch 18), train_loss = 2.624, time/batch = 0.031
Read data: 9.608268737792969e-05
iter 10995 (epoch 18), train_loss = 2.729, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 10996 (epoch 18), train_loss = 2.691, time/batch = 0.041
Read data: 8.678436279296875e-05
iter 10997 (epoch 18), train_loss = 2.483, time/batch = 0.024
Read data: 0.00010991096496582031
iter 10998 (epoch 18), train_loss = 2.857, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 10999 (epoch 18), train_loss = 1.968, time/batch = 0.027
image 976:    
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:      
image 2375:      
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.638891)
image 2798:     
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:      
evaluating validation preformance... 20/1000 (2.254724)
image 6903:    
image 3301:    
image 2019:    
image 5535:     
image 7680:     
image 5527:      
image 2568:    
image 160:    
image 8085:      
image 7670:      
evaluating validation preformance... 30/1000 (2.573783)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.930071)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:    
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.524251)
image 4940:      
image 4905:    UNK
image 469:    
image 102:    
image 6009:    UNK
image 4271:     
image 6329:    
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (2.824950)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.608645)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:    
image 2242:    
evaluating validation preformance... 80/1000 (2.685772)
image 3276:      
image 3812:   
image 1400:    
image 3443:    
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.150493)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:      
image 1165:    
image 6553:    
evaluating validation preformance... 100/1000 (2.918596)
image 2800:    
image 7249:    
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:      
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.832643)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:    
image 1450:    
image 3979:      
image 5302:    UNK
evaluating validation preformance... 120/1000 (2.390133)
image 3477:     
image 1212:     
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.927207)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:      
image 5542:     
image 8068:   
image 4450:    
image 1524:    
image 2867:     
evaluating validation preformance... 140/1000 (2.682058)
image 1738:     
image 1455:     
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:     
evaluating validation preformance... 150/1000 (2.915220)
image 1865:     
image 3830:      
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.822455)
image 4297:    
image 3315:     
image 1107:    
image 2051:     
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.589793)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:    
image 3000:    
image 1806:    
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.685829)
image 2313:    
image 6289:    
image 8084:   
image 2696:    
image 5830:     
image 6240:      
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.459704)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:    
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.287593)
image 5159:    
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.463615)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942:    
image 618:    
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.558840)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.246063)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.193248)
image 7143:     
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (2.574399)
image 3028:    
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.497850)
image 492:    
image 5429:     
image 6968:      
image 2672:      
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.986962)
image 833:     
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:     
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.581154)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.461680)
image 6835:     
image 4698:    
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.173019)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:    
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.775516)
image 3553:    
image 5971:     
image 122:    
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.371998)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:    
evaluating validation preformance... 330/1000 (2.738644)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:    UNK
image 3972:    
evaluating validation preformance... 340/1000 (2.448529)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.559586)
image 6881:    UNK
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:    
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.032138)
image 2905:    
image 7814:     
image 56:    
image 5034:    
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.574120)
image 4351:     
image 1054:     
image 129:     
image 2849:     
image 725:  UNK   
image 2573:    
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.645264)
image 2458:     
image 1084:      
image 4835:     
image 867:    
image 723:     
image 6255:     
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (2.858788)
image 828:    
image 2733:    
image 791:      
image 5408:    UNK
image 7842:     
image 1117:    
image 5817:      
image 1231:    
image 1630:    
image 6886:    
evaluating validation preformance... 400/1000 (2.246851)
image 2627:    
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:    
image 670:     
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.149347)
image 4359:     
image 2372:    
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.348577)
image 30:      
image 5540:     
image 2445:    
image 5896:      
image 7607:    
image 1426:     
image 6977:    
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.838554)
image 385:    
image 6938:      
image 2381:    
image 5796:     
image 4010:     
image 3452:     
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.910051)
image 1731:       
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:    
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.212721)
image 2241:      
image 2651:    
image 2315:     
image 4784:     
image 5160:      
image 2466:    
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.736319)
image 7979:    
image 1618:    
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.229725)
image 4503:     
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.909281)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.315160)
image 2044:    
image 4349:    
image 3855:      
image 1846:     
image 3724:     
image 606:    
image 6577:    
image 6820:       
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.550071)
image 1797:    
image 4670:      
image 4846:    
image 5907:     
image 3321:    
image 1700:     
image 438:    
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.994815)
image 3246:    
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.648275)
image 6806:    
image 6464:    
image 1872:     
image 1575:    
image 3045:    
image 303:   
image 5552:    
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.496613)
image 5619:    
image 4391:     
image 891:     
image 3072:    
image 7781:    
image 6163:    
image 7376:      
image 6034:    
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.486307)
image 5292:    
image 2901:     
image 3568:     
image 690:      
image 3345:     
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.610311)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:     
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.606820)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK 
image 7893:    
image 3623:    
image 7232:    
image 4778:     
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.563877)
image 7936:     
image 5433:    
image 5691:    
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.561191)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:    
image 1500:     
image 5094:    
image 5778:    
image 6422:     
evaluating validation preformance... 590/1000 (2.574648)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.551321)
image 353:     
image 1095:    
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.714634)
image 69:     
image 3465:    
image 6179:     
image 552:    
image 511:    
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.438007)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.477129)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.488003)
image 5313:      
image 2377:      
image 6058:    
image 4661:     
image 2955:    
image 3333:     
image 7124:     
image 4278:      
image 953:     
image 4037:      
evaluating validation preformance... 650/1000 (2.597897)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.665445)
image 5701:    
image 1709:    
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:     
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (2.861649)
image 7877:    
image 6761:     
image 6880:    
image 4914:    UNK
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.020538)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:      
image 4382:    
image 1257:     
image 6405:     
image 6504:    
evaluating validation preformance... 690/1000 (2.864015)
image 6860:    
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:     
image 6225:     
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.972816)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.517631)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.661005)
image 5729:    
image 6395:      
image 516:      
image 1026:    
image 2972:      
image 3005:     
image 1241:      
image 2743:      
image 3665:    
image 1290:     
evaluating validation preformance... 730/1000 (2.320637)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:     
image 5092:     
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.490765)
image 2239:     
image 120:     
image 4902:    
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.740299)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:      
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.010048)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    UNK
image 2452:    
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.182992)
image 6220:    
image 6238:     
image 4534:      
image 2732:      
image 7003:     
image 1739:     
image 5503:     
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.801557)
image 6867:    
image 5525:     
image 4746:    
image 5531:    
image 5425:     
image 6978:    
image 3450:     
image 3312:     
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.185429)
image 5047:    
image 325:       
image 7626:    
image 4552:     
image 983:      
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     UNK
evaluating validation preformance... 800/1000 (2.292131)
image 7288:    
image 7302:      
image 3055:    UNK
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.427821)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.967292)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    UNK
image 5514:     
image 7147:    
image 6348:     
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.395024)
image 5107:    
image 3973:    UNK
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:    
image 6117:      
evaluating validation preformance... 840/1000 (2.415747)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.802554)
image 4404:     
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:    
image 1921:       
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.798259)
image 4254:      
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:    
image 4002:     
evaluating validation preformance... 870/1000 (2.350577)
image 4934:    
image 6487:     
image 4217:      
image 6355:     
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.602180)
image 5460:      
image 3671:    UNK
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.892691)
image 7485:    
image 6102:    
image 1001:    
image 7167:    
image 4168:     
image 187:    
image 7798:     
image 4813:    
image 7753:    
image 210:    
evaluating validation preformance... 900/1000 (3.509952)
image 5664:     
image 4985:    UNK
image 4082:    
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.232073)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:    
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.600809)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:    
image 3189:     
image 6274:       
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.516927)
image 5636:      
image 7799:      
image 6025:     
image 6907:    
image 2507:    
image 7014:    
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.676225)
image 5860:    
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:    
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (2.998571)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:      
evaluating validation preformance... 960/1000 (2.775419)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.355884)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.768428)
image 7352:     
image 5113:     
image 7822:     
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.486648)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.374850)
average loss on validation: 2.612
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2808213233947754
Cider scores: 0.56448524402887
Read data: 0.3713803291320801
Cider scores: 0.5310711296208533
Read data: 0.3050365447998047
Cider scores: 0.5668187519315347
Read data: 0.22579216957092285
Cider scores: 0.503420753343059
Read data: 0.20398211479187012
Cider scores: 0.5220779351047573
Read data: 0.17008447647094727
Cider scores: 0.4877222200220507
Read data: 0.19827628135681152
Cider scores: 0.5503317517421095
Read data: 0.17718172073364258
Cider scores: 0.6066037654428252
Read data: 0.17785334587097168
Cider scores: 0.45862447996464095
Read data: 0.18336844444274902
Cider scores: 0.6528770592438256
Read data: 0.23528552055358887
Cider scores: 0.5889109815700492
Read data: 0.17741084098815918
Cider scores: 0.5936074075411557
Read data: 0.17916512489318848
Cider scores: 0.5778603622973492
Read data: 0.17287206649780273
Cider scores: 0.6160494010801166
Read data: 0.1827092170715332
Cider scores: 0.5668030064211284
Read data: 0.17299532890319824
Cider scores: 0.6128677403172389
Read data: 0.16278862953186035
Cider scores: 0.4452541246017404
Read data: 0.16529607772827148
Cider scores: 0.6025298340776084
Read data: 0.16675186157226562
Cider scores: 0.5264533702566044
Read data: 0.1616206169128418
Cider scores: 0.7367469890871837
Average cider score on test set: 0.566
End calculating cider score on TEST data set
===============================================
Read data: 0.16623425483703613
iter 11000 (epoch 18), train_loss = 3.108, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 11001 (epoch 18), train_loss = 2.537, time/batch = 0.023
Read data: 0.00011682510375976562
iter 11002 (epoch 18), train_loss = 2.232, time/batch = 0.021
Read data: 0.00012922286987304688
iter 11003 (epoch 18), train_loss = 2.788, time/batch = 0.031
Read data: 0.00010323524475097656
iter 11004 (epoch 18), train_loss = 2.632, time/batch = 0.023
Read data: 0.0001323223114013672
iter 11005 (epoch 18), train_loss = 2.407, time/batch = 0.028
Read data: 0.0001556873321533203
iter 11006 (epoch 18), train_loss = 2.568, time/batch = 0.028
Read data: 9.465217590332031e-05
iter 11007 (epoch 18), train_loss = 2.755, time/batch = 0.023
Read data: 0.00011777877807617188
iter 11008 (epoch 18), train_loss = 2.585, time/batch = 0.036
Read data: 0.00014829635620117188
iter 11009 (epoch 18), train_loss = 2.498, time/batch = 0.027
Read data: 0.00016188621520996094
iter 11010 (epoch 18), train_loss = 2.274, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 11011 (epoch 18), train_loss = 2.623, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 11012 (epoch 18), train_loss = 2.475, time/batch = 0.023
Read data: 0.0001442432403564453
iter 11013 (epoch 18), train_loss = 2.390, time/batch = 0.025
Read data: 0.00014281272888183594
iter 11014 (epoch 18), train_loss = 2.537, time/batch = 0.024
Read data: 0.00011873245239257812
iter 11015 (epoch 18), train_loss = 2.677, time/batch = 0.033
Read data: 8.678436279296875e-05
iter 11016 (epoch 18), train_loss = 2.341, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 11017 (epoch 18), train_loss = 2.719, time/batch = 0.023
Read data: 0.0001671314239501953
iter 11018 (epoch 18), train_loss = 2.224, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 11019 (epoch 18), train_loss = 2.212, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 11020 (epoch 18), train_loss = 2.711, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 11021 (epoch 18), train_loss = 2.961, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 11022 (epoch 18), train_loss = 2.554, time/batch = 0.025
Read data: 0.0001227855682373047
iter 11023 (epoch 18), train_loss = 2.684, time/batch = 0.036
Read data: 7.939338684082031e-05
iter 11024 (epoch 18), train_loss = 2.439, time/batch = 0.030
Read data: 0.00017762184143066406
iter 11025 (epoch 18), train_loss = 2.978, time/batch = 0.029
Read data: 0.00014019012451171875
iter 11026 (epoch 18), train_loss = 2.531, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 11027 (epoch 18), train_loss = 2.709, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 11028 (epoch 18), train_loss = 2.740, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 11029 (epoch 18), train_loss = 2.921, time/batch = 0.025
Read data: 0.00012874603271484375
iter 11030 (epoch 18), train_loss = 2.315, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 11031 (epoch 18), train_loss = 3.018, time/batch = 0.031
Read data: 7.748603820800781e-05
iter 11032 (epoch 18), train_loss = 2.276, time/batch = 0.026
Read data: 7.557868957519531e-05
iter 11033 (epoch 18), train_loss = 2.546, time/batch = 0.027
Read data: 0.00012111663818359375
iter 11034 (epoch 18), train_loss = 2.745, time/batch = 0.021
Read data: 7.700920104980469e-05
iter 11035 (epoch 18), train_loss = 2.578, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 11036 (epoch 18), train_loss = 2.969, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 11037 (epoch 18), train_loss = 2.533, time/batch = 0.023
Read data: 0.0001418590545654297
iter 11038 (epoch 18), train_loss = 2.097, time/batch = 0.021
Read data: 8.96453857421875e-05
iter 11039 (epoch 18), train_loss = 1.989, time/batch = 0.025
Read data: 0.00011992454528808594
iter 11040 (epoch 18), train_loss = 2.596, time/batch = 0.023
Read data: 0.00011539459228515625
iter 11041 (epoch 18), train_loss = 2.855, time/batch = 0.030
Read data: 0.00014448165893554688
iter 11042 (epoch 18), train_loss = 2.784, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 11043 (epoch 18), train_loss = 2.599, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 11044 (epoch 18), train_loss = 2.760, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 11045 (epoch 18), train_loss = 2.556, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 11046 (epoch 18), train_loss = 2.867, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 11047 (epoch 18), train_loss = 2.377, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 11048 (epoch 18), train_loss = 2.320, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 11049 (epoch 18), train_loss = 2.384, time/batch = 0.032
Read data: 0.00021219253540039062
iter 11050 (epoch 18), train_loss = 2.748, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 11051 (epoch 18), train_loss = 2.399, time/batch = 0.034
Read data: 0.00011491775512695312
iter 11052 (epoch 18), train_loss = 2.723, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 11053 (epoch 18), train_loss = 2.496, time/batch = 0.025
Read data: 0.0001399517059326172
iter 11054 (epoch 18), train_loss = 2.687, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 11055 (epoch 18), train_loss = 2.924, time/batch = 0.038
Read data: 0.00010991096496582031
iter 11056 (epoch 18), train_loss = 2.987, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 11057 (epoch 18), train_loss = 2.708, time/batch = 0.022
Read data: 0.00013589859008789062
iter 11058 (epoch 18), train_loss = 2.330, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 11059 (epoch 18), train_loss = 2.770, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 11060 (epoch 18), train_loss = 2.359, time/batch = 0.027
Read data: 0.00011396408081054688
iter 11061 (epoch 18), train_loss = 2.784, time/batch = 0.034
Read data: 0.00015807151794433594
iter 11062 (epoch 18), train_loss = 2.507, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 11063 (epoch 18), train_loss = 2.847, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 11064 (epoch 18), train_loss = 2.230, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 11065 (epoch 18), train_loss = 2.730, time/batch = 0.032
Read data: 0.0001308917999267578
iter 11066 (epoch 18), train_loss = 2.605, time/batch = 0.029
Read data: 9.107589721679688e-05
iter 11067 (epoch 18), train_loss = 2.837, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 11068 (epoch 18), train_loss = 2.546, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 11069 (epoch 18), train_loss = 2.542, time/batch = 0.027
Read data: 0.000125885009765625
iter 11070 (epoch 18), train_loss = 2.363, time/batch = 0.025
Read data: 0.00010919570922851562
iter 11071 (epoch 18), train_loss = 2.213, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 11072 (epoch 18), train_loss = 2.347, time/batch = 0.023
Read data: 0.00011467933654785156
iter 11073 (epoch 18), train_loss = 2.325, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 11074 (epoch 18), train_loss = 2.422, time/batch = 0.031
Read data: 9.918212890625e-05
iter 11075 (epoch 18), train_loss = 2.481, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 11076 (epoch 18), train_loss = 2.084, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 11077 (epoch 18), train_loss = 2.967, time/batch = 0.020
Read data: 8.749961853027344e-05
iter 11078 (epoch 18), train_loss = 2.399, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 11079 (epoch 18), train_loss = 2.613, time/batch = 0.038
Read data: 8.678436279296875e-05
iter 11080 (epoch 18), train_loss = 2.726, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 11081 (epoch 18), train_loss = 2.667, time/batch = 0.027
Read data: 0.00012493133544921875
iter 11082 (epoch 18), train_loss = 2.373, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 11083 (epoch 18), train_loss = 2.494, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 11084 (epoch 18), train_loss = 2.251, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 11085 (epoch 18), train_loss = 2.624, time/batch = 0.022
Read data: 0.00015115737915039062
iter 11086 (epoch 18), train_loss = 2.280, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 11087 (epoch 18), train_loss = 2.692, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 11088 (epoch 18), train_loss = 2.596, time/batch = 0.021
Read data: 0.000118255615234375
iter 11089 (epoch 18), train_loss = 2.356, time/batch = 0.024
Read data: 0.0001418590545654297
iter 11090 (epoch 18), train_loss = 2.318, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 11091 (epoch 18), train_loss = 2.836, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 11092 (epoch 18), train_loss = 2.255, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 11093 (epoch 18), train_loss = 2.412, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 11094 (epoch 18), train_loss = 2.349, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 11095 (epoch 18), train_loss = 2.554, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 11096 (epoch 18), train_loss = 2.201, time/batch = 0.032
Read data: 0.0016522407531738281
iter 11097 (epoch 18), train_loss = 2.283, time/batch = 0.028
Read data: 0.00012564659118652344
iter 11098 (epoch 18), train_loss = 2.200, time/batch = 0.021
Read data: 8.296966552734375e-05
iter 11099 (epoch 18), train_loss = 2.489, time/batch = 0.026
Read data: 0.00016236305236816406
iter 11100 (epoch 18), train_loss = 2.734, time/batch = 0.021
Read data: 0.00011372566223144531
iter 11101 (epoch 18), train_loss = 2.934, time/batch = 0.025
Read data: 0.00017189979553222656
iter 11102 (epoch 18), train_loss = 2.611, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 11103 (epoch 18), train_loss = 2.611, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 11104 (epoch 18), train_loss = 2.527, time/batch = 0.027
Read data: 0.00011110305786132812
iter 11105 (epoch 18), train_loss = 2.718, time/batch = 0.025
Read data: 0.0001728534698486328
iter 11106 (epoch 18), train_loss = 2.882, time/batch = 0.034
Read data: 7.939338684082031e-05
iter 11107 (epoch 18), train_loss = 2.673, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 11108 (epoch 18), train_loss = 2.595, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 11109 (epoch 18), train_loss = 2.340, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 11110 (epoch 18), train_loss = 2.581, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 11111 (epoch 18), train_loss = 2.407, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 11112 (epoch 18), train_loss = 2.374, time/batch = 0.023
Read data: 7.653236389160156e-05
iter 11113 (epoch 18), train_loss = 2.666, time/batch = 0.026
Read data: 0.0001266002655029297
iter 11114 (epoch 18), train_loss = 2.759, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 11115 (epoch 18), train_loss = 2.512, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 11116 (epoch 18), train_loss = 2.661, time/batch = 0.030
Read data: 9.1552734375e-05
iter 11117 (epoch 18), train_loss = 2.741, time/batch = 0.023
Read data: 0.0001347064971923828
iter 11118 (epoch 18), train_loss = 2.590, time/batch = 0.026
Read data: 9.393692016601562e-05
iter 11119 (epoch 18), train_loss = 2.553, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 11120 (epoch 18), train_loss = 2.359, time/batch = 0.025
Read data: 0.00011396408081054688
iter 11121 (epoch 18), train_loss = 2.737, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 11122 (epoch 18), train_loss = 2.593, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 11123 (epoch 18), train_loss = 2.746, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 11124 (epoch 18), train_loss = 2.845, time/batch = 0.025
Read data: 0.00016260147094726562
iter 11125 (epoch 18), train_loss = 2.853, time/batch = 0.034
Read data: 0.00013113021850585938
iter 11126 (epoch 18), train_loss = 2.619, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 11127 (epoch 18), train_loss = 2.665, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 11128 (epoch 18), train_loss = 2.905, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 11129 (epoch 18), train_loss = 2.738, time/batch = 0.023
Read data: 0.0001289844512939453
iter 11130 (epoch 18), train_loss = 2.446, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 11131 (epoch 18), train_loss = 2.374, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 11132 (epoch 18), train_loss = 2.411, time/batch = 0.023
Read data: 0.00011277198791503906
iter 11133 (epoch 18), train_loss = 2.577, time/batch = 0.031
Read data: 0.00012111663818359375
iter 11134 (epoch 18), train_loss = 2.827, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 11135 (epoch 18), train_loss = 2.528, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 11136 (epoch 18), train_loss = 2.359, time/batch = 0.028
Read data: 8.392333984375e-05
iter 11137 (epoch 18), train_loss = 2.503, time/batch = 0.028
Read data: 0.00015497207641601562
iter 11138 (epoch 18), train_loss = 2.690, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 11139 (epoch 18), train_loss = 3.109, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 11140 (epoch 18), train_loss = 2.344, time/batch = 0.035
Read data: 8.058547973632812e-05
iter 11141 (epoch 18), train_loss = 2.337, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 11142 (epoch 18), train_loss = 2.585, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 11143 (epoch 18), train_loss = 2.713, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 11144 (epoch 18), train_loss = 2.111, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 11145 (epoch 18), train_loss = 2.919, time/batch = 0.029
Read data: 0.0001437664031982422
iter 11146 (epoch 18), train_loss = 2.146, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 11147 (epoch 18), train_loss = 2.389, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 11148 (epoch 18), train_loss = 2.741, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 11149 (epoch 18), train_loss = 3.068, time/batch = 0.023
Read data: 0.0002002716064453125
iter 11150 (epoch 18), train_loss = 2.357, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 11151 (epoch 18), train_loss = 2.925, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 11152 (epoch 18), train_loss = 2.420, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 11153 (epoch 18), train_loss = 2.211, time/batch = 0.026
Read data: 0.0001277923583984375
iter 11154 (epoch 18), train_loss = 2.697, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 11155 (epoch 18), train_loss = 2.613, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 11156 (epoch 18), train_loss = 2.688, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 11157 (epoch 18), train_loss = 2.616, time/batch = 0.023
Read data: 0.0001251697540283203
iter 11158 (epoch 18), train_loss = 2.425, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 11159 (epoch 18), train_loss = 2.269, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 11160 (epoch 18), train_loss = 2.033, time/batch = 0.027
Read data: 0.0001277923583984375
iter 11161 (epoch 18), train_loss = 2.685, time/batch = 0.028
Read data: 9.918212890625e-05
iter 11162 (epoch 18), train_loss = 2.217, time/batch = 0.034
Read data: 0.00013685226440429688
iter 11163 (epoch 18), train_loss = 2.602, time/batch = 0.033
Read data: 0.00010728836059570312
iter 11164 (epoch 18), train_loss = 2.386, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 11165 (epoch 18), train_loss = 2.230, time/batch = 0.020
Read data: 8.058547973632812e-05
iter 11166 (epoch 18), train_loss = 2.395, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 11167 (epoch 18), train_loss = 2.283, time/batch = 0.022
Read data: 0.0001289844512939453
iter 11168 (epoch 18), train_loss = 2.597, time/batch = 0.027
Read data: 0.0001125335693359375
iter 11169 (epoch 18), train_loss = 2.677, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 11170 (epoch 18), train_loss = 2.878, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 11171 (epoch 18), train_loss = 2.516, time/batch = 0.021
Read data: 8.58306884765625e-05
iter 11172 (epoch 18), train_loss = 2.868, time/batch = 0.025
Read data: 0.00011467933654785156
iter 11173 (epoch 18), train_loss = 2.684, time/batch = 0.029
Read data: 0.00013494491577148438
iter 11174 (epoch 18), train_loss = 2.540, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 11175 (epoch 18), train_loss = 2.719, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 11176 (epoch 18), train_loss = 2.487, time/batch = 0.034
Read data: 8.368492126464844e-05
iter 11177 (epoch 18), train_loss = 2.403, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 11178 (epoch 18), train_loss = 2.385, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 11179 (epoch 18), train_loss = 2.322, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 11180 (epoch 18), train_loss = 2.567, time/batch = 0.028
Read data: 0.0001125335693359375
iter 11181 (epoch 18), train_loss = 2.396, time/batch = 0.023
Read data: 0.00013971328735351562
iter 11182 (epoch 18), train_loss = 2.712, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 11183 (epoch 18), train_loss = 2.644, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 11184 (epoch 18), train_loss = 2.749, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 11185 (epoch 18), train_loss = 2.794, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 11186 (epoch 18), train_loss = 2.211, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 11187 (epoch 18), train_loss = 2.571, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 11188 (epoch 18), train_loss = 2.894, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 11189 (epoch 18), train_loss = 2.620, time/batch = 0.024
Read data: 0.00015592575073242188
iter 11190 (epoch 18), train_loss = 2.599, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 11191 (epoch 18), train_loss = 2.661, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 11192 (epoch 18), train_loss = 2.524, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 11193 (epoch 18), train_loss = 2.301, time/batch = 0.023
Read data: 0.00018358230590820312
iter 11194 (epoch 18), train_loss = 2.491, time/batch = 0.042
Read data: 0.00010037422180175781
iter 11195 (epoch 18), train_loss = 2.712, time/batch = 0.024
Read data: 0.0001316070556640625
iter 11196 (epoch 18), train_loss = 2.864, time/batch = 0.041
Read data: 7.390975952148438e-05
iter 11197 (epoch 18), train_loss = 2.894, time/batch = 0.024
Read data: 0.00011730194091796875
iter 11198 (epoch 18), train_loss = 2.620, time/batch = 0.035
Read data: 7.605552673339844e-05
iter 11199 (epoch 18), train_loss = 2.677, time/batch = 0.029
Read data: 0.00013399124145507812
iter 11200 (epoch 18), train_loss = 2.611, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 11201 (epoch 18), train_loss = 2.587, time/batch = 0.033
Read data: 0.0001270771026611328
iter 11202 (epoch 18), train_loss = 2.393, time/batch = 0.028
Read data: 9.1552734375e-05
iter 11203 (epoch 18), train_loss = 2.542, time/batch = 0.026
Read data: 0.00013709068298339844
iter 11204 (epoch 18), train_loss = 2.602, time/batch = 0.023
Read data: 0.00011730194091796875
iter 11205 (epoch 18), train_loss = 2.249, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 11206 (epoch 18), train_loss = 2.396, time/batch = 0.026
Read data: 0.00011277198791503906
iter 11207 (epoch 18), train_loss = 2.578, time/batch = 0.030
Read data: 0.0001316070556640625
iter 11208 (epoch 18), train_loss = 2.410, time/batch = 0.029
Read data: 0.00011801719665527344
iter 11209 (epoch 18), train_loss = 2.882, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 11210 (epoch 18), train_loss = 2.307, time/batch = 0.026
Read data: 0.0001163482666015625
iter 11211 (epoch 18), train_loss = 2.351, time/batch = 0.030
Read data: 0.00013113021850585938
iter 11212 (epoch 18), train_loss = 2.295, time/batch = 0.021
Read data: 8.416175842285156e-05
iter 11213 (epoch 18), train_loss = 2.626, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 11214 (epoch 18), train_loss = 2.597, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 11215 (epoch 18), train_loss = 2.816, time/batch = 0.022
Read data: 0.00014281272888183594
iter 11216 (epoch 18), train_loss = 2.337, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 11217 (epoch 18), train_loss = 2.326, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 11218 (epoch 18), train_loss = 2.501, time/batch = 0.027
Read data: 0.00012731552124023438
iter 11219 (epoch 18), train_loss = 2.391, time/batch = 0.025
Read data: 0.0001227855682373047
iter 11220 (epoch 18), train_loss = 2.776, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 11221 (epoch 18), train_loss = 2.605, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 11222 (epoch 18), train_loss = 2.128, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 11223 (epoch 18), train_loss = 2.660, time/batch = 0.039
Read data: 0.00012922286987304688
iter 11224 (epoch 18), train_loss = 2.756, time/batch = 0.025
Read data: 0.00011157989501953125
iter 11225 (epoch 18), train_loss = 2.600, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 11226 (epoch 18), train_loss = 2.750, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 11227 (epoch 18), train_loss = 2.567, time/batch = 0.030
Read data: 0.0001277923583984375
iter 11228 (epoch 18), train_loss = 2.925, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 11229 (epoch 18), train_loss = 2.342, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 11230 (epoch 18), train_loss = 2.686, time/batch = 0.025
Read data: 0.00011467933654785156
iter 11231 (epoch 18), train_loss = 2.667, time/batch = 0.026
Read data: 0.0001227855682373047
iter 11232 (epoch 18), train_loss = 2.461, time/batch = 0.022
Read data: 0.00012040138244628906
iter 11233 (epoch 18), train_loss = 2.789, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 11234 (epoch 18), train_loss = 2.793, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 11235 (epoch 18), train_loss = 2.853, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 11236 (epoch 18), train_loss = 2.402, time/batch = 0.029
Read data: 0.0001289844512939453
iter 11237 (epoch 18), train_loss = 2.788, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 11238 (epoch 18), train_loss = 2.673, time/batch = 0.022
Read data: 0.00011706352233886719
iter 11239 (epoch 18), train_loss = 2.785, time/batch = 0.024
Read data: 0.0001251697540283203
iter 11240 (epoch 18), train_loss = 2.819, time/batch = 0.033
Read data: 0.00012159347534179688
iter 11241 (epoch 18), train_loss = 2.784, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 11242 (epoch 18), train_loss = 2.193, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 11243 (epoch 18), train_loss = 2.414, time/batch = 0.025
Read data: 0.00013113021850585938
iter 11244 (epoch 18), train_loss = 2.492, time/batch = 0.021
Read data: 0.00010538101196289062
iter 11245 (epoch 18), train_loss = 2.970, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 11246 (epoch 18), train_loss = 2.841, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 11247 (epoch 18), train_loss = 2.739, time/batch = 0.028
Read data: 0.00015926361083984375
iter 11248 (epoch 18), train_loss = 2.738, time/batch = 0.026
Read data: 0.00014591217041015625
iter 11249 (epoch 18), train_loss = 2.614, time/batch = 0.021
Read data: 0.00018930435180664062
iter 11250 (epoch 18), train_loss = 2.555, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 11251 (epoch 18), train_loss = 2.533, time/batch = 0.030
Read data: 0.0001385211944580078
iter 11252 (epoch 18), train_loss = 2.354, time/batch = 0.023
Read data: 0.00011444091796875
iter 11253 (epoch 18), train_loss = 2.912, time/batch = 0.030
Read data: 7.605552673339844e-05
iter 11254 (epoch 18), train_loss = 2.943, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 11255 (epoch 18), train_loss = 2.241, time/batch = 0.024
Read data: 0.000152587890625
iter 11256 (epoch 18), train_loss = 2.630, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 11257 (epoch 18), train_loss = 2.310, time/batch = 0.026
Read data: 9.584426879882812e-05
iter 11258 (epoch 18), train_loss = 2.214, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 11259 (epoch 18), train_loss = 2.558, time/batch = 0.028
Read data: 0.00015735626220703125
iter 11260 (epoch 18), train_loss = 2.573, time/batch = 0.027
Read data: 0.00014662742614746094
iter 11261 (epoch 18), train_loss = 2.541, time/batch = 0.022
Read data: 9.703636169433594e-05
iter 11262 (epoch 18), train_loss = 2.444, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 11263 (epoch 18), train_loss = 2.598, time/batch = 0.028
Read data: 0.0018265247344970703
iter 11264 (epoch 18), train_loss = 2.542, time/batch = 0.026
Read data: 0.00012922286987304688
iter 11265 (epoch 18), train_loss = 2.388, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 11266 (epoch 18), train_loss = 2.815, time/batch = 0.023
Read data: 0.00011730194091796875
iter 11267 (epoch 18), train_loss = 2.141, time/batch = 0.024
Read data: 0.0001220703125
iter 11268 (epoch 18), train_loss = 2.332, time/batch = 0.022
Read data: 0.0001232624053955078
iter 11269 (epoch 18), train_loss = 2.687, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 11270 (epoch 18), train_loss = 2.379, time/batch = 0.028
Read data: 0.00011587142944335938
iter 11271 (epoch 18), train_loss = 2.282, time/batch = 0.026
Read data: 0.00012254714965820312
iter 11272 (epoch 18), train_loss = 2.357, time/batch = 0.024
Read data: 0.00011754035949707031
iter 11273 (epoch 18), train_loss = 2.666, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 11274 (epoch 18), train_loss = 2.154, time/batch = 0.023
Read data: 0.00017023086547851562
iter 11275 (epoch 18), train_loss = 2.399, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 11276 (epoch 18), train_loss = 2.180, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 11277 (epoch 18), train_loss = 2.436, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 11278 (epoch 18), train_loss = 2.500, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 11279 (epoch 18), train_loss = 2.311, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 11280 (epoch 18), train_loss = 2.879, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 11281 (epoch 18), train_loss = 2.498, time/batch = 0.020
Read data: 8.845329284667969e-05
iter 11282 (epoch 18), train_loss = 2.246, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 11283 (epoch 18), train_loss = 2.369, time/batch = 0.026
Read data: 0.00017023086547851562
iter 11284 (epoch 18), train_loss = 2.443, time/batch = 0.030
Read data: 0.00012922286987304688
iter 11285 (epoch 18), train_loss = 2.277, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 11286 (epoch 18), train_loss = 2.804, time/batch = 0.026
Read data: 0.0001289844512939453
iter 11287 (epoch 18), train_loss = 2.812, time/batch = 0.036
Read data: 0.00016355514526367188
iter 11288 (epoch 18), train_loss = 2.840, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 11289 (epoch 18), train_loss = 2.237, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 11290 (epoch 18), train_loss = 2.265, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 11291 (epoch 18), train_loss = 2.635, time/batch = 0.028
Read data: 0.0001399517059326172
iter 11292 (epoch 18), train_loss = 2.538, time/batch = 0.026
Read data: 0.00011038780212402344
iter 11293 (epoch 18), train_loss = 2.599, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 11294 (epoch 18), train_loss = 2.512, time/batch = 0.026
Read data: 0.00011372566223144531
iter 11295 (epoch 18), train_loss = 2.395, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 11296 (epoch 18), train_loss = 2.662, time/batch = 0.026
Read data: 0.00010752677917480469
iter 11297 (epoch 18), train_loss = 2.683, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 11298 (epoch 18), train_loss = 2.970, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 11299 (epoch 18), train_loss = 2.508, time/batch = 0.027
Read data: 0.0002944469451904297
iter 11300 (epoch 18), train_loss = 2.708, time/batch = 0.025
Read data: 0.00014710426330566406
iter 11301 (epoch 18), train_loss = 3.348, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 11302 (epoch 18), train_loss = 2.020, time/batch = 0.024
Read data: 0.0001456737518310547
iter 11303 (epoch 18), train_loss = 2.612, time/batch = 0.023
Read data: 9.5367431640625e-05
iter 11304 (epoch 18), train_loss = 2.658, time/batch = 0.029
Read data: 0.00011181831359863281
iter 11305 (epoch 18), train_loss = 2.556, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 11306 (epoch 18), train_loss = 2.692, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 11307 (epoch 18), train_loss = 2.249, time/batch = 0.022
Read data: 0.00012612342834472656
iter 11308 (epoch 18), train_loss = 2.731, time/batch = 0.028
Read data: 0.000102996826171875
iter 11309 (epoch 18), train_loss = 2.584, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 11310 (epoch 18), train_loss = 2.769, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 11311 (epoch 18), train_loss = 2.332, time/batch = 0.026
Read data: 0.0001266002655029297
iter 11312 (epoch 18), train_loss = 2.168, time/batch = 0.026
Read data: 0.00011229515075683594
iter 11313 (epoch 18), train_loss = 2.629, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 11314 (epoch 18), train_loss = 2.296, time/batch = 0.028
Read data: 0.00012063980102539062
iter 11315 (epoch 18), train_loss = 2.307, time/batch = 0.026
Read data: 0.0001633167266845703
iter 11316 (epoch 18), train_loss = 2.683, time/batch = 0.028
Read data: 0.00015592575073242188
iter 11317 (epoch 18), train_loss = 2.800, time/batch = 0.036
Read data: 9.417533874511719e-05
iter 11318 (epoch 18), train_loss = 2.689, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 11319 (epoch 18), train_loss = 2.372, time/batch = 0.025
Read data: 0.00016164779663085938
iter 11320 (epoch 18), train_loss = 2.538, time/batch = 0.025
Read data: 0.00014853477478027344
iter 11321 (epoch 18), train_loss = 2.451, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 11322 (epoch 18), train_loss = 2.854, time/batch = 0.034
Read data: 8.0108642578125e-05
iter 11323 (epoch 18), train_loss = 2.639, time/batch = 0.026
Read data: 0.0001308917999267578
iter 11324 (epoch 18), train_loss = 2.181, time/batch = 0.025
Read data: 0.0002167224884033203
iter 11325 (epoch 18), train_loss = 2.326, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 11326 (epoch 18), train_loss = 2.796, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 11327 (epoch 18), train_loss = 3.004, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 11328 (epoch 18), train_loss = 2.368, time/batch = 0.031
Read data: 0.00011777877807617188
iter 11329 (epoch 18), train_loss = 2.788, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 11330 (epoch 18), train_loss = 2.900, time/batch = 0.021
Read data: 0.00013136863708496094
iter 11331 (epoch 18), train_loss = 2.402, time/batch = 0.030
Read data: 0.00013065338134765625
iter 11332 (epoch 18), train_loss = 2.698, time/batch = 0.034
Read data: 0.00011587142944335938
iter 11333 (epoch 18), train_loss = 2.173, time/batch = 0.024
Read data: 0.00016641616821289062
iter 11334 (epoch 18), train_loss = 2.385, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 11335 (epoch 18), train_loss = 2.607, time/batch = 0.023
Read data: 0.0001423358917236328
iter 11336 (epoch 18), train_loss = 2.735, time/batch = 0.025
Read data: 0.00011801719665527344
iter 11337 (epoch 18), train_loss = 2.580, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 11338 (epoch 18), train_loss = 3.000, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 11339 (epoch 18), train_loss = 2.538, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 11340 (epoch 18), train_loss = 2.620, time/batch = 0.025
Read data: 0.00017380714416503906
iter 11341 (epoch 18), train_loss = 2.814, time/batch = 0.032
Read data: 7.677078247070312e-05
iter 11342 (epoch 18), train_loss = 2.718, time/batch = 0.022
Read data: 0.0001366138458251953
iter 11343 (epoch 18), train_loss = 2.538, time/batch = 0.021
Read data: 0.0001010894775390625
iter 11344 (epoch 18), train_loss = 2.762, time/batch = 0.032
Read data: 0.00012493133544921875
iter 11345 (epoch 18), train_loss = 3.186, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 11346 (epoch 18), train_loss = 2.685, time/batch = 0.024
Read data: 0.00011539459228515625
iter 11347 (epoch 18), train_loss = 2.828, time/batch = 0.027
Read data: 0.0001373291015625
iter 11348 (epoch 18), train_loss = 2.439, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 11349 (epoch 18), train_loss = 2.654, time/batch = 0.026
Read data: 0.00016999244689941406
iter 11350 (epoch 18), train_loss = 1.984, time/batch = 0.021
Read data: 0.0001323223114013672
iter 11351 (epoch 18), train_loss = 2.316, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 11352 (epoch 18), train_loss = 2.427, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 11353 (epoch 18), train_loss = 2.335, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 11354 (epoch 18), train_loss = 2.361, time/batch = 0.025
Read data: 0.0001323223114013672
iter 11355 (epoch 18), train_loss = 2.797, time/batch = 0.029
Read data: 0.0001246929168701172
iter 11356 (epoch 18), train_loss = 2.399, time/batch = 0.021
Read data: 0.00010228157043457031
iter 11357 (epoch 18), train_loss = 2.400, time/batch = 0.028
Read data: 0.00010132789611816406
iter 11358 (epoch 18), train_loss = 2.968, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 11359 (epoch 18), train_loss = 2.318, time/batch = 0.024
Read data: 0.0001277923583984375
iter 11360 (epoch 18), train_loss = 2.561, time/batch = 0.032
Read data: 0.00012373924255371094
iter 11361 (epoch 18), train_loss = 2.586, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 11362 (epoch 18), train_loss = 2.639, time/batch = 0.025
Read data: 0.00011205673217773438
iter 11363 (epoch 18), train_loss = 2.576, time/batch = 0.026
Read data: 0.00012373924255371094
iter 11364 (epoch 18), train_loss = 2.570, time/batch = 0.025
Read data: 0.00010538101196289062
iter 11365 (epoch 18), train_loss = 2.637, time/batch = 0.033
Read data: 7.510185241699219e-05
iter 11366 (epoch 18), train_loss = 2.267, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 11367 (epoch 18), train_loss = 2.943, time/batch = 0.024
Read data: 0.00013017654418945312
iter 11368 (epoch 18), train_loss = 2.489, time/batch = 0.025
Read data: 0.00012230873107910156
iter 11369 (epoch 18), train_loss = 2.775, time/batch = 0.024
Read data: 0.00010156631469726562
iter 11370 (epoch 18), train_loss = 2.788, time/batch = 0.028
Read data: 0.00013065338134765625
iter 11371 (epoch 18), train_loss = 2.108, time/batch = 0.028
Read data: 0.00015783309936523438
iter 11372 (epoch 18), train_loss = 2.409, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 11373 (epoch 18), train_loss = 2.296, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 11374 (epoch 18), train_loss = 2.725, time/batch = 0.025
Read data: 0.00019240379333496094
iter 11375 (epoch 18), train_loss = 2.492, time/batch = 0.028
Read data: 0.0001251697540283203
iter 11376 (epoch 18), train_loss = 2.642, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 11377 (epoch 18), train_loss = 2.366, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 11378 (epoch 18), train_loss = 2.297, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 11379 (epoch 18), train_loss = 2.385, time/batch = 0.030
Read data: 9.560585021972656e-05
iter 11380 (epoch 18), train_loss = 3.041, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 11381 (epoch 18), train_loss = 2.487, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 11382 (epoch 18), train_loss = 2.739, time/batch = 0.037
Read data: 8.821487426757812e-05
iter 11383 (epoch 18), train_loss = 3.005, time/batch = 0.028
Read data: 0.00013303756713867188
iter 11384 (epoch 18), train_loss = 2.476, time/batch = 0.023
Read data: 0.00011515617370605469
iter 11385 (epoch 18), train_loss = 2.634, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 11386 (epoch 18), train_loss = 2.403, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 11387 (epoch 18), train_loss = 2.878, time/batch = 0.025
Read data: 0.00013446807861328125
iter 11388 (epoch 18), train_loss = 2.594, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 11389 (epoch 18), train_loss = 2.490, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 11390 (epoch 18), train_loss = 2.365, time/batch = 0.026
Read data: 0.00011229515075683594
iter 11391 (epoch 18), train_loss = 2.684, time/batch = 0.026
Read data: 0.0009357929229736328
iter 11392 (epoch 18), train_loss = 2.745, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 11393 (epoch 18), train_loss = 2.114, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 11394 (epoch 18), train_loss = 2.813, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 11395 (epoch 18), train_loss = 2.556, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 11396 (epoch 18), train_loss = 2.824, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 11397 (epoch 18), train_loss = 2.772, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 11398 (epoch 18), train_loss = 3.004, time/batch = 0.023
Read data: 0.00011134147644042969
iter 11399 (epoch 18), train_loss = 2.982, time/batch = 0.025
Read data: 0.00020837783813476562
iter 11400 (epoch 18), train_loss = 2.253, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 11401 (epoch 19), train_loss = 2.632, time/batch = 0.020
Read data: 9.274482727050781e-05
iter 11402 (epoch 19), train_loss = 2.603, time/batch = 0.035
Read data: 0.00015616416931152344
iter 11403 (epoch 19), train_loss = 2.205, time/batch = 0.023
Read data: 0.00012540817260742188
iter 11404 (epoch 19), train_loss = 2.095, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 11405 (epoch 19), train_loss = 2.511, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 11406 (epoch 19), train_loss = 2.616, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 11407 (epoch 19), train_loss = 2.516, time/batch = 0.025
Read data: 0.0001385211944580078
iter 11408 (epoch 19), train_loss = 3.062, time/batch = 0.024
Read data: 0.00011873245239257812
iter 11409 (epoch 19), train_loss = 2.592, time/batch = 0.026
Read data: 9.870529174804688e-05
iter 11410 (epoch 19), train_loss = 2.321, time/batch = 0.028
Read data: 0.00012826919555664062
iter 11411 (epoch 19), train_loss = 2.366, time/batch = 0.033
Read data: 0.000164031982421875
iter 11412 (epoch 19), train_loss = 2.855, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 11413 (epoch 19), train_loss = 2.483, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 11414 (epoch 19), train_loss = 2.201, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 11415 (epoch 19), train_loss = 2.414, time/batch = 0.027
Read data: 0.0001239776611328125
iter 11416 (epoch 19), train_loss = 2.448, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 11417 (epoch 19), train_loss = 2.583, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 11418 (epoch 19), train_loss = 2.178, time/batch = 0.021
Read data: 9.012222290039062e-05
iter 11419 (epoch 19), train_loss = 2.246, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 11420 (epoch 19), train_loss = 2.485, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 11421 (epoch 19), train_loss = 2.538, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 11422 (epoch 19), train_loss = 2.530, time/batch = 0.028
Read data: 0.00012230873107910156
iter 11423 (epoch 19), train_loss = 2.371, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 11424 (epoch 19), train_loss = 2.825, time/batch = 0.026
Read data: 0.00018167495727539062
iter 11425 (epoch 19), train_loss = 2.615, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 11426 (epoch 19), train_loss = 2.389, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 11427 (epoch 19), train_loss = 2.800, time/batch = 0.026
Read data: 0.00016546249389648438
iter 11428 (epoch 19), train_loss = 2.281, time/batch = 0.024
Read data: 0.00011229515075683594
iter 11429 (epoch 19), train_loss = 2.441, time/batch = 0.025
Read data: 0.00010585784912109375
iter 11430 (epoch 19), train_loss = 2.236, time/batch = 0.026
Read data: 0.00011229515075683594
iter 11431 (epoch 19), train_loss = 2.468, time/batch = 0.027
Read data: 0.00012445449829101562
iter 11432 (epoch 19), train_loss = 2.024, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 11433 (epoch 19), train_loss = 2.684, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 11434 (epoch 19), train_loss = 2.618, time/batch = 0.022
Read data: 0.00011873245239257812
iter 11435 (epoch 19), train_loss = 2.283, time/batch = 0.025
Read data: 0.00012493133544921875
iter 11436 (epoch 19), train_loss = 2.139, time/batch = 0.022
Read data: 0.00011444091796875
iter 11437 (epoch 19), train_loss = 2.252, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 11438 (epoch 19), train_loss = 2.363, time/batch = 0.027
Read data: 0.00011396408081054688
iter 11439 (epoch 19), train_loss = 2.519, time/batch = 0.024
Read data: 0.00014138221740722656
iter 11440 (epoch 19), train_loss = 2.663, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 11441 (epoch 19), train_loss = 2.539, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 11442 (epoch 19), train_loss = 2.770, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 11443 (epoch 19), train_loss = 2.257, time/batch = 0.025
Read data: 0.00012111663818359375
iter 11444 (epoch 19), train_loss = 2.524, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 11445 (epoch 19), train_loss = 2.805, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 11446 (epoch 19), train_loss = 2.505, time/batch = 0.024
Read data: 0.00016736984252929688
iter 11447 (epoch 19), train_loss = 2.594, time/batch = 0.032
Read data: 0.00015926361083984375
iter 11448 (epoch 19), train_loss = 2.510, time/batch = 0.041
Read data: 8.821487426757812e-05
iter 11449 (epoch 19), train_loss = 2.698, time/batch = 0.023
Read data: 0.00019812583923339844
iter 11450 (epoch 19), train_loss = 2.477, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 11451 (epoch 19), train_loss = 2.553, time/batch = 0.024
Read data: 0.00016736984252929688
iter 11452 (epoch 19), train_loss = 2.632, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 11453 (epoch 19), train_loss = 2.560, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 11454 (epoch 19), train_loss = 2.278, time/batch = 0.026
Read data: 0.0017242431640625
iter 11455 (epoch 19), train_loss = 2.355, time/batch = 0.023
Read data: 0.00010275840759277344
iter 11456 (epoch 19), train_loss = 2.325, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 11457 (epoch 19), train_loss = 2.223, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 11458 (epoch 19), train_loss = 2.516, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 11459 (epoch 19), train_loss = 2.316, time/batch = 0.026
Read data: 0.00015878677368164062
iter 11460 (epoch 19), train_loss = 2.725, time/batch = 0.024
Read data: 0.00010085105895996094
iter 11461 (epoch 19), train_loss = 2.427, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 11462 (epoch 19), train_loss = 2.259, time/batch = 0.029
Read data: 0.0001480579376220703
iter 11463 (epoch 19), train_loss = 2.277, time/batch = 0.026
Read data: 0.0001595020294189453
iter 11464 (epoch 19), train_loss = 2.544, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 11465 (epoch 19), train_loss = 2.398, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 11466 (epoch 19), train_loss = 2.541, time/batch = 0.025
Read data: 0.00014448165893554688
iter 11467 (epoch 19), train_loss = 2.727, time/batch = 0.030
Read data: 0.0001652240753173828
iter 11468 (epoch 19), train_loss = 2.106, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 11469 (epoch 19), train_loss = 2.887, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 11470 (epoch 19), train_loss = 2.420, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 11471 (epoch 19), train_loss = 2.372, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 11472 (epoch 19), train_loss = 2.891, time/batch = 0.032
Read data: 0.00011730194091796875
iter 11473 (epoch 19), train_loss = 2.644, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 11474 (epoch 19), train_loss = 2.961, time/batch = 0.024
Read data: 0.00020360946655273438
iter 11475 (epoch 19), train_loss = 2.475, time/batch = 0.026
Read data: 0.00016927719116210938
iter 11476 (epoch 19), train_loss = 2.363, time/batch = 0.023
Read data: 0.00011348724365234375
iter 11477 (epoch 19), train_loss = 2.495, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 11478 (epoch 19), train_loss = 2.791, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 11479 (epoch 19), train_loss = 2.594, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 11480 (epoch 19), train_loss = 2.409, time/batch = 0.026
Read data: 0.00011777877807617188
iter 11481 (epoch 19), train_loss = 2.966, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 11482 (epoch 19), train_loss = 2.301, time/batch = 0.026
Read data: 0.0001392364501953125
iter 11483 (epoch 19), train_loss = 1.999, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 11484 (epoch 19), train_loss = 3.077, time/batch = 0.028
Read data: 0.00012230873107910156
iter 11485 (epoch 19), train_loss = 2.657, time/batch = 0.038
Read data: 8.511543273925781e-05
iter 11486 (epoch 19), train_loss = 2.515, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 11487 (epoch 19), train_loss = 2.750, time/batch = 0.028
Read data: 0.0001819133758544922
iter 11488 (epoch 19), train_loss = 2.851, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 11489 (epoch 19), train_loss = 2.502, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 11490 (epoch 19), train_loss = 2.203, time/batch = 0.024
Read data: 0.0001323223114013672
iter 11491 (epoch 19), train_loss = 2.641, time/batch = 0.027
Read data: 0.00012731552124023438
iter 11492 (epoch 19), train_loss = 2.530, time/batch = 0.021
Read data: 0.00011754035949707031
iter 11493 (epoch 19), train_loss = 2.514, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 11494 (epoch 19), train_loss = 2.217, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 11495 (epoch 19), train_loss = 2.519, time/batch = 0.026
Read data: 0.0001442432403564453
iter 11496 (epoch 19), train_loss = 2.672, time/batch = 0.028
Read data: 0.00011706352233886719
iter 11497 (epoch 19), train_loss = 2.143, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 11498 (epoch 19), train_loss = 2.700, time/batch = 0.029
Read data: 0.00017523765563964844
iter 11499 (epoch 19), train_loss = 2.594, time/batch = 0.026
Read data: 0.00027561187744140625
iter 11500 (epoch 19), train_loss = 2.607, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 11501 (epoch 19), train_loss = 2.718, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 11502 (epoch 19), train_loss = 2.623, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 11503 (epoch 19), train_loss = 2.660, time/batch = 0.026
Read data: 0.00012946128845214844
iter 11504 (epoch 19), train_loss = 2.962, time/batch = 0.023
Read data: 9.512901306152344e-05
iter 11505 (epoch 19), train_loss = 1.933, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 11506 (epoch 19), train_loss = 2.467, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 11507 (epoch 19), train_loss = 2.334, time/batch = 0.024
Read data: 0.0001823902130126953
iter 11508 (epoch 19), train_loss = 2.336, time/batch = 0.025
Read data: 0.00011658668518066406
iter 11509 (epoch 19), train_loss = 2.394, time/batch = 0.030
Read data: 9.202957153320312e-05
iter 11510 (epoch 19), train_loss = 2.608, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 11511 (epoch 19), train_loss = 2.314, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 11512 (epoch 19), train_loss = 2.740, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 11513 (epoch 19), train_loss = 2.521, time/batch = 0.024
Read data: 0.00010371208190917969
iter 11514 (epoch 19), train_loss = 2.282, time/batch = 0.021
Read data: 8.559226989746094e-05
iter 11515 (epoch 19), train_loss = 2.603, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 11516 (epoch 19), train_loss = 2.189, time/batch = 0.029
Read data: 0.00011348724365234375
iter 11517 (epoch 19), train_loss = 2.215, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 11518 (epoch 19), train_loss = 2.601, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 11519 (epoch 19), train_loss = 2.845, time/batch = 0.029
Read data: 9.34600830078125e-05
iter 11520 (epoch 19), train_loss = 2.712, time/batch = 0.026
Read data: 0.0001418590545654297
iter 11521 (epoch 19), train_loss = 2.753, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 11522 (epoch 19), train_loss = 3.135, time/batch = 0.024
Read data: 0.00012159347534179688
iter 11523 (epoch 19), train_loss = 2.347, time/batch = 0.024
Read data: 0.00012445449829101562
iter 11524 (epoch 19), train_loss = 2.794, time/batch = 0.027
Read data: 0.00016117095947265625
iter 11525 (epoch 19), train_loss = 2.098, time/batch = 0.022
Read data: 9.989738464355469e-05
iter 11526 (epoch 19), train_loss = 2.642, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 11527 (epoch 19), train_loss = 2.127, time/batch = 0.020
Read data: 9.179115295410156e-05
iter 11528 (epoch 19), train_loss = 1.904, time/batch = 0.031
Read data: 0.00011706352233886719
iter 11529 (epoch 19), train_loss = 2.621, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 11530 (epoch 19), train_loss = 2.888, time/batch = 0.028
Read data: 0.00011396408081054688
iter 11531 (epoch 19), train_loss = 2.358, time/batch = 0.022
Read data: 0.0001246929168701172
iter 11532 (epoch 19), train_loss = 2.107, time/batch = 0.019
Read data: 0.00011873245239257812
iter 11533 (epoch 19), train_loss = 2.904, time/batch = 0.025
Read data: 8.392333984375e-05
iter 11534 (epoch 19), train_loss = 2.483, time/batch = 0.028
Read data: 9.560585021972656e-05
iter 11535 (epoch 19), train_loss = 2.564, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 11536 (epoch 19), train_loss = 2.203, time/batch = 0.022
Read data: 9.72747802734375e-05
iter 11537 (epoch 19), train_loss = 2.311, time/batch = 0.021
Read data: 8.96453857421875e-05
iter 11538 (epoch 19), train_loss = 2.612, time/batch = 0.024
Read data: 0.00012755393981933594
iter 11539 (epoch 19), train_loss = 2.252, time/batch = 0.023
Read data: 0.00015592575073242188
iter 11540 (epoch 19), train_loss = 2.309, time/batch = 0.023
Read data: 0.00011134147644042969
iter 11541 (epoch 19), train_loss = 1.785, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 11542 (epoch 19), train_loss = 2.730, time/batch = 0.027
Read data: 0.00014662742614746094
iter 11543 (epoch 19), train_loss = 2.754, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 11544 (epoch 19), train_loss = 2.647, time/batch = 0.032
Read data: 9.250640869140625e-05
iter 11545 (epoch 19), train_loss = 2.582, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 11546 (epoch 19), train_loss = 2.600, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 11547 (epoch 19), train_loss = 2.189, time/batch = 0.021
Read data: 9.679794311523438e-05
iter 11548 (epoch 19), train_loss = 2.997, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 11549 (epoch 19), train_loss = 2.362, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 11550 (epoch 19), train_loss = 2.057, time/batch = 0.029
Read data: 9.608268737792969e-05
iter 11551 (epoch 19), train_loss = 2.701, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 11552 (epoch 19), train_loss = 2.231, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 11553 (epoch 19), train_loss = 2.460, time/batch = 0.027
Read data: 0.00010013580322265625
iter 11554 (epoch 19), train_loss = 2.641, time/batch = 0.026
Read data: 0.0001010894775390625
iter 11555 (epoch 19), train_loss = 2.507, time/batch = 0.037
Read data: 0.0001475811004638672
iter 11556 (epoch 19), train_loss = 2.511, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 11557 (epoch 19), train_loss = 2.586, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 11558 (epoch 19), train_loss = 2.412, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 11559 (epoch 19), train_loss = 2.706, time/batch = 0.019
Read data: 8.559226989746094e-05
iter 11560 (epoch 19), train_loss = 2.793, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 11561 (epoch 19), train_loss = 2.498, time/batch = 0.036
Read data: 8.559226989746094e-05
iter 11562 (epoch 19), train_loss = 2.583, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 11563 (epoch 19), train_loss = 2.360, time/batch = 0.024
Read data: 0.00016617774963378906
iter 11564 (epoch 19), train_loss = 2.354, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 11565 (epoch 19), train_loss = 2.562, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 11566 (epoch 19), train_loss = 2.377, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 11567 (epoch 19), train_loss = 2.521, time/batch = 0.036
Read data: 0.0001354217529296875
iter 11568 (epoch 19), train_loss = 2.289, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 11569 (epoch 19), train_loss = 2.553, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 11570 (epoch 19), train_loss = 2.302, time/batch = 0.024
Read data: 0.00012063980102539062
iter 11571 (epoch 19), train_loss = 2.635, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 11572 (epoch 19), train_loss = 2.726, time/batch = 0.029
Read data: 7.677078247070312e-05
iter 11573 (epoch 19), train_loss = 2.358, time/batch = 0.023
Read data: 9.799003601074219e-05
iter 11574 (epoch 19), train_loss = 2.347, time/batch = 0.023
Read data: 0.0001270771026611328
iter 11575 (epoch 19), train_loss = 2.709, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 11576 (epoch 19), train_loss = 2.483, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 11577 (epoch 19), train_loss = 2.081, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 11578 (epoch 19), train_loss = 2.502, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 11579 (epoch 19), train_loss = 2.835, time/batch = 0.025
Read data: 0.00014901161193847656
iter 11580 (epoch 19), train_loss = 2.526, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 11581 (epoch 19), train_loss = 2.876, time/batch = 0.036
Read data: 0.00022864341735839844
iter 11582 (epoch 19), train_loss = 2.563, time/batch = 0.029
Read data: 0.00012493133544921875
iter 11583 (epoch 19), train_loss = 2.782, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 11584 (epoch 19), train_loss = 2.256, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 11585 (epoch 19), train_loss = 2.457, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 11586 (epoch 19), train_loss = 2.349, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 11587 (epoch 19), train_loss = 2.788, time/batch = 0.025
Read data: 0.00010180473327636719
iter 11588 (epoch 19), train_loss = 2.627, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 11589 (epoch 19), train_loss = 2.816, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 11590 (epoch 19), train_loss = 2.304, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 11591 (epoch 19), train_loss = 2.169, time/batch = 0.027
Read data: 0.00014352798461914062
iter 11592 (epoch 19), train_loss = 2.611, time/batch = 0.029
Read data: 0.00016760826110839844
iter 11593 (epoch 19), train_loss = 2.337, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 11594 (epoch 19), train_loss = 2.007, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 11595 (epoch 19), train_loss = 2.406, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 11596 (epoch 19), train_loss = 2.823, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 11597 (epoch 19), train_loss = 2.448, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 11598 (epoch 19), train_loss = 2.987, time/batch = 0.034
Read data: 8.034706115722656e-05
iter 11599 (epoch 19), train_loss = 2.125, time/batch = 0.025
Read data: 0.0002827644348144531
iter 11600 (epoch 19), train_loss = 2.502, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 11601 (epoch 19), train_loss = 2.406, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 11602 (epoch 19), train_loss = 2.246, time/batch = 0.021
Read data: 0.00014638900756835938
iter 11603 (epoch 19), train_loss = 2.871, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 11604 (epoch 19), train_loss = 2.435, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 11605 (epoch 19), train_loss = 3.044, time/batch = 0.027
Read data: 0.00014209747314453125
iter 11606 (epoch 19), train_loss = 2.431, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 11607 (epoch 19), train_loss = 2.624, time/batch = 0.025
Read data: 0.0001418590545654297
iter 11608 (epoch 19), train_loss = 2.395, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 11609 (epoch 19), train_loss = 2.377, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 11610 (epoch 19), train_loss = 2.332, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 11611 (epoch 19), train_loss = 2.253, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 11612 (epoch 19), train_loss = 2.645, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 11613 (epoch 19), train_loss = 2.675, time/batch = 0.025
Read data: 0.00010085105895996094
iter 11614 (epoch 19), train_loss = 2.816, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 11615 (epoch 19), train_loss = 2.756, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 11616 (epoch 19), train_loss = 2.869, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 11617 (epoch 19), train_loss = 2.279, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 11618 (epoch 19), train_loss = 2.259, time/batch = 0.027
Read data: 0.00012993812561035156
iter 11619 (epoch 19), train_loss = 2.457, time/batch = 0.027
Read data: 7.557868957519531e-05
iter 11620 (epoch 19), train_loss = 2.163, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 11621 (epoch 19), train_loss = 2.354, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 11622 (epoch 19), train_loss = 2.697, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 11623 (epoch 19), train_loss = 2.729, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 11624 (epoch 19), train_loss = 2.099, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 11625 (epoch 19), train_loss = 2.562, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 11626 (epoch 19), train_loss = 2.134, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 11627 (epoch 19), train_loss = 2.657, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 11628 (epoch 19), train_loss = 2.661, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 11629 (epoch 19), train_loss = 2.159, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 11630 (epoch 19), train_loss = 2.597, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 11631 (epoch 19), train_loss = 2.480, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 11632 (epoch 19), train_loss = 2.003, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 11633 (epoch 19), train_loss = 2.277, time/batch = 0.036
Read data: 8.702278137207031e-05
iter 11634 (epoch 19), train_loss = 2.940, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 11635 (epoch 19), train_loss = 2.624, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 11636 (epoch 19), train_loss = 2.380, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 11637 (epoch 19), train_loss = 2.926, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 11638 (epoch 19), train_loss = 2.178, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 11639 (epoch 19), train_loss = 2.437, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 11640 (epoch 19), train_loss = 2.743, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 11641 (epoch 19), train_loss = 2.477, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 11642 (epoch 19), train_loss = 2.426, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 11643 (epoch 19), train_loss = 2.382, time/batch = 0.021
Read data: 0.00011730194091796875
iter 11644 (epoch 19), train_loss = 2.618, time/batch = 0.032
Read data: 8.821487426757812e-05
iter 11645 (epoch 19), train_loss = 2.581, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 11646 (epoch 19), train_loss = 2.313, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 11647 (epoch 19), train_loss = 2.821, time/batch = 0.027
Read data: 0.0001323223114013672
iter 11648 (epoch 19), train_loss = 2.358, time/batch = 0.025
Read data: 0.0016853809356689453
iter 11649 (epoch 19), train_loss = 2.427, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 11650 (epoch 19), train_loss = 2.278, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 11651 (epoch 19), train_loss = 2.625, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 11652 (epoch 19), train_loss = 2.431, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 11653 (epoch 19), train_loss = 2.193, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 11654 (epoch 19), train_loss = 2.413, time/batch = 0.028
Read data: 0.00013184547424316406
iter 11655 (epoch 19), train_loss = 2.598, time/batch = 0.022
Read data: 0.00010061264038085938
iter 11656 (epoch 19), train_loss = 2.816, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 11657 (epoch 19), train_loss = 1.926, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 11658 (epoch 19), train_loss = 2.402, time/batch = 0.028
Read data: 0.0016186237335205078
iter 11659 (epoch 19), train_loss = 2.607, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 11660 (epoch 19), train_loss = 2.082, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 11661 (epoch 19), train_loss = 2.403, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 11662 (epoch 19), train_loss = 2.277, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 11663 (epoch 19), train_loss = 2.456, time/batch = 0.027
Read data: 0.00013303756713867188
iter 11664 (epoch 19), train_loss = 2.405, time/batch = 0.027
Read data: 0.00015115737915039062
iter 11665 (epoch 19), train_loss = 2.838, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 11666 (epoch 19), train_loss = 2.803, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 11667 (epoch 19), train_loss = 2.700, time/batch = 0.026
Read data: 0.00014448165893554688
iter 11668 (epoch 19), train_loss = 2.861, time/batch = 0.029
Read data: 9.512901306152344e-05
iter 11669 (epoch 19), train_loss = 2.336, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 11670 (epoch 19), train_loss = 2.647, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 11671 (epoch 19), train_loss = 2.753, time/batch = 0.029
Read data: 0.000133514404296875
iter 11672 (epoch 19), train_loss = 2.466, time/batch = 0.021
Read data: 9.822845458984375e-05
iter 11673 (epoch 19), train_loss = 2.958, time/batch = 0.027
Read data: 0.00010251998901367188
iter 11674 (epoch 19), train_loss = 2.509, time/batch = 0.032
Read data: 0.00012826919555664062
iter 11675 (epoch 19), train_loss = 2.873, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 11676 (epoch 19), train_loss = 2.795, time/batch = 0.028
Read data: 9.989738464355469e-05
iter 11677 (epoch 19), train_loss = 2.449, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 11678 (epoch 19), train_loss = 2.613, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 11679 (epoch 19), train_loss = 2.534, time/batch = 0.029
Read data: 0.00012922286987304688
iter 11680 (epoch 19), train_loss = 2.782, time/batch = 0.032
Read data: 0.00014853477478027344
iter 11681 (epoch 19), train_loss = 2.631, time/batch = 0.027
Read data: 9.942054748535156e-05
iter 11682 (epoch 19), train_loss = 2.702, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 11683 (epoch 19), train_loss = 2.508, time/batch = 0.032
Read data: 0.00013494491577148438
iter 11684 (epoch 19), train_loss = 2.514, time/batch = 0.025
Read data: 0.00012087821960449219
iter 11685 (epoch 19), train_loss = 3.074, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 11686 (epoch 19), train_loss = 2.449, time/batch = 0.027
Read data: 0.00013136863708496094
iter 11687 (epoch 19), train_loss = 2.021, time/batch = 0.022
Read data: 0.00012874603271484375
iter 11688 (epoch 19), train_loss = 2.497, time/batch = 0.026
Read data: 0.00010037422180175781
iter 11689 (epoch 19), train_loss = 2.432, time/batch = 0.023
Read data: 0.00013375282287597656
iter 11690 (epoch 19), train_loss = 2.757, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 11691 (epoch 19), train_loss = 2.359, time/batch = 0.031
Read data: 0.0001227855682373047
iter 11692 (epoch 19), train_loss = 2.198, time/batch = 0.026
Read data: 0.00011682510375976562
iter 11693 (epoch 19), train_loss = 2.394, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 11694 (epoch 19), train_loss = 2.745, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 11695 (epoch 19), train_loss = 2.170, time/batch = 0.027
Read data: 0.00015664100646972656
iter 11696 (epoch 19), train_loss = 2.588, time/batch = 0.030
Read data: 0.00014781951904296875
iter 11697 (epoch 19), train_loss = 2.328, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 11698 (epoch 19), train_loss = 2.499, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 11699 (epoch 19), train_loss = 3.102, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 11700 (epoch 19), train_loss = 2.143, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 11701 (epoch 19), train_loss = 2.374, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 11702 (epoch 19), train_loss = 2.582, time/batch = 0.022
Read data: 0.000125885009765625
iter 11703 (epoch 19), train_loss = 2.113, time/batch = 0.022
Read data: 0.00014352798461914062
iter 11704 (epoch 19), train_loss = 2.356, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 11705 (epoch 19), train_loss = 2.474, time/batch = 0.025
Read data: 9.1552734375e-05
iter 11706 (epoch 19), train_loss = 2.634, time/batch = 0.027
Read data: 0.000164031982421875
iter 11707 (epoch 19), train_loss = 2.336, time/batch = 0.024
Read data: 0.00011110305786132812
iter 11708 (epoch 19), train_loss = 3.029, time/batch = 0.030
Read data: 9.608268737792969e-05
iter 11709 (epoch 19), train_loss = 2.566, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 11710 (epoch 19), train_loss = 2.290, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 11711 (epoch 19), train_loss = 2.447, time/batch = 0.028
Read data: 0.0001323223114013672
iter 11712 (epoch 19), train_loss = 2.263, time/batch = 0.023
Read data: 0.00011658668518066406
iter 11713 (epoch 19), train_loss = 2.478, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 11714 (epoch 19), train_loss = 2.689, time/batch = 0.032
Read data: 0.0001647472381591797
iter 11715 (epoch 19), train_loss = 2.271, time/batch = 0.031
Read data: 0.0001628398895263672
iter 11716 (epoch 19), train_loss = 2.674, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 11717 (epoch 19), train_loss = 2.490, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 11718 (epoch 19), train_loss = 2.636, time/batch = 0.022
Read data: 0.0001220703125
iter 11719 (epoch 19), train_loss = 2.685, time/batch = 0.030
Read data: 0.000133514404296875
iter 11720 (epoch 19), train_loss = 2.479, time/batch = 0.026
Read data: 0.00014901161193847656
iter 11721 (epoch 19), train_loss = 2.310, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 11722 (epoch 19), train_loss = 2.141, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 11723 (epoch 19), train_loss = 2.528, time/batch = 0.025
Read data: 0.00010418891906738281
iter 11724 (epoch 19), train_loss = 2.698, time/batch = 0.039
Read data: 0.00010371208190917969
iter 11725 (epoch 19), train_loss = 2.323, time/batch = 0.028
Read data: 9.1552734375e-05
iter 11726 (epoch 19), train_loss = 2.754, time/batch = 0.032
Read data: 7.510185241699219e-05
iter 11727 (epoch 19), train_loss = 2.692, time/batch = 0.027
Read data: 0.00013756752014160156
iter 11728 (epoch 19), train_loss = 2.333, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 11729 (epoch 19), train_loss = 2.389, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 11730 (epoch 19), train_loss = 2.336, time/batch = 0.026
Read data: 0.00016570091247558594
iter 11731 (epoch 19), train_loss = 2.632, time/batch = 0.025
Read data: 0.00016927719116210938
iter 11732 (epoch 19), train_loss = 2.482, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 11733 (epoch 19), train_loss = 2.342, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 11734 (epoch 19), train_loss = 2.664, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 11735 (epoch 19), train_loss = 2.255, time/batch = 0.021
Read data: 0.00014710426330566406
iter 11736 (epoch 19), train_loss = 3.056, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 11737 (epoch 19), train_loss = 2.437, time/batch = 0.031
Read data: 0.0001373291015625
iter 11738 (epoch 19), train_loss = 2.158, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 11739 (epoch 19), train_loss = 2.500, time/batch = 0.033
Read data: 0.0001621246337890625
iter 11740 (epoch 19), train_loss = 2.414, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 11741 (epoch 19), train_loss = 2.904, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 11742 (epoch 19), train_loss = 2.567, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 11743 (epoch 19), train_loss = 2.852, time/batch = 0.027
Read data: 0.00012493133544921875
iter 11744 (epoch 19), train_loss = 2.546, time/batch = 0.028
Read data: 0.00010991096496582031
iter 11745 (epoch 19), train_loss = 2.498, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 11746 (epoch 19), train_loss = 2.323, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 11747 (epoch 19), train_loss = 2.597, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 11748 (epoch 19), train_loss = 2.400, time/batch = 0.019
Read data: 8.606910705566406e-05
iter 11749 (epoch 19), train_loss = 2.273, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 11750 (epoch 19), train_loss = 2.230, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 11751 (epoch 19), train_loss = 2.540, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 11752 (epoch 19), train_loss = 2.630, time/batch = 0.031
Read data: 0.00014781951904296875
iter 11753 (epoch 19), train_loss = 2.350, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 11754 (epoch 19), train_loss = 2.729, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 11755 (epoch 19), train_loss = 2.601, time/batch = 0.027
Read data: 0.00016689300537109375
iter 11756 (epoch 19), train_loss = 2.306, time/batch = 0.032
Read data: 0.00012111663818359375
iter 11757 (epoch 19), train_loss = 2.471, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 11758 (epoch 19), train_loss = 2.618, time/batch = 0.021
Read data: 0.00012445449829101562
iter 11759 (epoch 19), train_loss = 2.586, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 11760 (epoch 19), train_loss = 2.422, time/batch = 0.034
Read data: 8.20159912109375e-05
iter 11761 (epoch 19), train_loss = 2.320, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 11762 (epoch 19), train_loss = 2.490, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 11763 (epoch 19), train_loss = 2.370, time/batch = 0.026
Read data: 0.00016736984252929688
iter 11764 (epoch 19), train_loss = 2.358, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 11765 (epoch 19), train_loss = 2.598, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 11766 (epoch 19), train_loss = 2.469, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 11767 (epoch 19), train_loss = 2.531, time/batch = 0.023
Read data: 0.00013756752014160156
iter 11768 (epoch 19), train_loss = 2.834, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 11769 (epoch 19), train_loss = 2.455, time/batch = 0.031
Read data: 8.940696716308594e-05
iter 11770 (epoch 19), train_loss = 2.453, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 11771 (epoch 19), train_loss = 2.633, time/batch = 0.027
Read data: 0.00012731552124023438
iter 11772 (epoch 19), train_loss = 2.456, time/batch = 0.030
Read data: 0.00012111663818359375
iter 11773 (epoch 19), train_loss = 2.726, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 11774 (epoch 19), train_loss = 2.504, time/batch = 0.026
Read data: 0.00012445449829101562
iter 11775 (epoch 19), train_loss = 2.089, time/batch = 0.027
Read data: 0.00013899803161621094
iter 11776 (epoch 19), train_loss = 2.483, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 11777 (epoch 19), train_loss = 2.628, time/batch = 0.025
Read data: 0.00010156631469726562
iter 11778 (epoch 19), train_loss = 2.273, time/batch = 0.033
Read data: 8.273124694824219e-05
iter 11779 (epoch 19), train_loss = 2.795, time/batch = 0.024
Read data: 0.0001437664031982422
iter 11780 (epoch 19), train_loss = 2.600, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 11781 (epoch 19), train_loss = 2.598, time/batch = 0.023
Read data: 0.00010752677917480469
iter 11782 (epoch 19), train_loss = 2.735, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 11783 (epoch 19), train_loss = 2.892, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 11784 (epoch 19), train_loss = 2.496, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 11785 (epoch 19), train_loss = 2.568, time/batch = 0.027
Read data: 0.00010538101196289062
iter 11786 (epoch 19), train_loss = 2.527, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 11787 (epoch 19), train_loss = 2.716, time/batch = 0.027
Read data: 0.00018262863159179688
iter 11788 (epoch 19), train_loss = 2.953, time/batch = 0.039
Read data: 8.249282836914062e-05
iter 11789 (epoch 19), train_loss = 2.592, time/batch = 0.031
Read data: 9.202957153320312e-05
iter 11790 (epoch 19), train_loss = 2.464, time/batch = 0.030
Read data: 9.655952453613281e-05
iter 11791 (epoch 19), train_loss = 2.655, time/batch = 0.037
Read data: 0.0001392364501953125
iter 11792 (epoch 19), train_loss = 2.944, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 11793 (epoch 19), train_loss = 3.020, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 11794 (epoch 19), train_loss = 2.626, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 11795 (epoch 19), train_loss = 2.408, time/batch = 0.021
Read data: 0.0001308917999267578
iter 11796 (epoch 19), train_loss = 2.193, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 11797 (epoch 19), train_loss = 2.648, time/batch = 0.024
Read data: 8.392333984375e-05
iter 11798 (epoch 19), train_loss = 2.917, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 11799 (epoch 19), train_loss = 3.061, time/batch = 0.031
Read data: 0.0002105236053466797
iter 11800 (epoch 19), train_loss = 2.052, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 11801 (epoch 19), train_loss = 2.732, time/batch = 0.025
Read data: 0.00010609626770019531
iter 11802 (epoch 19), train_loss = 2.437, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 11803 (epoch 19), train_loss = 2.764, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 11804 (epoch 19), train_loss = 2.542, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 11805 (epoch 19), train_loss = 2.141, time/batch = 0.032
Read data: 9.369850158691406e-05
iter 11806 (epoch 19), train_loss = 2.532, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 11807 (epoch 19), train_loss = 2.815, time/batch = 0.029
Read data: 0.00017547607421875
iter 11808 (epoch 19), train_loss = 2.358, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 11809 (epoch 19), train_loss = 2.652, time/batch = 0.024
Read data: 0.0001361370086669922
iter 11810 (epoch 19), train_loss = 2.310, time/batch = 0.023
Read data: 0.00010085105895996094
iter 11811 (epoch 19), train_loss = 2.397, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 11812 (epoch 19), train_loss = 2.563, time/batch = 0.028
Read data: 9.512901306152344e-05
iter 11813 (epoch 19), train_loss = 2.824, time/batch = 0.026
Read data: 9.918212890625e-05
iter 11814 (epoch 19), train_loss = 2.973, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 11815 (epoch 19), train_loss = 2.769, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 11816 (epoch 19), train_loss = 2.402, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 11817 (epoch 19), train_loss = 2.636, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 11818 (epoch 19), train_loss = 2.611, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 11819 (epoch 19), train_loss = 3.223, time/batch = 0.026
Read data: 0.00012683868408203125
iter 11820 (epoch 19), train_loss = 2.828, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 11821 (epoch 19), train_loss = 2.512, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 11822 (epoch 19), train_loss = 2.520, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 11823 (epoch 19), train_loss = 2.486, time/batch = 0.027
Read data: 0.00012993812561035156
iter 11824 (epoch 19), train_loss = 2.365, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 11825 (epoch 19), train_loss = 2.384, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 11826 (epoch 19), train_loss = 2.395, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 11827 (epoch 19), train_loss = 2.573, time/batch = 0.031
Read data: 0.0001552104949951172
iter 11828 (epoch 19), train_loss = 3.068, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 11829 (epoch 19), train_loss = 3.013, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 11830 (epoch 19), train_loss = 2.723, time/batch = 0.025
Read data: 0.00013113021850585938
iter 11831 (epoch 19), train_loss = 2.604, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 11832 (epoch 19), train_loss = 2.916, time/batch = 0.023
Read data: 9.512901306152344e-05
iter 11833 (epoch 19), train_loss = 2.733, time/batch = 0.026
Read data: 0.00010776519775390625
iter 11834 (epoch 19), train_loss = 2.984, time/batch = 0.026
Read data: 9.965896606445312e-05
iter 11835 (epoch 19), train_loss = 2.818, time/batch = 0.028
Read data: 0.00012230873107910156
iter 11836 (epoch 19), train_loss = 2.352, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 11837 (epoch 19), train_loss = 2.338, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 11838 (epoch 19), train_loss = 2.099, time/batch = 0.028
Read data: 0.0001354217529296875
iter 11839 (epoch 19), train_loss = 2.893, time/batch = 0.030
Read data: 0.0001246929168701172
iter 11840 (epoch 19), train_loss = 2.446, time/batch = 0.027
Read data: 0.00013303756713867188
iter 11841 (epoch 19), train_loss = 2.426, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 11842 (epoch 19), train_loss = 2.337, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 11843 (epoch 19), train_loss = 2.546, time/batch = 0.021
Read data: 0.00020170211791992188
iter 11844 (epoch 19), train_loss = 2.639, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 11845 (epoch 19), train_loss = 2.866, time/batch = 0.025
Read data: 0.00010156631469726562
iter 11846 (epoch 19), train_loss = 2.638, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 11847 (epoch 19), train_loss = 2.706, time/batch = 0.027
Read data: 0.00014328956604003906
iter 11848 (epoch 19), train_loss = 2.860, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 11849 (epoch 19), train_loss = 2.245, time/batch = 0.025
Read data: 9.131431579589844e-05
iter 11850 (epoch 19), train_loss = 2.659, time/batch = 0.023
Read data: 7.534027099609375e-05
iter 11851 (epoch 19), train_loss = 2.896, time/batch = 0.027
Read data: 0.0001270771026611328
iter 11852 (epoch 19), train_loss = 2.510, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 11853 (epoch 19), train_loss = 2.735, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 11854 (epoch 19), train_loss = 2.280, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 11855 (epoch 19), train_loss = 2.501, time/batch = 0.028
Read data: 0.000156402587890625
iter 11856 (epoch 19), train_loss = 2.308, time/batch = 0.024
Read data: 9.5367431640625e-05
iter 11857 (epoch 19), train_loss = 2.538, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 11858 (epoch 19), train_loss = 2.492, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 11859 (epoch 19), train_loss = 2.695, time/batch = 0.029
Read data: 0.0001246929168701172
iter 11860 (epoch 19), train_loss = 2.456, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 11861 (epoch 19), train_loss = 2.688, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 11862 (epoch 19), train_loss = 1.902, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 11863 (epoch 19), train_loss = 2.473, time/batch = 0.029
Read data: 0.0001373291015625
iter 11864 (epoch 19), train_loss = 2.436, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 11865 (epoch 19), train_loss = 2.606, time/batch = 0.027
Read data: 0.00010466575622558594
iter 11866 (epoch 19), train_loss = 2.833, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 11867 (epoch 19), train_loss = 2.621, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 11868 (epoch 19), train_loss = 2.633, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 11869 (epoch 19), train_loss = 2.034, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 11870 (epoch 19), train_loss = 2.776, time/batch = 0.040
Read data: 8.559226989746094e-05
iter 11871 (epoch 19), train_loss = 2.627, time/batch = 0.025
Read data: 0.00017189979553222656
iter 11872 (epoch 19), train_loss = 2.001, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 11873 (epoch 19), train_loss = 2.565, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 11874 (epoch 19), train_loss = 2.385, time/batch = 0.022
Read data: 0.00017499923706054688
iter 11875 (epoch 19), train_loss = 2.647, time/batch = 0.027
Read data: 0.00013017654418945312
iter 11876 (epoch 19), train_loss = 2.386, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 11877 (epoch 19), train_loss = 2.226, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 11878 (epoch 19), train_loss = 2.624, time/batch = 0.023
Read data: 0.00015282630920410156
iter 11879 (epoch 19), train_loss = 2.347, time/batch = 0.025
Read data: 0.0001373291015625
iter 11880 (epoch 19), train_loss = 2.394, time/batch = 0.033
Read data: 9.393692016601562e-05
iter 11881 (epoch 19), train_loss = 2.505, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 11882 (epoch 19), train_loss = 2.575, time/batch = 0.027
Read data: 0.00016236305236816406
iter 11883 (epoch 19), train_loss = 2.444, time/batch = 0.027
Read data: 0.00015091896057128906
iter 11884 (epoch 19), train_loss = 2.283, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 11885 (epoch 19), train_loss = 2.566, time/batch = 0.027
Read data: 0.000102996826171875
iter 11886 (epoch 19), train_loss = 2.736, time/batch = 0.035
Read data: 8.344650268554688e-05
iter 11887 (epoch 19), train_loss = 2.473, time/batch = 0.028
Read data: 0.0001316070556640625
iter 11888 (epoch 19), train_loss = 2.214, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 11889 (epoch 19), train_loss = 2.678, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 11890 (epoch 19), train_loss = 2.820, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 11891 (epoch 19), train_loss = 2.674, time/batch = 0.027
Read data: 0.00010132789611816406
iter 11892 (epoch 19), train_loss = 2.510, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 11893 (epoch 19), train_loss = 2.619, time/batch = 0.023
Read data: 0.00010204315185546875
iter 11894 (epoch 19), train_loss = 2.259, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 11895 (epoch 19), train_loss = 2.615, time/batch = 0.021
Read data: 0.00014209747314453125
iter 11896 (epoch 19), train_loss = 2.678, time/batch = 0.027
Read data: 0.00011420249938964844
iter 11897 (epoch 19), train_loss = 3.096, time/batch = 0.040
Read data: 8.654594421386719e-05
iter 11898 (epoch 19), train_loss = 2.414, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 11899 (epoch 19), train_loss = 2.470, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 11900 (epoch 19), train_loss = 3.055, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 11901 (epoch 19), train_loss = 2.530, time/batch = 0.019
Read data: 9.72747802734375e-05
iter 11902 (epoch 19), train_loss = 2.486, time/batch = 0.033
Read data: 0.0001323223114013672
iter 11903 (epoch 19), train_loss = 2.778, time/batch = 0.027
Read data: 0.00015783309936523438
iter 11904 (epoch 19), train_loss = 2.807, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 11905 (epoch 19), train_loss = 2.367, time/batch = 0.025
Read data: 0.00010609626770019531
iter 11906 (epoch 19), train_loss = 2.531, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 11907 (epoch 19), train_loss = 2.479, time/batch = 0.023
Read data: 0.00017452239990234375
iter 11908 (epoch 19), train_loss = 2.692, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 11909 (epoch 19), train_loss = 2.739, time/batch = 0.032
Read data: 0.00010061264038085938
iter 11910 (epoch 19), train_loss = 2.547, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 11911 (epoch 19), train_loss = 2.262, time/batch = 0.025
Read data: 0.00012421607971191406
iter 11912 (epoch 19), train_loss = 2.249, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 11913 (epoch 19), train_loss = 2.489, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 11914 (epoch 19), train_loss = 3.054, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 11915 (epoch 19), train_loss = 2.035, time/batch = 0.023
Read data: 0.0001442432403564453
iter 11916 (epoch 19), train_loss = 2.557, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 11917 (epoch 19), train_loss = 2.424, time/batch = 0.024
Read data: 8.392333984375e-05
iter 11918 (epoch 19), train_loss = 2.707, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 11919 (epoch 19), train_loss = 2.602, time/batch = 0.025
Read data: 0.00017571449279785156
iter 11920 (epoch 19), train_loss = 2.349, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 11921 (epoch 19), train_loss = 2.593, time/batch = 0.029
Read data: 0.000102996826171875
iter 11922 (epoch 19), train_loss = 2.405, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 11923 (epoch 19), train_loss = 2.740, time/batch = 0.027
Read data: 0.00012373924255371094
iter 11924 (epoch 19), train_loss = 2.528, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 11925 (epoch 19), train_loss = 2.417, time/batch = 0.022
Read data: 9.560585021972656e-05
iter 11926 (epoch 19), train_loss = 2.385, time/batch = 0.025
Read data: 0.00015044212341308594
iter 11927 (epoch 19), train_loss = 2.599, time/batch = 0.031
Read data: 0.00011324882507324219
iter 11928 (epoch 19), train_loss = 2.681, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 11929 (epoch 19), train_loss = 2.311, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 11930 (epoch 19), train_loss = 2.670, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 11931 (epoch 19), train_loss = 2.609, time/batch = 0.023
Read data: 0.0001709461212158203
iter 11932 (epoch 19), train_loss = 2.516, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 11933 (epoch 19), train_loss = 2.697, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 11934 (epoch 19), train_loss = 2.503, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 11935 (epoch 19), train_loss = 2.616, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 11936 (epoch 19), train_loss = 2.464, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 11937 (epoch 19), train_loss = 2.798, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 11938 (epoch 19), train_loss = 2.811, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 11939 (epoch 19), train_loss = 2.396, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 11940 (epoch 19), train_loss = 2.749, time/batch = 0.034
Read data: 8.440017700195312e-05
iter 11941 (epoch 19), train_loss = 2.717, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 11942 (epoch 19), train_loss = 2.734, time/batch = 0.021
Read data: 9.012222290039062e-05
iter 11943 (epoch 19), train_loss = 2.500, time/batch = 0.027
Read data: 0.00015997886657714844
iter 11944 (epoch 19), train_loss = 2.428, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 11945 (epoch 19), train_loss = 2.824, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 11946 (epoch 19), train_loss = 2.546, time/batch = 0.023
Read data: 0.00012564659118652344
iter 11947 (epoch 19), train_loss = 2.311, time/batch = 0.030
Read data: 0.00012969970703125
iter 11948 (epoch 19), train_loss = 2.816, time/batch = 0.029
Read data: 9.036064147949219e-05
iter 11949 (epoch 19), train_loss = 2.546, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 11950 (epoch 19), train_loss = 2.401, time/batch = 0.023
Read data: 0.0001347064971923828
iter 11951 (epoch 19), train_loss = 2.441, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 11952 (epoch 19), train_loss = 2.502, time/batch = 0.025
Read data: 0.00014328956604003906
iter 11953 (epoch 19), train_loss = 2.468, time/batch = 0.022
Read data: 0.0001995563507080078
iter 11954 (epoch 19), train_loss = 2.591, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 11955 (epoch 19), train_loss = 2.779, time/batch = 0.035
Read data: 9.679794311523438e-05
iter 11956 (epoch 19), train_loss = 2.683, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 11957 (epoch 19), train_loss = 2.729, time/batch = 0.033
Read data: 9.298324584960938e-05
iter 11958 (epoch 19), train_loss = 2.238, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 11959 (epoch 19), train_loss = 2.369, time/batch = 0.025
Read data: 0.0001227855682373047
iter 11960 (epoch 19), train_loss = 2.540, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 11961 (epoch 19), train_loss = 3.028, time/batch = 0.037
Read data: 0.0001556873321533203
iter 11962 (epoch 19), train_loss = 2.701, time/batch = 0.028
Read data: 8.392333984375e-05
iter 11963 (epoch 19), train_loss = 2.871, time/batch = 0.031
Read data: 0.00013065338134765625
iter 11964 (epoch 19), train_loss = 2.567, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 11965 (epoch 19), train_loss = 2.637, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 11966 (epoch 19), train_loss = 2.196, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 11967 (epoch 19), train_loss = 2.378, time/batch = 0.023
Read data: 0.0001361370086669922
iter 11968 (epoch 19), train_loss = 2.538, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 11969 (epoch 19), train_loss = 2.654, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 11970 (epoch 19), train_loss = 2.604, time/batch = 0.032
Read data: 7.677078247070312e-05
iter 11971 (epoch 19), train_loss = 2.546, time/batch = 0.027
Read data: 0.00016736984252929688
iter 11972 (epoch 19), train_loss = 2.714, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 11973 (epoch 19), train_loss = 2.176, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 11974 (epoch 19), train_loss = 2.849, time/batch = 0.020
Read data: 8.296966552734375e-05
iter 11975 (epoch 19), train_loss = 2.706, time/batch = 0.027
Read data: 0.0001800060272216797
iter 11976 (epoch 19), train_loss = 2.444, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 11977 (epoch 19), train_loss = 2.653, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 11978 (epoch 19), train_loss = 2.807, time/batch = 0.027
Read data: 0.00015592575073242188
iter 11979 (epoch 19), train_loss = 1.975, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 11980 (epoch 19), train_loss = 2.623, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 11981 (epoch 19), train_loss = 2.158, time/batch = 0.028
Read data: 0.00012111663818359375
iter 11982 (epoch 19), train_loss = 2.464, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 11983 (epoch 19), train_loss = 2.698, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 11984 (epoch 19), train_loss = 2.904, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 11985 (epoch 19), train_loss = 2.797, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 11986 (epoch 19), train_loss = 2.321, time/batch = 0.027
Read data: 0.00010442733764648438
iter 11987 (epoch 19), train_loss = 2.172, time/batch = 0.022
Read data: 0.00017309188842773438
iter 11988 (epoch 19), train_loss = 2.478, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 11989 (epoch 19), train_loss = 2.770, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 11990 (epoch 19), train_loss = 2.788, time/batch = 0.027
Read data: 0.00014257431030273438
iter 11991 (epoch 19), train_loss = 2.337, time/batch = 0.027
Read data: 0.0008795261383056641
iter 11992 (epoch 19), train_loss = 2.406, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 11993 (epoch 19), train_loss = 2.928, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 11994 (epoch 19), train_loss = 2.614, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 11995 (epoch 19), train_loss = 2.786, time/batch = 0.029
Read data: 0.00012373924255371094
iter 11996 (epoch 19), train_loss = 2.650, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 11997 (epoch 19), train_loss = 2.721, time/batch = 0.025
Read data: 0.00010085105895996094
iter 11998 (epoch 19), train_loss = 2.385, time/batch = 0.024
Read data: 7.62939453125e-05
iter 11999 (epoch 19), train_loss = 2.467, time/batch = 0.019
image 976:    
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:     
image 2375:    
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.628865)
image 2798:     
image 5884:     
image 2067:     
image 3600:    
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.246036)
image 6903:      
image 3301:    
image 2019:    
image 5535:    
image 7680:     
image 5527:      
image 2568:    
image 160:    
image 8085:     
image 7670:    
evaluating validation preformance... 30/1000 (2.554351)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.936441)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:    
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.522730)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:     
image 6329:    
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (2.804949)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.598450)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.638707)
image 3276:      
image 3812:     
image 1400:    
image 3443:    
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.122424)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:      
evaluating validation preformance... 100/1000 (2.913361)
image 2800:    
image 7249:    
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.792635)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     UNK
evaluating validation preformance... 120/1000 (2.362784)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.921208)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:   
image 4450:    
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.699292)
image 1738:     
image 1455:     
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (2.918652)
image 1865:    
image 3830:      
image 360:     
image 5097:    
image 4455:     
image 1153:    
image 1248:    
image 7688:     
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.791205)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.576329)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:    
image 3000:    
image 1806:    
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.702607)
image 2313:    
image 6289:    
image 8084:      
image 2696:    
image 5830:     
image 6240:      
image 4541:     
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.419757)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.317252)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.457259)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:    
image 1725:    
image 1089:      
image 864:    
image 7345:    
evaluating validation preformance... 220/1000 (2.565514)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:   
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.243433)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.159697)
image 7143:     
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.540949)
image 3028:     
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.509846)
image 492:    
image 5429:     
image 6968:      
image 2672:      
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.989194)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.575726)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.431111)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.183309)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.776197)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:     
image 6423:    
evaluating validation preformance... 320/1000 (2.328533)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:      
evaluating validation preformance... 330/1000 (2.740471)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:     UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.441904)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.558198)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:    
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.023247)
image 2905:     
image 7814:      
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:    
image 4866:     
evaluating validation preformance... 370/1000 (2.593883)
image 4351:     
image 1054:     
image 129:     
image 2849:    
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.638191)
image 2458:     
image 1084:      
image 4835:     
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:    
image 60:     
evaluating validation preformance... 390/1000 (2.862267)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:    
image 1117:    
image 5817:      
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.228719)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.123836)
image 4359:    
image 2372:    
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:     
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.354103)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:    
image 6977:    
image 877:   
image 2408:    UNK
image 7706:     UNK
evaluating validation preformance... 430/1000 (2.790228)
image 385:    
image 6938:      
image 2381:    
image 5796:     
image 4010:     
image 3452:     
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.912404)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:     
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.233862)
image 2241:     
image 2651:    
image 2315:     
image 4784:     
image 5160:     
image 2466:    UNK
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.704536)
image 7979:    
image 1618:    
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.237404)
image 4503:     
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:      
image 7450:     
image 841:    
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.894946)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:     
image 3823:    
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.276930)
image 2044:    
image 4349:    
image 3855:     
image 1846:    UNK
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.502938)
image 1797:    
image 4670:   
image 4846:    
image 5907:     
image 3321:      
image 1700:     
image 438:     
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (3.001448)
image 3246:    
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.655220)
image 6806:      
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:   
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.478722)
image 5619:     
image 4391:     
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:      
image 6034:     
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.477145)
image 5292:    
image 2901:     
image 3568:    
image 690:     
image 3345:    
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.576193)
image 5439:    
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:     
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.601444)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.594280)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.577740)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:    
image 1500:     
image 5094:    
image 5778:     
image 6422:     
evaluating validation preformance... 590/1000 (2.565293)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.532045)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.690787)
image 69:     
image 3465:    
image 6179:    
image 552:    
image 511:    
image 761:    
image 5742:     
image 359:    
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.427017)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.510573)
image 8074:    
image 1904:     
image 7917:      
image 2394:     
image 4406:    UNK
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.484542)
image 5313:      
image 2377:      
image 6058:    
image 4661:    
image 2955:   
image 3333:     
image 7124:     
image 4278:      
image 953:     
image 4037:    
evaluating validation preformance... 650/1000 (2.545969)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:     
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.643501)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:     
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (2.864754)
image 7877:    
image 6761:     
image 6880:   
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (2.984573)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:     
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.877643)
image 6860:     
image 576:    
image 6580:     
image 1497:    
image 3360:     
image 4939:     
image 6225:     
image 3669:     
image 980:    
image 5362:      
evaluating validation preformance... 700/1000 (2.990337)
image 5343:      
image 68:    
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.479903)
image 7368:    
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.607552)
image 5729:     
image 6395:      
image 516:      
image 1026:     
image 2972:      
image 3005:    
image 1241:      
image 2743:      
image 3665:    
image 1290:    UNK
evaluating validation preformance... 730/1000 (2.302296)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:     
image 997:    
image 5092:     
image 7789:    
image 2504:      
evaluating validation preformance... 740/1000 (2.457656)
image 2239:     
image 120:     
image 4902:    
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.701754)
image 3279:     
image 6380:    
image 2663:    
image 3815:     
image 512:    
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.964035)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:    
image 1357:     
image 3449:    
evaluating validation preformance... 770/1000 (2.162004)
image 6220:    
image 6238:      
image 4534:     
image 2732:      
image 7003:    
image 1739:     
image 5503:     
image 2329:    
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (2.794635)
image 6867:    
image 5525:     
image 4746:    
image 5531:    
image 5425:    
image 6978:    
image 3450:     
image 3312:     
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.187355)
image 5047:    
image 325:      
image 7626:    
image 4552:     
image 983:    
image 8052:      
image 1585:      
image 4336:      
image 1728:     UNK
image 6725:     
evaluating validation preformance... 800/1000 (2.263391)
image 7288:    
image 7302:      
image 3055:     
image 5250:     
image 1158:     
image 290:     
image 159:     
image 4345:     
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.421172)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.962966)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:     
image 5514:     
image 7147:    
image 6348:     
image 580:    
image 2531:     
evaluating validation preformance... 830/1000 (2.379322)
image 5107:    
image 3973:    
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:     
evaluating validation preformance... 840/1000 (2.419218)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:     
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.786870)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:    
image 3596:      
image 1921:       
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.792500)
image 4254:     
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:    
evaluating validation preformance... 870/1000 (2.341280)
image 4934:    
image 6487:     
image 4217:    
image 6355:     
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.593514)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:     UNK
image 2314:     
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.889123)
image 7485:    
image 6102:    
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:    UNK
image 210:    
evaluating validation preformance... 900/1000 (3.517395)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:   
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.203716)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:    
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.611183)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.516188)
image 5636:     
image 7799:      
image 6025:    
image 6907:    
image 2507:    
image 7014:     
image 5566:     
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.658873)
image 5860:    
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (2.967261)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:    
image 1085:     
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:    
evaluating validation preformance... 960/1000 (2.748589)
image 4935:     
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.343429)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.742009)
image 7352:    
image 5113:     
image 7822:     
image 4858:    UNK
image 658:     
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.475187)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.362270)
average loss on validation: 2.601
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.4293534755706787
Cider scores: 0.5588498835688916
Read data: 0.21267080307006836
Cider scores: 0.590499182198109
Read data: 0.23565196990966797
Cider scores: 0.5908397555337697
Read data: 0.2222597599029541
Cider scores: 0.506205859681218
Read data: 0.22556090354919434
Cider scores: 0.5578900229556281
Read data: 0.17859935760498047
Cider scores: 0.5008269870867178
Read data: 0.19492101669311523
Cider scores: 0.45338257358258394
Read data: 0.20525288581848145
Cider scores: 0.6369276235290454
Read data: 0.16980195045471191
Cider scores: 0.48437024756687475
Read data: 0.18619441986083984
Cider scores: 0.6721986205321404
Read data: 0.24434733390808105
Cider scores: 0.5566042216170672
Read data: 0.17650675773620605
Cider scores: 0.5678811797653102
Read data: 0.19454145431518555
Cider scores: 0.5285359462963451
Read data: 0.17531180381774902
Cider scores: 0.616568848185656
Read data: 0.1800246238708496
Cider scores: 0.5851184566320212
Read data: 0.1686561107635498
Cider scores: 0.6599749435877107
Read data: 0.16312599182128906
Cider scores: 0.46931654033833714
Read data: 0.16009521484375
Cider scores: 0.5905286368466989
Read data: 0.1654510498046875
Cider scores: 0.6143912756093666
Read data: 0.16150140762329102
Cider scores: 0.7876534230204861
Average cider score on test set: 0.576
End calculating cider score on TEST data set
===============================================
Read data: 0.16135382652282715
iter 12000 (epoch 19), train_loss = 2.229, time/batch = 0.020
Read data: 0.00010585784912109375
iter 12001 (epoch 20), train_loss = 2.484, time/batch = 0.023
Read data: 0.00010728836059570312
iter 12002 (epoch 20), train_loss = 2.304, time/batch = 0.020
Read data: 0.00011134147644042969
iter 12003 (epoch 20), train_loss = 2.600, time/batch = 0.024
Read data: 0.00016927719116210938
iter 12004 (epoch 20), train_loss = 2.860, time/batch = 0.027
Read data: 0.00011467933654785156
iter 12005 (epoch 20), train_loss = 2.593, time/batch = 0.028
Read data: 0.00010657310485839844
iter 12006 (epoch 20), train_loss = 2.362, time/batch = 0.024
Read data: 0.000156402587890625
iter 12007 (epoch 20), train_loss = 2.555, time/batch = 0.030
Read data: 0.00011467933654785156
iter 12008 (epoch 20), train_loss = 2.389, time/batch = 0.028
Read data: 9.34600830078125e-05
iter 12009 (epoch 20), train_loss = 2.558, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 12010 (epoch 20), train_loss = 2.892, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 12011 (epoch 20), train_loss = 2.504, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 12012 (epoch 20), train_loss = 2.671, time/batch = 0.033
Read data: 0.00012254714965820312
iter 12013 (epoch 20), train_loss = 2.853, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 12014 (epoch 20), train_loss = 2.791, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 12015 (epoch 20), train_loss = 2.266, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 12016 (epoch 20), train_loss = 3.064, time/batch = 0.023
Read data: 0.00014328956604003906
iter 12017 (epoch 20), train_loss = 2.373, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 12018 (epoch 20), train_loss = 2.488, time/batch = 0.022
Read data: 0.00012159347534179688
iter 12019 (epoch 20), train_loss = 2.267, time/batch = 0.029
Read data: 8.988380432128906e-05
iter 12020 (epoch 20), train_loss = 2.610, time/batch = 0.037
Read data: 0.00013303756713867188
iter 12021 (epoch 20), train_loss = 2.318, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 12022 (epoch 20), train_loss = 2.513, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 12023 (epoch 20), train_loss = 2.136, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 12024 (epoch 20), train_loss = 2.069, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 12025 (epoch 20), train_loss = 2.967, time/batch = 0.024
Read data: 9.822845458984375e-05
iter 12026 (epoch 20), train_loss = 2.941, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 12027 (epoch 20), train_loss = 2.641, time/batch = 0.030
Read data: 7.557868957519531e-05
iter 12028 (epoch 20), train_loss = 2.721, time/batch = 0.026
Read data: 0.00016069412231445312
iter 12029 (epoch 20), train_loss = 2.822, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 12030 (epoch 20), train_loss = 3.002, time/batch = 0.036
Read data: 8.726119995117188e-05
iter 12031 (epoch 20), train_loss = 2.864, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 12032 (epoch 20), train_loss = 2.334, time/batch = 0.025
Read data: 0.00016307830810546875
iter 12033 (epoch 20), train_loss = 2.646, time/batch = 0.021
Read data: 7.772445678710938e-05
iter 12034 (epoch 20), train_loss = 2.225, time/batch = 0.020
Read data: 8.869171142578125e-05
iter 12035 (epoch 20), train_loss = 2.211, time/batch = 0.030
Read data: 0.00017523765563964844
iter 12036 (epoch 20), train_loss = 2.729, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 12037 (epoch 20), train_loss = 2.981, time/batch = 0.027
Read data: 0.00013375282287597656
iter 12038 (epoch 20), train_loss = 2.994, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 12039 (epoch 20), train_loss = 2.895, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 12040 (epoch 20), train_loss = 2.318, time/batch = 0.030
Read data: 0.0001270771026611328
iter 12041 (epoch 20), train_loss = 2.570, time/batch = 0.035
Read data: 9.059906005859375e-05
iter 12042 (epoch 20), train_loss = 2.832, time/batch = 0.026
Read data: 0.0001251697540283203
iter 12043 (epoch 20), train_loss = 2.291, time/batch = 0.029
Read data: 0.00013446807861328125
iter 12044 (epoch 20), train_loss = 2.501, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 12045 (epoch 20), train_loss = 2.456, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 12046 (epoch 20), train_loss = 2.438, time/batch = 0.030
Read data: 0.0001277923583984375
iter 12047 (epoch 20), train_loss = 2.823, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 12048 (epoch 20), train_loss = 2.586, time/batch = 0.023
Read data: 0.00012874603271484375
iter 12049 (epoch 20), train_loss = 2.851, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 12050 (epoch 20), train_loss = 2.551, time/batch = 0.028
Read data: 0.00013136863708496094
iter 12051 (epoch 20), train_loss = 2.697, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 12052 (epoch 20), train_loss = 2.249, time/batch = 0.032
Read data: 0.00014901161193847656
iter 12053 (epoch 20), train_loss = 2.492, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 12054 (epoch 20), train_loss = 2.580, time/batch = 0.026
Read data: 0.00012874603271484375
iter 12055 (epoch 20), train_loss = 2.323, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 12056 (epoch 20), train_loss = 2.378, time/batch = 0.028
Read data: 0.00013327598571777344
iter 12057 (epoch 20), train_loss = 2.429, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 12058 (epoch 20), train_loss = 2.446, time/batch = 0.026
Read data: 0.00013065338134765625
iter 12059 (epoch 20), train_loss = 2.573, time/batch = 0.022
Read data: 0.0001404285430908203
iter 12060 (epoch 20), train_loss = 2.360, time/batch = 0.029
Read data: 0.00011706352233886719
iter 12061 (epoch 20), train_loss = 2.777, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 12062 (epoch 20), train_loss = 2.063, time/batch = 0.026
Read data: 0.0001533031463623047
iter 12063 (epoch 20), train_loss = 2.598, time/batch = 0.025
Read data: 0.0001010894775390625
iter 12064 (epoch 20), train_loss = 2.704, time/batch = 0.034
Read data: 0.0001361370086669922
iter 12065 (epoch 20), train_loss = 2.891, time/batch = 0.032
Read data: 8.702278137207031e-05
iter 12066 (epoch 20), train_loss = 2.616, time/batch = 0.031
Read data: 0.00013399124145507812
iter 12067 (epoch 20), train_loss = 2.634, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 12068 (epoch 20), train_loss = 2.848, time/batch = 0.034
Read data: 0.00013780593872070312
iter 12069 (epoch 20), train_loss = 2.621, time/batch = 0.031
Read data: 0.0001399517059326172
iter 12070 (epoch 20), train_loss = 2.922, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 12071 (epoch 20), train_loss = 2.258, time/batch = 0.028
Read data: 8.869171142578125e-05
iter 12072 (epoch 20), train_loss = 2.628, time/batch = 0.029
Read data: 0.00014472007751464844
iter 12073 (epoch 20), train_loss = 2.439, time/batch = 0.036
Read data: 8.726119995117188e-05
iter 12074 (epoch 20), train_loss = 2.637, time/batch = 0.027
Read data: 0.00016069412231445312
iter 12075 (epoch 20), train_loss = 2.418, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 12076 (epoch 20), train_loss = 2.417, time/batch = 0.036
Read data: 8.916854858398438e-05
iter 12077 (epoch 20), train_loss = 2.567, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 12078 (epoch 20), train_loss = 2.253, time/batch = 0.024
Read data: 0.00013136863708496094
iter 12079 (epoch 20), train_loss = 2.639, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 12080 (epoch 20), train_loss = 2.603, time/batch = 0.024
Read data: 0.00012373924255371094
iter 12081 (epoch 20), train_loss = 2.432, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 12082 (epoch 20), train_loss = 2.737, time/batch = 0.030
Read data: 0.0001270771026611328
iter 12083 (epoch 20), train_loss = 2.415, time/batch = 0.026
Read data: 0.00013756752014160156
iter 12084 (epoch 20), train_loss = 2.537, time/batch = 0.028
Read data: 0.00016546249389648438
iter 12085 (epoch 20), train_loss = 2.543, time/batch = 0.032
Read data: 0.000141143798828125
iter 12086 (epoch 20), train_loss = 2.590, time/batch = 0.032
Read data: 0.00013446807861328125
iter 12087 (epoch 20), train_loss = 2.566, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 12088 (epoch 20), train_loss = 2.739, time/batch = 0.033
Read data: 0.00013780593872070312
iter 12089 (epoch 20), train_loss = 2.839, time/batch = 0.034
Read data: 0.0001354217529296875
iter 12090 (epoch 20), train_loss = 2.838, time/batch = 0.029
Read data: 0.00012969970703125
iter 12091 (epoch 20), train_loss = 2.458, time/batch = 0.025
Read data: 0.00012230873107910156
iter 12092 (epoch 20), train_loss = 2.729, time/batch = 0.029
Read data: 0.0001609325408935547
iter 12093 (epoch 20), train_loss = 2.177, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 12094 (epoch 20), train_loss = 2.618, time/batch = 0.028
Read data: 0.00012922286987304688
iter 12095 (epoch 20), train_loss = 2.787, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 12096 (epoch 20), train_loss = 2.560, time/batch = 0.028
Read data: 0.00013494491577148438
iter 12097 (epoch 20), train_loss = 2.541, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 12098 (epoch 20), train_loss = 2.234, time/batch = 0.027
Read data: 0.0001246929168701172
iter 12099 (epoch 20), train_loss = 2.760, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 12100 (epoch 20), train_loss = 2.418, time/batch = 0.027
Read data: 0.0001533031463623047
iter 12101 (epoch 20), train_loss = 2.747, time/batch = 0.042
Read data: 9.489059448242188e-05
iter 12102 (epoch 20), train_loss = 2.530, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 12103 (epoch 20), train_loss = 2.302, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 12104 (epoch 20), train_loss = 2.430, time/batch = 0.027
Read data: 0.00013637542724609375
iter 12105 (epoch 20), train_loss = 2.483, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 12106 (epoch 20), train_loss = 2.801, time/batch = 0.028
Read data: 0.00014734268188476562
iter 12107 (epoch 20), train_loss = 2.830, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 12108 (epoch 20), train_loss = 2.868, time/batch = 0.041
Read data: 9.942054748535156e-05
iter 12109 (epoch 20), train_loss = 2.771, time/batch = 0.043
Read data: 7.915496826171875e-05
iter 12110 (epoch 20), train_loss = 2.419, time/batch = 0.026
Read data: 7.414817810058594e-05
iter 12111 (epoch 20), train_loss = 2.373, time/batch = 0.024
Read data: 0.00011301040649414062
iter 12112 (epoch 20), train_loss = 2.621, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 12113 (epoch 20), train_loss = 2.306, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 12114 (epoch 20), train_loss = 2.676, time/batch = 0.028
Read data: 0.00015163421630859375
iter 12115 (epoch 20), train_loss = 2.889, time/batch = 0.034
Read data: 9.131431579589844e-05
iter 12116 (epoch 20), train_loss = 2.283, time/batch = 0.030
Read data: 0.00018262863159179688
iter 12117 (epoch 20), train_loss = 2.707, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 12118 (epoch 20), train_loss = 2.567, time/batch = 0.038
Read data: 0.00015091896057128906
iter 12119 (epoch 20), train_loss = 2.651, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 12120 (epoch 20), train_loss = 2.636, time/batch = 0.024
Read data: 0.00016689300537109375
iter 12121 (epoch 20), train_loss = 2.813, time/batch = 0.031
Read data: 9.799003601074219e-05
iter 12122 (epoch 20), train_loss = 2.403, time/batch = 0.028
Read data: 0.00012683868408203125
iter 12123 (epoch 20), train_loss = 2.337, time/batch = 0.022
Read data: 0.00012373924255371094
iter 12124 (epoch 20), train_loss = 2.506, time/batch = 0.029
Read data: 0.0002033710479736328
iter 12125 (epoch 20), train_loss = 2.607, time/batch = 0.028
Read data: 9.655952453613281e-05
iter 12126 (epoch 20), train_loss = 2.119, time/batch = 0.028
Read data: 0.000125885009765625
iter 12127 (epoch 20), train_loss = 2.526, time/batch = 0.025
Read data: 0.00012969970703125
iter 12128 (epoch 20), train_loss = 2.652, time/batch = 0.028
Read data: 0.00012874603271484375
iter 12129 (epoch 20), train_loss = 2.887, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 12130 (epoch 20), train_loss = 2.266, time/batch = 0.033
Read data: 0.00013637542724609375
iter 12131 (epoch 20), train_loss = 2.410, time/batch = 0.027
Read data: 0.00011682510375976562
iter 12132 (epoch 20), train_loss = 2.992, time/batch = 0.034
Read data: 0.00015115737915039062
iter 12133 (epoch 20), train_loss = 2.601, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 12134 (epoch 20), train_loss = 2.520, time/batch = 0.026
Read data: 0.00013256072998046875
iter 12135 (epoch 20), train_loss = 2.889, time/batch = 0.024
Read data: 0.00011777877807617188
iter 12136 (epoch 20), train_loss = 2.859, time/batch = 0.028
Read data: 0.0001277923583984375
iter 12137 (epoch 20), train_loss = 2.656, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 12138 (epoch 20), train_loss = 2.743, time/batch = 0.028
Read data: 0.0001266002655029297
iter 12139 (epoch 20), train_loss = 2.270, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 12140 (epoch 20), train_loss = 2.900, time/batch = 0.024
Read data: 0.0001323223114013672
iter 12141 (epoch 20), train_loss = 2.922, time/batch = 0.028
Read data: 0.0001201629638671875
iter 12142 (epoch 20), train_loss = 2.630, time/batch = 0.026
Read data: 0.00013399124145507812
iter 12143 (epoch 20), train_loss = 2.565, time/batch = 0.031
Read data: 9.465217590332031e-05
iter 12144 (epoch 20), train_loss = 2.249, time/batch = 0.037
Read data: 8.654594421386719e-05
iter 12145 (epoch 20), train_loss = 2.370, time/batch = 0.026
Read data: 0.0001342296600341797
iter 12146 (epoch 20), train_loss = 2.388, time/batch = 0.032
Read data: 0.00013303756713867188
iter 12147 (epoch 20), train_loss = 2.489, time/batch = 0.021
Read data: 7.748603820800781e-05
iter 12148 (epoch 20), train_loss = 2.262, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 12149 (epoch 20), train_loss = 2.413, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 12150 (epoch 20), train_loss = 2.371, time/batch = 0.034
Read data: 0.0001785755157470703
iter 12151 (epoch 20), train_loss = 2.684, time/batch = 0.030
Read data: 0.00013208389282226562
iter 12152 (epoch 20), train_loss = 2.436, time/batch = 0.029
Read data: 8.869171142578125e-05
iter 12153 (epoch 20), train_loss = 2.859, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 12154 (epoch 20), train_loss = 2.440, time/batch = 0.026
Read data: 0.00015878677368164062
iter 12155 (epoch 20), train_loss = 2.759, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 12156 (epoch 20), train_loss = 2.376, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 12157 (epoch 20), train_loss = 2.244, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 12158 (epoch 20), train_loss = 2.457, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 12159 (epoch 20), train_loss = 2.491, time/batch = 0.033
Read data: 8.296966552734375e-05
iter 12160 (epoch 20), train_loss = 2.297, time/batch = 0.029
Read data: 9.1552734375e-05
iter 12161 (epoch 20), train_loss = 2.483, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 12162 (epoch 20), train_loss = 2.487, time/batch = 0.025
Read data: 0.0001304149627685547
iter 12163 (epoch 20), train_loss = 2.503, time/batch = 0.024
Read data: 0.0001380443572998047
iter 12164 (epoch 20), train_loss = 2.564, time/batch = 0.035
Read data: 8.416175842285156e-05
iter 12165 (epoch 20), train_loss = 2.578, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 12166 (epoch 20), train_loss = 2.165, time/batch = 0.028
Read data: 0.00013017654418945312
iter 12167 (epoch 20), train_loss = 2.250, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 12168 (epoch 20), train_loss = 2.468, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 12169 (epoch 20), train_loss = 2.232, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 12170 (epoch 20), train_loss = 2.786, time/batch = 0.032
Read data: 0.0001361370086669922
iter 12171 (epoch 20), train_loss = 2.372, time/batch = 0.024
Read data: 0.00011897087097167969
iter 12172 (epoch 20), train_loss = 2.219, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 12173 (epoch 20), train_loss = 2.855, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 12174 (epoch 20), train_loss = 2.486, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 12175 (epoch 20), train_loss = 2.555, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 12176 (epoch 20), train_loss = 2.772, time/batch = 0.042
Read data: 8.535385131835938e-05
iter 12177 (epoch 20), train_loss = 2.561, time/batch = 0.030
Read data: 0.00012493133544921875
iter 12178 (epoch 20), train_loss = 3.068, time/batch = 0.031
Read data: 8.630752563476562e-05
iter 12179 (epoch 20), train_loss = 2.639, time/batch = 0.024
Read data: 0.00012421607971191406
iter 12180 (epoch 20), train_loss = 2.673, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 12181 (epoch 20), train_loss = 2.110, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 12182 (epoch 20), train_loss = 2.634, time/batch = 0.029
Read data: 0.00014662742614746094
iter 12183 (epoch 20), train_loss = 2.776, time/batch = 0.030
Read data: 0.00017380714416503906
iter 12184 (epoch 20), train_loss = 2.384, time/batch = 0.041
Read data: 8.726119995117188e-05
iter 12185 (epoch 20), train_loss = 2.586, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 12186 (epoch 20), train_loss = 2.445, time/batch = 0.027
Read data: 0.00013828277587890625
iter 12187 (epoch 20), train_loss = 2.640, time/batch = 0.028
Read data: 8.392333984375e-05
iter 12188 (epoch 20), train_loss = 3.060, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 12189 (epoch 20), train_loss = 2.487, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 12190 (epoch 20), train_loss = 2.669, time/batch = 0.028
Read data: 0.0001621246337890625
iter 12191 (epoch 20), train_loss = 2.899, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 12192 (epoch 20), train_loss = 2.517, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 12193 (epoch 20), train_loss = 2.770, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 12194 (epoch 20), train_loss = 2.474, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 12195 (epoch 20), train_loss = 2.501, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 12196 (epoch 20), train_loss = 2.893, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 12197 (epoch 20), train_loss = 2.501, time/batch = 0.026
Read data: 0.0001404285430908203
iter 12198 (epoch 20), train_loss = 2.755, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 12199 (epoch 20), train_loss = 2.863, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 12200 (epoch 20), train_loss = 2.318, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 12201 (epoch 20), train_loss = 2.524, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 12202 (epoch 20), train_loss = 2.580, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 12203 (epoch 20), train_loss = 2.362, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 12204 (epoch 20), train_loss = 2.879, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 12205 (epoch 20), train_loss = 2.585, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 12206 (epoch 20), train_loss = 2.620, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 12207 (epoch 20), train_loss = 2.856, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 12208 (epoch 20), train_loss = 2.701, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 12209 (epoch 20), train_loss = 2.934, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 12210 (epoch 20), train_loss = 2.713, time/batch = 0.023
Read data: 0.0001049041748046875
iter 12211 (epoch 20), train_loss = 2.530, time/batch = 0.030
Read data: 9.584426879882812e-05
iter 12212 (epoch 20), train_loss = 2.247, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 12213 (epoch 20), train_loss = 2.852, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 12214 (epoch 20), train_loss = 2.600, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 12215 (epoch 20), train_loss = 2.143, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 12216 (epoch 20), train_loss = 2.332, time/batch = 0.024
Read data: 0.00010466575622558594
iter 12217 (epoch 20), train_loss = 2.082, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 12218 (epoch 20), train_loss = 2.549, time/batch = 0.035
Read data: 0.00010037422180175781
iter 12219 (epoch 20), train_loss = 3.073, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 12220 (epoch 20), train_loss = 2.549, time/batch = 0.023
Read data: 0.00011873245239257812
iter 12221 (epoch 20), train_loss = 2.581, time/batch = 0.022
Read data: 0.00013208389282226562
iter 12222 (epoch 20), train_loss = 2.444, time/batch = 0.020
Read data: 8.487701416015625e-05
iter 12223 (epoch 20), train_loss = 2.518, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 12224 (epoch 20), train_loss = 2.793, time/batch = 0.025
Read data: 0.0002779960632324219
iter 12225 (epoch 20), train_loss = 2.458, time/batch = 0.021
Read data: 0.00017499923706054688
iter 12226 (epoch 20), train_loss = 2.364, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 12227 (epoch 20), train_loss = 2.684, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 12228 (epoch 20), train_loss = 3.074, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 12229 (epoch 20), train_loss = 2.785, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 12230 (epoch 20), train_loss = 2.161, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 12231 (epoch 20), train_loss = 3.044, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 12232 (epoch 20), train_loss = 2.509, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 12233 (epoch 20), train_loss = 2.683, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 12234 (epoch 20), train_loss = 2.703, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 12235 (epoch 20), train_loss = 2.468, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 12236 (epoch 20), train_loss = 2.836, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 12237 (epoch 20), train_loss = 2.998, time/batch = 0.030
Read data: 0.00013136863708496094
iter 12238 (epoch 20), train_loss = 2.642, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 12239 (epoch 20), train_loss = 2.753, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 12240 (epoch 20), train_loss = 2.443, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 12241 (epoch 20), train_loss = 2.387, time/batch = 0.021
Read data: 0.0001342296600341797
iter 12242 (epoch 20), train_loss = 2.466, time/batch = 0.023
Read data: 7.557868957519531e-05
iter 12243 (epoch 20), train_loss = 2.547, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 12244 (epoch 20), train_loss = 2.781, time/batch = 0.025
Read data: 9.1552734375e-05
iter 12245 (epoch 20), train_loss = 2.597, time/batch = 0.023
Read data: 0.00013947486877441406
iter 12246 (epoch 20), train_loss = 2.404, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 12247 (epoch 20), train_loss = 2.817, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 12248 (epoch 20), train_loss = 2.466, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 12249 (epoch 20), train_loss = 2.394, time/batch = 0.026
Read data: 0.00032639503479003906
iter 12250 (epoch 20), train_loss = 2.392, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 12251 (epoch 20), train_loss = 2.177, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 12252 (epoch 20), train_loss = 2.657, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 12253 (epoch 20), train_loss = 2.350, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 12254 (epoch 20), train_loss = 2.752, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 12255 (epoch 20), train_loss = 2.918, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 12256 (epoch 20), train_loss = 2.635, time/batch = 0.024
Read data: 0.00018715858459472656
iter 12257 (epoch 20), train_loss = 2.367, time/batch = 0.022
Read data: 0.000171661376953125
iter 12258 (epoch 20), train_loss = 2.824, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 12259 (epoch 20), train_loss = 2.441, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 12260 (epoch 20), train_loss = 2.726, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 12261 (epoch 20), train_loss = 2.673, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 12262 (epoch 20), train_loss = 2.598, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 12263 (epoch 20), train_loss = 2.421, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 12264 (epoch 20), train_loss = 2.673, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 12265 (epoch 20), train_loss = 2.559, time/batch = 0.027
Read data: 0.00015401840209960938
iter 12266 (epoch 20), train_loss = 2.755, time/batch = 0.021
Read data: 8.487701416015625e-05
iter 12267 (epoch 20), train_loss = 2.643, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 12268 (epoch 20), train_loss = 2.503, time/batch = 0.026
Read data: 0.0001437664031982422
iter 12269 (epoch 20), train_loss = 2.720, time/batch = 0.027
Read data: 0.00013399124145507812
iter 12270 (epoch 20), train_loss = 2.640, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 12271 (epoch 20), train_loss = 2.185, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 12272 (epoch 20), train_loss = 2.308, time/batch = 0.025
Read data: 0.00014519691467285156
iter 12273 (epoch 20), train_loss = 2.133, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 12274 (epoch 20), train_loss = 2.179, time/batch = 0.021
Read data: 0.00022268295288085938
iter 12275 (epoch 20), train_loss = 2.605, time/batch = 0.027
Read data: 9.822845458984375e-05
iter 12276 (epoch 20), train_loss = 2.468, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 12277 (epoch 20), train_loss = 2.957, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 12278 (epoch 20), train_loss = 2.244, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 12279 (epoch 20), train_loss = 2.376, time/batch = 0.028
Read data: 0.00010585784912109375
iter 12280 (epoch 20), train_loss = 2.889, time/batch = 0.030
Read data: 0.00011587142944335938
iter 12281 (epoch 20), train_loss = 2.489, time/batch = 0.022
Read data: 0.00012540817260742188
iter 12282 (epoch 20), train_loss = 2.932, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 12283 (epoch 20), train_loss = 2.558, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 12284 (epoch 20), train_loss = 2.450, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 12285 (epoch 20), train_loss = 2.562, time/batch = 0.024
Read data: 8.392333984375e-05
iter 12286 (epoch 20), train_loss = 2.668, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 12287 (epoch 20), train_loss = 2.328, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 12288 (epoch 20), train_loss = 2.694, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 12289 (epoch 20), train_loss = 2.440, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 12290 (epoch 20), train_loss = 3.045, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 12291 (epoch 20), train_loss = 2.561, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 12292 (epoch 20), train_loss = 2.467, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 12293 (epoch 20), train_loss = 2.341, time/batch = 0.028
Read data: 0.0001347064971923828
iter 12294 (epoch 20), train_loss = 2.337, time/batch = 0.022
Read data: 9.989738464355469e-05
iter 12295 (epoch 20), train_loss = 2.617, time/batch = 0.028
Read data: 9.679794311523438e-05
iter 12296 (epoch 20), train_loss = 2.845, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 12297 (epoch 20), train_loss = 2.335, time/batch = 0.030
Read data: 9.775161743164062e-05
iter 12298 (epoch 20), train_loss = 2.398, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 12299 (epoch 20), train_loss = 2.326, time/batch = 0.021
Read data: 8.058547973632812e-05
iter 12300 (epoch 20), train_loss = 2.728, time/batch = 0.023
Read data: 0.0001010894775390625
iter 12301 (epoch 20), train_loss = 2.811, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 12302 (epoch 20), train_loss = 2.148, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 12303 (epoch 20), train_loss = 2.239, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 12304 (epoch 20), train_loss = 2.004, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 12305 (epoch 20), train_loss = 2.948, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 12306 (epoch 20), train_loss = 2.774, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 12307 (epoch 20), train_loss = 2.309, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 12308 (epoch 20), train_loss = 2.965, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 12309 (epoch 20), train_loss = 2.413, time/batch = 0.025
Read data: 0.00015211105346679688
iter 12310 (epoch 20), train_loss = 2.971, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 12311 (epoch 20), train_loss = 2.771, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 12312 (epoch 20), train_loss = 2.585, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 12313 (epoch 20), train_loss = 2.229, time/batch = 0.021
Read data: 0.00014209747314453125
iter 12314 (epoch 20), train_loss = 2.453, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 12315 (epoch 20), train_loss = 2.443, time/batch = 0.026
Read data: 0.00014901161193847656
iter 12316 (epoch 20), train_loss = 2.544, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 12317 (epoch 20), train_loss = 2.547, time/batch = 0.021
Read data: 8.606910705566406e-05
iter 12318 (epoch 20), train_loss = 2.779, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 12319 (epoch 20), train_loss = 2.645, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 12320 (epoch 20), train_loss = 2.497, time/batch = 0.039
Read data: 0.00012946128845214844
iter 12321 (epoch 20), train_loss = 2.510, time/batch = 0.028
Read data: 0.00016736984252929688
iter 12322 (epoch 20), train_loss = 2.661, time/batch = 0.034
Read data: 9.131431579589844e-05
iter 12323 (epoch 20), train_loss = 2.559, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 12324 (epoch 20), train_loss = 2.634, time/batch = 0.021
Read data: 0.00021958351135253906
iter 12325 (epoch 20), train_loss = 2.609, time/batch = 0.021
Read data: 7.748603820800781e-05
iter 12326 (epoch 20), train_loss = 2.516, time/batch = 0.027
Read data: 0.00012683868408203125
iter 12327 (epoch 20), train_loss = 2.934, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 12328 (epoch 20), train_loss = 2.841, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 12329 (epoch 20), train_loss = 2.626, time/batch = 0.035
Read data: 8.7738037109375e-05
iter 12330 (epoch 20), train_loss = 2.397, time/batch = 0.023
Read data: 0.00013446807861328125
iter 12331 (epoch 20), train_loss = 2.734, time/batch = 0.019
Read data: 7.987022399902344e-05
iter 12332 (epoch 20), train_loss = 2.605, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 12333 (epoch 20), train_loss = 2.465, time/batch = 0.024
Read data: 9.775161743164062e-05
iter 12334 (epoch 20), train_loss = 2.354, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 12335 (epoch 20), train_loss = 2.203, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 12336 (epoch 20), train_loss = 2.699, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 12337 (epoch 20), train_loss = 2.738, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 12338 (epoch 20), train_loss = 2.215, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 12339 (epoch 20), train_loss = 2.462, time/batch = 0.026
Read data: 0.00018072128295898438
iter 12340 (epoch 20), train_loss = 2.584, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 12341 (epoch 20), train_loss = 2.517, time/batch = 0.030
Read data: 0.00016427040100097656
iter 12342 (epoch 20), train_loss = 2.273, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 12343 (epoch 20), train_loss = 2.573, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 12344 (epoch 20), train_loss = 2.088, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 12345 (epoch 20), train_loss = 2.551, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 12346 (epoch 20), train_loss = 2.642, time/batch = 0.027
Read data: 0.00010180473327636719
iter 12347 (epoch 20), train_loss = 2.539, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 12348 (epoch 20), train_loss = 2.401, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 12349 (epoch 20), train_loss = 2.186, time/batch = 0.024
Read data: 0.00022101402282714844
iter 12350 (epoch 20), train_loss = 2.619, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 12351 (epoch 20), train_loss = 2.758, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 12352 (epoch 20), train_loss = 2.395, time/batch = 0.027
Read data: 0.00014281272888183594
iter 12353 (epoch 20), train_loss = 2.162, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 12354 (epoch 20), train_loss = 2.599, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 12355 (epoch 20), train_loss = 2.634, time/batch = 0.021
Read data: 0.0001385211944580078
iter 12356 (epoch 20), train_loss = 2.669, time/batch = 0.023
Read data: 0.0001518726348876953
iter 12357 (epoch 20), train_loss = 2.710, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 12358 (epoch 20), train_loss = 2.464, time/batch = 0.028
Read data: 9.250640869140625e-05
iter 12359 (epoch 20), train_loss = 2.849, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 12360 (epoch 20), train_loss = 2.134, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 12361 (epoch 20), train_loss = 2.233, time/batch = 0.024
Read data: 0.00017523765563964844
iter 12362 (epoch 20), train_loss = 2.702, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 12363 (epoch 20), train_loss = 2.224, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 12364 (epoch 20), train_loss = 2.357, time/batch = 0.034
Read data: 8.225440979003906e-05
iter 12365 (epoch 20), train_loss = 2.876, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 12366 (epoch 20), train_loss = 3.344, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 12367 (epoch 20), train_loss = 2.656, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 12368 (epoch 20), train_loss = 2.598, time/batch = 0.024
Read data: 7.62939453125e-05
iter 12369 (epoch 20), train_loss = 2.604, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 12370 (epoch 20), train_loss = 2.756, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 12371 (epoch 20), train_loss = 2.848, time/batch = 0.034
Read data: 8.559226989746094e-05
iter 12372 (epoch 20), train_loss = 2.636, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 12373 (epoch 20), train_loss = 2.465, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 12374 (epoch 20), train_loss = 2.192, time/batch = 0.022
Read data: 0.0002205371856689453
iter 12375 (epoch 20), train_loss = 2.463, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 12376 (epoch 20), train_loss = 2.416, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 12377 (epoch 20), train_loss = 2.732, time/batch = 0.027
Read data: 0.00013136863708496094
iter 12378 (epoch 20), train_loss = 2.632, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 12379 (epoch 20), train_loss = 2.228, time/batch = 0.023
Read data: 0.0001475811004638672
iter 12380 (epoch 20), train_loss = 2.547, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 12381 (epoch 20), train_loss = 2.643, time/batch = 0.027
Read data: 0.00014162063598632812
iter 12382 (epoch 20), train_loss = 2.826, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 12383 (epoch 20), train_loss = 2.616, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 12384 (epoch 20), train_loss = 2.305, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 12385 (epoch 20), train_loss = 2.785, time/batch = 0.028
Read data: 0.00016117095947265625
iter 12386 (epoch 20), train_loss = 2.544, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 12387 (epoch 20), train_loss = 2.759, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 12388 (epoch 20), train_loss = 2.540, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 12389 (epoch 20), train_loss = 2.562, time/batch = 0.023
Read data: 0.0001347064971923828
iter 12390 (epoch 20), train_loss = 2.642, time/batch = 0.031
Read data: 7.700920104980469e-05
iter 12391 (epoch 20), train_loss = 2.667, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 12392 (epoch 20), train_loss = 2.734, time/batch = 0.019
Read data: 8.225440979003906e-05
iter 12393 (epoch 20), train_loss = 2.467, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 12394 (epoch 20), train_loss = 2.717, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 12395 (epoch 20), train_loss = 2.532, time/batch = 0.021
Read data: 8.58306884765625e-05
iter 12396 (epoch 20), train_loss = 3.062, time/batch = 0.033
Read data: 7.963180541992188e-05
iter 12397 (epoch 20), train_loss = 2.241, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 12398 (epoch 20), train_loss = 3.059, time/batch = 0.036
Read data: 0.0001442432403564453
iter 12399 (epoch 20), train_loss = 3.003, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 12400 (epoch 20), train_loss = 2.436, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 12401 (epoch 20), train_loss = 2.757, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 12402 (epoch 20), train_loss = 2.530, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 12403 (epoch 20), train_loss = 2.648, time/batch = 0.030
Read data: 9.775161743164062e-05
iter 12404 (epoch 20), train_loss = 2.511, time/batch = 0.025
Read data: 0.0001742839813232422
iter 12405 (epoch 20), train_loss = 2.534, time/batch = 0.027
Read data: 0.00015306472778320312
iter 12406 (epoch 20), train_loss = 2.728, time/batch = 0.023
Read data: 0.00010251998901367188
iter 12407 (epoch 20), train_loss = 2.649, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 12408 (epoch 20), train_loss = 2.628, time/batch = 0.027
Read data: 0.0001380443572998047
iter 12409 (epoch 20), train_loss = 2.970, time/batch = 0.031
Read data: 0.0001246929168701172
iter 12410 (epoch 20), train_loss = 2.320, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 12411 (epoch 20), train_loss = 2.614, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 12412 (epoch 20), train_loss = 2.180, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 12413 (epoch 20), train_loss = 2.442, time/batch = 0.023
Read data: 0.00013494491577148438
iter 12414 (epoch 20), train_loss = 2.491, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 12415 (epoch 20), train_loss = 2.397, time/batch = 0.025
Read data: 0.00013065338134765625
iter 12416 (epoch 20), train_loss = 2.520, time/batch = 0.028
Read data: 0.00012254714965820312
iter 12417 (epoch 20), train_loss = 2.780, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 12418 (epoch 20), train_loss = 2.567, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 12419 (epoch 20), train_loss = 2.396, time/batch = 0.030
Read data: 0.00013303756713867188
iter 12420 (epoch 20), train_loss = 2.464, time/batch = 0.027
Read data: 0.00013375282287597656
iter 12421 (epoch 20), train_loss = 2.598, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 12422 (epoch 20), train_loss = 2.431, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 12423 (epoch 20), train_loss = 2.431, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 12424 (epoch 20), train_loss = 2.858, time/batch = 0.031
Read data: 0.0003330707550048828
iter 12425 (epoch 20), train_loss = 2.687, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 12426 (epoch 20), train_loss = 2.344, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 12427 (epoch 20), train_loss = 2.502, time/batch = 0.025
Read data: 0.0001308917999267578
iter 12428 (epoch 20), train_loss = 2.346, time/batch = 0.027
Read data: 0.00016307830810546875
iter 12429 (epoch 20), train_loss = 2.745, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 12430 (epoch 20), train_loss = 2.359, time/batch = 0.021
Read data: 9.179115295410156e-05
iter 12431 (epoch 20), train_loss = 2.850, time/batch = 0.031
Read data: 0.000133514404296875
iter 12432 (epoch 20), train_loss = 2.802, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 12433 (epoch 20), train_loss = 2.515, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 12434 (epoch 20), train_loss = 2.408, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 12435 (epoch 20), train_loss = 2.343, time/batch = 0.025
Read data: 0.00013303756713867188
iter 12436 (epoch 20), train_loss = 2.595, time/batch = 0.027
Read data: 0.000133514404296875
iter 12437 (epoch 20), train_loss = 2.122, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 12438 (epoch 20), train_loss = 2.276, time/batch = 0.025
Read data: 0.00010395050048828125
iter 12439 (epoch 20), train_loss = 2.464, time/batch = 0.029
Read data: 0.00017213821411132812
iter 12440 (epoch 20), train_loss = 2.322, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 12441 (epoch 20), train_loss = 2.752, time/batch = 0.029
Read data: 9.298324584960938e-05
iter 12442 (epoch 20), train_loss = 2.756, time/batch = 0.025
Read data: 0.0001010894775390625
iter 12443 (epoch 20), train_loss = 2.705, time/batch = 0.024
Read data: 0.00014162063598632812
iter 12444 (epoch 20), train_loss = 2.843, time/batch = 0.027
Read data: 0.00012755393981933594
iter 12445 (epoch 20), train_loss = 2.173, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 12446 (epoch 20), train_loss = 2.659, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 12447 (epoch 20), train_loss = 2.396, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 12448 (epoch 20), train_loss = 2.280, time/batch = 0.025
Read data: 0.0001609325408935547
iter 12449 (epoch 20), train_loss = 2.376, time/batch = 0.024
Read data: 0.00021386146545410156
iter 12450 (epoch 20), train_loss = 2.406, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 12451 (epoch 20), train_loss = 2.312, time/batch = 0.025
Read data: 0.00014638900756835938
iter 12452 (epoch 20), train_loss = 2.180, time/batch = 0.029
Read data: 0.00015687942504882812
iter 12453 (epoch 20), train_loss = 2.067, time/batch = 0.021
Read data: 8.869171142578125e-05
iter 12454 (epoch 20), train_loss = 2.174, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 12455 (epoch 20), train_loss = 2.498, time/batch = 0.024
Read data: 0.00011086463928222656
iter 12456 (epoch 20), train_loss = 2.540, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 12457 (epoch 20), train_loss = 2.841, time/batch = 0.033
Read data: 7.939338684082031e-05
iter 12458 (epoch 20), train_loss = 2.697, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 12459 (epoch 20), train_loss = 2.796, time/batch = 0.036
Read data: 0.00013446807861328125
iter 12460 (epoch 20), train_loss = 2.527, time/batch = 0.026
Read data: 0.00013589859008789062
iter 12461 (epoch 20), train_loss = 2.776, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 12462 (epoch 20), train_loss = 2.383, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 12463 (epoch 20), train_loss = 2.815, time/batch = 0.031
Read data: 0.0001316070556640625
iter 12464 (epoch 20), train_loss = 3.004, time/batch = 0.032
Read data: 0.0001354217529296875
iter 12465 (epoch 20), train_loss = 3.003, time/batch = 0.025
Read data: 0.00013375282287597656
iter 12466 (epoch 20), train_loss = 2.704, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 12467 (epoch 20), train_loss = 2.263, time/batch = 0.022
Read data: 0.0001251697540283203
iter 12468 (epoch 20), train_loss = 2.459, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 12469 (epoch 20), train_loss = 3.368, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 12470 (epoch 20), train_loss = 2.917, time/batch = 0.035
Read data: 8.96453857421875e-05
iter 12471 (epoch 20), train_loss = 2.286, time/batch = 0.026
Read data: 0.00017309188842773438
iter 12472 (epoch 20), train_loss = 2.305, time/batch = 0.026
Read data: 0.0001361370086669922
iter 12473 (epoch 20), train_loss = 2.653, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 12474 (epoch 20), train_loss = 2.553, time/batch = 0.026
Read data: 0.0002124309539794922
iter 12475 (epoch 20), train_loss = 2.824, time/batch = 0.031
Read data: 0.00012803077697753906
iter 12476 (epoch 20), train_loss = 2.770, time/batch = 0.025
Read data: 0.00013208389282226562
iter 12477 (epoch 20), train_loss = 2.441, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 12478 (epoch 20), train_loss = 2.746, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 12479 (epoch 20), train_loss = 2.593, time/batch = 0.029
Read data: 0.00015807151794433594
iter 12480 (epoch 20), train_loss = 2.346, time/batch = 0.027
Read data: 0.00016307830810546875
iter 12481 (epoch 20), train_loss = 2.459, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 12482 (epoch 20), train_loss = 2.444, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 12483 (epoch 20), train_loss = 3.198, time/batch = 0.034
Read data: 8.273124694824219e-05
iter 12484 (epoch 20), train_loss = 2.949, time/batch = 0.028
Read data: 0.0001804828643798828
iter 12485 (epoch 20), train_loss = 2.460, time/batch = 0.032
Read data: 0.0001392364501953125
iter 12486 (epoch 20), train_loss = 2.789, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 12487 (epoch 20), train_loss = 2.737, time/batch = 0.036
Read data: 0.00014209747314453125
iter 12488 (epoch 20), train_loss = 2.362, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 12489 (epoch 20), train_loss = 2.423, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 12490 (epoch 20), train_loss = 2.555, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 12491 (epoch 20), train_loss = 2.311, time/batch = 0.027
Read data: 0.0001609325408935547
iter 12492 (epoch 20), train_loss = 2.430, time/batch = 0.027
Read data: 0.0001323223114013672
iter 12493 (epoch 20), train_loss = 2.917, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 12494 (epoch 20), train_loss = 2.587, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 12495 (epoch 20), train_loss = 2.679, time/batch = 0.025
Read data: 0.0001323223114013672
iter 12496 (epoch 20), train_loss = 2.387, time/batch = 0.024
Read data: 0.0001556873321533203
iter 12497 (epoch 20), train_loss = 2.673, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 12498 (epoch 20), train_loss = 2.931, time/batch = 0.038
Read data: 8.177757263183594e-05
iter 12499 (epoch 20), train_loss = 2.927, time/batch = 0.027
Read data: 0.00012731552124023438
iter 12500 (epoch 20), train_loss = 2.804, time/batch = 0.025
Read data: 0.00013971328735351562
iter 12501 (epoch 20), train_loss = 2.589, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 12502 (epoch 20), train_loss = 2.552, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 12503 (epoch 20), train_loss = 2.645, time/batch = 0.029
Read data: 8.7738037109375e-05
iter 12504 (epoch 20), train_loss = 2.681, time/batch = 0.032
Read data: 0.00013065338134765625
iter 12505 (epoch 20), train_loss = 2.341, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 12506 (epoch 20), train_loss = 2.827, time/batch = 0.023
Read data: 0.0001201629638671875
iter 12507 (epoch 20), train_loss = 2.463, time/batch = 0.029
Read data: 0.00022745132446289062
iter 12508 (epoch 20), train_loss = 2.734, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 12509 (epoch 20), train_loss = 2.593, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 12510 (epoch 20), train_loss = 2.578, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 12511 (epoch 20), train_loss = 2.603, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 12512 (epoch 20), train_loss = 2.758, time/batch = 0.024
Read data: 0.00010013580322265625
iter 12513 (epoch 20), train_loss = 2.573, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 12514 (epoch 20), train_loss = 2.084, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 12515 (epoch 20), train_loss = 2.441, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 12516 (epoch 20), train_loss = 2.367, time/batch = 0.029
Read data: 0.0001659393310546875
iter 12517 (epoch 20), train_loss = 2.730, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 12518 (epoch 20), train_loss = 2.764, time/batch = 0.035
Read data: 0.0001423358917236328
iter 12519 (epoch 20), train_loss = 2.756, time/batch = 0.026
Read data: 0.00013875961303710938
iter 12520 (epoch 20), train_loss = 2.831, time/batch = 0.030
Read data: 0.00012731552124023438
iter 12521 (epoch 20), train_loss = 2.752, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 12522 (epoch 20), train_loss = 2.749, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 12523 (epoch 20), train_loss = 2.750, time/batch = 0.027
Read data: 0.00012302398681640625
iter 12524 (epoch 20), train_loss = 2.269, time/batch = 0.023
Read data: 0.0002391338348388672
iter 12525 (epoch 20), train_loss = 2.845, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 12526 (epoch 20), train_loss = 2.326, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 12527 (epoch 20), train_loss = 2.260, time/batch = 0.022
Read data: 0.00013709068298339844
iter 12528 (epoch 20), train_loss = 2.387, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 12529 (epoch 20), train_loss = 2.493, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 12530 (epoch 20), train_loss = 2.677, time/batch = 0.030
Read data: 9.72747802734375e-05
iter 12531 (epoch 20), train_loss = 2.556, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 12532 (epoch 20), train_loss = 2.436, time/batch = 0.031
Read data: 0.00014138221740722656
iter 12533 (epoch 20), train_loss = 2.146, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 12534 (epoch 20), train_loss = 2.327, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 12535 (epoch 20), train_loss = 2.757, time/batch = 0.029
Read data: 9.441375732421875e-05
iter 12536 (epoch 20), train_loss = 2.794, time/batch = 0.027
Read data: 0.000148773193359375
iter 12537 (epoch 20), train_loss = 2.858, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 12538 (epoch 20), train_loss = 3.084, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 12539 (epoch 20), train_loss = 2.461, time/batch = 0.022
Read data: 0.00013828277587890625
iter 12540 (epoch 20), train_loss = 2.137, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 12541 (epoch 20), train_loss = 2.546, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 12542 (epoch 20), train_loss = 2.576, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 12543 (epoch 20), train_loss = 2.436, time/batch = 0.027
Read data: 0.00013113021850585938
iter 12544 (epoch 20), train_loss = 2.414, time/batch = 0.032
Read data: 0.00013113021850585938
iter 12545 (epoch 20), train_loss = 2.423, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 12546 (epoch 20), train_loss = 2.520, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 12547 (epoch 20), train_loss = 2.298, time/batch = 0.023
Read data: 0.0001373291015625
iter 12548 (epoch 20), train_loss = 2.228, time/batch = 0.029
Read data: 0.00012946128845214844
iter 12549 (epoch 20), train_loss = 2.550, time/batch = 0.022
Read data: 0.0002238750457763672
iter 12550 (epoch 20), train_loss = 2.511, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 12551 (epoch 20), train_loss = 2.148, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 12552 (epoch 20), train_loss = 2.320, time/batch = 0.026
Read data: 0.00012373924255371094
iter 12553 (epoch 20), train_loss = 2.181, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 12554 (epoch 20), train_loss = 2.703, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 12555 (epoch 20), train_loss = 2.817, time/batch = 0.024
Read data: 0.00013518333435058594
iter 12556 (epoch 20), train_loss = 2.487, time/batch = 0.025
Read data: 0.0001308917999267578
iter 12557 (epoch 20), train_loss = 2.511, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 12558 (epoch 20), train_loss = 2.814, time/batch = 0.033
Read data: 0.00018143653869628906
iter 12559 (epoch 20), train_loss = 3.034, time/batch = 0.028
Read data: 0.0001354217529296875
iter 12560 (epoch 20), train_loss = 2.349, time/batch = 0.028
Read data: 0.00013828277587890625
iter 12561 (epoch 20), train_loss = 2.170, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 12562 (epoch 20), train_loss = 2.586, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 12563 (epoch 20), train_loss = 2.615, time/batch = 0.027
Read data: 0.0001277923583984375
iter 12564 (epoch 20), train_loss = 2.628, time/batch = 0.026
Read data: 0.00012874603271484375
iter 12565 (epoch 20), train_loss = 2.650, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 12566 (epoch 20), train_loss = 2.144, time/batch = 0.027
Read data: 0.00011754035949707031
iter 12567 (epoch 20), train_loss = 2.765, time/batch = 0.024
Read data: 0.00013256072998046875
iter 12568 (epoch 20), train_loss = 2.312, time/batch = 0.024
Read data: 0.0001239776611328125
iter 12569 (epoch 20), train_loss = 2.289, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 12570 (epoch 20), train_loss = 2.813, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 12571 (epoch 20), train_loss = 2.751, time/batch = 0.029
Read data: 0.00012946128845214844
iter 12572 (epoch 20), train_loss = 2.564, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 12573 (epoch 20), train_loss = 2.311, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 12574 (epoch 20), train_loss = 2.762, time/batch = 0.025
Read data: 0.00023818016052246094
iter 12575 (epoch 20), train_loss = 2.461, time/batch = 0.021
Read data: 0.0001785755157470703
iter 12576 (epoch 20), train_loss = 2.481, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 12577 (epoch 20), train_loss = 2.698, time/batch = 0.029
Read data: 0.00010323524475097656
iter 12578 (epoch 20), train_loss = 2.623, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 12579 (epoch 20), train_loss = 2.654, time/batch = 0.019
Read data: 0.00014972686767578125
iter 12580 (epoch 20), train_loss = 2.746, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 12581 (epoch 20), train_loss = 2.840, time/batch = 0.029
Read data: 9.846687316894531e-05
iter 12582 (epoch 20), train_loss = 2.690, time/batch = 0.037
Read data: 0.00012183189392089844
iter 12583 (epoch 20), train_loss = 2.414, time/batch = 0.025
Read data: 0.00013065338134765625
iter 12584 (epoch 20), train_loss = 2.547, time/batch = 0.025
Read data: 0.00013375282287597656
iter 12585 (epoch 20), train_loss = 2.698, time/batch = 0.033
Read data: 7.987022399902344e-05
iter 12586 (epoch 20), train_loss = 2.513, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 12587 (epoch 20), train_loss = 2.636, time/batch = 0.040
Read data: 9.417533874511719e-05
iter 12588 (epoch 20), train_loss = 2.616, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 12589 (epoch 20), train_loss = 2.688, time/batch = 0.026
Read data: 0.00011849403381347656
iter 12590 (epoch 20), train_loss = 2.842, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 12591 (epoch 20), train_loss = 2.433, time/batch = 0.031
Read data: 0.0008864402770996094
iter 12592 (epoch 20), train_loss = 2.412, time/batch = 0.031
Read data: 0.00011491775512695312
iter 12593 (epoch 20), train_loss = 2.303, time/batch = 0.025
Read data: 0.00013136863708496094
iter 12594 (epoch 20), train_loss = 2.262, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 12595 (epoch 20), train_loss = 2.269, time/batch = 0.024
Read data: 0.0001347064971923828
iter 12596 (epoch 20), train_loss = 2.788, time/batch = 0.024
Read data: 0.0001761913299560547
iter 12597 (epoch 20), train_loss = 2.448, time/batch = 0.023
Read data: 9.799003601074219e-05
iter 12598 (epoch 20), train_loss = 2.569, time/batch = 0.037
Read data: 8.106231689453125e-05
iter 12599 (epoch 20), train_loss = 2.496, time/batch = 0.031
Read data: 0.00023865699768066406
iter 12600 (epoch 20), train_loss = 2.569, time/batch = 0.025
Read data: 0.00016307830810546875
iter 12601 (epoch 21), train_loss = 2.631, time/batch = 0.029
Read data: 0.0001475811004638672
iter 12602 (epoch 21), train_loss = 2.589, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 12603 (epoch 21), train_loss = 2.723, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 12604 (epoch 21), train_loss = 2.538, time/batch = 0.022
Read data: 9.965896606445312e-05
iter 12605 (epoch 21), train_loss = 2.494, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 12606 (epoch 21), train_loss = 2.727, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 12607 (epoch 21), train_loss = 2.077, time/batch = 0.029
Read data: 0.00012755393981933594
iter 12608 (epoch 21), train_loss = 2.526, time/batch = 0.026
Read data: 0.00013303756713867188
iter 12609 (epoch 21), train_loss = 2.702, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 12610 (epoch 21), train_loss = 2.614, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 12611 (epoch 21), train_loss = 2.591, time/batch = 0.021
Read data: 0.00013971328735351562
iter 12612 (epoch 21), train_loss = 2.732, time/batch = 0.025
Read data: 0.00010132789611816406
iter 12613 (epoch 21), train_loss = 2.324, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 12614 (epoch 21), train_loss = 2.188, time/batch = 0.039
Read data: 9.1552734375e-05
iter 12615 (epoch 21), train_loss = 2.170, time/batch = 0.024
Read data: 0.0001556873321533203
iter 12616 (epoch 21), train_loss = 2.604, time/batch = 0.034
Read data: 0.0001201629638671875
iter 12617 (epoch 21), train_loss = 2.745, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 12618 (epoch 21), train_loss = 2.344, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 12619 (epoch 21), train_loss = 2.799, time/batch = 0.027
Read data: 0.000133514404296875
iter 12620 (epoch 21), train_loss = 2.499, time/batch = 0.027
Read data: 0.00013399124145507812
iter 12621 (epoch 21), train_loss = 2.347, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 12622 (epoch 21), train_loss = 2.485, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 12623 (epoch 21), train_loss = 2.679, time/batch = 0.033
Read data: 0.0001277923583984375
iter 12624 (epoch 21), train_loss = 2.488, time/batch = 0.023
Read data: 0.00021028518676757812
iter 12625 (epoch 21), train_loss = 2.468, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 12626 (epoch 21), train_loss = 2.921, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 12627 (epoch 21), train_loss = 2.344, time/batch = 0.021
Read data: 0.00014591217041015625
iter 12628 (epoch 21), train_loss = 2.531, time/batch = 0.028
Read data: 0.0001049041748046875
iter 12629 (epoch 21), train_loss = 2.724, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 12630 (epoch 21), train_loss = 2.834, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 12631 (epoch 21), train_loss = 2.573, time/batch = 0.029
Read data: 0.00010728836059570312
iter 12632 (epoch 21), train_loss = 2.638, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 12633 (epoch 21), train_loss = 2.647, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 12634 (epoch 21), train_loss = 2.453, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 12635 (epoch 21), train_loss = 2.558, time/batch = 0.028
Read data: 0.0001609325408935547
iter 12636 (epoch 21), train_loss = 2.378, time/batch = 0.025
Read data: 0.0001289844512939453
iter 12637 (epoch 21), train_loss = 2.202, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 12638 (epoch 21), train_loss = 2.550, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 12639 (epoch 21), train_loss = 2.551, time/batch = 0.024
Read data: 0.00012612342834472656
iter 12640 (epoch 21), train_loss = 2.670, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 12641 (epoch 21), train_loss = 2.523, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 12642 (epoch 21), train_loss = 2.101, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 12643 (epoch 21), train_loss = 2.255, time/batch = 0.027
Read data: 0.00012993812561035156
iter 12644 (epoch 21), train_loss = 2.750, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 12645 (epoch 21), train_loss = 2.646, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 12646 (epoch 21), train_loss = 2.925, time/batch = 0.027
Read data: 0.00013446807861328125
iter 12647 (epoch 21), train_loss = 2.528, time/batch = 0.028
Read data: 0.00013375282287597656
iter 12648 (epoch 21), train_loss = 2.464, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 12649 (epoch 21), train_loss = 2.340, time/batch = 0.027
Read data: 0.00021195411682128906
iter 12650 (epoch 21), train_loss = 2.619, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 12651 (epoch 21), train_loss = 2.608, time/batch = 0.022
Read data: 0.00014519691467285156
iter 12652 (epoch 21), train_loss = 2.671, time/batch = 0.024
Read data: 0.00010704994201660156
iter 12653 (epoch 21), train_loss = 2.825, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 12654 (epoch 21), train_loss = 2.847, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 12655 (epoch 21), train_loss = 2.311, time/batch = 0.029
Read data: 0.00016117095947265625
iter 12656 (epoch 21), train_loss = 2.650, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 12657 (epoch 21), train_loss = 2.530, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 12658 (epoch 21), train_loss = 2.501, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 12659 (epoch 21), train_loss = 2.472, time/batch = 0.025
Read data: 0.00016045570373535156
iter 12660 (epoch 21), train_loss = 2.644, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 12661 (epoch 21), train_loss = 2.379, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 12662 (epoch 21), train_loss = 2.359, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 12663 (epoch 21), train_loss = 2.542, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 12664 (epoch 21), train_loss = 2.141, time/batch = 0.028
Read data: 0.0001308917999267578
iter 12665 (epoch 21), train_loss = 2.668, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 12666 (epoch 21), train_loss = 2.315, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 12667 (epoch 21), train_loss = 2.483, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 12668 (epoch 21), train_loss = 2.692, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 12669 (epoch 21), train_loss = 2.287, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 12670 (epoch 21), train_loss = 2.226, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 12671 (epoch 21), train_loss = 2.207, time/batch = 0.025
Read data: 0.00014448165893554688
iter 12672 (epoch 21), train_loss = 2.935, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 12673 (epoch 21), train_loss = 2.594, time/batch = 0.028
Read data: 0.00010037422180175781
iter 12674 (epoch 21), train_loss = 2.345, time/batch = 0.028
Read data: 0.00020241737365722656
iter 12675 (epoch 21), train_loss = 2.141, time/batch = 0.035
Read data: 8.273124694824219e-05
iter 12676 (epoch 21), train_loss = 2.486, time/batch = 0.031
Read data: 0.0001728534698486328
iter 12677 (epoch 21), train_loss = 2.798, time/batch = 0.039
Read data: 7.62939453125e-05
iter 12678 (epoch 21), train_loss = 2.601, time/batch = 0.032
Read data: 7.510185241699219e-05
iter 12679 (epoch 21), train_loss = 2.874, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 12680 (epoch 21), train_loss = 2.627, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 12681 (epoch 21), train_loss = 2.600, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 12682 (epoch 21), train_loss = 2.478, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 12683 (epoch 21), train_loss = 2.773, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 12684 (epoch 21), train_loss = 2.839, time/batch = 0.029
Read data: 7.605552673339844e-05
iter 12685 (epoch 21), train_loss = 2.304, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 12686 (epoch 21), train_loss = 2.658, time/batch = 0.026
Read data: 7.534027099609375e-05
iter 12687 (epoch 21), train_loss = 2.757, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 12688 (epoch 21), train_loss = 2.740, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 12689 (epoch 21), train_loss = 2.587, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 12690 (epoch 21), train_loss = 2.723, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 12691 (epoch 21), train_loss = 2.364, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 12692 (epoch 21), train_loss = 2.495, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 12693 (epoch 21), train_loss = 2.292, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 12694 (epoch 21), train_loss = 2.424, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 12695 (epoch 21), train_loss = 2.675, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 12696 (epoch 21), train_loss = 2.450, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 12697 (epoch 21), train_loss = 2.720, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 12698 (epoch 21), train_loss = 2.469, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 12699 (epoch 21), train_loss = 2.263, time/batch = 0.029
Read data: 0.00013113021850585938
iter 12700 (epoch 21), train_loss = 2.502, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 12701 (epoch 21), train_loss = 2.573, time/batch = 0.021
Read data: 0.00011730194091796875
iter 12702 (epoch 21), train_loss = 2.162, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 12703 (epoch 21), train_loss = 2.152, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 12704 (epoch 21), train_loss = 2.328, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 12705 (epoch 21), train_loss = 2.408, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 12706 (epoch 21), train_loss = 2.070, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 12707 (epoch 21), train_loss = 2.687, time/batch = 0.027
Read data: 0.00012254714965820312
iter 12708 (epoch 21), train_loss = 2.733, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 12709 (epoch 21), train_loss = 2.342, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 12710 (epoch 21), train_loss = 2.498, time/batch = 0.021
Read data: 9.226799011230469e-05
iter 12711 (epoch 21), train_loss = 2.189, time/batch = 0.028
Read data: 0.00013184547424316406
iter 12712 (epoch 21), train_loss = 2.466, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 12713 (epoch 21), train_loss = 2.298, time/batch = 0.025
Read data: 0.00011610984802246094
iter 12714 (epoch 21), train_loss = 2.377, time/batch = 0.029
Read data: 7.510185241699219e-05
iter 12715 (epoch 21), train_loss = 2.652, time/batch = 0.023
Read data: 0.0001804828643798828
iter 12716 (epoch 21), train_loss = 2.801, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 12717 (epoch 21), train_loss = 2.392, time/batch = 0.025
Read data: 0.00011801719665527344
iter 12718 (epoch 21), train_loss = 2.917, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 12719 (epoch 21), train_loss = 2.194, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 12720 (epoch 21), train_loss = 2.530, time/batch = 0.025
Read data: 0.0001418590545654297
iter 12721 (epoch 21), train_loss = 2.094, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 12722 (epoch 21), train_loss = 2.813, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 12723 (epoch 21), train_loss = 2.407, time/batch = 0.026
Read data: 0.0001895427703857422
iter 12724 (epoch 21), train_loss = 2.588, time/batch = 0.026
Read data: 0.00039458274841308594
iter 12725 (epoch 21), train_loss = 2.625, time/batch = 0.037
Read data: 8.988380432128906e-05
iter 12726 (epoch 21), train_loss = 2.500, time/batch = 0.026
Read data: 0.0001385211944580078
iter 12727 (epoch 21), train_loss = 2.685, time/batch = 0.034
Read data: 9.012222290039062e-05
iter 12728 (epoch 21), train_loss = 2.800, time/batch = 0.031
Read data: 0.00013518333435058594
iter 12729 (epoch 21), train_loss = 2.399, time/batch = 0.025
Read data: 0.00012350082397460938
iter 12730 (epoch 21), train_loss = 2.458, time/batch = 0.035
Read data: 0.00011992454528808594
iter 12731 (epoch 21), train_loss = 2.201, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 12732 (epoch 21), train_loss = 2.140, time/batch = 0.023
Read data: 0.00015211105346679688
iter 12733 (epoch 21), train_loss = 2.644, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 12734 (epoch 21), train_loss = 2.874, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 12735 (epoch 21), train_loss = 2.851, time/batch = 0.025
Read data: 0.00011157989501953125
iter 12736 (epoch 21), train_loss = 2.462, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 12737 (epoch 21), train_loss = 2.561, time/batch = 0.030
Read data: 9.989738464355469e-05
iter 12738 (epoch 21), train_loss = 2.382, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 12739 (epoch 21), train_loss = 2.813, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 12740 (epoch 21), train_loss = 2.195, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 12741 (epoch 21), train_loss = 2.458, time/batch = 0.026
Read data: 0.00011777877807617188
iter 12742 (epoch 21), train_loss = 2.654, time/batch = 0.024
Read data: 0.000141143798828125
iter 12743 (epoch 21), train_loss = 2.627, time/batch = 0.030
Read data: 0.00014019012451171875
iter 12744 (epoch 21), train_loss = 2.573, time/batch = 0.025
Read data: 0.00012135505676269531
iter 12745 (epoch 21), train_loss = 2.249, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 12746 (epoch 21), train_loss = 2.860, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 12747 (epoch 21), train_loss = 2.757, time/batch = 0.027
Read data: 0.00014829635620117188
iter 12748 (epoch 21), train_loss = 2.413, time/batch = 0.022
Read data: 0.00013113021850585938
iter 12749 (epoch 21), train_loss = 2.603, time/batch = 0.019
Read data: 0.00025534629821777344
iter 12750 (epoch 21), train_loss = 2.787, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 12751 (epoch 21), train_loss = 2.554, time/batch = 0.032
Read data: 0.00014448165893554688
iter 12752 (epoch 21), train_loss = 2.180, time/batch = 0.025
Read data: 0.0001125335693359375
iter 12753 (epoch 21), train_loss = 2.649, time/batch = 0.021
Read data: 9.1552734375e-05
iter 12754 (epoch 21), train_loss = 2.508, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 12755 (epoch 21), train_loss = 2.762, time/batch = 0.035
Read data: 7.987022399902344e-05
iter 12756 (epoch 21), train_loss = 2.890, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 12757 (epoch 21), train_loss = 2.505, time/batch = 0.033
Read data: 0.0001697540283203125
iter 12758 (epoch 21), train_loss = 2.663, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 12759 (epoch 21), train_loss = 2.425, time/batch = 0.025
Read data: 0.000148773193359375
iter 12760 (epoch 21), train_loss = 2.575, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 12761 (epoch 21), train_loss = 2.530, time/batch = 0.026
Read data: 7.62939453125e-05
iter 12762 (epoch 21), train_loss = 2.099, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 12763 (epoch 21), train_loss = 2.159, time/batch = 0.029
Read data: 9.989738464355469e-05
iter 12764 (epoch 21), train_loss = 2.278, time/batch = 0.028
Read data: 0.00014781951904296875
iter 12765 (epoch 21), train_loss = 2.214, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 12766 (epoch 21), train_loss = 2.072, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 12767 (epoch 21), train_loss = 2.226, time/batch = 0.022
Read data: 0.00012087821960449219
iter 12768 (epoch 21), train_loss = 2.719, time/batch = 0.025
Read data: 0.0001404285430908203
iter 12769 (epoch 21), train_loss = 2.184, time/batch = 0.024
Read data: 0.00011920928955078125
iter 12770 (epoch 21), train_loss = 2.627, time/batch = 0.033
Read data: 9.417533874511719e-05
iter 12771 (epoch 21), train_loss = 2.750, time/batch = 0.036
Read data: 8.869171142578125e-05
iter 12772 (epoch 21), train_loss = 2.781, time/batch = 0.038
Read data: 8.106231689453125e-05
iter 12773 (epoch 21), train_loss = 2.430, time/batch = 0.024
Read data: 0.0001678466796875
iter 12774 (epoch 21), train_loss = 2.148, time/batch = 0.023
Read data: 0.0002460479736328125
iter 12775 (epoch 21), train_loss = 2.889, time/batch = 0.036
Read data: 8.368492126464844e-05
iter 12776 (epoch 21), train_loss = 2.781, time/batch = 0.024
Read data: 0.00011730194091796875
iter 12777 (epoch 21), train_loss = 2.542, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 12778 (epoch 21), train_loss = 2.552, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 12779 (epoch 21), train_loss = 2.620, time/batch = 0.034
Read data: 0.00012111663818359375
iter 12780 (epoch 21), train_loss = 2.575, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 12781 (epoch 21), train_loss = 2.676, time/batch = 0.037
Read data: 9.036064147949219e-05
iter 12782 (epoch 21), train_loss = 2.489, time/batch = 0.023
Read data: 0.00013017654418945312
iter 12783 (epoch 21), train_loss = 2.743, time/batch = 0.034
Read data: 8.630752563476562e-05
iter 12784 (epoch 21), train_loss = 2.499, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 12785 (epoch 21), train_loss = 2.135, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 12786 (epoch 21), train_loss = 2.245, time/batch = 0.025
Read data: 7.43865966796875e-05
iter 12787 (epoch 21), train_loss = 2.281, time/batch = 0.024
Read data: 0.00011897087097167969
iter 12788 (epoch 21), train_loss = 2.033, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 12789 (epoch 21), train_loss = 2.858, time/batch = 0.027
Read data: 9.775161743164062e-05
iter 12790 (epoch 21), train_loss = 2.489, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 12791 (epoch 21), train_loss = 2.979, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 12792 (epoch 21), train_loss = 2.558, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 12793 (epoch 21), train_loss = 2.411, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 12794 (epoch 21), train_loss = 2.198, time/batch = 0.027
Read data: 7.653236389160156e-05
iter 12795 (epoch 21), train_loss = 2.807, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 12796 (epoch 21), train_loss = 2.505, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 12797 (epoch 21), train_loss = 2.601, time/batch = 0.023
Read data: 0.0001671314239501953
iter 12798 (epoch 21), train_loss = 2.660, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 12799 (epoch 21), train_loss = 2.898, time/batch = 0.025
Read data: 0.00011205673217773438
iter 12800 (epoch 21), train_loss = 2.321, time/batch = 0.025
Read data: 0.00011920928955078125
iter 12801 (epoch 21), train_loss = 2.951, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 12802 (epoch 21), train_loss = 2.165, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 12803 (epoch 21), train_loss = 2.284, time/batch = 0.022
Read data: 0.00012612342834472656
iter 12804 (epoch 21), train_loss = 2.745, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 12805 (epoch 21), train_loss = 2.579, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 12806 (epoch 21), train_loss = 3.020, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 12807 (epoch 21), train_loss = 2.624, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 12808 (epoch 21), train_loss = 2.887, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 12809 (epoch 21), train_loss = 2.451, time/batch = 0.027
Read data: 0.000156402587890625
iter 12810 (epoch 21), train_loss = 2.490, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 12811 (epoch 21), train_loss = 2.354, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 12812 (epoch 21), train_loss = 2.751, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 12813 (epoch 21), train_loss = 2.488, time/batch = 0.029
Read data: 0.00016236305236816406
iter 12814 (epoch 21), train_loss = 2.522, time/batch = 0.027
Read data: 0.00010132789611816406
iter 12815 (epoch 21), train_loss = 2.535, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 12816 (epoch 21), train_loss = 2.744, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 12817 (epoch 21), train_loss = 2.597, time/batch = 0.037
Read data: 9.560585021972656e-05
iter 12818 (epoch 21), train_loss = 2.699, time/batch = 0.024
Read data: 0.00011515617370605469
iter 12819 (epoch 21), train_loss = 2.528, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 12820 (epoch 21), train_loss = 2.315, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 12821 (epoch 21), train_loss = 2.414, time/batch = 0.027
Read data: 0.00017404556274414062
iter 12822 (epoch 21), train_loss = 2.804, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 12823 (epoch 21), train_loss = 2.240, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 12824 (epoch 21), train_loss = 2.519, time/batch = 0.023
Read data: 0.00021028518676757812
iter 12825 (epoch 21), train_loss = 2.166, time/batch = 0.023
Read data: 0.00011897087097167969
iter 12826 (epoch 21), train_loss = 2.909, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 12827 (epoch 21), train_loss = 2.596, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 12828 (epoch 21), train_loss = 2.434, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 12829 (epoch 21), train_loss = 2.485, time/batch = 0.023
Read data: 0.00011682510375976562
iter 12830 (epoch 21), train_loss = 2.573, time/batch = 0.024
Read data: 0.00010228157043457031
iter 12831 (epoch 21), train_loss = 2.370, time/batch = 0.027
Read data: 0.00010967254638671875
iter 12832 (epoch 21), train_loss = 2.857, time/batch = 0.035
Read data: 8.058547973632812e-05
iter 12833 (epoch 21), train_loss = 2.945, time/batch = 0.028
Read data: 0.00015878677368164062
iter 12834 (epoch 21), train_loss = 2.706, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 12835 (epoch 21), train_loss = 2.555, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 12836 (epoch 21), train_loss = 2.800, time/batch = 0.027
Read data: 0.00012135505676269531
iter 12837 (epoch 21), train_loss = 2.190, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 12838 (epoch 21), train_loss = 2.217, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 12839 (epoch 21), train_loss = 3.057, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 12840 (epoch 21), train_loss = 2.765, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 12841 (epoch 21), train_loss = 2.506, time/batch = 0.023
Read data: 0.00011897087097167969
iter 12842 (epoch 21), train_loss = 2.729, time/batch = 0.027
Read data: 0.00014066696166992188
iter 12843 (epoch 21), train_loss = 2.295, time/batch = 0.026
Read data: 0.0017368793487548828
iter 12844 (epoch 21), train_loss = 2.672, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 12845 (epoch 21), train_loss = 2.419, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 12846 (epoch 21), train_loss = 2.627, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 12847 (epoch 21), train_loss = 2.916, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 12848 (epoch 21), train_loss = 2.505, time/batch = 0.031
Read data: 0.00015020370483398438
iter 12849 (epoch 21), train_loss = 2.585, time/batch = 0.025
Read data: 0.00026726722717285156
iter 12850 (epoch 21), train_loss = 2.454, time/batch = 0.026
Read data: 9.441375732421875e-05
iter 12851 (epoch 21), train_loss = 2.903, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 12852 (epoch 21), train_loss = 2.749, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 12853 (epoch 21), train_loss = 2.575, time/batch = 0.025
Read data: 0.00010085105895996094
iter 12854 (epoch 21), train_loss = 2.337, time/batch = 0.023
Read data: 0.0001785755157470703
iter 12855 (epoch 21), train_loss = 2.584, time/batch = 0.027
Read data: 0.00011610984802246094
iter 12856 (epoch 21), train_loss = 2.669, time/batch = 0.032
Read data: 0.0001556873321533203
iter 12857 (epoch 21), train_loss = 2.311, time/batch = 0.024
Read data: 0.0001010894775390625
iter 12858 (epoch 21), train_loss = 2.422, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 12859 (epoch 21), train_loss = 2.637, time/batch = 0.021
Read data: 0.00011324882507324219
iter 12860 (epoch 21), train_loss = 2.370, time/batch = 0.028
Read data: 0.00010275840759277344
iter 12861 (epoch 21), train_loss = 2.664, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 12862 (epoch 21), train_loss = 2.927, time/batch = 0.028
Read data: 0.00010085105895996094
iter 12863 (epoch 21), train_loss = 2.660, time/batch = 0.025
Read data: 0.00011754035949707031
iter 12864 (epoch 21), train_loss = 2.563, time/batch = 0.024
Read data: 0.00011467933654785156
iter 12865 (epoch 21), train_loss = 2.416, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 12866 (epoch 21), train_loss = 2.761, time/batch = 0.025
Read data: 0.00014162063598632812
iter 12867 (epoch 21), train_loss = 2.506, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 12868 (epoch 21), train_loss = 2.554, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 12869 (epoch 21), train_loss = 2.397, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 12870 (epoch 21), train_loss = 2.405, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 12871 (epoch 21), train_loss = 2.666, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 12872 (epoch 21), train_loss = 2.673, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 12873 (epoch 21), train_loss = 2.332, time/batch = 0.027
Read data: 0.00012922286987304688
iter 12874 (epoch 21), train_loss = 2.269, time/batch = 0.025
Read data: 0.00024247169494628906
iter 12875 (epoch 21), train_loss = 2.534, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 12876 (epoch 21), train_loss = 2.623, time/batch = 0.027
Read data: 9.965896606445312e-05
iter 12877 (epoch 21), train_loss = 2.616, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 12878 (epoch 21), train_loss = 2.438, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 12879 (epoch 21), train_loss = 2.432, time/batch = 0.026
Read data: 0.00013494491577148438
iter 12880 (epoch 21), train_loss = 2.987, time/batch = 0.032
Read data: 0.00011873245239257812
iter 12881 (epoch 21), train_loss = 2.243, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 12882 (epoch 21), train_loss = 2.742, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 12883 (epoch 21), train_loss = 2.634, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 12884 (epoch 21), train_loss = 2.327, time/batch = 0.030
Read data: 0.00011372566223144531
iter 12885 (epoch 21), train_loss = 2.370, time/batch = 0.026
Read data: 9.822845458984375e-05
iter 12886 (epoch 21), train_loss = 2.240, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 12887 (epoch 21), train_loss = 2.649, time/batch = 0.027
Read data: 0.00011992454528808594
iter 12888 (epoch 21), train_loss = 2.717, time/batch = 0.026
Read data: 0.00011372566223144531
iter 12889 (epoch 21), train_loss = 2.951, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 12890 (epoch 21), train_loss = 2.331, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 12891 (epoch 21), train_loss = 2.630, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 12892 (epoch 21), train_loss = 2.533, time/batch = 0.026
Read data: 0.0001125335693359375
iter 12893 (epoch 21), train_loss = 2.596, time/batch = 0.030
Read data: 9.34600830078125e-05
iter 12894 (epoch 21), train_loss = 2.466, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 12895 (epoch 21), train_loss = 2.389, time/batch = 0.023
Read data: 0.00015783309936523438
iter 12896 (epoch 21), train_loss = 2.824, time/batch = 0.026
Read data: 0.0001494884490966797
iter 12897 (epoch 21), train_loss = 2.461, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 12898 (epoch 21), train_loss = 2.807, time/batch = 0.032
Read data: 0.00011730194091796875
iter 12899 (epoch 21), train_loss = 2.956, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 12900 (epoch 21), train_loss = 2.412, time/batch = 0.032
Read data: 0.00010418891906738281
iter 12901 (epoch 21), train_loss = 2.534, time/batch = 0.030
Read data: 0.00013899803161621094
iter 12902 (epoch 21), train_loss = 2.420, time/batch = 0.026
Read data: 0.0001323223114013672
iter 12903 (epoch 21), train_loss = 2.511, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 12904 (epoch 21), train_loss = 2.661, time/batch = 0.023
Read data: 0.00011968612670898438
iter 12905 (epoch 21), train_loss = 2.198, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 12906 (epoch 21), train_loss = 2.587, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 12907 (epoch 21), train_loss = 2.618, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 12908 (epoch 21), train_loss = 2.533, time/batch = 0.027
Read data: 0.00011897087097167969
iter 12909 (epoch 21), train_loss = 2.239, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 12910 (epoch 21), train_loss = 3.300, time/batch = 0.038
Read data: 0.00012493133544921875
iter 12911 (epoch 21), train_loss = 2.219, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 12912 (epoch 21), train_loss = 2.758, time/batch = 0.030
Read data: 0.0001468658447265625
iter 12913 (epoch 21), train_loss = 2.506, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 12914 (epoch 21), train_loss = 2.666, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 12915 (epoch 21), train_loss = 2.913, time/batch = 0.029
Read data: 0.00011229515075683594
iter 12916 (epoch 21), train_loss = 2.587, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 12917 (epoch 21), train_loss = 2.698, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 12918 (epoch 21), train_loss = 2.566, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 12919 (epoch 21), train_loss = 2.720, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 12920 (epoch 21), train_loss = 2.453, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 12921 (epoch 21), train_loss = 2.550, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 12922 (epoch 21), train_loss = 2.561, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 12923 (epoch 21), train_loss = 2.593, time/batch = 0.025
Read data: 0.00011181831359863281
iter 12924 (epoch 21), train_loss = 2.493, time/batch = 0.025
Read data: 0.00029015541076660156
iter 12925 (epoch 21), train_loss = 2.954, time/batch = 0.030
Read data: 0.00010323524475097656
iter 12926 (epoch 21), train_loss = 2.574, time/batch = 0.022
Read data: 9.942054748535156e-05
iter 12927 (epoch 21), train_loss = 2.500, time/batch = 0.026
Read data: 0.00010418891906738281
iter 12928 (epoch 21), train_loss = 2.712, time/batch = 0.031
Read data: 0.00011301040649414062
iter 12929 (epoch 21), train_loss = 2.130, time/batch = 0.030
Read data: 0.00010013580322265625
iter 12930 (epoch 21), train_loss = 2.494, time/batch = 0.030
Read data: 0.00011038780212402344
iter 12931 (epoch 21), train_loss = 2.422, time/batch = 0.030
Read data: 0.00011730194091796875
iter 12932 (epoch 21), train_loss = 2.851, time/batch = 0.032
Read data: 0.00012254714965820312
iter 12933 (epoch 21), train_loss = 2.586, time/batch = 0.028
Read data: 0.00017571449279785156
iter 12934 (epoch 21), train_loss = 2.817, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 12935 (epoch 21), train_loss = 2.682, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 12936 (epoch 21), train_loss = 2.321, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 12937 (epoch 21), train_loss = 2.742, time/batch = 0.029
Read data: 0.0001010894775390625
iter 12938 (epoch 21), train_loss = 2.685, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 12939 (epoch 21), train_loss = 2.655, time/batch = 0.025
Read data: 8.392333984375e-05
iter 12940 (epoch 21), train_loss = 2.750, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 12941 (epoch 21), train_loss = 2.443, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 12942 (epoch 21), train_loss = 2.380, time/batch = 0.025
Read data: 0.0001728534698486328
iter 12943 (epoch 21), train_loss = 2.054, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 12944 (epoch 21), train_loss = 2.427, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 12945 (epoch 21), train_loss = 2.489, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 12946 (epoch 21), train_loss = 2.558, time/batch = 0.026
Read data: 0.00016736984252929688
iter 12947 (epoch 21), train_loss = 2.828, time/batch = 0.028
Read data: 9.465217590332031e-05
iter 12948 (epoch 21), train_loss = 2.749, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 12949 (epoch 21), train_loss = 2.791, time/batch = 0.028
Read data: 0.00021600723266601562
iter 12950 (epoch 21), train_loss = 2.245, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 12951 (epoch 21), train_loss = 2.450, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 12952 (epoch 21), train_loss = 2.178, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 12953 (epoch 21), train_loss = 2.718, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 12954 (epoch 21), train_loss = 2.418, time/batch = 0.034
Read data: 0.00010991096496582031
iter 12955 (epoch 21), train_loss = 2.411, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 12956 (epoch 21), train_loss = 2.518, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 12957 (epoch 21), train_loss = 2.302, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 12958 (epoch 21), train_loss = 2.639, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 12959 (epoch 21), train_loss = 2.963, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 12960 (epoch 21), train_loss = 2.804, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 12961 (epoch 21), train_loss = 2.707, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 12962 (epoch 21), train_loss = 2.385, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 12963 (epoch 21), train_loss = 2.573, time/batch = 0.037
Read data: 0.0001552104949951172
iter 12964 (epoch 21), train_loss = 2.612, time/batch = 0.026
Read data: 0.00011014938354492188
iter 12965 (epoch 21), train_loss = 2.407, time/batch = 0.026
Read data: 0.00013589859008789062
iter 12966 (epoch 21), train_loss = 2.654, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 12967 (epoch 21), train_loss = 2.469, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 12968 (epoch 21), train_loss = 2.688, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 12969 (epoch 21), train_loss = 2.270, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 12970 (epoch 21), train_loss = 2.383, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 12971 (epoch 21), train_loss = 2.322, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 12972 (epoch 21), train_loss = 2.794, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 12973 (epoch 21), train_loss = 2.288, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 12974 (epoch 21), train_loss = 2.850, time/batch = 0.026
Read data: 0.00026798248291015625
iter 12975 (epoch 21), train_loss = 2.475, time/batch = 0.034
Read data: 8.153915405273438e-05
iter 12976 (epoch 21), train_loss = 2.313, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 12977 (epoch 21), train_loss = 2.211, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 12978 (epoch 21), train_loss = 2.248, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 12979 (epoch 21), train_loss = 2.480, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 12980 (epoch 21), train_loss = 2.666, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 12981 (epoch 21), train_loss = 2.732, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 12982 (epoch 21), train_loss = 2.444, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 12983 (epoch 21), train_loss = 2.382, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 12984 (epoch 21), train_loss = 2.479, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 12985 (epoch 21), train_loss = 2.622, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 12986 (epoch 21), train_loss = 2.507, time/batch = 0.030
Read data: 8.845329284667969e-05
iter 12987 (epoch 21), train_loss = 2.654, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 12988 (epoch 21), train_loss = 2.703, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 12989 (epoch 21), train_loss = 2.771, time/batch = 0.021
Read data: 8.034706115722656e-05
iter 12990 (epoch 21), train_loss = 2.693, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 12991 (epoch 21), train_loss = 2.621, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 12992 (epoch 21), train_loss = 2.155, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 12993 (epoch 21), train_loss = 2.141, time/batch = 0.029
Read data: 9.226799011230469e-05
iter 12994 (epoch 21), train_loss = 2.599, time/batch = 0.021
Read data: 8.153915405273438e-05
iter 12995 (epoch 21), train_loss = 2.653, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 12996 (epoch 21), train_loss = 2.489, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 12997 (epoch 21), train_loss = 2.733, time/batch = 0.022
Read data: 0.00014853477478027344
iter 12998 (epoch 21), train_loss = 2.707, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 12999 (epoch 21), train_loss = 2.929, time/batch = 0.031
image 976:    
image 5399:     
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:    
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.608907)
image 2798:    
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:     
image 6767:    
image 6023:     
image 6550:     
image 6718:      
evaluating validation preformance... 20/1000 (2.228589)
image 6903:      
image 3301:    
image 2019:     
image 5535:     
image 7680:      
image 5527:      
image 2568:    
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.546989)
image 4604:    UNK
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.970160)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:   
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.491241)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:     
image 6329:    
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (2.796444)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.574624)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.614648)
image 3276:      
image 3812:   
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.126202)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.910048)
image 2800:    
image 7249:      
image 3211:    
image 686:   
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.771574)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     UNK
evaluating validation preformance... 120/1000 (2.366472)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:     
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.918337)
image 6214:     
image 429:    
image 7743:    
image 3657:      
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:    
image 2867:     
evaluating validation preformance... 140/1000 (2.705233)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    UNK
evaluating validation preformance... 150/1000 (2.895741)
image 1865:    
image 3830:      
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:    
image 7688:    
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.774578)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:      
image 5662:     
image 2095:    
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.579385)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:     
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.673624)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:      
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.388796)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:   
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.291194)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:      
image 4023:     
evaluating validation preformance... 210/1000 (2.451098)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.564853)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.233564)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.173965)
image 7143:     
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:    
image 528:     
evaluating validation preformance... 250/1000 (2.531316)
image 3028:   
image 3141:    
image 7137:    
image 3444:     
image 2049:     
image 550:     
image 3367:     
image 4907:    UNK
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.486688)
image 492:    
image 5429:     
image 6968:      
image 2672:      
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.972833)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:    
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.527331)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.433738)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.155099)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.767418)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.358898)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:    
evaluating validation preformance... 330/1000 (2.736061)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.424718)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.510837)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:     
image 1215:    
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.042431)
image 2905:    
image 7814:      
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.596687)
image 4351:     
image 1054:     
image 129:     
image 2849:    
image 725:   
image 2573:    
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.639248)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:     
image 60:     
evaluating validation preformance... 390/1000 (2.815735)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:     
image 1117:    
image 5817:      
image 1231:    
image 1630:    
image 6886:    
evaluating validation preformance... 400/1000 (2.221577)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.120660)
image 4359:     
image 2372:    
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:    
image 6688:    
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.343910)
image 30:     
image 5540:     
image 2445:      
image 5896:      
image 7607:     
image 1426:    
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     UNK
evaluating validation preformance... 430/1000 (2.800637)
image 385:    
image 6938:       
image 2381:    
image 5796:     
image 4010:     
image 3452:     
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.909449)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:     
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.187891)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:     
image 2466:    
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.702083)
image 7979:    UNK
image 1618:    UNK
image 7608:     
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.235019)
image 4503:    
image 7112:     
image 3480:     
image 7533:     
image 5050:    
image 6862:      
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.902108)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:       
image 3823:    
image 1595:    
image 4757:    
image 205:     
evaluating validation preformance... 490/1000 (3.265387)
image 2044:    
image 4349:    
image 3855:      
image 1846:     
image 3724:     
image 606:      
image 6577:    
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.542077)
image 1797:    
image 4670:   
image 4846:     
image 5907:     
image 3321:    
image 1700:     
image 438:      
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.993189)
image 3246:       
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:     
evaluating validation preformance... 520/1000 (2.648613)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.461037)
image 5619:     
image 4391:    UNK
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:    
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.474550)
image 5292:    
image 2901:     
image 3568:    
image 690:      
image 3345:    
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.550049)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:     
image 4340:    
image 2134:      
evaluating validation preformance... 560/1000 (2.579200)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:    
image 4778:     
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.574699)
image 7936:     
image 5433:    UNK
image 5691:     
image 1628:    
image 4501:    
image 1247:     
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.549132)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.578891)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.511498)
image 353:     
image 1095:     
image 3583:      
image 3264:    UNK
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.653102)
image 69:     
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.422728)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:    
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.473962)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.457498)
image 5313:      
image 2377:     
image 6058:    
image 4661:     
image 2955:    
image 3333:    
image 7124:    UNK
image 4278:      
image 953:     
image 4037:    
evaluating validation preformance... 650/1000 (2.555585)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:     
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.650780)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (2.848145)
image 7877:    
image 6761:     
image 6880:    
image 4914:    UNK
image 4522:     
image 2311:    
image 7587:     
image 4848:     
image 6722:    UNK
image 7784:      
evaluating validation preformance... 680/1000 (2.991263)
image 1445:     
image 6841:     
image 2896:     
image 6947:   
image 4782:    
image 7669:     
image 4382:    
image 1257:     
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.853780)
image 6860:     
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:      
image 6225:    
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.990361)
image 5343:      
image 68:     
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.476870)
image 7368:    
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:    
evaluating validation preformance... 720/1000 (2.606746)
image 5729:     
image 6395:      
image 516:      
image 1026:    
image 2972:      
image 3005:    
image 1241:      
image 2743:      
image 3665:     
image 1290:     
evaluating validation preformance... 730/1000 (2.302857)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:     
image 997:    
image 5092:      
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.431525)
image 2239:     
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:      
image 6197:     
evaluating validation preformance... 750/1000 (2.684349)
image 3279:     
image 6380:    
image 2663:    
image 3815:    
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (3.004065)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:     
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.174873)
image 6220:     
image 6238:    UNK
image 4534:     
image 2732:      
image 7003:     
image 1739:     
image 5503:     
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.787533)
image 6867:    
image 5525:     
image 4746:    
image 5531:    
image 5425:     
image 6978:    
image 3450:     
image 3312:    UNK
image 7824:     
image 2032:     
evaluating validation preformance... 790/1000 (3.134521)
image 5047:    
image 325:      
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.252695)
image 7288:    
image 7302:      
image 3055:    UNK
image 5250:     
image 1158:      
image 290:     
image 159:     
image 4345:     
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.412759)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.940319)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:    UNK
image 7147:    
image 6348:     
image 580:      
image 2531:    
evaluating validation preformance... 830/1000 (2.366174)
image 5107:    
image 3973:    
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:      
evaluating validation preformance... 840/1000 (2.420278)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.751837)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:     
image 336:    
image 3596:      
image 1921:       
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.757590)
image 4254:     
image 6842:     
image 1644:   
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:    
image 4002:    
evaluating validation preformance... 870/1000 (2.335779)
image 4934:    
image 6487:     
image 4217:     
image 6355:     
image 2793:     
image 7201:     
image 5681:      
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.606967)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:     UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.867392)
image 7485:    
image 6102:    
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:    
image 210:    
evaluating validation preformance... 900/1000 (3.546146)
image 5664:     
image 4985:    UNK
image 4082:     
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.222150)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:    
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.612487)
image 7152:    
image 4559:      
image 7233:    
image 1341:     
image 5337:     
image 3189:     
image 6274:      
image 7102:      
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.498927)
image 5636:      
image 7799:      
image 6025:     
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.670580)
image 5860:    
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:    
image 5984:     
image 5804:     
image 6691:    
image 6530:     
evaluating validation preformance... 950/1000 (2.973669)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:     
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:    
evaluating validation preformance... 960/1000 (2.751700)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.319561)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:      
evaluating validation preformance... 980/1000 (2.745594)
image 7352:    
image 5113:     
image 7822:    
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.451251)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.344390)
average loss on validation: 2.592
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.4046051502227783
Cider scores: 0.5705381486573077
Read data: 0.2449510097503662
Cider scores: 0.5919856380792768
Read data: 0.2747046947479248
Cider scores: 0.6751082032715301
Read data: 0.23798274993896484
Cider scores: 0.5373014354663161
Read data: 0.2286224365234375
Cider scores: 0.5651798873539973
Read data: 0.1689145565032959
Cider scores: 0.5109085145198519
Read data: 0.2066812515258789
Cider scores: 0.5585855199849199
Read data: 0.19026589393615723
Cider scores: 0.6237454338737467
Read data: 0.1690526008605957
Cider scores: 0.5082857674894332
Read data: 0.19192051887512207
Cider scores: 0.6895713906219748
Read data: 0.24160480499267578
Cider scores: 0.6242792968006178
Read data: 0.1783292293548584
Cider scores: 0.6636163523280472
Read data: 0.1760692596435547
Cider scores: 0.5401926577364901
Read data: 0.18094921112060547
Cider scores: 0.6110341936481752
Read data: 0.17885184288024902
Cider scores: 0.5197624178519523
Read data: 0.16730475425720215
Cider scores: 0.7077897332605025
Read data: 0.1635727882385254
Cider scores: 0.4597192974830176
Read data: 0.16417908668518066
Cider scores: 0.6627591874135724
Read data: 0.1630096435546875
Cider scores: 0.5648584626453493
Read data: 0.16243815422058105
Cider scores: 0.7139245661052759
Average cider score on test set: 0.595
End calculating cider score on TEST data set
===============================================
Read data: 0.16564655303955078
iter 13000 (epoch 21), train_loss = 2.644, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 13001 (epoch 21), train_loss = 2.647, time/batch = 0.019
Read data: 0.00011801719665527344
iter 13002 (epoch 21), train_loss = 2.465, time/batch = 0.025
Read data: 0.0001366138458251953
iter 13003 (epoch 21), train_loss = 2.298, time/batch = 0.023
Read data: 0.00010347366333007812
iter 13004 (epoch 21), train_loss = 3.197, time/batch = 0.038
Read data: 0.00010013580322265625
iter 13005 (epoch 21), train_loss = 2.830, time/batch = 0.042
Read data: 0.00010752677917480469
iter 13006 (epoch 21), train_loss = 3.030, time/batch = 0.036
Read data: 9.059906005859375e-05
iter 13007 (epoch 21), train_loss = 2.570, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 13008 (epoch 21), train_loss = 2.383, time/batch = 0.021
Read data: 8.392333984375e-05
iter 13009 (epoch 21), train_loss = 2.160, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 13010 (epoch 21), train_loss = 2.715, time/batch = 0.026
Read data: 0.00015234947204589844
iter 13011 (epoch 21), train_loss = 2.877, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 13012 (epoch 21), train_loss = 2.898, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 13013 (epoch 21), train_loss = 2.722, time/batch = 0.030
Read data: 8.988380432128906e-05
iter 13014 (epoch 21), train_loss = 2.609, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 13015 (epoch 21), train_loss = 2.954, time/batch = 0.031
Read data: 0.0001010894775390625
iter 13016 (epoch 21), train_loss = 2.777, time/batch = 0.026
Read data: 9.393692016601562e-05
iter 13017 (epoch 21), train_loss = 2.627, time/batch = 0.034
Read data: 0.00014448165893554688
iter 13018 (epoch 21), train_loss = 2.692, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 13019 (epoch 21), train_loss = 2.295, time/batch = 0.028
Read data: 0.0001327991485595703
iter 13020 (epoch 21), train_loss = 2.413, time/batch = 0.029
Read data: 8.845329284667969e-05
iter 13021 (epoch 21), train_loss = 2.570, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 13022 (epoch 21), train_loss = 2.497, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 13023 (epoch 21), train_loss = 2.110, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 13024 (epoch 21), train_loss = 2.814, time/batch = 0.030
Read data: 0.00024008750915527344
iter 13025 (epoch 21), train_loss = 2.719, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 13026 (epoch 21), train_loss = 2.724, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 13027 (epoch 21), train_loss = 2.744, time/batch = 0.027
Read data: 0.00010323524475097656
iter 13028 (epoch 21), train_loss = 2.479, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 13029 (epoch 21), train_loss = 1.981, time/batch = 0.027
Read data: 9.846687316894531e-05
iter 13030 (epoch 21), train_loss = 2.359, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 13031 (epoch 21), train_loss = 2.855, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 13032 (epoch 21), train_loss = 2.236, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 13033 (epoch 21), train_loss = 2.600, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 13034 (epoch 21), train_loss = 2.526, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 13035 (epoch 21), train_loss = 2.939, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 13036 (epoch 21), train_loss = 2.627, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 13037 (epoch 21), train_loss = 2.346, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 13038 (epoch 21), train_loss = 2.456, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 13039 (epoch 21), train_loss = 2.587, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 13040 (epoch 21), train_loss = 2.381, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 13041 (epoch 21), train_loss = 2.412, time/batch = 0.029
Read data: 0.0001239776611328125
iter 13042 (epoch 21), train_loss = 2.954, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 13043 (epoch 21), train_loss = 2.515, time/batch = 0.030
Read data: 0.00014638900756835938
iter 13044 (epoch 21), train_loss = 2.302, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 13045 (epoch 21), train_loss = 2.720, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 13046 (epoch 21), train_loss = 2.746, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 13047 (epoch 21), train_loss = 2.766, time/batch = 0.033
Read data: 9.703636169433594e-05
iter 13048 (epoch 21), train_loss = 2.334, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 13049 (epoch 21), train_loss = 2.434, time/batch = 0.027
Read data: 0.0002155303955078125
iter 13050 (epoch 21), train_loss = 2.637, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 13051 (epoch 21), train_loss = 2.609, time/batch = 0.038
Read data: 8.702278137207031e-05
iter 13052 (epoch 21), train_loss = 2.614, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 13053 (epoch 21), train_loss = 2.400, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 13054 (epoch 21), train_loss = 2.984, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 13055 (epoch 21), train_loss = 2.455, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 13056 (epoch 21), train_loss = 2.422, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 13057 (epoch 21), train_loss = 2.700, time/batch = 0.031
Read data: 8.7738037109375e-05
iter 13058 (epoch 21), train_loss = 2.580, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 13059 (epoch 21), train_loss = 2.483, time/batch = 0.022
Read data: 0.00014853477478027344
iter 13060 (epoch 21), train_loss = 2.622, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 13061 (epoch 21), train_loss = 2.997, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 13062 (epoch 21), train_loss = 2.534, time/batch = 0.023
Read data: 7.62939453125e-05
iter 13063 (epoch 21), train_loss = 2.070, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 13064 (epoch 21), train_loss = 2.771, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 13065 (epoch 21), train_loss = 2.567, time/batch = 0.031
Read data: 0.00010657310485839844
iter 13066 (epoch 21), train_loss = 2.230, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 13067 (epoch 21), train_loss = 2.538, time/batch = 0.027
Read data: 0.00010228157043457031
iter 13068 (epoch 21), train_loss = 2.541, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 13069 (epoch 21), train_loss = 2.005, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 13070 (epoch 21), train_loss = 2.400, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 13071 (epoch 21), train_loss = 2.633, time/batch = 0.027
Read data: 0.0001010894775390625
iter 13072 (epoch 21), train_loss = 2.068, time/batch = 0.021
Read data: 9.918212890625e-05
iter 13073 (epoch 21), train_loss = 2.251, time/batch = 0.029
Read data: 0.00013065338134765625
iter 13074 (epoch 21), train_loss = 2.119, time/batch = 0.026
Read data: 0.0002474784851074219
iter 13075 (epoch 21), train_loss = 2.733, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 13076 (epoch 21), train_loss = 2.896, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13077 (epoch 21), train_loss = 2.285, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 13078 (epoch 21), train_loss = 2.492, time/batch = 0.021
Read data: 9.512901306152344e-05
iter 13079 (epoch 21), train_loss = 2.636, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 13080 (epoch 21), train_loss = 2.535, time/batch = 0.034
Read data: 8.416175842285156e-05
iter 13081 (epoch 21), train_loss = 2.396, time/batch = 0.030
Read data: 0.00017380714416503906
iter 13082 (epoch 21), train_loss = 2.326, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 13083 (epoch 21), train_loss = 2.607, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 13084 (epoch 21), train_loss = 2.345, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 13085 (epoch 21), train_loss = 2.625, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 13086 (epoch 21), train_loss = 2.428, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 13087 (epoch 21), train_loss = 2.276, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 13088 (epoch 21), train_loss = 2.683, time/batch = 0.024
Read data: 7.724761962890625e-05
iter 13089 (epoch 21), train_loss = 2.719, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 13090 (epoch 21), train_loss = 2.330, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 13091 (epoch 21), train_loss = 2.673, time/batch = 0.036
Read data: 0.00012159347534179688
iter 13092 (epoch 21), train_loss = 2.194, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 13093 (epoch 21), train_loss = 2.475, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 13094 (epoch 21), train_loss = 2.618, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 13095 (epoch 21), train_loss = 2.554, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 13096 (epoch 21), train_loss = 2.552, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 13097 (epoch 21), train_loss = 2.583, time/batch = 0.030
Read data: 7.605552673339844e-05
iter 13098 (epoch 21), train_loss = 2.392, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 13099 (epoch 21), train_loss = 2.737, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 13100 (epoch 21), train_loss = 2.385, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 13101 (epoch 21), train_loss = 2.625, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 13102 (epoch 21), train_loss = 2.623, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 13103 (epoch 21), train_loss = 2.538, time/batch = 0.028
Read data: 9.870529174804688e-05
iter 13104 (epoch 21), train_loss = 2.479, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 13105 (epoch 21), train_loss = 2.546, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 13106 (epoch 21), train_loss = 2.333, time/batch = 0.019
Read data: 9.512901306152344e-05
iter 13107 (epoch 21), train_loss = 2.592, time/batch = 0.029
Read data: 0.00010442733764648438
iter 13108 (epoch 21), train_loss = 2.700, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 13109 (epoch 21), train_loss = 2.662, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 13110 (epoch 21), train_loss = 2.127, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 13111 (epoch 21), train_loss = 2.576, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 13112 (epoch 21), train_loss = 2.394, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 13113 (epoch 21), train_loss = 2.419, time/batch = 0.024
Read data: 0.0001361370086669922
iter 13114 (epoch 21), train_loss = 2.636, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 13115 (epoch 21), train_loss = 2.293, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 13116 (epoch 21), train_loss = 2.547, time/batch = 0.024
Read data: 8.678436279296875e-05
iter 13117 (epoch 21), train_loss = 2.532, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 13118 (epoch 21), train_loss = 2.556, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 13119 (epoch 21), train_loss = 2.742, time/batch = 0.023
Read data: 0.00015044212341308594
iter 13120 (epoch 21), train_loss = 2.527, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 13121 (epoch 21), train_loss = 2.420, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 13122 (epoch 21), train_loss = 2.478, time/batch = 0.023
Read data: 9.512901306152344e-05
iter 13123 (epoch 21), train_loss = 2.447, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 13124 (epoch 21), train_loss = 2.276, time/batch = 0.027
Read data: 0.0002319812774658203
iter 13125 (epoch 21), train_loss = 2.559, time/batch = 0.028
Read data: 9.655952453613281e-05
iter 13126 (epoch 21), train_loss = 2.518, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 13127 (epoch 21), train_loss = 2.603, time/batch = 0.029
Read data: 9.775161743164062e-05
iter 13128 (epoch 21), train_loss = 2.790, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 13129 (epoch 21), train_loss = 2.224, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 13130 (epoch 21), train_loss = 2.248, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 13131 (epoch 21), train_loss = 2.448, time/batch = 0.029
Read data: 0.00014662742614746094
iter 13132 (epoch 21), train_loss = 2.847, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 13133 (epoch 21), train_loss = 2.504, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 13134 (epoch 21), train_loss = 2.396, time/batch = 0.024
Read data: 0.00010132789611816406
iter 13135 (epoch 21), train_loss = 2.412, time/batch = 0.028
Read data: 0.00015783309936523438
iter 13136 (epoch 21), train_loss = 2.635, time/batch = 0.025
Read data: 0.00010395050048828125
iter 13137 (epoch 21), train_loss = 2.728, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 13138 (epoch 21), train_loss = 2.292, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 13139 (epoch 21), train_loss = 2.823, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 13140 (epoch 21), train_loss = 2.628, time/batch = 0.035
Read data: 7.891654968261719e-05
iter 13141 (epoch 21), train_loss = 2.190, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 13142 (epoch 21), train_loss = 2.312, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 13143 (epoch 21), train_loss = 2.555, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 13144 (epoch 21), train_loss = 2.306, time/batch = 0.023
Read data: 0.0001246929168701172
iter 13145 (epoch 21), train_loss = 2.354, time/batch = 0.028
Read data: 0.00011134147644042969
iter 13146 (epoch 21), train_loss = 2.416, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 13147 (epoch 21), train_loss = 3.017, time/batch = 0.028
Read data: 0.0001468658447265625
iter 13148 (epoch 21), train_loss = 2.783, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 13149 (epoch 21), train_loss = 2.594, time/batch = 0.026
Read data: 0.0003635883331298828
iter 13150 (epoch 21), train_loss = 2.588, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 13151 (epoch 21), train_loss = 2.400, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 13152 (epoch 21), train_loss = 2.677, time/batch = 0.023
Read data: 0.00010251998901367188
iter 13153 (epoch 21), train_loss = 2.419, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 13154 (epoch 21), train_loss = 2.739, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 13155 (epoch 21), train_loss = 2.638, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 13156 (epoch 21), train_loss = 2.128, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 13157 (epoch 21), train_loss = 2.728, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 13158 (epoch 21), train_loss = 2.945, time/batch = 0.036
Read data: 7.987022399902344e-05
iter 13159 (epoch 21), train_loss = 2.730, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 13160 (epoch 21), train_loss = 2.658, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 13161 (epoch 21), train_loss = 2.676, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 13162 (epoch 21), train_loss = 2.776, time/batch = 0.024
Read data: 0.00010752677917480469
iter 13163 (epoch 21), train_loss = 2.443, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 13164 (epoch 21), train_loss = 2.373, time/batch = 0.027
Read data: 9.822845458984375e-05
iter 13165 (epoch 21), train_loss = 2.442, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 13166 (epoch 21), train_loss = 2.649, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 13167 (epoch 21), train_loss = 2.061, time/batch = 0.030
Read data: 0.00012087821960449219
iter 13168 (epoch 21), train_loss = 2.283, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 13169 (epoch 21), train_loss = 2.357, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 13170 (epoch 21), train_loss = 2.732, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 13171 (epoch 21), train_loss = 2.260, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 13172 (epoch 21), train_loss = 2.369, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 13173 (epoch 21), train_loss = 2.519, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 13174 (epoch 21), train_loss = 2.892, time/batch = 0.025
Read data: 0.00021219253540039062
iter 13175 (epoch 21), train_loss = 2.319, time/batch = 0.025
Read data: 0.00011491775512695312
iter 13176 (epoch 21), train_loss = 2.430, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 13177 (epoch 21), train_loss = 2.691, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 13178 (epoch 21), train_loss = 2.805, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 13179 (epoch 21), train_loss = 2.543, time/batch = 0.021
Read data: 0.000118255615234375
iter 13180 (epoch 21), train_loss = 2.851, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 13181 (epoch 21), train_loss = 2.611, time/batch = 0.027
Read data: 0.00010752677917480469
iter 13182 (epoch 21), train_loss = 2.692, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 13183 (epoch 21), train_loss = 2.819, time/batch = 0.038
Read data: 8.440017700195312e-05
iter 13184 (epoch 21), train_loss = 2.857, time/batch = 0.035
Read data: 9.226799011230469e-05
iter 13185 (epoch 21), train_loss = 3.178, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 13186 (epoch 21), train_loss = 2.661, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 13187 (epoch 21), train_loss = 2.354, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 13188 (epoch 21), train_loss = 2.384, time/batch = 0.028
Read data: 0.00010776519775390625
iter 13189 (epoch 21), train_loss = 2.698, time/batch = 0.030
Read data: 0.00014138221740722656
iter 13190 (epoch 21), train_loss = 2.180, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 13191 (epoch 21), train_loss = 2.452, time/batch = 0.023
Read data: 0.0009405612945556641
iter 13192 (epoch 21), train_loss = 2.585, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 13193 (epoch 21), train_loss = 2.209, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 13194 (epoch 21), train_loss = 2.653, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 13195 (epoch 21), train_loss = 2.626, time/batch = 0.028
Read data: 0.00015115737915039062
iter 13196 (epoch 21), train_loss = 2.481, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 13197 (epoch 21), train_loss = 2.741, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 13198 (epoch 21), train_loss = 2.004, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 13199 (epoch 21), train_loss = 2.772, time/batch = 0.028
Read data: 0.0002849102020263672
iter 13200 (epoch 21), train_loss = 2.457, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 13201 (epoch 22), train_loss = 2.529, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 13202 (epoch 22), train_loss = 2.792, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 13203 (epoch 22), train_loss = 2.429, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 13204 (epoch 22), train_loss = 2.831, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 13205 (epoch 22), train_loss = 2.691, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 13206 (epoch 22), train_loss = 2.614, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 13207 (epoch 22), train_loss = 2.253, time/batch = 0.023
Read data: 0.0001430511474609375
iter 13208 (epoch 22), train_loss = 2.484, time/batch = 0.026
Read data: 9.1552734375e-05
iter 13209 (epoch 22), train_loss = 2.357, time/batch = 0.031
Read data: 9.775161743164062e-05
iter 13210 (epoch 22), train_loss = 2.502, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 13211 (epoch 22), train_loss = 2.727, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 13212 (epoch 22), train_loss = 2.153, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 13213 (epoch 22), train_loss = 2.449, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 13214 (epoch 22), train_loss = 2.671, time/batch = 0.030
Read data: 7.486343383789062e-05
iter 13215 (epoch 22), train_loss = 2.866, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 13216 (epoch 22), train_loss = 1.989, time/batch = 0.020
Read data: 9.322166442871094e-05
iter 13217 (epoch 22), train_loss = 2.573, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 13218 (epoch 22), train_loss = 2.711, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 13219 (epoch 22), train_loss = 2.389, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 13220 (epoch 22), train_loss = 2.265, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 13221 (epoch 22), train_loss = 2.556, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 13222 (epoch 22), train_loss = 2.642, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 13223 (epoch 22), train_loss = 2.571, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 13224 (epoch 22), train_loss = 2.278, time/batch = 0.025
Read data: 0.00026035308837890625
iter 13225 (epoch 22), train_loss = 2.538, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 13226 (epoch 22), train_loss = 2.515, time/batch = 0.037
Read data: 8.797645568847656e-05
iter 13227 (epoch 22), train_loss = 2.935, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 13228 (epoch 22), train_loss = 2.388, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 13229 (epoch 22), train_loss = 2.352, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 13230 (epoch 22), train_loss = 2.604, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 13231 (epoch 22), train_loss = 2.425, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 13232 (epoch 22), train_loss = 2.298, time/batch = 0.021
Read data: 0.00012230873107910156
iter 13233 (epoch 22), train_loss = 2.655, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 13234 (epoch 22), train_loss = 2.133, time/batch = 0.019
Read data: 0.00011610984802246094
iter 13235 (epoch 22), train_loss = 2.667, time/batch = 0.033
Read data: 9.036064147949219e-05
iter 13236 (epoch 22), train_loss = 2.444, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 13237 (epoch 22), train_loss = 2.457, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 13238 (epoch 22), train_loss = 2.461, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 13239 (epoch 22), train_loss = 2.831, time/batch = 0.027
Read data: 0.00010514259338378906
iter 13240 (epoch 22), train_loss = 1.944, time/batch = 0.019
Read data: 0.000102996826171875
iter 13241 (epoch 22), train_loss = 2.786, time/batch = 0.033
Read data: 8.416175842285156e-05
iter 13242 (epoch 22), train_loss = 2.380, time/batch = 0.030
Read data: 7.796287536621094e-05
iter 13243 (epoch 22), train_loss = 2.321, time/batch = 0.023
Read data: 0.00012254714965820312
iter 13244 (epoch 22), train_loss = 2.464, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 13245 (epoch 22), train_loss = 2.675, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 13246 (epoch 22), train_loss = 2.350, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 13247 (epoch 22), train_loss = 3.058, time/batch = 0.023
Read data: 0.00011730194091796875
iter 13248 (epoch 22), train_loss = 2.297, time/batch = 0.020
Read data: 9.274482727050781e-05
iter 13249 (epoch 22), train_loss = 2.055, time/batch = 0.025
Read data: 0.00023293495178222656
iter 13250 (epoch 22), train_loss = 2.305, time/batch = 0.032
Read data: 9.512901306152344e-05
iter 13251 (epoch 22), train_loss = 2.598, time/batch = 0.028
Read data: 0.00011682510375976562
iter 13252 (epoch 22), train_loss = 2.552, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 13253 (epoch 22), train_loss = 2.641, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 13254 (epoch 22), train_loss = 3.135, time/batch = 0.037
Read data: 8.797645568847656e-05
iter 13255 (epoch 22), train_loss = 2.366, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 13256 (epoch 22), train_loss = 2.628, time/batch = 0.028
Read data: 0.0001399517059326172
iter 13257 (epoch 22), train_loss = 2.447, time/batch = 0.027
Read data: 0.00013399124145507812
iter 13258 (epoch 22), train_loss = 2.729, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 13259 (epoch 22), train_loss = 2.387, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 13260 (epoch 22), train_loss = 2.604, time/batch = 0.024
Read data: 0.0001232624053955078
iter 13261 (epoch 22), train_loss = 2.610, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 13262 (epoch 22), train_loss = 2.243, time/batch = 0.024
Read data: 0.0001201629638671875
iter 13263 (epoch 22), train_loss = 2.175, time/batch = 0.031
Read data: 7.843971252441406e-05
iter 13264 (epoch 22), train_loss = 2.372, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 13265 (epoch 22), train_loss = 2.335, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 13266 (epoch 22), train_loss = 2.670, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 13267 (epoch 22), train_loss = 2.415, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 13268 (epoch 22), train_loss = 2.918, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 13269 (epoch 22), train_loss = 2.592, time/batch = 0.022
Read data: 9.369850158691406e-05
iter 13270 (epoch 22), train_loss = 2.285, time/batch = 0.025
Read data: 0.0001201629638671875
iter 13271 (epoch 22), train_loss = 2.368, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 13272 (epoch 22), train_loss = 2.423, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 13273 (epoch 22), train_loss = 2.600, time/batch = 0.028
Read data: 0.00010848045349121094
iter 13274 (epoch 22), train_loss = 2.217, time/batch = 0.024
Read data: 0.00021719932556152344
iter 13275 (epoch 22), train_loss = 2.420, time/batch = 0.030
Read data: 0.00011014938354492188
iter 13276 (epoch 22), train_loss = 2.523, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 13277 (epoch 22), train_loss = 2.659, time/batch = 0.018
Read data: 8.893013000488281e-05
iter 13278 (epoch 22), train_loss = 2.114, time/batch = 0.027
Read data: 0.00011682510375976562
iter 13279 (epoch 22), train_loss = 2.287, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 13280 (epoch 22), train_loss = 2.462, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 13281 (epoch 22), train_loss = 2.720, time/batch = 0.027
Read data: 0.00010132789611816406
iter 13282 (epoch 22), train_loss = 2.631, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 13283 (epoch 22), train_loss = 2.659, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 13284 (epoch 22), train_loss = 2.705, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 13285 (epoch 22), train_loss = 2.534, time/batch = 0.035
Read data: 7.987022399902344e-05
iter 13286 (epoch 22), train_loss = 2.314, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 13287 (epoch 22), train_loss = 2.371, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 13288 (epoch 22), train_loss = 2.119, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 13289 (epoch 22), train_loss = 2.708, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 13290 (epoch 22), train_loss = 2.541, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 13291 (epoch 22), train_loss = 2.407, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 13292 (epoch 22), train_loss = 2.254, time/batch = 0.022
Read data: 0.00012183189392089844
iter 13293 (epoch 22), train_loss = 2.294, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 13294 (epoch 22), train_loss = 2.291, time/batch = 0.022
Read data: 0.00012421607971191406
iter 13295 (epoch 22), train_loss = 2.247, time/batch = 0.030
Read data: 9.322166442871094e-05
iter 13296 (epoch 22), train_loss = 2.637, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 13297 (epoch 22), train_loss = 2.565, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 13298 (epoch 22), train_loss = 2.019, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 13299 (epoch 22), train_loss = 2.859, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 13300 (epoch 22), train_loss = 2.789, time/batch = 0.034
Read data: 0.0001304149627685547
iter 13301 (epoch 22), train_loss = 2.500, time/batch = 0.024
Read data: 0.0001285076141357422
iter 13302 (epoch 22), train_loss = 2.336, time/batch = 0.028
Read data: 0.00011801719665527344
iter 13303 (epoch 22), train_loss = 2.348, time/batch = 0.028
Read data: 8.392333984375e-05
iter 13304 (epoch 22), train_loss = 2.449, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 13305 (epoch 22), train_loss = 2.212, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 13306 (epoch 22), train_loss = 2.321, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 13307 (epoch 22), train_loss = 2.421, time/batch = 0.026
Read data: 0.0001659393310546875
iter 13308 (epoch 22), train_loss = 2.790, time/batch = 0.041
Read data: 8.940696716308594e-05
iter 13309 (epoch 22), train_loss = 2.419, time/batch = 0.025
Read data: 0.00011754035949707031
iter 13310 (epoch 22), train_loss = 2.585, time/batch = 0.024
Read data: 0.00012540817260742188
iter 13311 (epoch 22), train_loss = 2.531, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 13312 (epoch 22), train_loss = 2.764, time/batch = 0.028
Read data: 0.00012493133544921875
iter 13313 (epoch 22), train_loss = 2.252, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 13314 (epoch 22), train_loss = 2.432, time/batch = 0.034
Read data: 8.654594421386719e-05
iter 13315 (epoch 22), train_loss = 2.023, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 13316 (epoch 22), train_loss = 2.607, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 13317 (epoch 22), train_loss = 2.350, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 13318 (epoch 22), train_loss = 2.391, time/batch = 0.028
Read data: 9.512901306152344e-05
iter 13319 (epoch 22), train_loss = 2.283, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 13320 (epoch 22), train_loss = 2.713, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 13321 (epoch 22), train_loss = 2.223, time/batch = 0.028
Read data: 9.34600830078125e-05
iter 13322 (epoch 22), train_loss = 2.117, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 13323 (epoch 22), train_loss = 2.540, time/batch = 0.024
Read data: 0.0001571178436279297
iter 13324 (epoch 22), train_loss = 2.506, time/batch = 0.036
Read data: 8.630752563476562e-05
iter 13325 (epoch 22), train_loss = 2.188, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 13326 (epoch 22), train_loss = 2.563, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 13327 (epoch 22), train_loss = 2.407, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 13328 (epoch 22), train_loss = 2.468, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 13329 (epoch 22), train_loss = 2.288, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 13330 (epoch 22), train_loss = 2.568, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 13331 (epoch 22), train_loss = 2.096, time/batch = 0.022
Read data: 9.560585021972656e-05
iter 13332 (epoch 22), train_loss = 2.532, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 13333 (epoch 22), train_loss = 2.303, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 13334 (epoch 22), train_loss = 2.264, time/batch = 0.036
Read data: 8.249282836914062e-05
iter 13335 (epoch 22), train_loss = 2.395, time/batch = 0.028
Read data: 0.00013446807861328125
iter 13336 (epoch 22), train_loss = 2.013, time/batch = 0.030
Read data: 0.0001418590545654297
iter 13337 (epoch 22), train_loss = 2.635, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 13338 (epoch 22), train_loss = 2.670, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 13339 (epoch 22), train_loss = 2.472, time/batch = 0.034
Read data: 0.00013375282287597656
iter 13340 (epoch 22), train_loss = 2.361, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 13341 (epoch 22), train_loss = 2.380, time/batch = 0.034
Read data: 0.00012040138244628906
iter 13342 (epoch 22), train_loss = 2.421, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 13343 (epoch 22), train_loss = 2.624, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 13344 (epoch 22), train_loss = 2.959, time/batch = 0.032
Read data: 9.012222290039062e-05
iter 13345 (epoch 22), train_loss = 2.266, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 13346 (epoch 22), train_loss = 2.622, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 13347 (epoch 22), train_loss = 2.831, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 13348 (epoch 22), train_loss = 2.360, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 13349 (epoch 22), train_loss = 2.348, time/batch = 0.026
Read data: 0.0001652240753173828
iter 13350 (epoch 22), train_loss = 2.501, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 13351 (epoch 22), train_loss = 2.319, time/batch = 0.030
Read data: 0.000148773193359375
iter 13352 (epoch 22), train_loss = 2.851, time/batch = 0.041
Read data: 0.0001323223114013672
iter 13353 (epoch 22), train_loss = 2.668, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 13354 (epoch 22), train_loss = 2.334, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 13355 (epoch 22), train_loss = 2.743, time/batch = 0.026
Read data: 0.0001373291015625
iter 13356 (epoch 22), train_loss = 2.121, time/batch = 0.028
Read data: 0.00013327598571777344
iter 13357 (epoch 22), train_loss = 3.066, time/batch = 0.035
Read data: 0.00013828277587890625
iter 13358 (epoch 22), train_loss = 2.556, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 13359 (epoch 22), train_loss = 2.481, time/batch = 0.025
Read data: 0.0001442432403564453
iter 13360 (epoch 22), train_loss = 2.357, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 13361 (epoch 22), train_loss = 2.736, time/batch = 0.032
Read data: 0.0001704692840576172
iter 13362 (epoch 22), train_loss = 2.753, time/batch = 0.031
Read data: 0.00012111663818359375
iter 13363 (epoch 22), train_loss = 2.601, time/batch = 0.028
Read data: 9.608268737792969e-05
iter 13364 (epoch 22), train_loss = 2.147, time/batch = 0.029
Read data: 8.7738037109375e-05
iter 13365 (epoch 22), train_loss = 2.377, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 13366 (epoch 22), train_loss = 2.635, time/batch = 0.034
Read data: 8.845329284667969e-05
iter 13367 (epoch 22), train_loss = 2.571, time/batch = 0.022
Read data: 8.273124694824219e-05
iter 13368 (epoch 22), train_loss = 2.171, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 13369 (epoch 22), train_loss = 2.430, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 13370 (epoch 22), train_loss = 2.250, time/batch = 0.028
Read data: 0.00010275840759277344
iter 13371 (epoch 22), train_loss = 2.645, time/batch = 0.027
Read data: 9.72747802734375e-05
iter 13372 (epoch 22), train_loss = 2.695, time/batch = 0.026
Read data: 0.00012683868408203125
iter 13373 (epoch 22), train_loss = 2.308, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 13374 (epoch 22), train_loss = 2.802, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 13375 (epoch 22), train_loss = 2.731, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 13376 (epoch 22), train_loss = 2.881, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 13377 (epoch 22), train_loss = 2.643, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 13378 (epoch 22), train_loss = 2.141, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 13379 (epoch 22), train_loss = 2.268, time/batch = 0.028
Read data: 0.0001475811004638672
iter 13380 (epoch 22), train_loss = 2.563, time/batch = 0.037
Read data: 0.00013113021850585938
iter 13381 (epoch 22), train_loss = 2.554, time/batch = 0.030
Read data: 8.797645568847656e-05
iter 13382 (epoch 22), train_loss = 2.347, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 13383 (epoch 22), train_loss = 2.370, time/batch = 0.021
Read data: 0.00012159347534179688
iter 13384 (epoch 22), train_loss = 2.926, time/batch = 0.026
Read data: 0.00011515617370605469
iter 13385 (epoch 22), train_loss = 2.789, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 13386 (epoch 22), train_loss = 2.545, time/batch = 0.027
Read data: 9.5367431640625e-05
iter 13387 (epoch 22), train_loss = 2.467, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 13388 (epoch 22), train_loss = 2.683, time/batch = 0.030
Read data: 0.0001277923583984375
iter 13389 (epoch 22), train_loss = 2.825, time/batch = 0.043
Read data: 8.821487426757812e-05
iter 13390 (epoch 22), train_loss = 2.101, time/batch = 0.034
Read data: 0.00010657310485839844
iter 13391 (epoch 22), train_loss = 2.176, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 13392 (epoch 22), train_loss = 2.411, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 13393 (epoch 22), train_loss = 2.579, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 13394 (epoch 22), train_loss = 2.711, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 13395 (epoch 22), train_loss = 2.363, time/batch = 0.037
Read data: 9.703636169433594e-05
iter 13396 (epoch 22), train_loss = 2.664, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 13397 (epoch 22), train_loss = 2.498, time/batch = 0.028
Read data: 9.274482727050781e-05
iter 13398 (epoch 22), train_loss = 2.394, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 13399 (epoch 22), train_loss = 2.243, time/batch = 0.028
Read data: 0.00011444091796875
iter 13400 (epoch 22), train_loss = 2.623, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 13401 (epoch 22), train_loss = 2.374, time/batch = 0.031
Read data: 9.179115295410156e-05
iter 13402 (epoch 22), train_loss = 2.184, time/batch = 0.032
Read data: 9.012222290039062e-05
iter 13403 (epoch 22), train_loss = 2.750, time/batch = 0.028
Read data: 0.0001323223114013672
iter 13404 (epoch 22), train_loss = 2.453, time/batch = 0.032
Read data: 0.0001327991485595703
iter 13405 (epoch 22), train_loss = 2.261, time/batch = 0.031
Read data: 0.0001735687255859375
iter 13406 (epoch 22), train_loss = 2.259, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 13407 (epoch 22), train_loss = 2.142, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 13408 (epoch 22), train_loss = 2.434, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 13409 (epoch 22), train_loss = 2.874, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 13410 (epoch 22), train_loss = 2.448, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 13411 (epoch 22), train_loss = 2.584, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 13412 (epoch 22), train_loss = 2.702, time/batch = 0.033
Read data: 0.00012540817260742188
iter 13413 (epoch 22), train_loss = 2.365, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 13414 (epoch 22), train_loss = 2.754, time/batch = 0.034
Read data: 8.368492126464844e-05
iter 13415 (epoch 22), train_loss = 2.644, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 13416 (epoch 22), train_loss = 2.705, time/batch = 0.030
Read data: 0.0001373291015625
iter 13417 (epoch 22), train_loss = 2.326, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 13418 (epoch 22), train_loss = 2.822, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 13419 (epoch 22), train_loss = 2.111, time/batch = 0.024
Read data: 0.00013446807861328125
iter 13420 (epoch 22), train_loss = 2.136, time/batch = 0.030
Read data: 8.702278137207031e-05
iter 13421 (epoch 22), train_loss = 2.496, time/batch = 0.025
Read data: 7.62939453125e-05
iter 13422 (epoch 22), train_loss = 2.430, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 13423 (epoch 22), train_loss = 2.677, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 13424 (epoch 22), train_loss = 2.693, time/batch = 0.030
Read data: 0.0001952648162841797
iter 13425 (epoch 22), train_loss = 2.738, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 13426 (epoch 22), train_loss = 2.559, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 13427 (epoch 22), train_loss = 2.553, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 13428 (epoch 22), train_loss = 2.788, time/batch = 0.028
Read data: 0.00012111663818359375
iter 13429 (epoch 22), train_loss = 2.565, time/batch = 0.028
Read data: 0.0001125335693359375
iter 13430 (epoch 22), train_loss = 2.770, time/batch = 0.029
Read data: 8.916854858398438e-05
iter 13431 (epoch 22), train_loss = 2.492, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 13432 (epoch 22), train_loss = 2.421, time/batch = 0.030
Read data: 0.0001239776611328125
iter 13433 (epoch 22), train_loss = 2.554, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13434 (epoch 22), train_loss = 2.299, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 13435 (epoch 22), train_loss = 2.136, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 13436 (epoch 22), train_loss = 2.273, time/batch = 0.025
Read data: 0.00010418891906738281
iter 13437 (epoch 22), train_loss = 2.076, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 13438 (epoch 22), train_loss = 2.105, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 13439 (epoch 22), train_loss = 2.797, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 13440 (epoch 22), train_loss = 2.981, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 13441 (epoch 22), train_loss = 2.832, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 13442 (epoch 22), train_loss = 2.920, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 13443 (epoch 22), train_loss = 2.051, time/batch = 0.026
Read data: 0.00010037422180175781
iter 13444 (epoch 22), train_loss = 2.465, time/batch = 0.024
Read data: 8.392333984375e-05
iter 13445 (epoch 22), train_loss = 2.436, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 13446 (epoch 22), train_loss = 2.911, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 13447 (epoch 22), train_loss = 2.455, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 13448 (epoch 22), train_loss = 2.888, time/batch = 0.031
Read data: 0.00012755393981933594
iter 13449 (epoch 22), train_loss = 2.652, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 13450 (epoch 22), train_loss = 2.809, time/batch = 0.020
Read data: 9.179115295410156e-05
iter 13451 (epoch 22), train_loss = 2.491, time/batch = 0.030
Read data: 0.0001068115234375
iter 13452 (epoch 22), train_loss = 2.655, time/batch = 0.035
Read data: 0.00012087821960449219
iter 13453 (epoch 22), train_loss = 2.568, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 13454 (epoch 22), train_loss = 2.453, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 13455 (epoch 22), train_loss = 2.869, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13456 (epoch 22), train_loss = 2.538, time/batch = 0.023
Read data: 9.1552734375e-05
iter 13457 (epoch 22), train_loss = 2.813, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 13458 (epoch 22), train_loss = 2.064, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 13459 (epoch 22), train_loss = 2.393, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 13460 (epoch 22), train_loss = 2.268, time/batch = 0.027
Read data: 0.0001475811004638672
iter 13461 (epoch 22), train_loss = 2.571, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 13462 (epoch 22), train_loss = 2.412, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 13463 (epoch 22), train_loss = 2.419, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 13464 (epoch 22), train_loss = 2.595, time/batch = 0.025
Read data: 0.000148773193359375
iter 13465 (epoch 22), train_loss = 2.777, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 13466 (epoch 22), train_loss = 1.992, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 13467 (epoch 22), train_loss = 2.658, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 13468 (epoch 22), train_loss = 2.662, time/batch = 0.025
Read data: 0.00015044212341308594
iter 13469 (epoch 22), train_loss = 2.807, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 13470 (epoch 22), train_loss = 2.606, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 13471 (epoch 22), train_loss = 2.162, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 13472 (epoch 22), train_loss = 2.402, time/batch = 0.023
Read data: 0.00011730194091796875
iter 13473 (epoch 22), train_loss = 2.634, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 13474 (epoch 22), train_loss = 2.500, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 13475 (epoch 22), train_loss = 2.663, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 13476 (epoch 22), train_loss = 2.596, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 13477 (epoch 22), train_loss = 2.337, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 13478 (epoch 22), train_loss = 2.308, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 13479 (epoch 22), train_loss = 2.474, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 13480 (epoch 22), train_loss = 2.466, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 13481 (epoch 22), train_loss = 2.539, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 13482 (epoch 22), train_loss = 2.444, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 13483 (epoch 22), train_loss = 2.530, time/batch = 0.027
Read data: 0.00014209747314453125
iter 13484 (epoch 22), train_loss = 2.658, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 13485 (epoch 22), train_loss = 2.925, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 13486 (epoch 22), train_loss = 2.532, time/batch = 0.025
Read data: 0.00010466575622558594
iter 13487 (epoch 22), train_loss = 2.065, time/batch = 0.026
Read data: 0.0001220703125
iter 13488 (epoch 22), train_loss = 2.523, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 13489 (epoch 22), train_loss = 2.409, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 13490 (epoch 22), train_loss = 2.805, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 13491 (epoch 22), train_loss = 2.485, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 13492 (epoch 22), train_loss = 2.420, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 13493 (epoch 22), train_loss = 2.828, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 13494 (epoch 22), train_loss = 2.502, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 13495 (epoch 22), train_loss = 2.783, time/batch = 0.027
Read data: 0.0001556873321533203
iter 13496 (epoch 22), train_loss = 2.218, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 13497 (epoch 22), train_loss = 2.486, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 13498 (epoch 22), train_loss = 2.197, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 13499 (epoch 22), train_loss = 2.214, time/batch = 0.025
Read data: 0.0001678466796875
iter 13500 (epoch 22), train_loss = 2.502, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 13501 (epoch 22), train_loss = 2.709, time/batch = 0.028
Read data: 9.1552734375e-05
iter 13502 (epoch 22), train_loss = 2.579, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 13503 (epoch 22), train_loss = 2.929, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 13504 (epoch 22), train_loss = 3.002, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 13505 (epoch 22), train_loss = 2.788, time/batch = 0.033
Read data: 0.00010919570922851562
iter 13506 (epoch 22), train_loss = 2.523, time/batch = 0.030
Read data: 8.678436279296875e-05
iter 13507 (epoch 22), train_loss = 2.543, time/batch = 0.026
Read data: 0.00013756752014160156
iter 13508 (epoch 22), train_loss = 2.797, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 13509 (epoch 22), train_loss = 2.663, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 13510 (epoch 22), train_loss = 3.118, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 13511 (epoch 22), train_loss = 2.261, time/batch = 0.027
Read data: 0.00015926361083984375
iter 13512 (epoch 22), train_loss = 2.433, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 13513 (epoch 22), train_loss = 2.509, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 13514 (epoch 22), train_loss = 2.647, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 13515 (epoch 22), train_loss = 2.544, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 13516 (epoch 22), train_loss = 3.095, time/batch = 0.036
Read data: 8.559226989746094e-05
iter 13517 (epoch 22), train_loss = 2.693, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 13518 (epoch 22), train_loss = 2.628, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 13519 (epoch 22), train_loss = 2.158, time/batch = 0.029
Read data: 8.654594421386719e-05
iter 13520 (epoch 22), train_loss = 2.486, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 13521 (epoch 22), train_loss = 2.252, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 13522 (epoch 22), train_loss = 2.652, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 13523 (epoch 22), train_loss = 2.379, time/batch = 0.023
Read data: 0.00011444091796875
iter 13524 (epoch 22), train_loss = 2.053, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 13525 (epoch 22), train_loss = 2.413, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 13526 (epoch 22), train_loss = 2.815, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 13527 (epoch 22), train_loss = 2.601, time/batch = 0.034
Read data: 8.630752563476562e-05
iter 13528 (epoch 22), train_loss = 3.016, time/batch = 0.036
Read data: 8.869171142578125e-05
iter 13529 (epoch 22), train_loss = 2.162, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 13530 (epoch 22), train_loss = 2.356, time/batch = 0.027
Read data: 0.00014328956604003906
iter 13531 (epoch 22), train_loss = 2.085, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 13532 (epoch 22), train_loss = 2.541, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 13533 (epoch 22), train_loss = 2.480, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 13534 (epoch 22), train_loss = 2.577, time/batch = 0.026
Read data: 9.584426879882812e-05
iter 13535 (epoch 22), train_loss = 2.698, time/batch = 0.031
Read data: 0.00012946128845214844
iter 13536 (epoch 22), train_loss = 2.231, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 13537 (epoch 22), train_loss = 2.809, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 13538 (epoch 22), train_loss = 2.583, time/batch = 0.021
Read data: 8.58306884765625e-05
iter 13539 (epoch 22), train_loss = 2.470, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 13540 (epoch 22), train_loss = 1.991, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 13541 (epoch 22), train_loss = 2.870, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 13542 (epoch 22), train_loss = 2.214, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 13543 (epoch 22), train_loss = 2.737, time/batch = 0.032
Read data: 0.00015735626220703125
iter 13544 (epoch 22), train_loss = 2.514, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 13545 (epoch 22), train_loss = 2.521, time/batch = 0.021
Read data: 9.298324584960938e-05
iter 13546 (epoch 22), train_loss = 2.557, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 13547 (epoch 22), train_loss = 2.470, time/batch = 0.030
Read data: 0.00016498565673828125
iter 13548 (epoch 22), train_loss = 2.768, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 13549 (epoch 22), train_loss = 2.293, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 13550 (epoch 22), train_loss = 2.245, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 13551 (epoch 22), train_loss = 2.688, time/batch = 0.030
Read data: 0.00013399124145507812
iter 13552 (epoch 22), train_loss = 2.595, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 13553 (epoch 22), train_loss = 2.647, time/batch = 0.030
Read data: 0.00011444091796875
iter 13554 (epoch 22), train_loss = 1.977, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 13555 (epoch 22), train_loss = 2.472, time/batch = 0.020
Read data: 9.560585021972656e-05
iter 13556 (epoch 22), train_loss = 2.502, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 13557 (epoch 22), train_loss = 2.360, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 13558 (epoch 22), train_loss = 2.442, time/batch = 0.025
Read data: 0.0001595020294189453
iter 13559 (epoch 22), train_loss = 2.741, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 13560 (epoch 22), train_loss = 2.431, time/batch = 0.027
Read data: 0.00013017654418945312
iter 13561 (epoch 22), train_loss = 2.278, time/batch = 0.026
Read data: 0.00012826919555664062
iter 13562 (epoch 22), train_loss = 2.642, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 13563 (epoch 22), train_loss = 2.590, time/batch = 0.029
Read data: 0.0016918182373046875
iter 13564 (epoch 22), train_loss = 2.628, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 13565 (epoch 22), train_loss = 2.414, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 13566 (epoch 22), train_loss = 2.222, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 13567 (epoch 22), train_loss = 2.611, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 13568 (epoch 22), train_loss = 2.718, time/batch = 0.023
Read data: 7.605552673339844e-05
iter 13569 (epoch 22), train_loss = 2.394, time/batch = 0.024
Read data: 0.00011515617370605469
iter 13570 (epoch 22), train_loss = 2.451, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 13571 (epoch 22), train_loss = 2.208, time/batch = 0.032
Read data: 0.00013756752014160156
iter 13572 (epoch 22), train_loss = 2.438, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 13573 (epoch 22), train_loss = 2.570, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13574 (epoch 22), train_loss = 2.629, time/batch = 0.029
Read data: 0.000125885009765625
iter 13575 (epoch 22), train_loss = 2.641, time/batch = 0.033
Read data: 0.00013446807861328125
iter 13576 (epoch 22), train_loss = 2.588, time/batch = 0.021
Read data: 8.177757263183594e-05
iter 13577 (epoch 22), train_loss = 2.925, time/batch = 0.025
Read data: 0.00012612342834472656
iter 13578 (epoch 22), train_loss = 2.719, time/batch = 0.021
Read data: 8.988380432128906e-05
iter 13579 (epoch 22), train_loss = 3.002, time/batch = 0.040
Read data: 8.082389831542969e-05
iter 13580 (epoch 22), train_loss = 2.493, time/batch = 0.032
Read data: 9.012222290039062e-05
iter 13581 (epoch 22), train_loss = 2.041, time/batch = 0.027
Read data: 0.0001347064971923828
iter 13582 (epoch 22), train_loss = 2.514, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 13583 (epoch 22), train_loss = 2.365, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 13584 (epoch 22), train_loss = 2.182, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 13585 (epoch 22), train_loss = 2.709, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 13586 (epoch 22), train_loss = 2.366, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 13587 (epoch 22), train_loss = 1.889, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 13588 (epoch 22), train_loss = 2.669, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 13589 (epoch 22), train_loss = 2.468, time/batch = 0.028
Read data: 9.655952453613281e-05
iter 13590 (epoch 22), train_loss = 2.714, time/batch = 0.035
Read data: 8.654594421386719e-05
iter 13591 (epoch 22), train_loss = 2.572, time/batch = 0.032
Read data: 0.0001914501190185547
iter 13592 (epoch 22), train_loss = 2.728, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 13593 (epoch 22), train_loss = 2.967, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 13594 (epoch 22), train_loss = 2.490, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 13595 (epoch 22), train_loss = 2.834, time/batch = 0.035
Read data: 0.0001327991485595703
iter 13596 (epoch 22), train_loss = 2.667, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 13597 (epoch 22), train_loss = 2.528, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 13598 (epoch 22), train_loss = 2.704, time/batch = 0.035
Read data: 7.987022399902344e-05
iter 13599 (epoch 22), train_loss = 2.454, time/batch = 0.025
Read data: 0.00012922286987304688
iter 13600 (epoch 22), train_loss = 2.528, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 13601 (epoch 22), train_loss = 2.995, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 13602 (epoch 22), train_loss = 2.389, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 13603 (epoch 22), train_loss = 2.715, time/batch = 0.029
Read data: 0.00013756752014160156
iter 13604 (epoch 22), train_loss = 2.691, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 13605 (epoch 22), train_loss = 2.918, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 13606 (epoch 22), train_loss = 2.563, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 13607 (epoch 22), train_loss = 2.231, time/batch = 0.024
Read data: 0.00013136863708496094
iter 13608 (epoch 22), train_loss = 2.536, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 13609 (epoch 22), train_loss = 2.732, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 13610 (epoch 22), train_loss = 2.362, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 13611 (epoch 22), train_loss = 2.053, time/batch = 0.024
Read data: 0.0001628398895263672
iter 13612 (epoch 22), train_loss = 2.833, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 13613 (epoch 22), train_loss = 2.592, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 13614 (epoch 22), train_loss = 2.798, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 13615 (epoch 22), train_loss = 2.626, time/batch = 0.027
Read data: 0.0001666545867919922
iter 13616 (epoch 22), train_loss = 2.583, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 13617 (epoch 22), train_loss = 2.182, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 13618 (epoch 22), train_loss = 2.569, time/batch = 0.029
Read data: 9.489059448242188e-05
iter 13619 (epoch 22), train_loss = 2.410, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 13620 (epoch 22), train_loss = 2.618, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 13621 (epoch 22), train_loss = 2.673, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 13622 (epoch 22), train_loss = 2.330, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 13623 (epoch 22), train_loss = 2.225, time/batch = 0.022
Read data: 0.0001392364501953125
iter 13624 (epoch 22), train_loss = 2.726, time/batch = 0.024
Read data: 0.00010323524475097656
iter 13625 (epoch 22), train_loss = 2.707, time/batch = 0.027
Read data: 9.942054748535156e-05
iter 13626 (epoch 22), train_loss = 2.942, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 13627 (epoch 22), train_loss = 2.711, time/batch = 0.029
Read data: 9.965896606445312e-05
iter 13628 (epoch 22), train_loss = 2.420, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 13629 (epoch 22), train_loss = 2.598, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 13630 (epoch 22), train_loss = 2.861, time/batch = 0.026
Read data: 0.0001430511474609375
iter 13631 (epoch 22), train_loss = 2.562, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 13632 (epoch 22), train_loss = 2.553, time/batch = 0.032
Read data: 0.00011706352233886719
iter 13633 (epoch 22), train_loss = 2.236, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 13634 (epoch 22), train_loss = 2.494, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 13635 (epoch 22), train_loss = 2.549, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 13636 (epoch 22), train_loss = 2.381, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 13637 (epoch 22), train_loss = 2.353, time/batch = 0.025
Read data: 0.00010061264038085938
iter 13638 (epoch 22), train_loss = 2.641, time/batch = 0.025
Read data: 0.00010538101196289062
iter 13639 (epoch 22), train_loss = 2.696, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 13640 (epoch 22), train_loss = 2.619, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 13641 (epoch 22), train_loss = 2.116, time/batch = 0.021
Read data: 9.274482727050781e-05
iter 13642 (epoch 22), train_loss = 2.592, time/batch = 0.029
Read data: 9.608268737792969e-05
iter 13643 (epoch 22), train_loss = 2.554, time/batch = 0.026
Read data: 0.0016551017761230469
iter 13644 (epoch 22), train_loss = 2.732, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 13645 (epoch 22), train_loss = 2.616, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 13646 (epoch 22), train_loss = 1.940, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 13647 (epoch 22), train_loss = 2.771, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 13648 (epoch 22), train_loss = 2.475, time/batch = 0.025
Read data: 9.1552734375e-05
iter 13649 (epoch 22), train_loss = 2.507, time/batch = 0.030
Read data: 0.00016355514526367188
iter 13650 (epoch 22), train_loss = 2.606, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 13651 (epoch 22), train_loss = 2.496, time/batch = 0.033
Read data: 8.96453857421875e-05
iter 13652 (epoch 22), train_loss = 2.801, time/batch = 0.029
Read data: 9.036064147949219e-05
iter 13653 (epoch 22), train_loss = 2.526, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 13654 (epoch 22), train_loss = 2.232, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 13655 (epoch 22), train_loss = 2.497, time/batch = 0.028
Read data: 0.0001595020294189453
iter 13656 (epoch 22), train_loss = 2.980, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 13657 (epoch 22), train_loss = 2.370, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 13658 (epoch 22), train_loss = 1.916, time/batch = 0.023
Read data: 0.00010085105895996094
iter 13659 (epoch 22), train_loss = 2.511, time/batch = 0.021
Read data: 8.845329284667969e-05
iter 13660 (epoch 22), train_loss = 2.539, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 13661 (epoch 22), train_loss = 2.765, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 13662 (epoch 22), train_loss = 2.517, time/batch = 0.023
Read data: 8.440017700195312e-05
iter 13663 (epoch 22), train_loss = 2.322, time/batch = 0.029
Read data: 0.0001571178436279297
iter 13664 (epoch 22), train_loss = 2.618, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 13665 (epoch 22), train_loss = 2.601, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 13666 (epoch 22), train_loss = 2.752, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 13667 (epoch 22), train_loss = 2.454, time/batch = 0.025
Read data: 0.00020599365234375
iter 13668 (epoch 22), train_loss = 2.679, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13669 (epoch 22), train_loss = 2.407, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 13670 (epoch 22), train_loss = 2.315, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 13671 (epoch 22), train_loss = 2.999, time/batch = 0.032
Read data: 0.0001239776611328125
iter 13672 (epoch 22), train_loss = 2.529, time/batch = 0.021
Read data: 8.034706115722656e-05
iter 13673 (epoch 22), train_loss = 2.247, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 13674 (epoch 22), train_loss = 2.529, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 13675 (epoch 22), train_loss = 2.786, time/batch = 0.023
Read data: 0.00010156631469726562
iter 13676 (epoch 22), train_loss = 2.640, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 13677 (epoch 22), train_loss = 2.713, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 13678 (epoch 22), train_loss = 2.261, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 13679 (epoch 22), train_loss = 2.790, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 13680 (epoch 22), train_loss = 2.608, time/batch = 0.029
Read data: 0.00010013580322265625
iter 13681 (epoch 22), train_loss = 2.399, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 13682 (epoch 22), train_loss = 2.640, time/batch = 0.024
Read data: 0.00010013580322265625
iter 13683 (epoch 22), train_loss = 2.676, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 13684 (epoch 22), train_loss = 2.354, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 13685 (epoch 22), train_loss = 2.138, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13686 (epoch 22), train_loss = 2.620, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 13687 (epoch 22), train_loss = 2.720, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 13688 (epoch 22), train_loss = 2.410, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 13689 (epoch 22), train_loss = 2.544, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 13690 (epoch 22), train_loss = 3.016, time/batch = 0.036
Read data: 8.177757263183594e-05
iter 13691 (epoch 22), train_loss = 2.522, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13692 (epoch 22), train_loss = 2.128, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 13693 (epoch 22), train_loss = 2.938, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 13694 (epoch 22), train_loss = 2.465, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 13695 (epoch 22), train_loss = 2.512, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 13696 (epoch 22), train_loss = 2.390, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 13697 (epoch 22), train_loss = 2.812, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 13698 (epoch 22), train_loss = 2.592, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 13699 (epoch 22), train_loss = 2.016, time/batch = 0.034
Read data: 7.867813110351562e-05
iter 13700 (epoch 22), train_loss = 2.531, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 13701 (epoch 22), train_loss = 2.183, time/batch = 0.021
Read data: 7.700920104980469e-05
iter 13702 (epoch 22), train_loss = 2.508, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 13703 (epoch 22), train_loss = 2.320, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 13704 (epoch 22), train_loss = 2.300, time/batch = 0.031
Read data: 8.702278137207031e-05
iter 13705 (epoch 22), train_loss = 2.517, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 13706 (epoch 22), train_loss = 2.763, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 13707 (epoch 22), train_loss = 2.908, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 13708 (epoch 22), train_loss = 2.698, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 13709 (epoch 22), train_loss = 2.539, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 13710 (epoch 22), train_loss = 2.907, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13711 (epoch 22), train_loss = 2.095, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 13712 (epoch 22), train_loss = 2.402, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 13713 (epoch 22), train_loss = 2.485, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 13714 (epoch 22), train_loss = 2.737, time/batch = 0.040
Read data: 9.083747863769531e-05
iter 13715 (epoch 22), train_loss = 2.749, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 13716 (epoch 22), train_loss = 2.596, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 13717 (epoch 22), train_loss = 2.816, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 13718 (epoch 22), train_loss = 2.225, time/batch = 0.022
Read data: 9.584426879882812e-05
iter 13719 (epoch 22), train_loss = 2.562, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 13720 (epoch 22), train_loss = 2.287, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 13721 (epoch 22), train_loss = 2.596, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 13722 (epoch 22), train_loss = 2.834, time/batch = 0.025
Read data: 0.0001704692840576172
iter 13723 (epoch 22), train_loss = 2.475, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 13724 (epoch 22), train_loss = 2.516, time/batch = 0.023
Read data: 8.702278137207031e-05
iter 13725 (epoch 22), train_loss = 2.449, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 13726 (epoch 22), train_loss = 2.142, time/batch = 0.027
Read data: 0.0001404285430908203
iter 13727 (epoch 22), train_loss = 2.310, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 13728 (epoch 22), train_loss = 2.800, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 13729 (epoch 22), train_loss = 2.827, time/batch = 0.032
Read data: 7.843971252441406e-05
iter 13730 (epoch 22), train_loss = 2.658, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 13731 (epoch 22), train_loss = 2.430, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 13732 (epoch 22), train_loss = 2.406, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 13733 (epoch 22), train_loss = 2.486, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 13734 (epoch 22), train_loss = 2.429, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 13735 (epoch 22), train_loss = 2.761, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 13736 (epoch 22), train_loss = 2.471, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 13737 (epoch 22), train_loss = 2.851, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 13738 (epoch 22), train_loss = 2.314, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13739 (epoch 22), train_loss = 2.950, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 13740 (epoch 22), train_loss = 2.424, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 13741 (epoch 22), train_loss = 2.598, time/batch = 0.033
Read data: 7.963180541992188e-05
iter 13742 (epoch 22), train_loss = 2.619, time/batch = 0.029
Read data: 0.000118255615234375
iter 13743 (epoch 22), train_loss = 2.863, time/batch = 0.041
Read data: 7.748603820800781e-05
iter 13744 (epoch 22), train_loss = 2.409, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 13745 (epoch 22), train_loss = 2.255, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 13746 (epoch 22), train_loss = 3.092, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 13747 (epoch 22), train_loss = 2.528, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 13748 (epoch 22), train_loss = 2.407, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 13749 (epoch 22), train_loss = 2.307, time/batch = 0.030
Read data: 0.0002009868621826172
iter 13750 (epoch 22), train_loss = 2.426, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 13751 (epoch 22), train_loss = 2.422, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 13752 (epoch 22), train_loss = 2.197, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 13753 (epoch 22), train_loss = 2.181, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 13754 (epoch 22), train_loss = 2.316, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 13755 (epoch 22), train_loss = 2.645, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 13756 (epoch 22), train_loss = 2.958, time/batch = 0.030
Read data: 8.845329284667969e-05
iter 13757 (epoch 22), train_loss = 2.448, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 13758 (epoch 22), train_loss = 2.509, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 13759 (epoch 22), train_loss = 2.234, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 13760 (epoch 22), train_loss = 2.458, time/batch = 0.029
Read data: 9.298324584960938e-05
iter 13761 (epoch 22), train_loss = 2.484, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 13762 (epoch 22), train_loss = 2.752, time/batch = 0.038
Read data: 8.368492126464844e-05
iter 13763 (epoch 22), train_loss = 2.139, time/batch = 0.025
Read data: 9.918212890625e-05
iter 13764 (epoch 22), train_loss = 2.619, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 13765 (epoch 22), train_loss = 2.259, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 13766 (epoch 22), train_loss = 2.522, time/batch = 0.035
Read data: 8.082389831542969e-05
iter 13767 (epoch 22), train_loss = 2.317, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 13768 (epoch 22), train_loss = 2.642, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 13769 (epoch 22), train_loss = 2.696, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 13770 (epoch 22), train_loss = 2.640, time/batch = 0.022
Read data: 0.00014352798461914062
iter 13771 (epoch 22), train_loss = 2.746, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 13772 (epoch 22), train_loss = 2.028, time/batch = 0.023
Read data: 8.535385131835938e-05
iter 13773 (epoch 22), train_loss = 2.401, time/batch = 0.031
Read data: 0.00010037422180175781
iter 13774 (epoch 22), train_loss = 2.625, time/batch = 0.029
Read data: 0.000244140625
iter 13775 (epoch 22), train_loss = 2.341, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 13776 (epoch 22), train_loss = 2.671, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 13777 (epoch 22), train_loss = 2.586, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 13778 (epoch 22), train_loss = 2.714, time/batch = 0.025
Read data: 9.131431579589844e-05
iter 13779 (epoch 22), train_loss = 2.686, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 13780 (epoch 22), train_loss = 2.640, time/batch = 0.022
Read data: 9.72747802734375e-05
iter 13781 (epoch 22), train_loss = 2.573, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 13782 (epoch 22), train_loss = 2.273, time/batch = 0.023
Read data: 0.00013947486877441406
iter 13783 (epoch 22), train_loss = 2.622, time/batch = 0.032
Read data: 0.00010538101196289062
iter 13784 (epoch 22), train_loss = 2.469, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 13785 (epoch 22), train_loss = 2.627, time/batch = 0.038
Read data: 8.702278137207031e-05
iter 13786 (epoch 22), train_loss = 2.481, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 13787 (epoch 22), train_loss = 2.558, time/batch = 0.032
Read data: 8.845329284667969e-05
iter 13788 (epoch 22), train_loss = 2.517, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 13789 (epoch 22), train_loss = 2.755, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 13790 (epoch 22), train_loss = 2.700, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 13791 (epoch 22), train_loss = 2.125, time/batch = 0.024
Read data: 0.0008652210235595703
iter 13792 (epoch 22), train_loss = 2.328, time/batch = 0.021
Read data: 0.00013065338134765625
iter 13793 (epoch 22), train_loss = 2.051, time/batch = 0.022
Read data: 0.00011920928955078125
iter 13794 (epoch 22), train_loss = 2.380, time/batch = 0.025
Read data: 0.0001404285430908203
iter 13795 (epoch 22), train_loss = 3.201, time/batch = 0.029
Read data: 9.393692016601562e-05
iter 13796 (epoch 22), train_loss = 2.861, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 13797 (epoch 22), train_loss = 2.787, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 13798 (epoch 22), train_loss = 2.472, time/batch = 0.031
Read data: 7.867813110351562e-05
iter 13799 (epoch 22), train_loss = 2.107, time/batch = 0.025
Read data: 0.00020003318786621094
iter 13800 (epoch 22), train_loss = 2.354, time/batch = 0.025
Read data: 8.392333984375e-05
iter 13801 (epoch 23), train_loss = 2.704, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 13802 (epoch 23), train_loss = 2.831, time/batch = 0.035
Read data: 0.00013375282287597656
iter 13803 (epoch 23), train_loss = 2.606, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 13804 (epoch 23), train_loss = 2.330, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 13805 (epoch 23), train_loss = 2.359, time/batch = 0.025
Read data: 8.392333984375e-05
iter 13806 (epoch 23), train_loss = 2.375, time/batch = 0.023
Read data: 9.918212890625e-05
iter 13807 (epoch 23), train_loss = 2.454, time/batch = 0.031
Read data: 0.00015211105346679688
iter 13808 (epoch 23), train_loss = 2.332, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 13809 (epoch 23), train_loss = 2.579, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 13810 (epoch 23), train_loss = 2.213, time/batch = 0.023
Read data: 0.00011038780212402344
iter 13811 (epoch 23), train_loss = 2.769, time/batch = 0.031
Read data: 0.00010538101196289062
iter 13812 (epoch 23), train_loss = 2.629, time/batch = 0.024
Read data: 9.775161743164062e-05
iter 13813 (epoch 23), train_loss = 2.488, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13814 (epoch 23), train_loss = 2.288, time/batch = 0.021
Read data: 7.796287536621094e-05
iter 13815 (epoch 23), train_loss = 2.355, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 13816 (epoch 23), train_loss = 2.387, time/batch = 0.023
Read data: 0.00012874603271484375
iter 13817 (epoch 23), train_loss = 2.721, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 13818 (epoch 23), train_loss = 2.450, time/batch = 0.023
Read data: 0.0001392364501953125
iter 13819 (epoch 23), train_loss = 2.447, time/batch = 0.031
Read data: 9.417533874511719e-05
iter 13820 (epoch 23), train_loss = 2.529, time/batch = 0.026
Read data: 0.00010776519775390625
iter 13821 (epoch 23), train_loss = 2.357, time/batch = 0.036
Read data: 0.00014710426330566406
iter 13822 (epoch 23), train_loss = 2.515, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 13823 (epoch 23), train_loss = 2.281, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 13824 (epoch 23), train_loss = 2.344, time/batch = 0.026
Read data: 0.00021696090698242188
iter 13825 (epoch 23), train_loss = 2.312, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 13826 (epoch 23), train_loss = 2.525, time/batch = 0.025
Read data: 0.00016236305236816406
iter 13827 (epoch 23), train_loss = 2.428, time/batch = 0.030
Read data: 0.0001628398895263672
iter 13828 (epoch 23), train_loss = 2.587, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 13829 (epoch 23), train_loss = 2.364, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 13830 (epoch 23), train_loss = 2.495, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13831 (epoch 23), train_loss = 2.101, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 13832 (epoch 23), train_loss = 2.410, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 13833 (epoch 23), train_loss = 2.732, time/batch = 0.029
Read data: 0.00010228157043457031
iter 13834 (epoch 23), train_loss = 2.661, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 13835 (epoch 23), train_loss = 2.441, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 13836 (epoch 23), train_loss = 2.520, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 13837 (epoch 23), train_loss = 2.738, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 13838 (epoch 23), train_loss = 2.315, time/batch = 0.021
Read data: 0.00010085105895996094
iter 13839 (epoch 23), train_loss = 2.745, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 13840 (epoch 23), train_loss = 2.223, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 13841 (epoch 23), train_loss = 2.361, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 13842 (epoch 23), train_loss = 1.994, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 13843 (epoch 23), train_loss = 2.274, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 13844 (epoch 23), train_loss = 2.285, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 13845 (epoch 23), train_loss = 2.231, time/batch = 0.025
Read data: 0.0001289844512939453
iter 13846 (epoch 23), train_loss = 2.842, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 13847 (epoch 23), train_loss = 2.710, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 13848 (epoch 23), train_loss = 2.710, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 13849 (epoch 23), train_loss = 2.519, time/batch = 0.033
Read data: 0.0002300739288330078
iter 13850 (epoch 23), train_loss = 2.576, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 13851 (epoch 23), train_loss = 2.598, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13852 (epoch 23), train_loss = 2.555, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 13853 (epoch 23), train_loss = 2.328, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 13854 (epoch 23), train_loss = 2.191, time/batch = 0.021
Read data: 0.0001697540283203125
iter 13855 (epoch 23), train_loss = 2.079, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 13856 (epoch 23), train_loss = 2.294, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 13857 (epoch 23), train_loss = 2.267, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 13858 (epoch 23), train_loss = 2.715, time/batch = 0.027
Read data: 8.392333984375e-05
iter 13859 (epoch 23), train_loss = 2.594, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 13860 (epoch 23), train_loss = 2.362, time/batch = 0.035
Read data: 8.845329284667969e-05
iter 13861 (epoch 23), train_loss = 2.077, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 13862 (epoch 23), train_loss = 2.323, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 13863 (epoch 23), train_loss = 2.301, time/batch = 0.030
Read data: 8.606910705566406e-05
iter 13864 (epoch 23), train_loss = 2.673, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 13865 (epoch 23), train_loss = 2.452, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 13866 (epoch 23), train_loss = 2.525, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 13867 (epoch 23), train_loss = 2.618, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 13868 (epoch 23), train_loss = 2.372, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 13869 (epoch 23), train_loss = 2.385, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 13870 (epoch 23), train_loss = 2.227, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 13871 (epoch 23), train_loss = 2.227, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 13872 (epoch 23), train_loss = 2.598, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 13873 (epoch 23), train_loss = 2.750, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 13874 (epoch 23), train_loss = 2.467, time/batch = 0.023
Read data: 0.000244140625
iter 13875 (epoch 23), train_loss = 2.051, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 13876 (epoch 23), train_loss = 2.343, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 13877 (epoch 23), train_loss = 2.476, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 13878 (epoch 23), train_loss = 2.745, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 13879 (epoch 23), train_loss = 3.002, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 13880 (epoch 23), train_loss = 2.549, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 13881 (epoch 23), train_loss = 2.574, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 13882 (epoch 23), train_loss = 2.187, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 13883 (epoch 23), train_loss = 1.986, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 13884 (epoch 23), train_loss = 2.337, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 13885 (epoch 23), train_loss = 2.732, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 13886 (epoch 23), train_loss = 2.356, time/batch = 0.027
Read data: 0.00012302398681640625
iter 13887 (epoch 23), train_loss = 2.246, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 13888 (epoch 23), train_loss = 2.581, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 13889 (epoch 23), train_loss = 2.798, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 13890 (epoch 23), train_loss = 2.516, time/batch = 0.023
Read data: 0.00010633468627929688
iter 13891 (epoch 23), train_loss = 2.619, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 13892 (epoch 23), train_loss = 2.735, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 13893 (epoch 23), train_loss = 2.258, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 13894 (epoch 23), train_loss = 2.516, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 13895 (epoch 23), train_loss = 2.810, time/batch = 0.035
Read data: 8.392333984375e-05
iter 13896 (epoch 23), train_loss = 2.288, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 13897 (epoch 23), train_loss = 2.662, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 13898 (epoch 23), train_loss = 2.643, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 13899 (epoch 23), train_loss = 2.295, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 13900 (epoch 23), train_loss = 2.197, time/batch = 0.034
Read data: 9.679794311523438e-05
iter 13901 (epoch 23), train_loss = 2.459, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 13902 (epoch 23), train_loss = 2.603, time/batch = 0.038
Read data: 0.00012922286987304688
iter 13903 (epoch 23), train_loss = 2.572, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 13904 (epoch 23), train_loss = 2.550, time/batch = 0.019
Read data: 7.963180541992188e-05
iter 13905 (epoch 23), train_loss = 2.848, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 13906 (epoch 23), train_loss = 2.606, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 13907 (epoch 23), train_loss = 1.877, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 13908 (epoch 23), train_loss = 2.344, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 13909 (epoch 23), train_loss = 2.443, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 13910 (epoch 23), train_loss = 2.228, time/batch = 0.022
Read data: 0.0001780986785888672
iter 13911 (epoch 23), train_loss = 2.543, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 13912 (epoch 23), train_loss = 2.326, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 13913 (epoch 23), train_loss = 2.648, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 13914 (epoch 23), train_loss = 2.464, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 13915 (epoch 23), train_loss = 2.373, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 13916 (epoch 23), train_loss = 2.770, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 13917 (epoch 23), train_loss = 2.744, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 13918 (epoch 23), train_loss = 2.420, time/batch = 0.029
Read data: 9.1552734375e-05
iter 13919 (epoch 23), train_loss = 2.366, time/batch = 0.033
Read data: 0.00012969970703125
iter 13920 (epoch 23), train_loss = 2.746, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 13921 (epoch 23), train_loss = 2.179, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 13922 (epoch 23), train_loss = 2.713, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 13923 (epoch 23), train_loss = 2.295, time/batch = 0.025
Read data: 0.00016260147094726562
iter 13924 (epoch 23), train_loss = 2.268, time/batch = 0.023
Read data: 0.0001704692840576172
iter 13925 (epoch 23), train_loss = 2.194, time/batch = 0.025
Read data: 0.0001010894775390625
iter 13926 (epoch 23), train_loss = 2.470, time/batch = 0.023
Read data: 0.00012969970703125
iter 13927 (epoch 23), train_loss = 2.578, time/batch = 0.030
Read data: 0.00013017654418945312
iter 13928 (epoch 23), train_loss = 2.533, time/batch = 0.025
Read data: 0.00011277198791503906
iter 13929 (epoch 23), train_loss = 2.458, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 13930 (epoch 23), train_loss = 2.487, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 13931 (epoch 23), train_loss = 2.641, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 13932 (epoch 23), train_loss = 2.295, time/batch = 0.034
Read data: 7.939338684082031e-05
iter 13933 (epoch 23), train_loss = 2.497, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 13934 (epoch 23), train_loss = 2.441, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 13935 (epoch 23), train_loss = 2.272, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 13936 (epoch 23), train_loss = 2.166, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 13937 (epoch 23), train_loss = 2.001, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 13938 (epoch 23), train_loss = 2.515, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 13939 (epoch 23), train_loss = 2.494, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 13940 (epoch 23), train_loss = 2.411, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 13941 (epoch 23), train_loss = 2.417, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 13942 (epoch 23), train_loss = 2.541, time/batch = 0.021
Read data: 9.72747802734375e-05
iter 13943 (epoch 23), train_loss = 2.109, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 13944 (epoch 23), train_loss = 2.359, time/batch = 0.027
Read data: 9.608268737792969e-05
iter 13945 (epoch 23), train_loss = 2.774, time/batch = 0.038
Read data: 8.440017700195312e-05
iter 13946 (epoch 23), train_loss = 2.136, time/batch = 0.019
Read data: 8.320808410644531e-05
iter 13947 (epoch 23), train_loss = 2.480, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 13948 (epoch 23), train_loss = 2.737, time/batch = 0.036
Read data: 8.130073547363281e-05
iter 13949 (epoch 23), train_loss = 2.309, time/batch = 0.021
Read data: 0.0002205371856689453
iter 13950 (epoch 23), train_loss = 2.408, time/batch = 0.025
Read data: 0.00010514259338378906
iter 13951 (epoch 23), train_loss = 2.543, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 13952 (epoch 23), train_loss = 2.545, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 13953 (epoch 23), train_loss = 2.859, time/batch = 0.025
Read data: 0.000110626220703125
iter 13954 (epoch 23), train_loss = 2.091, time/batch = 0.021
Read data: 9.274482727050781e-05
iter 13955 (epoch 23), train_loss = 2.469, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 13956 (epoch 23), train_loss = 2.554, time/batch = 0.031
Read data: 9.489059448242188e-05
iter 13957 (epoch 23), train_loss = 2.361, time/batch = 0.033
Read data: 9.202957153320312e-05
iter 13958 (epoch 23), train_loss = 2.292, time/batch = 0.024
Read data: 0.00012302398681640625
iter 13959 (epoch 23), train_loss = 2.597, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 13960 (epoch 23), train_loss = 2.437, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 13961 (epoch 23), train_loss = 2.940, time/batch = 0.030
Read data: 0.00011491775512695312
iter 13962 (epoch 23), train_loss = 2.647, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 13963 (epoch 23), train_loss = 2.003, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 13964 (epoch 23), train_loss = 2.444, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 13965 (epoch 23), train_loss = 2.585, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 13966 (epoch 23), train_loss = 2.171, time/batch = 0.031
Read data: 0.00014901161193847656
iter 13967 (epoch 23), train_loss = 2.441, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 13968 (epoch 23), train_loss = 2.436, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 13969 (epoch 23), train_loss = 2.297, time/batch = 0.033
Read data: 7.43865966796875e-05
iter 13970 (epoch 23), train_loss = 2.477, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 13971 (epoch 23), train_loss = 2.036, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 13972 (epoch 23), train_loss = 2.176, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 13973 (epoch 23), train_loss = 2.699, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 13974 (epoch 23), train_loss = 2.604, time/batch = 0.033
Read data: 0.00016808509826660156
iter 13975 (epoch 23), train_loss = 2.794, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 13976 (epoch 23), train_loss = 2.209, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 13977 (epoch 23), train_loss = 2.540, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 13978 (epoch 23), train_loss = 2.604, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 13979 (epoch 23), train_loss = 2.422, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 13980 (epoch 23), train_loss = 2.491, time/batch = 0.029
Read data: 7.62939453125e-05
iter 13981 (epoch 23), train_loss = 2.641, time/batch = 0.030
Read data: 0.00010514259338378906
iter 13982 (epoch 23), train_loss = 2.107, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 13983 (epoch 23), train_loss = 2.447, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 13984 (epoch 23), train_loss = 2.779, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 13985 (epoch 23), train_loss = 2.386, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 13986 (epoch 23), train_loss = 2.737, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 13987 (epoch 23), train_loss = 2.569, time/batch = 0.026
Read data: 7.62939453125e-05
iter 13988 (epoch 23), train_loss = 2.730, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 13989 (epoch 23), train_loss = 2.323, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 13990 (epoch 23), train_loss = 2.391, time/batch = 0.022
Read data: 0.00015544891357421875
iter 13991 (epoch 23), train_loss = 2.378, time/batch = 0.026
Read data: 0.0001552104949951172
iter 13992 (epoch 23), train_loss = 2.730, time/batch = 0.030
Read data: 9.1552734375e-05
iter 13993 (epoch 23), train_loss = 2.656, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 13994 (epoch 23), train_loss = 2.557, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 13995 (epoch 23), train_loss = 2.652, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 13996 (epoch 23), train_loss = 1.981, time/batch = 0.027
Read data: 0.0001697540283203125
iter 13997 (epoch 23), train_loss = 2.161, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 13998 (epoch 23), train_loss = 2.779, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 13999 (epoch 23), train_loss = 2.600, time/batch = 0.028
image 976:    
image 5399:     
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.641043)
image 2798:    
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:     
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.216873)
image 6903:    UNK
image 3301:    
image 2019:     
image 5535:     
image 7680:      
image 5527:      
image 2568:      
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.539906)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.991661)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:   
image 5629:     
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.507768)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.766188)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.574291)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.603296)
image 3276:      
image 3812:   
image 1400:     
image 3443:     
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.125114)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:         
evaluating validation preformance... 100/1000 (2.894279)
image 2800:    
image 7249:      
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.790697)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:     
image 6505:     
image 1450:    
image 3979:      
image 5302:    
evaluating validation preformance... 120/1000 (2.382271)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.895936)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:  UNK  
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.669878)
image 1738:     
image 1455:     
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:     
evaluating validation preformance... 150/1000 (2.925699)
image 1865:    
image 3830:      
image 360:     
image 5097:    
image 4455:     
image 1153:    
image 1248:    
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.776673)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:      
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.558790)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:     
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.682750)
image 2313:    
image 6289:    
image 8084:      
image 2696:    
image 5830:     
image 6240:      
image 4541:     UNK
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.394354)
image 5372:    
image 7529:    UNK
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:      
evaluating validation preformance... 200/1000 (2.282375)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.430253)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.537015)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.243275)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:     
evaluating validation preformance... 240/1000 (2.141229)
image 7143:    
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (2.523551)
image 3028:   
image 3141:    
image 7137:    
image 3444:    
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.488965)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.991456)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:     
evaluating validation preformance... 280/1000 (2.537279)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.401911)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.157481)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.810250)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.291413)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:      
evaluating validation preformance... 330/1000 (2.789394)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:      
image 2601:    
image 4524:    UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.429069)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.513830)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:     
image 5241:     
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.053576)
image 2905:    
image 7814:      
image 56:    
image 5034:     
image 7946:      
image 3470:     
image 4655:     
image 818:     
image 6607:    
image 4866:     
evaluating validation preformance... 370/1000 (2.595667)
image 4351:     
image 1054:     
image 129:     
image 2849:    
image 725:   
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.628716)
image 2458:     
image 1084:      
image 4835:     
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:      
image 60:     
evaluating validation preformance... 390/1000 (2.856552)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:     
image 1117:      
image 5817:      
image 1231:    
image 1630:    
image 6886:    
evaluating validation preformance... 400/1000 (2.229558)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:     
image 670:     
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.141898)
image 4359:     
image 2372:    
image 4472:      
image 6810:     
image 1592:     
image 7864:    
image 4286:    
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.355371)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:    
image 6977:    
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.837035)
image 385:    
image 6938:       
image 2381:    
image 5796:    
image 4010:    
image 3452:     
image 2023:     
image 3052:    
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.891773)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:     
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.169970)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:      
image 2466:    
image 975:     
image 3818:    
image 6995:    
image 3682:    
evaluating validation preformance... 460/1000 (2.691104)
image 7979:    
image 1618:    
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.244525)
image 4503:     
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (2.918539)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:      
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.299179)
image 2044:    
image 4349:    
image 3855:      
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.490433)
image 1797:    
image 4670:     
image 4846:    
image 5907:     
image 3321:      
image 1700:     
image 438:    
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.964221)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.611640)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:    
image 303:    
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.492923)
image 5619:    
image 4391:    
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:      
image 6034:     
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.451446)
image 5292:    
image 2901:    
image 3568:    
image 690:      
image 3345:     
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.589137)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:     
image 5079:     
image 6169:     
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.562888)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:    
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.579512)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.590054)
image 2135:      
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.532582)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.490056)
image 353:     
image 1095:     
image 3583:      
image 3264:      
image 5668:     
image 7189:     
image 6573:    
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.670894)
image 69:     
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:     
image 359:     
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.383613)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.503027)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.476802)
image 5313:      
image 2377:      
image 6058:    
image 4661:     
image 2955:    
image 3333:    
image 7124:     
image 4278:      
image 953:     
image 4037:      
evaluating validation preformance... 650/1000 (2.518327)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.618746)
image 5701:      
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (2.840843)
image 7877:    
image 6761:     
image 6880:    
image 4914:    UNK
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK UNK
image 7784:      
evaluating validation preformance... 680/1000 (2.985105)
image 1445:     
image 6841:     
image 2896:    
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.857902)
image 6860:     
image 576:    
image 6580:     
image 1497:     
image 3360:     
image 4939:      
image 6225:     
image 3669:     
image 980:    
image 5362:      
evaluating validation preformance... 700/1000 (2.984428)
image 5343:      
image 68:    UNK
image 3184:    
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.469348)
image 7368:    
image 709:     
image 3197:    
image 5214:    
image 445:      
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.627079)
image 5729:     
image 6395:     
image 516:      
image 1026:     
image 2972:      
image 3005:    
image 1241:     
image 2743:      
image 3665:    
image 1290:     UNK
evaluating validation preformance... 730/1000 (2.280128)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:     
image 997:    
image 5092:     
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.405375)
image 2239:     
image 120:    
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:      
image 6197:     
evaluating validation preformance... 750/1000 (2.683655)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.956348)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.131955)
image 6220:    
image 6238:    
image 4534:     
image 2732:     
image 7003:    
image 1739:     
image 5503:     
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.800375)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:     
image 6978:    
image 3450:     
image 3312:    UNK
image 7824:      
image 2032:    
evaluating validation preformance... 790/1000 (3.115432)
image 5047:    
image 325:      
image 7626:    
image 4552:     
image 983:    
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.250276)
image 7288:     
image 7302:      
image 3055:     
image 5250:     
image 1158:     
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.398431)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.915358)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:    
image 7147:    
image 6348:     
image 580:    
image 2531:    
evaluating validation preformance... 830/1000 (2.345349)
image 5107:     
image 3973:    
image 4233:     
image 3593:    
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:   
evaluating validation preformance... 840/1000 (2.424823)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.796039)
image 4404:     
image 5501:      
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:       
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.753765)
image 4254:     
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:      
image 3222:   
image 4002:    
evaluating validation preformance... 870/1000 (2.342922)
image 4934:    
image 6487:     
image 4217:     
image 6355:      
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.604248)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.903321)
image 7485:    
image 6102:    
image 1001:      
image 7167:    
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.543306)
image 5664:     
image 4985:    
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.201075)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.619779)
image 7152:    
image 4559:      
image 7233:      
image 1341:    
image 5337:       
image 3189:     
image 6274:      
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.507624)
image 5636:      
image 7799:      
image 6025:    
image 6907:      
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.681627)
image 5860:    
image 3275:    
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:     
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.944701)
image 1081:    
image 1179:     
image 4316:    
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:     
image 1550:    
evaluating validation preformance... 960/1000 (2.730280)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.317053)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.772050)
image 7352:     
image 5113:     
image 7822:    
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.432014)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:    
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.333699)
average loss on validation: 2.589
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3532600402832031
Cider scores: 0.5566875825730269
Read data: 0.3305835723876953
Cider scores: 0.5833550675353373
Read data: 0.2553365230560303
Cider scores: 0.6153437379653142
Read data: 0.2446587085723877
Cider scores: 0.6111482318144632
Read data: 0.23828601837158203
Cider scores: 0.5626955905059939
Read data: 0.17181730270385742
Cider scores: 0.5253667017383855
Read data: 0.19541120529174805
Cider scores: 0.5236224232462671
Read data: 0.17909526824951172
Cider scores: 0.6398639312680359
Read data: 0.17268109321594238
Cider scores: 0.443358491247936
Read data: 0.1855478286743164
Cider scores: 0.6054408665718956
Read data: 0.23852276802062988
Cider scores: 0.6344241667897346
Read data: 0.1764540672302246
Cider scores: 0.6633258026823159
Read data: 0.17780184745788574
Cider scores: 0.5398476244010156
Read data: 0.1772782802581787
Cider scores: 0.5936739695798633
Read data: 0.18202924728393555
Cider scores: 0.6620428037298848
Read data: 0.1707897186279297
Cider scores: 0.6180517251128937
Read data: 0.16783809661865234
Cider scores: 0.46722382091583303
Read data: 0.165574312210083
Cider scores: 0.6299452405525401
Read data: 0.1652357578277588
Cider scores: 0.5322499768811328
Read data: 0.16375184059143066
Cider scores: 0.7281916137278406
Average cider score on test set: 0.587
End calculating cider score on TEST data set
===============================================
Read data: 0.16670918464660645
iter 14000 (epoch 23), train_loss = 2.765, time/batch = 0.035
Read data: 0.000118255615234375
iter 14001 (epoch 23), train_loss = 2.694, time/batch = 0.033
Read data: 0.00016045570373535156
iter 14002 (epoch 23), train_loss = 2.277, time/batch = 0.029
Read data: 0.0001537799835205078
iter 14003 (epoch 23), train_loss = 2.672, time/batch = 0.023
Read data: 0.00014281272888183594
iter 14004 (epoch 23), train_loss = 2.360, time/batch = 0.026
Read data: 0.00010776519775390625
iter 14005 (epoch 23), train_loss = 2.718, time/batch = 0.031
Read data: 9.107589721679688e-05
iter 14006 (epoch 23), train_loss = 2.792, time/batch = 0.032
Read data: 9.584426879882812e-05
iter 14007 (epoch 23), train_loss = 2.857, time/batch = 0.039
Read data: 0.00015616416931152344
iter 14008 (epoch 23), train_loss = 2.390, time/batch = 0.033
Read data: 0.0001544952392578125
iter 14009 (epoch 23), train_loss = 2.556, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 14010 (epoch 23), train_loss = 2.472, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 14011 (epoch 23), train_loss = 2.340, time/batch = 0.030
Read data: 9.655952453613281e-05
iter 14012 (epoch 23), train_loss = 2.291, time/batch = 0.025
Read data: 0.00011587142944335938
iter 14013 (epoch 23), train_loss = 2.794, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 14014 (epoch 23), train_loss = 2.884, time/batch = 0.031
Read data: 9.584426879882812e-05
iter 14015 (epoch 23), train_loss = 2.681, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 14016 (epoch 23), train_loss = 2.506, time/batch = 0.028
Read data: 0.00011992454528808594
iter 14017 (epoch 23), train_loss = 2.655, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 14018 (epoch 23), train_loss = 2.941, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 14019 (epoch 23), train_loss = 2.411, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 14020 (epoch 23), train_loss = 2.763, time/batch = 0.032
Read data: 0.00012159347534179688
iter 14021 (epoch 23), train_loss = 2.371, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 14022 (epoch 23), train_loss = 2.853, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 14023 (epoch 23), train_loss = 2.676, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 14024 (epoch 23), train_loss = 2.238, time/batch = 0.032
Read data: 0.0002067089080810547
iter 14025 (epoch 23), train_loss = 2.815, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 14026 (epoch 23), train_loss = 2.726, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 14027 (epoch 23), train_loss = 2.485, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 14028 (epoch 23), train_loss = 2.365, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 14029 (epoch 23), train_loss = 2.574, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 14030 (epoch 23), train_loss = 2.295, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 14031 (epoch 23), train_loss = 2.405, time/batch = 0.022
Read data: 0.00012087821960449219
iter 14032 (epoch 23), train_loss = 2.924, time/batch = 0.029
Read data: 0.000148773193359375
iter 14033 (epoch 23), train_loss = 2.561, time/batch = 0.026
Read data: 0.000102996826171875
iter 14034 (epoch 23), train_loss = 2.469, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 14035 (epoch 23), train_loss = 2.263, time/batch = 0.022
Read data: 0.0001316070556640625
iter 14036 (epoch 23), train_loss = 2.318, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 14037 (epoch 23), train_loss = 2.202, time/batch = 0.026
Read data: 0.00010418891906738281
iter 14038 (epoch 23), train_loss = 2.017, time/batch = 0.023
Read data: 0.00011205673217773438
iter 14039 (epoch 23), train_loss = 2.656, time/batch = 0.026
Read data: 0.00014281272888183594
iter 14040 (epoch 23), train_loss = 2.591, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 14041 (epoch 23), train_loss = 2.478, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 14042 (epoch 23), train_loss = 2.513, time/batch = 0.023
Read data: 0.00011348724365234375
iter 14043 (epoch 23), train_loss = 2.755, time/batch = 0.026
Read data: 0.00012636184692382812
iter 14044 (epoch 23), train_loss = 2.643, time/batch = 0.030
Read data: 9.5367431640625e-05
iter 14045 (epoch 23), train_loss = 2.573, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 14046 (epoch 23), train_loss = 2.494, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 14047 (epoch 23), train_loss = 2.579, time/batch = 0.030
Read data: 9.393692016601562e-05
iter 14048 (epoch 23), train_loss = 2.752, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 14049 (epoch 23), train_loss = 2.722, time/batch = 0.024
Read data: 0.00010704994201660156
iter 14050 (epoch 23), train_loss = 2.296, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 14051 (epoch 23), train_loss = 2.286, time/batch = 0.023
Read data: 8.392333984375e-05
iter 14052 (epoch 23), train_loss = 2.463, time/batch = 0.023
Read data: 9.918212890625e-05
iter 14053 (epoch 23), train_loss = 2.578, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 14054 (epoch 23), train_loss = 2.188, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 14055 (epoch 23), train_loss = 2.655, time/batch = 0.026
Read data: 0.00013303756713867188
iter 14056 (epoch 23), train_loss = 2.678, time/batch = 0.027
Read data: 0.0001399517059326172
iter 14057 (epoch 23), train_loss = 2.299, time/batch = 0.023
Read data: 8.702278137207031e-05
iter 14058 (epoch 23), train_loss = 2.343, time/batch = 0.026
Read data: 0.00011587142944335938
iter 14059 (epoch 23), train_loss = 2.531, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 14060 (epoch 23), train_loss = 2.431, time/batch = 0.026
Read data: 0.00013947486877441406
iter 14061 (epoch 23), train_loss = 2.460, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 14062 (epoch 23), train_loss = 2.497, time/batch = 0.036
Read data: 8.511543273925781e-05
iter 14063 (epoch 23), train_loss = 2.389, time/batch = 0.029
Read data: 0.00014162063598632812
iter 14064 (epoch 23), train_loss = 2.631, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 14065 (epoch 23), train_loss = 2.210, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 14066 (epoch 23), train_loss = 2.434, time/batch = 0.024
Read data: 8.392333984375e-05
iter 14067 (epoch 23), train_loss = 2.693, time/batch = 0.025
Read data: 0.00016570091247558594
iter 14068 (epoch 23), train_loss = 2.381, time/batch = 0.033
Read data: 8.463859558105469e-05
iter 14069 (epoch 23), train_loss = 2.574, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 14070 (epoch 23), train_loss = 2.470, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 14071 (epoch 23), train_loss = 2.337, time/batch = 0.030
Read data: 0.0001614093780517578
iter 14072 (epoch 23), train_loss = 2.601, time/batch = 0.026
Read data: 0.00013709068298339844
iter 14073 (epoch 23), train_loss = 2.429, time/batch = 0.026
Read data: 9.5367431640625e-05
iter 14074 (epoch 23), train_loss = 2.490, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 14075 (epoch 23), train_loss = 2.713, time/batch = 0.035
Read data: 0.00012373924255371094
iter 14076 (epoch 23), train_loss = 2.427, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 14077 (epoch 23), train_loss = 2.692, time/batch = 0.033
Read data: 0.00011968612670898438
iter 14078 (epoch 23), train_loss = 2.650, time/batch = 0.034
Read data: 0.00011301040649414062
iter 14079 (epoch 23), train_loss = 2.854, time/batch = 0.028
Read data: 0.0001666545867919922
iter 14080 (epoch 23), train_loss = 2.551, time/batch = 0.031
Read data: 0.000125885009765625
iter 14081 (epoch 23), train_loss = 2.589, time/batch = 0.032
Read data: 0.00011301040649414062
iter 14082 (epoch 23), train_loss = 2.253, time/batch = 0.030
Read data: 0.00011038780212402344
iter 14083 (epoch 23), train_loss = 2.396, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 14084 (epoch 23), train_loss = 2.744, time/batch = 0.023
Read data: 0.0001327991485595703
iter 14085 (epoch 23), train_loss = 2.659, time/batch = 0.028
Read data: 0.00010204315185546875
iter 14086 (epoch 23), train_loss = 2.085, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 14087 (epoch 23), train_loss = 2.770, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 14088 (epoch 23), train_loss = 2.401, time/batch = 0.027
Read data: 0.00013494491577148438
iter 14089 (epoch 23), train_loss = 1.970, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 14090 (epoch 23), train_loss = 2.448, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 14091 (epoch 23), train_loss = 2.820, time/batch = 0.021
Read data: 0.00014066696166992188
iter 14092 (epoch 23), train_loss = 2.366, time/batch = 0.028
Read data: 0.00013709068298339844
iter 14093 (epoch 23), train_loss = 2.883, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 14094 (epoch 23), train_loss = 2.119, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 14095 (epoch 23), train_loss = 1.960, time/batch = 0.021
Read data: 0.00013637542724609375
iter 14096 (epoch 23), train_loss = 2.288, time/batch = 0.030
Read data: 9.036064147949219e-05
iter 14097 (epoch 23), train_loss = 2.188, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 14098 (epoch 23), train_loss = 2.079, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 14099 (epoch 23), train_loss = 2.737, time/batch = 0.039
Read data: 0.00016236305236816406
iter 14100 (epoch 23), train_loss = 2.146, time/batch = 0.024
Read data: 0.00013113021850585938
iter 14101 (epoch 23), train_loss = 2.570, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 14102 (epoch 23), train_loss = 2.538, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 14103 (epoch 23), train_loss = 2.383, time/batch = 0.032
Read data: 0.0001747608184814453
iter 14104 (epoch 23), train_loss = 2.882, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 14105 (epoch 23), train_loss = 2.814, time/batch = 0.033
Read data: 8.845329284667969e-05
iter 14106 (epoch 23), train_loss = 2.395, time/batch = 0.020
Read data: 8.440017700195312e-05
iter 14107 (epoch 23), train_loss = 2.823, time/batch = 0.023
Read data: 0.00013399124145507812
iter 14108 (epoch 23), train_loss = 2.627, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 14109 (epoch 23), train_loss = 2.625, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 14110 (epoch 23), train_loss = 2.886, time/batch = 0.033
Read data: 8.177757263183594e-05
iter 14111 (epoch 23), train_loss = 2.706, time/batch = 0.036
Read data: 9.036064147949219e-05
iter 14112 (epoch 23), train_loss = 2.201, time/batch = 0.036
Read data: 7.915496826171875e-05
iter 14113 (epoch 23), train_loss = 2.549, time/batch = 0.018
Read data: 9.131431579589844e-05
iter 14114 (epoch 23), train_loss = 2.644, time/batch = 0.033
Read data: 9.965896606445312e-05
iter 14115 (epoch 23), train_loss = 2.553, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 14116 (epoch 23), train_loss = 2.221, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 14117 (epoch 23), train_loss = 2.547, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 14118 (epoch 23), train_loss = 2.824, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 14119 (epoch 23), train_loss = 2.460, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 14120 (epoch 23), train_loss = 2.583, time/batch = 0.031
Read data: 0.00010037422180175781
iter 14121 (epoch 23), train_loss = 2.556, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 14122 (epoch 23), train_loss = 2.411, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 14123 (epoch 23), train_loss = 1.987, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 14124 (epoch 23), train_loss = 2.355, time/batch = 0.020
Read data: 9.655952453613281e-05
iter 14125 (epoch 23), train_loss = 2.657, time/batch = 0.027
Read data: 9.34600830078125e-05
iter 14126 (epoch 23), train_loss = 2.332, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 14127 (epoch 23), train_loss = 2.080, time/batch = 0.028
Read data: 9.107589721679688e-05
iter 14128 (epoch 23), train_loss = 2.449, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 14129 (epoch 23), train_loss = 2.530, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 14130 (epoch 23), train_loss = 2.624, time/batch = 0.031
Read data: 8.630752563476562e-05
iter 14131 (epoch 23), train_loss = 2.373, time/batch = 0.027
Read data: 0.0001342296600341797
iter 14132 (epoch 23), train_loss = 2.775, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 14133 (epoch 23), train_loss = 2.811, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 14134 (epoch 23), train_loss = 2.249, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 14135 (epoch 23), train_loss = 2.452, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 14136 (epoch 23), train_loss = 2.326, time/batch = 0.021
Read data: 0.00015616416931152344
iter 14137 (epoch 23), train_loss = 2.523, time/batch = 0.028
Read data: 0.00011968612670898438
iter 14138 (epoch 23), train_loss = 2.902, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 14139 (epoch 23), train_loss = 2.516, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 14140 (epoch 23), train_loss = 2.440, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 14141 (epoch 23), train_loss = 2.639, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 14142 (epoch 23), train_loss = 2.693, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 14143 (epoch 23), train_loss = 2.869, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 14144 (epoch 23), train_loss = 2.203, time/batch = 0.023
Read data: 0.00013828277587890625
iter 14145 (epoch 23), train_loss = 2.640, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 14146 (epoch 23), train_loss = 2.599, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 14147 (epoch 23), train_loss = 2.630, time/batch = 0.025
Read data: 0.00012636184692382812
iter 14148 (epoch 23), train_loss = 2.737, time/batch = 0.025
Read data: 0.00012874603271484375
iter 14149 (epoch 23), train_loss = 2.509, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 14150 (epoch 23), train_loss = 2.199, time/batch = 0.023
Read data: 0.00010013580322265625
iter 14151 (epoch 23), train_loss = 2.727, time/batch = 0.024
Read data: 0.0001010894775390625
iter 14152 (epoch 23), train_loss = 2.796, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 14153 (epoch 23), train_loss = 2.198, time/batch = 0.027
Read data: 0.0001456737518310547
iter 14154 (epoch 23), train_loss = 2.840, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 14155 (epoch 23), train_loss = 2.616, time/batch = 0.022
Read data: 0.00013971328735351562
iter 14156 (epoch 23), train_loss = 2.563, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 14157 (epoch 23), train_loss = 2.750, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 14158 (epoch 23), train_loss = 2.509, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 14159 (epoch 23), train_loss = 3.082, time/batch = 0.027
Read data: 0.00013065338134765625
iter 14160 (epoch 23), train_loss = 2.587, time/batch = 0.024
Read data: 0.00016689300537109375
iter 14161 (epoch 23), train_loss = 2.430, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 14162 (epoch 23), train_loss = 2.706, time/batch = 0.027
Read data: 0.00016379356384277344
iter 14163 (epoch 23), train_loss = 2.761, time/batch = 0.030
Read data: 0.00013566017150878906
iter 14164 (epoch 23), train_loss = 2.862, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 14165 (epoch 23), train_loss = 2.801, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 14166 (epoch 23), train_loss = 2.607, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 14167 (epoch 23), train_loss = 2.587, time/batch = 0.022
Read data: 0.00016069412231445312
iter 14168 (epoch 23), train_loss = 2.155, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 14169 (epoch 23), train_loss = 2.577, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 14170 (epoch 23), train_loss = 2.669, time/batch = 0.024
Read data: 0.00015306472778320312
iter 14171 (epoch 23), train_loss = 2.525, time/batch = 0.029
Read data: 0.00012612342834472656
iter 14172 (epoch 23), train_loss = 2.515, time/batch = 0.032
Read data: 0.0001373291015625
iter 14173 (epoch 23), train_loss = 2.253, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 14174 (epoch 23), train_loss = 2.572, time/batch = 0.025
Read data: 0.00021982192993164062
iter 14175 (epoch 23), train_loss = 2.386, time/batch = 0.020
Read data: 0.000125885009765625
iter 14176 (epoch 23), train_loss = 2.798, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 14177 (epoch 23), train_loss = 2.740, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 14178 (epoch 23), train_loss = 2.189, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 14179 (epoch 23), train_loss = 2.596, time/batch = 0.028
Read data: 0.00013589859008789062
iter 14180 (epoch 23), train_loss = 2.361, time/batch = 0.030
Read data: 0.00011396408081054688
iter 14181 (epoch 23), train_loss = 2.397, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 14182 (epoch 23), train_loss = 2.481, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 14183 (epoch 23), train_loss = 2.283, time/batch = 0.025
Read data: 0.00012731552124023438
iter 14184 (epoch 23), train_loss = 2.566, time/batch = 0.031
Read data: 0.00013017654418945312
iter 14185 (epoch 23), train_loss = 2.258, time/batch = 0.038
Read data: 9.202957153320312e-05
iter 14186 (epoch 23), train_loss = 2.123, time/batch = 0.028
Read data: 0.00015687942504882812
iter 14187 (epoch 23), train_loss = 2.622, time/batch = 0.031
Read data: 9.012222290039062e-05
iter 14188 (epoch 23), train_loss = 2.498, time/batch = 0.026
Read data: 0.00016546249389648438
iter 14189 (epoch 23), train_loss = 2.720, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 14190 (epoch 23), train_loss = 2.516, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 14191 (epoch 23), train_loss = 2.786, time/batch = 0.034
Read data: 0.00017333030700683594
iter 14192 (epoch 23), train_loss = 2.555, time/batch = 0.024
Read data: 0.00013375282287597656
iter 14193 (epoch 23), train_loss = 2.741, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 14194 (epoch 23), train_loss = 2.605, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 14195 (epoch 23), train_loss = 2.520, time/batch = 0.022
Read data: 9.274482727050781e-05
iter 14196 (epoch 23), train_loss = 2.666, time/batch = 0.030
Read data: 0.00021409988403320312
iter 14197 (epoch 23), train_loss = 2.517, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 14198 (epoch 23), train_loss = 3.047, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 14199 (epoch 23), train_loss = 2.241, time/batch = 0.025
Read data: 0.0001652240753173828
iter 14200 (epoch 23), train_loss = 2.275, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 14201 (epoch 23), train_loss = 2.422, time/batch = 0.024
Read data: 0.0001595020294189453
iter 14202 (epoch 23), train_loss = 2.512, time/batch = 0.029
Read data: 0.0001709461212158203
iter 14203 (epoch 23), train_loss = 2.555, time/batch = 0.025
Read data: 0.00013017654418945312
iter 14204 (epoch 23), train_loss = 2.399, time/batch = 0.026
Read data: 0.00013184547424316406
iter 14205 (epoch 23), train_loss = 2.398, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 14206 (epoch 23), train_loss = 2.615, time/batch = 0.026
Read data: 0.00015783309936523438
iter 14207 (epoch 23), train_loss = 2.516, time/batch = 0.021
Read data: 8.988380432128906e-05
iter 14208 (epoch 23), train_loss = 2.201, time/batch = 0.028
Read data: 9.703636169433594e-05
iter 14209 (epoch 23), train_loss = 2.657, time/batch = 0.030
Read data: 0.00015974044799804688
iter 14210 (epoch 23), train_loss = 2.059, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 14211 (epoch 23), train_loss = 2.386, time/batch = 0.023
Read data: 0.000125885009765625
iter 14212 (epoch 23), train_loss = 2.595, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 14213 (epoch 23), train_loss = 2.479, time/batch = 0.034
Read data: 8.463859558105469e-05
iter 14214 (epoch 23), train_loss = 2.947, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 14215 (epoch 23), train_loss = 2.458, time/batch = 0.026
Read data: 0.00016307830810546875
iter 14216 (epoch 23), train_loss = 2.667, time/batch = 0.026
Read data: 0.00013875961303710938
iter 14217 (epoch 23), train_loss = 2.011, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 14218 (epoch 23), train_loss = 2.672, time/batch = 0.026
Read data: 0.00016617774963378906
iter 14219 (epoch 23), train_loss = 2.806, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 14220 (epoch 23), train_loss = 2.409, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 14221 (epoch 23), train_loss = 2.225, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 14222 (epoch 23), train_loss = 2.514, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 14223 (epoch 23), train_loss = 2.395, time/batch = 0.032
Read data: 9.059906005859375e-05
iter 14224 (epoch 23), train_loss = 2.435, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 14225 (epoch 23), train_loss = 2.656, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 14226 (epoch 23), train_loss = 2.604, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 14227 (epoch 23), train_loss = 2.249, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 14228 (epoch 23), train_loss = 2.538, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 14229 (epoch 23), train_loss = 2.418, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 14230 (epoch 23), train_loss = 2.333, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 14231 (epoch 23), train_loss = 2.052, time/batch = 0.037
Read data: 8.916854858398438e-05
iter 14232 (epoch 23), train_loss = 2.537, time/batch = 0.032
Read data: 9.1552734375e-05
iter 14233 (epoch 23), train_loss = 2.256, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 14234 (epoch 23), train_loss = 2.634, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 14235 (epoch 23), train_loss = 2.702, time/batch = 0.032
Read data: 0.00013899803161621094
iter 14236 (epoch 23), train_loss = 2.387, time/batch = 0.025
Read data: 0.00012922286987304688
iter 14237 (epoch 23), train_loss = 2.830, time/batch = 0.021
Read data: 8.177757263183594e-05
iter 14238 (epoch 23), train_loss = 2.855, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 14239 (epoch 23), train_loss = 2.308, time/batch = 0.028
Read data: 9.1552734375e-05
iter 14240 (epoch 23), train_loss = 2.468, time/batch = 0.028
Read data: 0.00016832351684570312
iter 14241 (epoch 23), train_loss = 2.769, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 14242 (epoch 23), train_loss = 2.320, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 14243 (epoch 23), train_loss = 3.136, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 14244 (epoch 23), train_loss = 2.247, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 14245 (epoch 23), train_loss = 2.835, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 14246 (epoch 23), train_loss = 2.287, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 14247 (epoch 23), train_loss = 2.418, time/batch = 0.022
Read data: 0.0001575946807861328
iter 14248 (epoch 23), train_loss = 2.812, time/batch = 0.031
Read data: 0.00013327598571777344
iter 14249 (epoch 23), train_loss = 2.656, time/batch = 0.025
Read data: 0.0001678466796875
iter 14250 (epoch 23), train_loss = 2.539, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 14251 (epoch 23), train_loss = 2.181, time/batch = 0.023
Read data: 0.00013184547424316406
iter 14252 (epoch 23), train_loss = 2.578, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 14253 (epoch 23), train_loss = 2.384, time/batch = 0.022
Read data: 0.00015497207641601562
iter 14254 (epoch 23), train_loss = 2.649, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 14255 (epoch 23), train_loss = 2.342, time/batch = 0.030
Read data: 0.00012445449829101562
iter 14256 (epoch 23), train_loss = 2.399, time/batch = 0.024
Read data: 0.0001583099365234375
iter 14257 (epoch 23), train_loss = 2.670, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 14258 (epoch 23), train_loss = 2.374, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 14259 (epoch 23), train_loss = 2.448, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 14260 (epoch 23), train_loss = 2.313, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 14261 (epoch 23), train_loss = 2.743, time/batch = 0.027
Read data: 0.00011682510375976562
iter 14262 (epoch 23), train_loss = 2.453, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 14263 (epoch 23), train_loss = 2.480, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 14264 (epoch 23), train_loss = 2.722, time/batch = 0.025
Read data: 0.00013017654418945312
iter 14265 (epoch 23), train_loss = 2.406, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 14266 (epoch 23), train_loss = 2.262, time/batch = 0.038
Read data: 0.0001323223114013672
iter 14267 (epoch 23), train_loss = 2.431, time/batch = 0.027
Read data: 0.00014472007751464844
iter 14268 (epoch 23), train_loss = 2.377, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 14269 (epoch 23), train_loss = 2.632, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 14270 (epoch 23), train_loss = 2.392, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 14271 (epoch 23), train_loss = 2.031, time/batch = 0.025
Read data: 7.62939453125e-05
iter 14272 (epoch 23), train_loss = 2.757, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 14273 (epoch 23), train_loss = 2.154, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 14274 (epoch 23), train_loss = 2.724, time/batch = 0.027
Read data: 0.00019168853759765625
iter 14275 (epoch 23), train_loss = 2.626, time/batch = 0.027
Read data: 0.0001220703125
iter 14276 (epoch 23), train_loss = 2.603, time/batch = 0.031
Read data: 0.0001308917999267578
iter 14277 (epoch 23), train_loss = 2.511, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 14278 (epoch 23), train_loss = 2.269, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 14279 (epoch 23), train_loss = 2.044, time/batch = 0.027
Read data: 0.00013184547424316406
iter 14280 (epoch 23), train_loss = 2.915, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 14281 (epoch 23), train_loss = 3.142, time/batch = 0.024
Read data: 0.00011897087097167969
iter 14282 (epoch 23), train_loss = 2.449, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 14283 (epoch 23), train_loss = 2.297, time/batch = 0.025
Read data: 0.00013113021850585938
iter 14284 (epoch 23), train_loss = 2.660, time/batch = 0.034
Read data: 0.00012302398681640625
iter 14285 (epoch 23), train_loss = 2.630, time/batch = 0.028
Read data: 0.0001316070556640625
iter 14286 (epoch 23), train_loss = 2.644, time/batch = 0.032
Read data: 9.083747863769531e-05
iter 14287 (epoch 23), train_loss = 2.795, time/batch = 0.024
Read data: 0.00013875961303710938
iter 14288 (epoch 23), train_loss = 2.696, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 14289 (epoch 23), train_loss = 2.101, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 14290 (epoch 23), train_loss = 2.816, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 14291 (epoch 23), train_loss = 2.427, time/batch = 0.021
Read data: 0.0001456737518310547
iter 14292 (epoch 23), train_loss = 2.564, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 14293 (epoch 23), train_loss = 2.261, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 14294 (epoch 23), train_loss = 2.389, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 14295 (epoch 23), train_loss = 2.516, time/batch = 0.025
Read data: 0.00013375282287597656
iter 14296 (epoch 23), train_loss = 2.525, time/batch = 0.022
Read data: 7.939338684082031e-05
iter 14297 (epoch 23), train_loss = 2.768, time/batch = 0.024
Read data: 0.00016760826110839844
iter 14298 (epoch 23), train_loss = 2.604, time/batch = 0.027
Read data: 0.0001571178436279297
iter 14299 (epoch 23), train_loss = 2.670, time/batch = 0.024
Read data: 0.0002734661102294922
iter 14300 (epoch 23), train_loss = 2.160, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 14301 (epoch 23), train_loss = 2.567, time/batch = 0.022
Read data: 0.00016880035400390625
iter 14302 (epoch 23), train_loss = 2.855, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 14303 (epoch 23), train_loss = 2.350, time/batch = 0.021
Read data: 0.00015211105346679688
iter 14304 (epoch 23), train_loss = 2.617, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 14305 (epoch 23), train_loss = 2.541, time/batch = 0.024
Read data: 0.00014495849609375
iter 14306 (epoch 23), train_loss = 2.669, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 14307 (epoch 23), train_loss = 2.610, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 14308 (epoch 23), train_loss = 2.977, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 14309 (epoch 23), train_loss = 2.490, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 14310 (epoch 23), train_loss = 2.630, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 14311 (epoch 23), train_loss = 2.848, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 14312 (epoch 23), train_loss = 1.972, time/batch = 0.030
Read data: 0.00013113021850585938
iter 14313 (epoch 23), train_loss = 2.524, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 14314 (epoch 23), train_loss = 2.578, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 14315 (epoch 23), train_loss = 2.433, time/batch = 0.023
Read data: 0.00012826919555664062
iter 14316 (epoch 23), train_loss = 2.310, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 14317 (epoch 23), train_loss = 2.321, time/batch = 0.029
Read data: 0.00015091896057128906
iter 14318 (epoch 23), train_loss = 2.208, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 14319 (epoch 23), train_loss = 2.732, time/batch = 0.041
Read data: 8.511543273925781e-05
iter 14320 (epoch 23), train_loss = 2.357, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 14321 (epoch 23), train_loss = 2.325, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 14322 (epoch 23), train_loss = 2.493, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 14323 (epoch 23), train_loss = 2.324, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 14324 (epoch 23), train_loss = 2.377, time/batch = 0.023
Read data: 0.00013065338134765625
iter 14325 (epoch 23), train_loss = 2.387, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 14326 (epoch 23), train_loss = 2.703, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 14327 (epoch 23), train_loss = 2.404, time/batch = 0.027
Read data: 0.00013446807861328125
iter 14328 (epoch 23), train_loss = 2.284, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 14329 (epoch 23), train_loss = 2.416, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 14330 (epoch 23), train_loss = 2.262, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 14331 (epoch 23), train_loss = 2.726, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 14332 (epoch 23), train_loss = 2.344, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 14333 (epoch 23), train_loss = 2.595, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 14334 (epoch 23), train_loss = 2.467, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 14335 (epoch 23), train_loss = 2.736, time/batch = 0.028
Read data: 0.00014710426330566406
iter 14336 (epoch 23), train_loss = 2.588, time/batch = 0.040
Read data: 8.654594421386719e-05
iter 14337 (epoch 23), train_loss = 2.730, time/batch = 0.028
Read data: 8.869171142578125e-05
iter 14338 (epoch 23), train_loss = 2.515, time/batch = 0.030
Read data: 8.869171142578125e-05
iter 14339 (epoch 23), train_loss = 2.835, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 14340 (epoch 23), train_loss = 2.668, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 14341 (epoch 23), train_loss = 2.497, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 14342 (epoch 23), train_loss = 2.459, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 14343 (epoch 23), train_loss = 2.428, time/batch = 0.032
Read data: 0.00020122528076171875
iter 14344 (epoch 23), train_loss = 2.426, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 14345 (epoch 23), train_loss = 2.420, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 14346 (epoch 23), train_loss = 2.123, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 14347 (epoch 23), train_loss = 2.257, time/batch = 0.020
Read data: 0.00014901161193847656
iter 14348 (epoch 23), train_loss = 2.496, time/batch = 0.027
Read data: 0.00018358230590820312
iter 14349 (epoch 23), train_loss = 2.468, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 14350 (epoch 23), train_loss = 2.124, time/batch = 0.034
Read data: 7.987022399902344e-05
iter 14351 (epoch 23), train_loss = 2.278, time/batch = 0.029
Read data: 0.00012755393981933594
iter 14352 (epoch 23), train_loss = 2.559, time/batch = 0.026
Read data: 0.00010251998901367188
iter 14353 (epoch 23), train_loss = 2.373, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 14354 (epoch 23), train_loss = 2.508, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 14355 (epoch 23), train_loss = 2.598, time/batch = 0.024
Read data: 0.0001621246337890625
iter 14356 (epoch 23), train_loss = 2.499, time/batch = 0.022
Read data: 9.918212890625e-05
iter 14357 (epoch 23), train_loss = 2.352, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 14358 (epoch 23), train_loss = 2.789, time/batch = 0.027
Read data: 0.00010347366333007812
iter 14359 (epoch 23), train_loss = 2.670, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 14360 (epoch 23), train_loss = 2.778, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 14361 (epoch 23), train_loss = 2.373, time/batch = 0.026
Read data: 0.00016069412231445312
iter 14362 (epoch 23), train_loss = 2.470, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 14363 (epoch 23), train_loss = 2.317, time/batch = 0.023
Read data: 0.0001266002655029297
iter 14364 (epoch 23), train_loss = 2.152, time/batch = 0.027
Read data: 0.00016236305236816406
iter 14365 (epoch 23), train_loss = 2.628, time/batch = 0.025
Read data: 0.00016355514526367188
iter 14366 (epoch 23), train_loss = 2.272, time/batch = 0.028
Read data: 0.00016021728515625
iter 14367 (epoch 23), train_loss = 2.568, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 14368 (epoch 23), train_loss = 2.453, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 14369 (epoch 23), train_loss = 2.435, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 14370 (epoch 23), train_loss = 2.106, time/batch = 0.026
Read data: 0.00016355514526367188
iter 14371 (epoch 23), train_loss = 2.287, time/batch = 0.025
Read data: 0.00015687942504882812
iter 14372 (epoch 23), train_loss = 2.149, time/batch = 0.029
Read data: 0.00016045570373535156
iter 14373 (epoch 23), train_loss = 2.444, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 14374 (epoch 23), train_loss = 2.452, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 14375 (epoch 23), train_loss = 2.592, time/batch = 0.027
Read data: 0.0001285076141357422
iter 14376 (epoch 23), train_loss = 2.487, time/batch = 0.030
Read data: 0.00012969970703125
iter 14377 (epoch 23), train_loss = 2.418, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 14378 (epoch 23), train_loss = 2.804, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 14379 (epoch 23), train_loss = 2.261, time/batch = 0.025
Read data: 0.00013494491577148438
iter 14380 (epoch 23), train_loss = 2.477, time/batch = 0.025
Read data: 9.1552734375e-05
iter 14381 (epoch 23), train_loss = 2.400, time/batch = 0.029
Read data: 0.0001518726348876953
iter 14382 (epoch 23), train_loss = 2.559, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 14383 (epoch 23), train_loss = 2.610, time/batch = 0.022
Read data: 0.00016236305236816406
iter 14384 (epoch 23), train_loss = 2.551, time/batch = 0.031
Read data: 0.00016736984252929688
iter 14385 (epoch 23), train_loss = 2.676, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 14386 (epoch 23), train_loss = 2.711, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 14387 (epoch 23), train_loss = 2.730, time/batch = 0.024
Read data: 0.00013256072998046875
iter 14388 (epoch 23), train_loss = 2.206, time/batch = 0.024
Read data: 0.00014734268188476562
iter 14389 (epoch 23), train_loss = 2.490, time/batch = 0.036
Read data: 8.153915405273438e-05
iter 14390 (epoch 23), train_loss = 2.434, time/batch = 0.036
Read data: 9.918212890625e-05
iter 14391 (epoch 23), train_loss = 2.130, time/batch = 0.028
Read data: 0.0009851455688476562
iter 14392 (epoch 23), train_loss = 2.888, time/batch = 0.020
Read data: 8.58306884765625e-05
iter 14393 (epoch 23), train_loss = 2.508, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 14394 (epoch 23), train_loss = 2.990, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 14395 (epoch 23), train_loss = 2.075, time/batch = 0.026
Read data: 0.00018739700317382812
iter 14396 (epoch 23), train_loss = 2.478, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 14397 (epoch 23), train_loss = 2.393, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 14398 (epoch 23), train_loss = 2.581, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 14399 (epoch 23), train_loss = 2.560, time/batch = 0.021
Read data: 0.0001735687255859375
iter 14400 (epoch 23), train_loss = 2.763, time/batch = 0.032
Read data: 0.000164031982421875
iter 14401 (epoch 24), train_loss = 2.502, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 14402 (epoch 24), train_loss = 2.520, time/batch = 0.021
Read data: 0.0001494884490966797
iter 14403 (epoch 24), train_loss = 2.397, time/batch = 0.026
Read data: 0.00012612342834472656
iter 14404 (epoch 24), train_loss = 3.029, time/batch = 0.037
Read data: 8.225440979003906e-05
iter 14405 (epoch 24), train_loss = 2.494, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 14406 (epoch 24), train_loss = 2.380, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 14407 (epoch 24), train_loss = 2.761, time/batch = 0.028
Read data: 0.0001761913299560547
iter 14408 (epoch 24), train_loss = 2.784, time/batch = 0.028
Read data: 0.0001251697540283203
iter 14409 (epoch 24), train_loss = 2.870, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 14410 (epoch 24), train_loss = 2.448, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 14411 (epoch 24), train_loss = 2.650, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 14412 (epoch 24), train_loss = 2.406, time/batch = 0.028
Read data: 0.000156402587890625
iter 14413 (epoch 24), train_loss = 2.396, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 14414 (epoch 24), train_loss = 2.414, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 14415 (epoch 24), train_loss = 2.598, time/batch = 0.025
Read data: 0.00012636184692382812
iter 14416 (epoch 24), train_loss = 2.337, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 14417 (epoch 24), train_loss = 2.721, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 14418 (epoch 24), train_loss = 2.876, time/batch = 0.041
Read data: 8.797645568847656e-05
iter 14419 (epoch 24), train_loss = 2.678, time/batch = 0.029
Read data: 9.083747863769531e-05
iter 14420 (epoch 24), train_loss = 2.652, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 14421 (epoch 24), train_loss = 2.262, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 14422 (epoch 24), train_loss = 2.593, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 14423 (epoch 24), train_loss = 2.610, time/batch = 0.024
Read data: 0.0001633167266845703
iter 14424 (epoch 24), train_loss = 2.736, time/batch = 0.030
Read data: 0.0001552104949951172
iter 14425 (epoch 24), train_loss = 2.498, time/batch = 0.036
Read data: 8.821487426757812e-05
iter 14426 (epoch 24), train_loss = 2.552, time/batch = 0.037
Read data: 7.724761962890625e-05
iter 14427 (epoch 24), train_loss = 2.410, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 14428 (epoch 24), train_loss = 2.352, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 14429 (epoch 24), train_loss = 2.369, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 14430 (epoch 24), train_loss = 2.792, time/batch = 0.029
Read data: 0.00012373924255371094
iter 14431 (epoch 24), train_loss = 2.650, time/batch = 0.033
Read data: 8.893013000488281e-05
iter 14432 (epoch 24), train_loss = 2.585, time/batch = 0.026
Read data: 0.00012922286987304688
iter 14433 (epoch 24), train_loss = 2.040, time/batch = 0.026
Read data: 0.00015044212341308594
iter 14434 (epoch 24), train_loss = 2.506, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 14435 (epoch 24), train_loss = 2.257, time/batch = 0.023
Read data: 0.00012922286987304688
iter 14436 (epoch 24), train_loss = 2.667, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 14437 (epoch 24), train_loss = 2.624, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 14438 (epoch 24), train_loss = 2.525, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 14439 (epoch 24), train_loss = 2.369, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 14440 (epoch 24), train_loss = 2.395, time/batch = 0.031
Read data: 0.0001285076141357422
iter 14441 (epoch 24), train_loss = 2.037, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 14442 (epoch 24), train_loss = 2.301, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 14443 (epoch 24), train_loss = 2.087, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 14444 (epoch 24), train_loss = 2.314, time/batch = 0.025
Read data: 0.00012946128845214844
iter 14445 (epoch 24), train_loss = 2.255, time/batch = 0.021
Read data: 8.034706115722656e-05
iter 14446 (epoch 24), train_loss = 2.307, time/batch = 0.025
Read data: 0.00010013580322265625
iter 14447 (epoch 24), train_loss = 2.517, time/batch = 0.025
Read data: 9.1552734375e-05
iter 14448 (epoch 24), train_loss = 2.085, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 14449 (epoch 24), train_loss = 2.557, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 14450 (epoch 24), train_loss = 2.104, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 14451 (epoch 24), train_loss = 2.414, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 14452 (epoch 24), train_loss = 2.449, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 14453 (epoch 24), train_loss = 2.165, time/batch = 0.021
Read data: 9.250640869140625e-05
iter 14454 (epoch 24), train_loss = 2.565, time/batch = 0.024
Read data: 0.00015854835510253906
iter 14455 (epoch 24), train_loss = 2.548, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 14456 (epoch 24), train_loss = 2.649, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 14457 (epoch 24), train_loss = 2.643, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 14458 (epoch 24), train_loss = 1.889, time/batch = 0.024
Read data: 9.107589721679688e-05
iter 14459 (epoch 24), train_loss = 2.441, time/batch = 0.026
Read data: 0.00012993812561035156
iter 14460 (epoch 24), train_loss = 1.853, time/batch = 0.026
Read data: 9.822845458984375e-05
iter 14461 (epoch 24), train_loss = 2.278, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 14462 (epoch 24), train_loss = 2.284, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 14463 (epoch 24), train_loss = 2.500, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 14464 (epoch 24), train_loss = 2.424, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 14465 (epoch 24), train_loss = 2.399, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 14466 (epoch 24), train_loss = 1.676, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 14467 (epoch 24), train_loss = 2.251, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 14468 (epoch 24), train_loss = 2.340, time/batch = 0.028
Read data: 0.00012445449829101562
iter 14469 (epoch 24), train_loss = 2.563, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 14470 (epoch 24), train_loss = 2.562, time/batch = 0.021
Read data: 9.5367431640625e-05
iter 14471 (epoch 24), train_loss = 2.590, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 14472 (epoch 24), train_loss = 2.187, time/batch = 0.023
Read data: 0.0001773834228515625
iter 14473 (epoch 24), train_loss = 2.256, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 14474 (epoch 24), train_loss = 2.622, time/batch = 0.032
Read data: 7.700920104980469e-05
iter 14475 (epoch 24), train_loss = 2.713, time/batch = 0.023
Read data: 0.0001418590545654297
iter 14476 (epoch 24), train_loss = 2.767, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 14477 (epoch 24), train_loss = 2.479, time/batch = 0.034
Read data: 8.535385131835938e-05
iter 14478 (epoch 24), train_loss = 2.484, time/batch = 0.028
Read data: 0.00014090538024902344
iter 14479 (epoch 24), train_loss = 2.233, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 14480 (epoch 24), train_loss = 2.582, time/batch = 0.025
Read data: 0.00013446807861328125
iter 14481 (epoch 24), train_loss = 2.620, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 14482 (epoch 24), train_loss = 2.296, time/batch = 0.023
Read data: 0.00010061264038085938
iter 14483 (epoch 24), train_loss = 2.486, time/batch = 0.029
Read data: 0.0001010894775390625
iter 14484 (epoch 24), train_loss = 2.243, time/batch = 0.029
Read data: 9.34600830078125e-05
iter 14485 (epoch 24), train_loss = 2.668, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 14486 (epoch 24), train_loss = 2.415, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 14487 (epoch 24), train_loss = 2.439, time/batch = 0.026
Read data: 0.0001609325408935547
iter 14488 (epoch 24), train_loss = 2.335, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 14489 (epoch 24), train_loss = 2.553, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 14490 (epoch 24), train_loss = 2.675, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 14491 (epoch 24), train_loss = 2.536, time/batch = 0.025
Read data: 0.00016164779663085938
iter 14492 (epoch 24), train_loss = 2.631, time/batch = 0.025
Read data: 0.0001659393310546875
iter 14493 (epoch 24), train_loss = 2.601, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 14494 (epoch 24), train_loss = 2.167, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 14495 (epoch 24), train_loss = 2.412, time/batch = 0.030
Read data: 0.00013208389282226562
iter 14496 (epoch 24), train_loss = 2.426, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 14497 (epoch 24), train_loss = 2.092, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 14498 (epoch 24), train_loss = 2.299, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 14499 (epoch 24), train_loss = 2.501, time/batch = 0.028
Read data: 0.0001556873321533203
iter 14500 (epoch 24), train_loss = 2.608, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 14501 (epoch 24), train_loss = 2.778, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 14502 (epoch 24), train_loss = 2.503, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 14503 (epoch 24), train_loss = 2.301, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 14504 (epoch 24), train_loss = 2.655, time/batch = 0.025
Read data: 0.00016188621520996094
iter 14505 (epoch 24), train_loss = 2.437, time/batch = 0.025
Read data: 0.0001068115234375
iter 14506 (epoch 24), train_loss = 2.113, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 14507 (epoch 24), train_loss = 2.419, time/batch = 0.033
Read data: 0.00012564659118652344
iter 14508 (epoch 24), train_loss = 2.261, time/batch = 0.023
Read data: 0.00014138221740722656
iter 14509 (epoch 24), train_loss = 2.283, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 14510 (epoch 24), train_loss = 2.713, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 14511 (epoch 24), train_loss = 2.890, time/batch = 0.023
Read data: 0.0001480579376220703
iter 14512 (epoch 24), train_loss = 2.586, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 14513 (epoch 24), train_loss = 2.017, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 14514 (epoch 24), train_loss = 2.362, time/batch = 0.028
Read data: 9.72747802734375e-05
iter 14515 (epoch 24), train_loss = 2.738, time/batch = 0.022
Read data: 0.00018739700317382812
iter 14516 (epoch 24), train_loss = 2.559, time/batch = 0.032
Read data: 9.441375732421875e-05
iter 14517 (epoch 24), train_loss = 2.556, time/batch = 0.039
Read data: 9.441375732421875e-05
iter 14518 (epoch 24), train_loss = 2.438, time/batch = 0.030
Read data: 9.608268737792969e-05
iter 14519 (epoch 24), train_loss = 2.578, time/batch = 0.026
Read data: 0.00018215179443359375
iter 14520 (epoch 24), train_loss = 2.644, time/batch = 0.022
Read data: 8.368492126464844e-05
iter 14521 (epoch 24), train_loss = 2.603, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 14522 (epoch 24), train_loss = 2.681, time/batch = 0.021
Read data: 0.0001316070556640625
iter 14523 (epoch 24), train_loss = 2.648, time/batch = 0.028
Read data: 0.00016450881958007812
iter 14524 (epoch 24), train_loss = 2.477, time/batch = 0.035
Read data: 0.00015687942504882812
iter 14525 (epoch 24), train_loss = 2.827, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 14526 (epoch 24), train_loss = 2.578, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 14527 (epoch 24), train_loss = 2.459, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 14528 (epoch 24), train_loss = 2.090, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 14529 (epoch 24), train_loss = 2.417, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 14530 (epoch 24), train_loss = 2.444, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 14531 (epoch 24), train_loss = 2.815, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 14532 (epoch 24), train_loss = 2.558, time/batch = 0.025
Read data: 0.000102996826171875
iter 14533 (epoch 24), train_loss = 2.411, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 14534 (epoch 24), train_loss = 2.666, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 14535 (epoch 24), train_loss = 2.425, time/batch = 0.027
Read data: 0.00017690658569335938
iter 14536 (epoch 24), train_loss = 2.236, time/batch = 0.025
Read data: 0.0001533031463623047
iter 14537 (epoch 24), train_loss = 2.477, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 14538 (epoch 24), train_loss = 2.573, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 14539 (epoch 24), train_loss = 2.515, time/batch = 0.028
Read data: 0.00012302398681640625
iter 14540 (epoch 24), train_loss = 1.866, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 14541 (epoch 24), train_loss = 2.356, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 14542 (epoch 24), train_loss = 2.391, time/batch = 0.024
Read data: 7.557868957519531e-05
iter 14543 (epoch 24), train_loss = 2.327, time/batch = 0.021
Read data: 0.0002110004425048828
iter 14544 (epoch 24), train_loss = 2.644, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 14545 (epoch 24), train_loss = 2.247, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 14546 (epoch 24), train_loss = 2.218, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 14547 (epoch 24), train_loss = 2.242, time/batch = 0.029
Read data: 0.0001461505889892578
iter 14548 (epoch 24), train_loss = 2.302, time/batch = 0.040
Read data: 0.00016260147094726562
iter 14549 (epoch 24), train_loss = 2.603, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 14550 (epoch 24), train_loss = 2.498, time/batch = 0.028
Read data: 9.632110595703125e-05
iter 14551 (epoch 24), train_loss = 2.258, time/batch = 0.022
Read data: 0.00013399124145507812
iter 14552 (epoch 24), train_loss = 2.571, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 14553 (epoch 24), train_loss = 2.209, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 14554 (epoch 24), train_loss = 2.975, time/batch = 0.026
Read data: 0.00010347366333007812
iter 14555 (epoch 24), train_loss = 2.368, time/batch = 0.025
Read data: 0.00012254714965820312
iter 14556 (epoch 24), train_loss = 2.574, time/batch = 0.031
Read data: 0.0001838207244873047
iter 14557 (epoch 24), train_loss = 2.356, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 14558 (epoch 24), train_loss = 2.446, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 14559 (epoch 24), train_loss = 2.583, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 14560 (epoch 24), train_loss = 2.902, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 14561 (epoch 24), train_loss = 2.427, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 14562 (epoch 24), train_loss = 2.624, time/batch = 0.025
Read data: 0.00012540817260742188
iter 14563 (epoch 24), train_loss = 2.251, time/batch = 0.023
Read data: 8.535385131835938e-05
iter 14564 (epoch 24), train_loss = 2.477, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 14565 (epoch 24), train_loss = 2.350, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 14566 (epoch 24), train_loss = 2.614, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 14567 (epoch 24), train_loss = 2.452, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 14568 (epoch 24), train_loss = 2.812, time/batch = 0.023
Read data: 0.0001456737518310547
iter 14569 (epoch 24), train_loss = 2.402, time/batch = 0.027
Read data: 0.00012493133544921875
iter 14570 (epoch 24), train_loss = 2.417, time/batch = 0.025
Read data: 0.00014972686767578125
iter 14571 (epoch 24), train_loss = 2.621, time/batch = 0.025
Read data: 0.00014209747314453125
iter 14572 (epoch 24), train_loss = 2.879, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 14573 (epoch 24), train_loss = 2.205, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 14574 (epoch 24), train_loss = 3.003, time/batch = 0.023
Read data: 0.00012636184692382812
iter 14575 (epoch 24), train_loss = 2.255, time/batch = 0.025
Read data: 0.00013327598571777344
iter 14576 (epoch 24), train_loss = 2.664, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 14577 (epoch 24), train_loss = 2.363, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 14578 (epoch 24), train_loss = 2.739, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 14579 (epoch 24), train_loss = 2.412, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 14580 (epoch 24), train_loss = 2.299, time/batch = 0.023
Read data: 0.0001342296600341797
iter 14581 (epoch 24), train_loss = 2.465, time/batch = 0.023
Read data: 9.5367431640625e-05
iter 14582 (epoch 24), train_loss = 2.656, time/batch = 0.039
Read data: 8.320808410644531e-05
iter 14583 (epoch 24), train_loss = 2.846, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 14584 (epoch 24), train_loss = 2.381, time/batch = 0.032
Read data: 0.0001246929168701172
iter 14585 (epoch 24), train_loss = 2.489, time/batch = 0.023
Read data: 0.00013136863708496094
iter 14586 (epoch 24), train_loss = 2.523, time/batch = 0.021
Read data: 0.00014090538024902344
iter 14587 (epoch 24), train_loss = 2.777, time/batch = 0.029
Read data: 0.00013065338134765625
iter 14588 (epoch 24), train_loss = 2.267, time/batch = 0.022
Read data: 0.00014138221740722656
iter 14589 (epoch 24), train_loss = 2.355, time/batch = 0.032
Read data: 0.00010418891906738281
iter 14590 (epoch 24), train_loss = 3.009, time/batch = 0.038
Read data: 8.487701416015625e-05
iter 14591 (epoch 24), train_loss = 2.634, time/batch = 0.034
Read data: 0.0002071857452392578
iter 14592 (epoch 24), train_loss = 2.703, time/batch = 0.026
Read data: 0.0001361370086669922
iter 14593 (epoch 24), train_loss = 2.251, time/batch = 0.030
Read data: 0.00013589859008789062
iter 14594 (epoch 24), train_loss = 2.254, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 14595 (epoch 24), train_loss = 2.568, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 14596 (epoch 24), train_loss = 2.312, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 14597 (epoch 24), train_loss = 2.794, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 14598 (epoch 24), train_loss = 2.374, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 14599 (epoch 24), train_loss = 2.667, time/batch = 0.033
Read data: 0.0001308917999267578
iter 14600 (epoch 24), train_loss = 2.262, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 14601 (epoch 24), train_loss = 2.820, time/batch = 0.035
Read data: 8.726119995117188e-05
iter 14602 (epoch 24), train_loss = 2.522, time/batch = 0.030
Read data: 0.00011205673217773438
iter 14603 (epoch 24), train_loss = 2.357, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 14604 (epoch 24), train_loss = 2.449, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 14605 (epoch 24), train_loss = 2.649, time/batch = 0.031
Read data: 9.036064147949219e-05
iter 14606 (epoch 24), train_loss = 2.380, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 14607 (epoch 24), train_loss = 2.709, time/batch = 0.035
Read data: 0.00013494491577148438
iter 14608 (epoch 24), train_loss = 2.274, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 14609 (epoch 24), train_loss = 2.623, time/batch = 0.035
Read data: 8.726119995117188e-05
iter 14610 (epoch 24), train_loss = 2.522, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 14611 (epoch 24), train_loss = 2.318, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 14612 (epoch 24), train_loss = 2.252, time/batch = 0.025
Read data: 0.0001220703125
iter 14613 (epoch 24), train_loss = 2.600, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 14614 (epoch 24), train_loss = 2.451, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 14615 (epoch 24), train_loss = 2.716, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 14616 (epoch 24), train_loss = 2.493, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 14617 (epoch 24), train_loss = 2.792, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 14618 (epoch 24), train_loss = 2.487, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 14619 (epoch 24), train_loss = 2.284, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 14620 (epoch 24), train_loss = 2.651, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 14621 (epoch 24), train_loss = 2.184, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 14622 (epoch 24), train_loss = 2.396, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 14623 (epoch 24), train_loss = 2.379, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 14624 (epoch 24), train_loss = 2.662, time/batch = 0.034
Read data: 8.082389831542969e-05
iter 14625 (epoch 24), train_loss = 3.077, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 14626 (epoch 24), train_loss = 2.838, time/batch = 0.033
Read data: 7.724761962890625e-05
iter 14627 (epoch 24), train_loss = 2.630, time/batch = 0.021
Read data: 8.130073547363281e-05
iter 14628 (epoch 24), train_loss = 2.738, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 14629 (epoch 24), train_loss = 2.071, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 14630 (epoch 24), train_loss = 2.564, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 14631 (epoch 24), train_loss = 2.329, time/batch = 0.022
Read data: 8.392333984375e-05
iter 14632 (epoch 24), train_loss = 2.184, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 14633 (epoch 24), train_loss = 2.448, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 14634 (epoch 24), train_loss = 2.636, time/batch = 0.028
Read data: 9.274482727050781e-05
iter 14635 (epoch 24), train_loss = 2.026, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 14636 (epoch 24), train_loss = 2.468, time/batch = 0.032
Read data: 8.106231689453125e-05
iter 14637 (epoch 24), train_loss = 2.630, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 14638 (epoch 24), train_loss = 2.379, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 14639 (epoch 24), train_loss = 2.658, time/batch = 0.021
Read data: 8.130073547363281e-05
iter 14640 (epoch 24), train_loss = 2.313, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 14641 (epoch 24), train_loss = 2.278, time/batch = 0.029
Read data: 0.00012564659118652344
iter 14642 (epoch 24), train_loss = 2.376, time/batch = 0.031
Read data: 7.82012939453125e-05
iter 14643 (epoch 24), train_loss = 2.965, time/batch = 0.029
Read data: 0.00010585784912109375
iter 14644 (epoch 24), train_loss = 2.409, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 14645 (epoch 24), train_loss = 2.522, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 14646 (epoch 24), train_loss = 2.105, time/batch = 0.028
Read data: 8.392333984375e-05
iter 14647 (epoch 24), train_loss = 2.545, time/batch = 0.031
Read data: 7.772445678710938e-05
iter 14648 (epoch 24), train_loss = 2.608, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 14649 (epoch 24), train_loss = 2.340, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 14650 (epoch 24), train_loss = 2.701, time/batch = 0.034
Read data: 8.034706115722656e-05
iter 14651 (epoch 24), train_loss = 2.453, time/batch = 0.028
Read data: 0.00015282630920410156
iter 14652 (epoch 24), train_loss = 2.536, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 14653 (epoch 24), train_loss = 2.154, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 14654 (epoch 24), train_loss = 2.119, time/batch = 0.021
Read data: 0.00010085105895996094
iter 14655 (epoch 24), train_loss = 2.261, time/batch = 0.024
Read data: 9.560585021972656e-05
iter 14656 (epoch 24), train_loss = 2.485, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 14657 (epoch 24), train_loss = 2.183, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 14658 (epoch 24), train_loss = 2.569, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 14659 (epoch 24), train_loss = 2.389, time/batch = 0.026
Read data: 0.0001575946807861328
iter 14660 (epoch 24), train_loss = 2.292, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 14661 (epoch 24), train_loss = 2.792, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 14662 (epoch 24), train_loss = 2.543, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 14663 (epoch 24), train_loss = 2.507, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 14664 (epoch 24), train_loss = 2.727, time/batch = 0.028
Read data: 0.0001010894775390625
iter 14665 (epoch 24), train_loss = 2.511, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 14666 (epoch 24), train_loss = 2.721, time/batch = 0.026
Read data: 0.0001304149627685547
iter 14667 (epoch 24), train_loss = 2.294, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 14668 (epoch 24), train_loss = 2.308, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 14669 (epoch 24), train_loss = 2.820, time/batch = 0.023
Read data: 0.00010347366333007812
iter 14670 (epoch 24), train_loss = 2.607, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 14671 (epoch 24), train_loss = 2.880, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 14672 (epoch 24), train_loss = 2.504, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 14673 (epoch 24), train_loss = 2.544, time/batch = 0.025
Read data: 0.00014066696166992188
iter 14674 (epoch 24), train_loss = 2.133, time/batch = 0.022
Read data: 0.0002276897430419922
iter 14675 (epoch 24), train_loss = 2.177, time/batch = 0.028
Read data: 0.00015163421630859375
iter 14676 (epoch 24), train_loss = 2.262, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 14677 (epoch 24), train_loss = 2.363, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 14678 (epoch 24), train_loss = 2.332, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 14679 (epoch 24), train_loss = 2.875, time/batch = 0.029
Read data: 0.00013971328735351562
iter 14680 (epoch 24), train_loss = 2.420, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 14681 (epoch 24), train_loss = 2.490, time/batch = 0.035
Read data: 0.00016021728515625
iter 14682 (epoch 24), train_loss = 2.295, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 14683 (epoch 24), train_loss = 2.397, time/batch = 0.030
Read data: 9.131431579589844e-05
iter 14684 (epoch 24), train_loss = 2.475, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 14685 (epoch 24), train_loss = 2.442, time/batch = 0.025
Read data: 8.392333984375e-05
iter 14686 (epoch 24), train_loss = 2.528, time/batch = 0.026
Read data: 0.00015664100646972656
iter 14687 (epoch 24), train_loss = 2.101, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 14688 (epoch 24), train_loss = 2.795, time/batch = 0.029
Read data: 0.00015091896057128906
iter 14689 (epoch 24), train_loss = 2.246, time/batch = 0.031
Read data: 0.00016570091247558594
iter 14690 (epoch 24), train_loss = 2.421, time/batch = 0.023
Read data: 0.00010037422180175781
iter 14691 (epoch 24), train_loss = 3.017, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 14692 (epoch 24), train_loss = 2.820, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 14693 (epoch 24), train_loss = 2.060, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 14694 (epoch 24), train_loss = 2.605, time/batch = 0.025
Read data: 0.00011444091796875
iter 14695 (epoch 24), train_loss = 2.213, time/batch = 0.028
Read data: 9.584426879882812e-05
iter 14696 (epoch 24), train_loss = 2.626, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 14697 (epoch 24), train_loss = 2.398, time/batch = 0.030
Read data: 0.0001609325408935547
iter 14698 (epoch 24), train_loss = 2.373, time/batch = 0.021
Read data: 0.00011587142944335938
iter 14699 (epoch 24), train_loss = 2.467, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 14700 (epoch 24), train_loss = 2.309, time/batch = 0.022
Read data: 0.0001456737518310547
iter 14701 (epoch 24), train_loss = 2.644, time/batch = 0.030
Read data: 0.00015878677368164062
iter 14702 (epoch 24), train_loss = 2.647, time/batch = 0.024
Read data: 0.00011658668518066406
iter 14703 (epoch 24), train_loss = 2.076, time/batch = 0.028
Read data: 0.00010395050048828125
iter 14704 (epoch 24), train_loss = 2.473, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 14705 (epoch 24), train_loss = 2.665, time/batch = 0.033
Read data: 0.00016570091247558594
iter 14706 (epoch 24), train_loss = 2.131, time/batch = 0.025
Read data: 0.00010967254638671875
iter 14707 (epoch 24), train_loss = 2.738, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 14708 (epoch 24), train_loss = 3.043, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 14709 (epoch 24), train_loss = 2.198, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 14710 (epoch 24), train_loss = 2.620, time/batch = 0.026
Read data: 0.00011610984802246094
iter 14711 (epoch 24), train_loss = 2.380, time/batch = 0.032
Read data: 8.678436279296875e-05
iter 14712 (epoch 24), train_loss = 2.222, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 14713 (epoch 24), train_loss = 2.715, time/batch = 0.023
Read data: 9.1552734375e-05
iter 14714 (epoch 24), train_loss = 2.515, time/batch = 0.034
Read data: 7.772445678710938e-05
iter 14715 (epoch 24), train_loss = 2.259, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 14716 (epoch 24), train_loss = 2.589, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 14717 (epoch 24), train_loss = 2.206, time/batch = 0.023
Read data: 7.748603820800781e-05
iter 14718 (epoch 24), train_loss = 2.492, time/batch = 0.028
Read data: 0.00011777877807617188
iter 14719 (epoch 24), train_loss = 2.342, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 14720 (epoch 24), train_loss = 2.534, time/batch = 0.030
Read data: 0.00013256072998046875
iter 14721 (epoch 24), train_loss = 2.819, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 14722 (epoch 24), train_loss = 2.388, time/batch = 0.025
Read data: 0.00014829635620117188
iter 14723 (epoch 24), train_loss = 2.236, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 14724 (epoch 24), train_loss = 2.339, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 14725 (epoch 24), train_loss = 2.439, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 14726 (epoch 24), train_loss = 2.342, time/batch = 0.035
Read data: 8.0108642578125e-05
iter 14727 (epoch 24), train_loss = 2.817, time/batch = 0.026
Read data: 0.00012373924255371094
iter 14728 (epoch 24), train_loss = 2.233, time/batch = 0.022
Read data: 0.000102996826171875
iter 14729 (epoch 24), train_loss = 2.139, time/batch = 0.024
Read data: 0.0001614093780517578
iter 14730 (epoch 24), train_loss = 2.335, time/batch = 0.030
Read data: 0.00012135505676269531
iter 14731 (epoch 24), train_loss = 2.442, time/batch = 0.034
Read data: 0.0001125335693359375
iter 14732 (epoch 24), train_loss = 2.269, time/batch = 0.024
Read data: 0.00011563301086425781
iter 14733 (epoch 24), train_loss = 2.136, time/batch = 0.032
Read data: 8.392333984375e-05
iter 14734 (epoch 24), train_loss = 2.743, time/batch = 0.039
Read data: 0.00011372566223144531
iter 14735 (epoch 24), train_loss = 2.218, time/batch = 0.029
Read data: 8.392333984375e-05
iter 14736 (epoch 24), train_loss = 2.836, time/batch = 0.029
Read data: 8.893013000488281e-05
iter 14737 (epoch 24), train_loss = 2.353, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 14738 (epoch 24), train_loss = 2.381, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 14739 (epoch 24), train_loss = 2.568, time/batch = 0.034
Read data: 8.273124694824219e-05
iter 14740 (epoch 24), train_loss = 2.715, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 14741 (epoch 24), train_loss = 2.784, time/batch = 0.025
Read data: 0.00018143653869628906
iter 14742 (epoch 24), train_loss = 2.297, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 14743 (epoch 24), train_loss = 2.574, time/batch = 0.020
Read data: 0.0001575946807861328
iter 14744 (epoch 24), train_loss = 2.540, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 14745 (epoch 24), train_loss = 2.372, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 14746 (epoch 24), train_loss = 2.654, time/batch = 0.029
Read data: 0.00010156631469726562
iter 14747 (epoch 24), train_loss = 2.536, time/batch = 0.037
Read data: 0.00016450881958007812
iter 14748 (epoch 24), train_loss = 2.625, time/batch = 0.034
Read data: 9.322166442871094e-05
iter 14749 (epoch 24), train_loss = 2.128, time/batch = 0.022
Read data: 8.20159912109375e-05
iter 14750 (epoch 24), train_loss = 2.823, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 14751 (epoch 24), train_loss = 2.880, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 14752 (epoch 24), train_loss = 2.826, time/batch = 0.030
Read data: 0.0001385211944580078
iter 14753 (epoch 24), train_loss = 2.721, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 14754 (epoch 24), train_loss = 2.452, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 14755 (epoch 24), train_loss = 2.915, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 14756 (epoch 24), train_loss = 2.532, time/batch = 0.023
Read data: 0.00010323524475097656
iter 14757 (epoch 24), train_loss = 1.978, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 14758 (epoch 24), train_loss = 2.375, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 14759 (epoch 24), train_loss = 2.280, time/batch = 0.020
Read data: 9.012222290039062e-05
iter 14760 (epoch 24), train_loss = 2.976, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 14761 (epoch 24), train_loss = 2.415, time/batch = 0.026
Read data: 0.00014162063598632812
iter 14762 (epoch 24), train_loss = 2.651, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 14763 (epoch 24), train_loss = 2.638, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 14764 (epoch 24), train_loss = 2.469, time/batch = 0.026
Read data: 8.988380432128906e-05
iter 14765 (epoch 24), train_loss = 2.508, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 14766 (epoch 24), train_loss = 2.392, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 14767 (epoch 24), train_loss = 2.522, time/batch = 0.024
Read data: 9.274482727050781e-05
iter 14768 (epoch 24), train_loss = 2.860, time/batch = 0.031
Read data: 0.0001232624053955078
iter 14769 (epoch 24), train_loss = 2.472, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 14770 (epoch 24), train_loss = 2.142, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 14771 (epoch 24), train_loss = 2.254, time/batch = 0.036
Read data: 0.0001678466796875
iter 14772 (epoch 24), train_loss = 2.378, time/batch = 0.029
Read data: 9.012222290039062e-05
iter 14773 (epoch 24), train_loss = 2.538, time/batch = 0.024
Read data: 9.417533874511719e-05
iter 14774 (epoch 24), train_loss = 2.113, time/batch = 0.026
Read data: 0.0001785755157470703
iter 14775 (epoch 24), train_loss = 2.288, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 14776 (epoch 24), train_loss = 2.360, time/batch = 0.023
Read data: 0.00010156631469726562
iter 14777 (epoch 24), train_loss = 2.889, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 14778 (epoch 24), train_loss = 1.911, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 14779 (epoch 24), train_loss = 2.315, time/batch = 0.023
Read data: 0.00012636184692382812
iter 14780 (epoch 24), train_loss = 2.224, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 14781 (epoch 24), train_loss = 2.272, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 14782 (epoch 24), train_loss = 2.382, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 14783 (epoch 24), train_loss = 2.511, time/batch = 0.030
Read data: 8.988380432128906e-05
iter 14784 (epoch 24), train_loss = 2.430, time/batch = 0.025
Read data: 0.00010061264038085938
iter 14785 (epoch 24), train_loss = 2.224, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 14786 (epoch 24), train_loss = 2.607, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 14787 (epoch 24), train_loss = 2.676, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 14788 (epoch 24), train_loss = 2.401, time/batch = 0.027
Read data: 0.0001437664031982422
iter 14789 (epoch 24), train_loss = 2.027, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 14790 (epoch 24), train_loss = 2.291, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 14791 (epoch 24), train_loss = 2.419, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 14792 (epoch 24), train_loss = 2.480, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 14793 (epoch 24), train_loss = 2.482, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 14794 (epoch 24), train_loss = 2.541, time/batch = 0.028
Read data: 9.918212890625e-05
iter 14795 (epoch 24), train_loss = 2.533, time/batch = 0.027
Read data: 0.0001571178436279297
iter 14796 (epoch 24), train_loss = 2.570, time/batch = 0.030
Read data: 0.00012087821960449219
iter 14797 (epoch 24), train_loss = 2.230, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 14798 (epoch 24), train_loss = 2.763, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 14799 (epoch 24), train_loss = 2.041, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 14800 (epoch 24), train_loss = 2.386, time/batch = 0.027
Read data: 0.00010061264038085938
iter 14801 (epoch 24), train_loss = 2.268, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 14802 (epoch 24), train_loss = 2.620, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 14803 (epoch 24), train_loss = 2.588, time/batch = 0.026
Read data: 0.00011277198791503906
iter 14804 (epoch 24), train_loss = 2.181, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 14805 (epoch 24), train_loss = 2.730, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 14806 (epoch 24), train_loss = 2.351, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 14807 (epoch 24), train_loss = 2.747, time/batch = 0.024
Read data: 0.00010061264038085938
iter 14808 (epoch 24), train_loss = 2.479, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 14809 (epoch 24), train_loss = 2.648, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 14810 (epoch 24), train_loss = 2.434, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 14811 (epoch 24), train_loss = 2.402, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 14812 (epoch 24), train_loss = 2.687, time/batch = 0.023
Read data: 9.918212890625e-05
iter 14813 (epoch 24), train_loss = 2.400, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 14814 (epoch 24), train_loss = 2.434, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 14815 (epoch 24), train_loss = 2.268, time/batch = 0.033
Read data: 0.00011181831359863281
iter 14816 (epoch 24), train_loss = 2.336, time/batch = 0.023
Read data: 0.00010919570922851562
iter 14817 (epoch 24), train_loss = 2.605, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 14818 (epoch 24), train_loss = 2.497, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 14819 (epoch 24), train_loss = 2.083, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 14820 (epoch 24), train_loss = 2.580, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 14821 (epoch 24), train_loss = 2.571, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 14822 (epoch 24), train_loss = 2.308, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 14823 (epoch 24), train_loss = 2.112, time/batch = 0.028
Read data: 9.822845458984375e-05
iter 14824 (epoch 24), train_loss = 2.531, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 14825 (epoch 24), train_loss = 2.259, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 14826 (epoch 24), train_loss = 2.352, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 14827 (epoch 24), train_loss = 2.473, time/batch = 0.030
Read data: 0.00011706352233886719
iter 14828 (epoch 24), train_loss = 2.147, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 14829 (epoch 24), train_loss = 2.495, time/batch = 0.027
Read data: 0.00011801719665527344
iter 14830 (epoch 24), train_loss = 2.774, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 14831 (epoch 24), train_loss = 2.388, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 14832 (epoch 24), train_loss = 2.271, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 14833 (epoch 24), train_loss = 2.597, time/batch = 0.025
Read data: 0.0001361370086669922
iter 14834 (epoch 24), train_loss = 2.437, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 14835 (epoch 24), train_loss = 2.450, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 14836 (epoch 24), train_loss = 2.447, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 14837 (epoch 24), train_loss = 2.565, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 14838 (epoch 24), train_loss = 2.586, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 14839 (epoch 24), train_loss = 2.516, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 14840 (epoch 24), train_loss = 2.597, time/batch = 0.025
Read data: 0.00011873245239257812
iter 14841 (epoch 24), train_loss = 2.609, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 14842 (epoch 24), train_loss = 2.226, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 14843 (epoch 24), train_loss = 2.673, time/batch = 0.026
Read data: 0.00010204315185546875
iter 14844 (epoch 24), train_loss = 2.431, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 14845 (epoch 24), train_loss = 2.412, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 14846 (epoch 24), train_loss = 2.405, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 14847 (epoch 24), train_loss = 2.616, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 14848 (epoch 24), train_loss = 2.262, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 14849 (epoch 24), train_loss = 2.168, time/batch = 0.033
Read data: 0.00016307830810546875
iter 14850 (epoch 24), train_loss = 2.490, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 14851 (epoch 24), train_loss = 2.425, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 14852 (epoch 24), train_loss = 2.364, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 14853 (epoch 24), train_loss = 2.533, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 14854 (epoch 24), train_loss = 2.764, time/batch = 0.038
Read data: 8.797645568847656e-05
iter 14855 (epoch 24), train_loss = 1.877, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 14856 (epoch 24), train_loss = 2.393, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 14857 (epoch 24), train_loss = 2.265, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 14858 (epoch 24), train_loss = 2.837, time/batch = 0.034
Read data: 8.130073547363281e-05
iter 14859 (epoch 24), train_loss = 2.181, time/batch = 0.025
Read data: 0.00011730194091796875
iter 14860 (epoch 24), train_loss = 2.366, time/batch = 0.023
Read data: 0.00013685226440429688
iter 14861 (epoch 24), train_loss = 2.346, time/batch = 0.023
Read data: 0.00012969970703125
iter 14862 (epoch 24), train_loss = 2.780, time/batch = 0.022
Read data: 0.00016832351684570312
iter 14863 (epoch 24), train_loss = 2.516, time/batch = 0.034
Read data: 9.083747863769531e-05
iter 14864 (epoch 24), train_loss = 2.648, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 14865 (epoch 24), train_loss = 2.537, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 14866 (epoch 24), train_loss = 2.335, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 14867 (epoch 24), train_loss = 2.658, time/batch = 0.029
Read data: 0.00015354156494140625
iter 14868 (epoch 24), train_loss = 2.236, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 14869 (epoch 24), train_loss = 2.507, time/batch = 0.031
Read data: 7.939338684082031e-05
iter 14870 (epoch 24), train_loss = 2.628, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 14871 (epoch 24), train_loss = 2.669, time/batch = 0.033
Read data: 0.00013971328735351562
iter 14872 (epoch 24), train_loss = 2.446, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 14873 (epoch 24), train_loss = 2.506, time/batch = 0.023
Read data: 0.00014138221740722656
iter 14874 (epoch 24), train_loss = 2.178, time/batch = 0.021
Read data: 0.0002613067626953125
iter 14875 (epoch 24), train_loss = 2.773, time/batch = 0.037
Read data: 0.0001277923583984375
iter 14876 (epoch 24), train_loss = 3.008, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 14877 (epoch 24), train_loss = 2.377, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 14878 (epoch 24), train_loss = 2.189, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 14879 (epoch 24), train_loss = 2.612, time/batch = 0.033
Read data: 0.00011348724365234375
iter 14880 (epoch 24), train_loss = 2.027, time/batch = 0.023
Read data: 0.00010395050048828125
iter 14881 (epoch 24), train_loss = 2.563, time/batch = 0.031
Read data: 0.00015282630920410156
iter 14882 (epoch 24), train_loss = 2.481, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 14883 (epoch 24), train_loss = 2.511, time/batch = 0.026
Read data: 0.00010967254638671875
iter 14884 (epoch 24), train_loss = 2.581, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 14885 (epoch 24), train_loss = 2.612, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 14886 (epoch 24), train_loss = 2.551, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 14887 (epoch 24), train_loss = 2.286, time/batch = 0.028
Read data: 0.00014662742614746094
iter 14888 (epoch 24), train_loss = 2.467, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 14889 (epoch 24), train_loss = 2.578, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 14890 (epoch 24), train_loss = 2.684, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 14891 (epoch 24), train_loss = 2.386, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 14892 (epoch 24), train_loss = 2.332, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 14893 (epoch 24), train_loss = 2.021, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 14894 (epoch 24), train_loss = 2.506, time/batch = 0.033
Read data: 7.581710815429688e-05
iter 14895 (epoch 24), train_loss = 2.555, time/batch = 0.030
Read data: 0.00012373924255371094
iter 14896 (epoch 24), train_loss = 2.431, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 14897 (epoch 24), train_loss = 2.274, time/batch = 0.026
Read data: 0.00012159347534179688
iter 14898 (epoch 24), train_loss = 2.814, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 14899 (epoch 24), train_loss = 2.506, time/batch = 0.025
Read data: 0.0001571178436279297
iter 14900 (epoch 24), train_loss = 2.369, time/batch = 0.037
Read data: 8.225440979003906e-05
iter 14901 (epoch 24), train_loss = 2.814, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 14902 (epoch 24), train_loss = 2.567, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 14903 (epoch 24), train_loss = 2.201, time/batch = 0.026
Read data: 0.00011944770812988281
iter 14904 (epoch 24), train_loss = 2.292, time/batch = 0.034
Read data: 7.987022399902344e-05
iter 14905 (epoch 24), train_loss = 2.471, time/batch = 0.021
Read data: 0.00012803077697753906
iter 14906 (epoch 24), train_loss = 2.460, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 14907 (epoch 24), train_loss = 2.313, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 14908 (epoch 24), train_loss = 2.467, time/batch = 0.020
Read data: 8.487701416015625e-05
iter 14909 (epoch 24), train_loss = 2.304, time/batch = 0.022
Read data: 0.00011539459228515625
iter 14910 (epoch 24), train_loss = 2.619, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 14911 (epoch 24), train_loss = 2.196, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 14912 (epoch 24), train_loss = 2.228, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 14913 (epoch 24), train_loss = 2.394, time/batch = 0.025
Read data: 0.00017714500427246094
iter 14914 (epoch 24), train_loss = 2.536, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 14915 (epoch 24), train_loss = 2.498, time/batch = 0.024
Read data: 0.00015163421630859375
iter 14916 (epoch 24), train_loss = 2.477, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 14917 (epoch 24), train_loss = 2.079, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 14918 (epoch 24), train_loss = 2.821, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 14919 (epoch 24), train_loss = 2.416, time/batch = 0.030
Read data: 0.00011754035949707031
iter 14920 (epoch 24), train_loss = 2.485, time/batch = 0.026
Read data: 9.179115295410156e-05
iter 14921 (epoch 24), train_loss = 2.696, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 14922 (epoch 24), train_loss = 2.636, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 14923 (epoch 24), train_loss = 2.365, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 14924 (epoch 24), train_loss = 1.994, time/batch = 0.022
Read data: 0.00018167495727539062
iter 14925 (epoch 24), train_loss = 2.539, time/batch = 0.025
Read data: 0.0001430511474609375
iter 14926 (epoch 24), train_loss = 2.596, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 14927 (epoch 24), train_loss = 2.170, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 14928 (epoch 24), train_loss = 2.746, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 14929 (epoch 24), train_loss = 2.533, time/batch = 0.031
Read data: 8.535385131835938e-05
iter 14930 (epoch 24), train_loss = 2.317, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 14931 (epoch 24), train_loss = 2.486, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 14932 (epoch 24), train_loss = 2.416, time/batch = 0.026
Read data: 0.00016379356384277344
iter 14933 (epoch 24), train_loss = 2.398, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 14934 (epoch 24), train_loss = 2.706, time/batch = 0.029
Read data: 9.655952453613281e-05
iter 14935 (epoch 24), train_loss = 2.222, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 14936 (epoch 24), train_loss = 2.191, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 14937 (epoch 24), train_loss = 2.409, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 14938 (epoch 24), train_loss = 2.836, time/batch = 0.022
Read data: 0.00010180473327636719
iter 14939 (epoch 24), train_loss = 2.272, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 14940 (epoch 24), train_loss = 2.616, time/batch = 0.038
Read data: 9.918212890625e-05
iter 14941 (epoch 24), train_loss = 2.827, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 14942 (epoch 24), train_loss = 2.327, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 14943 (epoch 24), train_loss = 2.256, time/batch = 0.037
Read data: 8.296966552734375e-05
iter 14944 (epoch 24), train_loss = 2.826, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 14945 (epoch 24), train_loss = 2.309, time/batch = 0.025
Read data: 0.00014781951904296875
iter 14946 (epoch 24), train_loss = 2.249, time/batch = 0.022
Read data: 7.987022399902344e-05
iter 14947 (epoch 24), train_loss = 2.475, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 14948 (epoch 24), train_loss = 2.680, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 14949 (epoch 24), train_loss = 2.757, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 14950 (epoch 24), train_loss = 2.892, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 14951 (epoch 24), train_loss = 2.012, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 14952 (epoch 24), train_loss = 2.240, time/batch = 0.025
Read data: 9.918212890625e-05
iter 14953 (epoch 24), train_loss = 2.401, time/batch = 0.028
Read data: 0.00015306472778320312
iter 14954 (epoch 24), train_loss = 2.160, time/batch = 0.021
Read data: 0.00010228157043457031
iter 14955 (epoch 24), train_loss = 1.972, time/batch = 0.023
Read data: 9.1552734375e-05
iter 14956 (epoch 24), train_loss = 2.339, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 14957 (epoch 24), train_loss = 2.344, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 14958 (epoch 24), train_loss = 2.150, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 14959 (epoch 24), train_loss = 2.451, time/batch = 0.025
Read data: 0.00010347366333007812
iter 14960 (epoch 24), train_loss = 2.403, time/batch = 0.027
Read data: 0.00014209747314453125
iter 14961 (epoch 24), train_loss = 2.634, time/batch = 0.035
Read data: 0.00013899803161621094
iter 14962 (epoch 24), train_loss = 2.589, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 14963 (epoch 24), train_loss = 2.517, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 14964 (epoch 24), train_loss = 2.337, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 14965 (epoch 24), train_loss = 2.597, time/batch = 0.037
Read data: 0.00012183189392089844
iter 14966 (epoch 24), train_loss = 2.424, time/batch = 0.019
Read data: 8.034706115722656e-05
iter 14967 (epoch 24), train_loss = 2.233, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 14968 (epoch 24), train_loss = 2.593, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 14969 (epoch 24), train_loss = 2.588, time/batch = 0.032
Read data: 0.0001456737518310547
iter 14970 (epoch 24), train_loss = 2.368, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 14971 (epoch 24), train_loss = 2.450, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 14972 (epoch 24), train_loss = 2.336, time/batch = 0.027
Read data: 9.965896606445312e-05
iter 14973 (epoch 24), train_loss = 2.461, time/batch = 0.021
Read data: 9.894371032714844e-05
iter 14974 (epoch 24), train_loss = 2.475, time/batch = 0.023
Read data: 0.0001628398895263672
iter 14975 (epoch 24), train_loss = 2.851, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 14976 (epoch 24), train_loss = 2.477, time/batch = 0.029
Read data: 8.749961853027344e-05
iter 14977 (epoch 24), train_loss = 2.555, time/batch = 0.024
Read data: 0.00015234947204589844
iter 14978 (epoch 24), train_loss = 2.389, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 14979 (epoch 24), train_loss = 2.393, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 14980 (epoch 24), train_loss = 2.567, time/batch = 0.025
Read data: 0.0001575946807861328
iter 14981 (epoch 24), train_loss = 2.474, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 14982 (epoch 24), train_loss = 2.717, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 14983 (epoch 24), train_loss = 2.487, time/batch = 0.027
Read data: 0.00010514259338378906
iter 14984 (epoch 24), train_loss = 2.629, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 14985 (epoch 24), train_loss = 2.386, time/batch = 0.025
Read data: 0.00014066696166992188
iter 14986 (epoch 24), train_loss = 2.266, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 14987 (epoch 24), train_loss = 2.424, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 14988 (epoch 24), train_loss = 2.544, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 14989 (epoch 24), train_loss = 2.577, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 14990 (epoch 24), train_loss = 2.657, time/batch = 0.031
Read data: 9.560585021972656e-05
iter 14991 (epoch 24), train_loss = 2.281, time/batch = 0.022
Read data: 0.0009925365447998047
iter 14992 (epoch 24), train_loss = 2.523, time/batch = 0.025
Read data: 0.00011944770812988281
iter 14993 (epoch 24), train_loss = 3.047, time/batch = 0.027
Read data: 0.0001404285430908203
iter 14994 (epoch 24), train_loss = 2.488, time/batch = 0.037
Read data: 8.106231689453125e-05
iter 14995 (epoch 24), train_loss = 2.402, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 14996 (epoch 24), train_loss = 2.726, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 14997 (epoch 24), train_loss = 2.576, time/batch = 0.027
Read data: 0.00011086463928222656
iter 14998 (epoch 24), train_loss = 2.545, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 14999 (epoch 24), train_loss = 2.604, time/batch = 0.025
image 976:     
image 5399:     
image 6910:    
image 660:      
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.625216)
image 2798:    
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:      
evaluating validation preformance... 20/1000 (2.197340)
image 6903:      
image 3301:    
image 2019:     
image 5535:     
image 7680:     
image 5527:      
image 2568:    
image 160:     
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.530147)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (2.999581)
image 2938:    UNK
image 5183:     
image 2380:     
image 6973:    
image 5629:     
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.503455)
image 4940:      
image 4905:    UNK
image 469:      
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    UNK
image 1729:     
image 4444:    
image 6070:     
evaluating validation preformance... 60/1000 (2.789577)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.573364)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:    
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.601943)
image 3276:      
image 3812:    
image 1400:    
image 3443:     
image 5027:     
image 7251:     
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.097780)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:     
image 6612:     
image 7701:     
image 7379:      
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.911536)
image 2800:    
image 7249:       
image 3211:    
image 686:     
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.761962)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     UNK
evaluating validation preformance... 120/1000 (2.353465)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.877132)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:    
image 4450:     
image 1524:     
image 2867:    
evaluating validation preformance... 140/1000 (2.675101)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (2.940427)
image 1865:    
image 3830:      
image 360:     
image 5097:      
image 4455:    
image 1153:    
image 1248:    
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.803913)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.567524)
image 7922:     
image 2353:     
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.705035)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.386583)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:      
evaluating validation preformance... 200/1000 (2.258586)
image 5159:    
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:      
image 4023:     
evaluating validation preformance... 210/1000 (2.428859)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.529855)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:   
image 4483:     
image 6582:     
evaluating validation preformance... 230/1000 (2.240811)
image 1917:     
image 5844:    
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.122256)
image 7143:    
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:    
image 528:    
evaluating validation preformance... 250/1000 (2.525657)
image 3028:   
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.458453)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.978125)
image 833:    
image 5483:     
image 2476:     
image 5930:     
image 59:    
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:     
evaluating validation preformance... 280/1000 (2.521630)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.415804)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.144714)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.763274)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:    
evaluating validation preformance... 320/1000 (2.276138)
image 489:    
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.755580)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:      
image 4524:    UNK
image 3972:     
evaluating validation preformance... 340/1000 (2.392123)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.474184)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:     
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.037185)
image 2905:     
image 7814:      
image 56:    
image 5034:    
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.577535)
image 4351:      
image 1054:     
image 129:    
image 2849:     
image 725:    
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.628301)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:      
image 60:     
evaluating validation preformance... 390/1000 (2.839677)
image 828:     
image 2733:    
image 791:    
image 5408:     
image 7842:     
image 1117:      
image 5817:      
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.244869)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.130877)
image 4359:     
image 2372:     
image 4472:      
image 6810:     
image 1592:    
image 7864:     
image 4286:    
image 6688:     
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.307012)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:      
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.777967)
image 385:    
image 6938:      
image 2381:    
image 5796:     
image 4010:     
image 3452:     
image 2023:     
image 3052:    
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.877628)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:     
image 4790:     
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.149407)
image 2241:     
image 2651:    UNK
image 2315:     
image 4784:      
image 5160:      
image 2466:     
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.652405)
image 7979:    
image 1618:    UNK
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:     
evaluating validation preformance... 470/1000 (3.223902)
image 4503:     
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:      
image 7450:     
image 841:     
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (2.884221)
image 358:     
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:    UNK
image 1595:    
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.317889)
image 2044:    
image 4349:    
image 3855:      
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.505906)
image 1797:    
image 4670:     
image 4846:    
image 5907:     
image 3321:    
image 1700:     
image 438:    
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.960491)
image 3246:       
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.580031)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.456179)
image 5619:     
image 4391:    UNK
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:      
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.431674)
image 5292:    
image 2901:     
image 3568:    
image 690:      
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.537555)
image 5439:    
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:     
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.552437)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:      
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.564873)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:      
image 3267:    
evaluating validation preformance... 580/1000 (2.545351)
image 2135:      
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.511056)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:     
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.467361)
image 353:     
image 1095:     
image 3583:      
image 3264:      
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.630033)
image 69:    
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:     
image 359:      
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.375698)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:     
evaluating validation preformance... 630/1000 (2.473564)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.458760)
image 5313:      
image 2377:      
image 6058:    
image 4661:     
image 2955:   
image 3333:    
image 7124:    UNK
image 4278:      
image 953:     
image 4037:    
evaluating validation preformance... 650/1000 (2.559439)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:    
image 2824:    
image 1639:    
image 1475:    
image 3991:     
image 1023:     
evaluating validation preformance... 660/1000 (2.589847)
image 5701:    
image 1709:      
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:    
image 1972:     
evaluating validation preformance... 670/1000 (2.823720)
image 7877:    
image 6761:     
image 6880:   
image 4914:    UNK
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (2.985426)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:    UNK
image 1257:     
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.827548)
image 6860:     
image 576:     
image 6580:     
image 1497:     
image 3360:     
image 4939:      
image 6225:     
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.948915)
image 5343:      
image 68:    UNK
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.468396)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:    
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.610963)
image 5729:    
image 6395:     
image 516:      
image 1026:     
image 2972:      
image 3005:     
image 1241:      
image 2743:      
image 3665:     
image 1290:    UNK
evaluating validation preformance... 730/1000 (2.271468)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:     
image 5092:      
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.407327)
image 2239:      
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.635499)
image 3279:     
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.976137)
image 4582:    
image 5484:    
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.126073)
image 6220:     
image 6238:     
image 4534:     
image 2732:     
image 7003:     
image 1739:     
image 5503:       
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.777516)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:     
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.104596)
image 5047:      
image 325:       
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.245899)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.379182)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.902120)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:    UNK
image 7147:    
image 6348:     
image 580:     
image 2531:     
evaluating validation preformance... 830/1000 (2.354680)
image 5107:     
image 3973:     
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.424075)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.740132)
image 4404:    
image 5501:      
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:       
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.740685)
image 4254:      
image 6842:     
image 1644:     
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:      
image 3222:   
image 4002:    
evaluating validation preformance... 870/1000 (2.314864)
image 4934:    
image 6487:     
image 4217:    
image 6355:      
image 2793:     
image 7201:     
image 5681:      
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.589300)
image 5460:      
image 3671:    
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:     UNK
image 2314:     
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.863242)
image 7485:    
image 6102:    
image 1001:      
image 7167:    
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.542321)
image 5664:     
image 4985:     
image 4082:      
image 6291:    
image 5573:     
image 1405:     
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.199566)
image 1368:     
image 1925:     
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.570704)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:       
image 7102:     
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.513037)
image 5636:      
image 7799:      
image 6025:    
image 6907:      
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.667088)
image 5860:     
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:    
image 5984:    
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.965130)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:      
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:      
evaluating validation preformance... 960/1000 (2.738721)
image 4935:    
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.288312)
image 5688:     
image 5448:     
image 5871:     
image 7516:    
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.746984)
image 7352:     
image 5113:     
image 7822:     
image 4858:    
image 658:     
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.433512)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.329491)
average loss on validation: 2.575
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3832359313964844
Cider scores: 0.5059102258741757
Read data: 0.2821543216705322
Cider scores: 0.6059008455459135
Read data: 0.2617990970611572
Cider scores: 0.6145289181881373
Read data: 0.23648524284362793
Cider scores: 0.5585098324196778
Read data: 0.19666361808776855
Cider scores: 0.5459447725279406
Read data: 0.19463849067687988
Cider scores: 0.5164276449659112
Read data: 0.19256258010864258
Cider scores: 0.5031523250941614
Read data: 0.18793916702270508
Cider scores: 0.6370575356925308
Read data: 0.18678879737854004
Cider scores: 0.5841813137225395
Read data: 0.18939590454101562
Cider scores: 0.7075196490011924
Read data: 0.18080806732177734
Cider scores: 0.5844586409658287
Read data: 0.24382925033569336
Cider scores: 0.6235378106191147
Read data: 0.1890730857849121
Cider scores: 0.5760159378513218
Read data: 0.17848515510559082
Cider scores: 0.6050010163473565
Read data: 0.1864778995513916
Cider scores: 0.649431527575578
Read data: 0.17035984992980957
Cider scores: 0.6711034724198208
Read data: 0.16152143478393555
Cider scores: 0.4668512955285795
Read data: 0.16161799430847168
Cider scores: 0.6087567673601817
Read data: 0.16357922554016113
Cider scores: 0.5557216975071733
Read data: 0.16301441192626953
Cider scores: 0.7481955395847678
Average cider score on test set: 0.593
End calculating cider score on TEST data set
===============================================
Read data: 0.1614987850189209
iter 15000 (epoch 24), train_loss = 2.654, time/batch = 0.025
Read data: 0.00011372566223144531
iter 15001 (epoch 25), train_loss = 2.317, time/batch = 0.020
Read data: 0.00011348724365234375
iter 15002 (epoch 25), train_loss = 2.461, time/batch = 0.029
Read data: 0.0001404285430908203
iter 15003 (epoch 25), train_loss = 2.662, time/batch = 0.029
Read data: 0.00016951560974121094
iter 15004 (epoch 25), train_loss = 2.762, time/batch = 0.035
Read data: 0.00012636184692382812
iter 15005 (epoch 25), train_loss = 2.130, time/batch = 0.027
Read data: 0.0002117156982421875
iter 15006 (epoch 25), train_loss = 2.728, time/batch = 0.030
Read data: 0.000133514404296875
iter 15007 (epoch 25), train_loss = 2.390, time/batch = 0.026
Read data: 0.0001201629638671875
iter 15008 (epoch 25), train_loss = 2.665, time/batch = 0.029
Read data: 0.0001163482666015625
iter 15009 (epoch 25), train_loss = 2.934, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 15010 (epoch 25), train_loss = 2.283, time/batch = 0.041
Read data: 0.00014448165893554688
iter 15011 (epoch 25), train_loss = 2.451, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 15012 (epoch 25), train_loss = 2.655, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 15013 (epoch 25), train_loss = 2.071, time/batch = 0.025
Read data: 0.0001506805419921875
iter 15014 (epoch 25), train_loss = 2.461, time/batch = 0.027
Read data: 0.00010371208190917969
iter 15015 (epoch 25), train_loss = 2.711, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 15016 (epoch 25), train_loss = 2.404, time/batch = 0.023
Read data: 0.00010085105895996094
iter 15017 (epoch 25), train_loss = 2.564, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 15018 (epoch 25), train_loss = 2.840, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 15019 (epoch 25), train_loss = 2.796, time/batch = 0.028
Read data: 9.465217590332031e-05
iter 15020 (epoch 25), train_loss = 2.496, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 15021 (epoch 25), train_loss = 2.591, time/batch = 0.029
Read data: 9.012222290039062e-05
iter 15022 (epoch 25), train_loss = 2.500, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 15023 (epoch 25), train_loss = 2.322, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 15024 (epoch 25), train_loss = 2.486, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 15025 (epoch 25), train_loss = 2.409, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 15026 (epoch 25), train_loss = 2.538, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 15027 (epoch 25), train_loss = 1.968, time/batch = 0.028
Read data: 8.702278137207031e-05
iter 15028 (epoch 25), train_loss = 2.611, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 15029 (epoch 25), train_loss = 2.293, time/batch = 0.035
Read data: 8.893013000488281e-05
iter 15030 (epoch 25), train_loss = 2.574, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 15031 (epoch 25), train_loss = 2.513, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 15032 (epoch 25), train_loss = 2.521, time/batch = 0.029
Read data: 0.00010251998901367188
iter 15033 (epoch 25), train_loss = 2.576, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 15034 (epoch 25), train_loss = 2.559, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 15035 (epoch 25), train_loss = 2.657, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 15036 (epoch 25), train_loss = 2.324, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 15037 (epoch 25), train_loss = 2.770, time/batch = 0.027
Read data: 0.0001361370086669922
iter 15038 (epoch 25), train_loss = 2.199, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 15039 (epoch 25), train_loss = 2.337, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 15040 (epoch 25), train_loss = 2.607, time/batch = 0.029
Read data: 9.870529174804688e-05
iter 15041 (epoch 25), train_loss = 2.560, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 15042 (epoch 25), train_loss = 2.392, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 15043 (epoch 25), train_loss = 2.023, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 15044 (epoch 25), train_loss = 2.632, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 15045 (epoch 25), train_loss = 2.323, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 15046 (epoch 25), train_loss = 2.361, time/batch = 0.025
Read data: 8.392333984375e-05
iter 15047 (epoch 25), train_loss = 1.965, time/batch = 0.024
Read data: 9.608268737792969e-05
iter 15048 (epoch 25), train_loss = 2.386, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 15049 (epoch 25), train_loss = 2.712, time/batch = 0.029
Read data: 0.00017905235290527344
iter 15050 (epoch 25), train_loss = 2.436, time/batch = 0.028
Read data: 0.00010228157043457031
iter 15051 (epoch 25), train_loss = 2.136, time/batch = 0.026
Read data: 0.00010561943054199219
iter 15052 (epoch 25), train_loss = 2.710, time/batch = 0.031
Read data: 0.00010561943054199219
iter 15053 (epoch 25), train_loss = 2.732, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 15054 (epoch 25), train_loss = 2.542, time/batch = 0.033
Read data: 0.00011110305786132812
iter 15055 (epoch 25), train_loss = 2.621, time/batch = 0.030
Read data: 0.00012254714965820312
iter 15056 (epoch 25), train_loss = 2.449, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 15057 (epoch 25), train_loss = 2.587, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 15058 (epoch 25), train_loss = 3.029, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 15059 (epoch 25), train_loss = 2.682, time/batch = 0.023
Read data: 8.392333984375e-05
iter 15060 (epoch 25), train_loss = 2.526, time/batch = 0.025
Read data: 0.00010132789611816406
iter 15061 (epoch 25), train_loss = 2.573, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 15062 (epoch 25), train_loss = 2.652, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 15063 (epoch 25), train_loss = 2.650, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 15064 (epoch 25), train_loss = 2.657, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 15065 (epoch 25), train_loss = 2.420, time/batch = 0.024
Read data: 0.0001590251922607422
iter 15066 (epoch 25), train_loss = 2.817, time/batch = 0.022
Read data: 7.724761962890625e-05
iter 15067 (epoch 25), train_loss = 2.600, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 15068 (epoch 25), train_loss = 2.898, time/batch = 0.038
Read data: 8.296966552734375e-05
iter 15069 (epoch 25), train_loss = 2.437, time/batch = 0.026
Read data: 0.00010037422180175781
iter 15070 (epoch 25), train_loss = 2.837, time/batch = 0.029
Read data: 8.797645568847656e-05
iter 15071 (epoch 25), train_loss = 2.332, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 15072 (epoch 25), train_loss = 2.540, time/batch = 0.021
Read data: 9.989738464355469e-05
iter 15073 (epoch 25), train_loss = 2.284, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 15074 (epoch 25), train_loss = 2.668, time/batch = 0.028
Read data: 0.0001773834228515625
iter 15075 (epoch 25), train_loss = 2.324, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 15076 (epoch 25), train_loss = 2.339, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 15077 (epoch 25), train_loss = 2.467, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 15078 (epoch 25), train_loss = 2.703, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 15079 (epoch 25), train_loss = 2.106, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 15080 (epoch 25), train_loss = 2.463, time/batch = 0.021
Read data: 8.58306884765625e-05
iter 15081 (epoch 25), train_loss = 2.552, time/batch = 0.029
Read data: 0.00013899803161621094
iter 15082 (epoch 25), train_loss = 2.166, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 15083 (epoch 25), train_loss = 2.200, time/batch = 0.030
Read data: 0.0001323223114013672
iter 15084 (epoch 25), train_loss = 2.404, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 15085 (epoch 25), train_loss = 2.937, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 15086 (epoch 25), train_loss = 2.584, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 15087 (epoch 25), train_loss = 2.568, time/batch = 0.021
Read data: 8.845329284667969e-05
iter 15088 (epoch 25), train_loss = 2.388, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 15089 (epoch 25), train_loss = 2.541, time/batch = 0.023
Read data: 0.0001366138458251953
iter 15090 (epoch 25), train_loss = 2.504, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 15091 (epoch 25), train_loss = 2.635, time/batch = 0.033
Read data: 9.441375732421875e-05
iter 15092 (epoch 25), train_loss = 2.226, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 15093 (epoch 25), train_loss = 2.736, time/batch = 0.034
Read data: 0.00015425682067871094
iter 15094 (epoch 25), train_loss = 2.273, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 15095 (epoch 25), train_loss = 2.807, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 15096 (epoch 25), train_loss = 2.454, time/batch = 0.021
Read data: 9.012222290039062e-05
iter 15097 (epoch 25), train_loss = 2.728, time/batch = 0.028
Read data: 0.00015234947204589844
iter 15098 (epoch 25), train_loss = 2.221, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 15099 (epoch 25), train_loss = 2.911, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 15100 (epoch 25), train_loss = 2.425, time/batch = 0.031
Read data: 0.0001289844512939453
iter 15101 (epoch 25), train_loss = 2.383, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 15102 (epoch 25), train_loss = 2.390, time/batch = 0.028
Read data: 0.000133514404296875
iter 15103 (epoch 25), train_loss = 2.253, time/batch = 0.023
Read data: 9.5367431640625e-05
iter 15104 (epoch 25), train_loss = 2.883, time/batch = 0.026
Read data: 0.000171661376953125
iter 15105 (epoch 25), train_loss = 2.489, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 15106 (epoch 25), train_loss = 2.553, time/batch = 0.037
Read data: 0.00016164779663085938
iter 15107 (epoch 25), train_loss = 3.071, time/batch = 0.032
Read data: 0.00010824203491210938
iter 15108 (epoch 25), train_loss = 2.216, time/batch = 0.025
Read data: 0.00014328956604003906
iter 15109 (epoch 25), train_loss = 2.223, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 15110 (epoch 25), train_loss = 2.742, time/batch = 0.028
Read data: 0.0001678466796875
iter 15111 (epoch 25), train_loss = 2.393, time/batch = 0.038
Read data: 9.608268737792969e-05
iter 15112 (epoch 25), train_loss = 2.801, time/batch = 0.034
Read data: 0.00014901161193847656
iter 15113 (epoch 25), train_loss = 2.379, time/batch = 0.027
Read data: 7.62939453125e-05
iter 15114 (epoch 25), train_loss = 2.896, time/batch = 0.027
Read data: 0.0001747608184814453
iter 15115 (epoch 25), train_loss = 2.315, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 15116 (epoch 25), train_loss = 2.708, time/batch = 0.035
Read data: 0.00019407272338867188
iter 15117 (epoch 25), train_loss = 2.522, time/batch = 0.030
Read data: 0.0001399517059326172
iter 15118 (epoch 25), train_loss = 2.333, time/batch = 0.030
Read data: 0.0001251697540283203
iter 15119 (epoch 25), train_loss = 1.981, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 15120 (epoch 25), train_loss = 2.731, time/batch = 0.027
Read data: 0.00013399124145507812
iter 15121 (epoch 25), train_loss = 2.293, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 15122 (epoch 25), train_loss = 2.435, time/batch = 0.022
Read data: 0.00013113021850585938
iter 15123 (epoch 25), train_loss = 3.032, time/batch = 0.030
Read data: 7.581710815429688e-05
iter 15124 (epoch 25), train_loss = 1.991, time/batch = 0.026
Read data: 0.00013113021850585938
iter 15125 (epoch 25), train_loss = 2.512, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 15126 (epoch 25), train_loss = 2.988, time/batch = 0.037
Read data: 9.179115295410156e-05
iter 15127 (epoch 25), train_loss = 2.324, time/batch = 0.021
Read data: 9.489059448242188e-05
iter 15128 (epoch 25), train_loss = 2.560, time/batch = 0.026
Read data: 0.00012993812561035156
iter 15129 (epoch 25), train_loss = 1.889, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 15130 (epoch 25), train_loss = 2.579, time/batch = 0.028
Read data: 0.00015997886657714844
iter 15131 (epoch 25), train_loss = 2.498, time/batch = 0.032
Read data: 0.0001342296600341797
iter 15132 (epoch 25), train_loss = 2.234, time/batch = 0.028
Read data: 0.00014138221740722656
iter 15133 (epoch 25), train_loss = 2.729, time/batch = 0.028
Read data: 0.00014400482177734375
iter 15134 (epoch 25), train_loss = 2.556, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 15135 (epoch 25), train_loss = 2.652, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 15136 (epoch 25), train_loss = 2.672, time/batch = 0.031
Read data: 0.00013518333435058594
iter 15137 (epoch 25), train_loss = 2.623, time/batch = 0.032
Read data: 0.00013589859008789062
iter 15138 (epoch 25), train_loss = 2.235, time/batch = 0.034
Read data: 0.00016570091247558594
iter 15139 (epoch 25), train_loss = 2.462, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 15140 (epoch 25), train_loss = 2.236, time/batch = 0.025
Read data: 0.0001342296600341797
iter 15141 (epoch 25), train_loss = 2.536, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 15142 (epoch 25), train_loss = 2.620, time/batch = 0.027
Read data: 0.00012421607971191406
iter 15143 (epoch 25), train_loss = 2.543, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 15144 (epoch 25), train_loss = 2.301, time/batch = 0.037
Read data: 0.0001392364501953125
iter 15145 (epoch 25), train_loss = 2.622, time/batch = 0.034
Read data: 7.772445678710938e-05
iter 15146 (epoch 25), train_loss = 2.305, time/batch = 0.029
Read data: 8.392333984375e-05
iter 15147 (epoch 25), train_loss = 2.347, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 15148 (epoch 25), train_loss = 2.485, time/batch = 0.034
Read data: 8.7738037109375e-05
iter 15149 (epoch 25), train_loss = 2.415, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 15150 (epoch 25), train_loss = 2.505, time/batch = 0.025
Read data: 0.00016927719116210938
iter 15151 (epoch 25), train_loss = 2.763, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 15152 (epoch 25), train_loss = 2.181, time/batch = 0.026
Read data: 0.00016236305236816406
iter 15153 (epoch 25), train_loss = 2.557, time/batch = 0.029
Read data: 9.34600830078125e-05
iter 15154 (epoch 25), train_loss = 2.181, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 15155 (epoch 25), train_loss = 2.344, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 15156 (epoch 25), train_loss = 2.325, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 15157 (epoch 25), train_loss = 2.727, time/batch = 0.024
Read data: 9.1552734375e-05
iter 15158 (epoch 25), train_loss = 2.355, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 15159 (epoch 25), train_loss = 2.400, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 15160 (epoch 25), train_loss = 2.778, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 15161 (epoch 25), train_loss = 2.584, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 15162 (epoch 25), train_loss = 2.477, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 15163 (epoch 25), train_loss = 2.422, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 15164 (epoch 25), train_loss = 2.511, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 15165 (epoch 25), train_loss = 2.640, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 15166 (epoch 25), train_loss = 2.485, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 15167 (epoch 25), train_loss = 2.590, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 15168 (epoch 25), train_loss = 2.314, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 15169 (epoch 25), train_loss = 2.645, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 15170 (epoch 25), train_loss = 2.443, time/batch = 0.022
Read data: 0.00014781951904296875
iter 15171 (epoch 25), train_loss = 3.116, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 15172 (epoch 25), train_loss = 2.569, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 15173 (epoch 25), train_loss = 2.075, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 15174 (epoch 25), train_loss = 2.457, time/batch = 0.025
Read data: 0.00021648406982421875
iter 15175 (epoch 25), train_loss = 2.507, time/batch = 0.029
Read data: 8.606910705566406e-05
iter 15176 (epoch 25), train_loss = 2.449, time/batch = 0.024
Read data: 0.00016808509826660156
iter 15177 (epoch 25), train_loss = 2.326, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 15178 (epoch 25), train_loss = 2.394, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 15179 (epoch 25), train_loss = 2.390, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 15180 (epoch 25), train_loss = 2.547, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 15181 (epoch 25), train_loss = 2.465, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 15182 (epoch 25), train_loss = 2.762, time/batch = 0.024
Read data: 0.00011730194091796875
iter 15183 (epoch 25), train_loss = 2.704, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 15184 (epoch 25), train_loss = 2.421, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 15185 (epoch 25), train_loss = 2.410, time/batch = 0.029
Read data: 7.62939453125e-05
iter 15186 (epoch 25), train_loss = 2.404, time/batch = 0.024
Read data: 0.00015497207641601562
iter 15187 (epoch 25), train_loss = 2.727, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 15188 (epoch 25), train_loss = 2.240, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 15189 (epoch 25), train_loss = 2.417, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 15190 (epoch 25), train_loss = 2.421, time/batch = 0.023
Read data: 8.559226989746094e-05
iter 15191 (epoch 25), train_loss = 2.287, time/batch = 0.027
Read data: 0.00012874603271484375
iter 15192 (epoch 25), train_loss = 2.786, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 15193 (epoch 25), train_loss = 2.291, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 15194 (epoch 25), train_loss = 2.630, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 15195 (epoch 25), train_loss = 2.869, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 15196 (epoch 25), train_loss = 2.752, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 15197 (epoch 25), train_loss = 2.369, time/batch = 0.030
Read data: 7.43865966796875e-05
iter 15198 (epoch 25), train_loss = 2.581, time/batch = 0.027
Read data: 7.581710815429688e-05
iter 15199 (epoch 25), train_loss = 2.912, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 15200 (epoch 25), train_loss = 2.327, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 15201 (epoch 25), train_loss = 2.446, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 15202 (epoch 25), train_loss = 2.690, time/batch = 0.038
Read data: 0.00010013580322265625
iter 15203 (epoch 25), train_loss = 2.631, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 15204 (epoch 25), train_loss = 2.036, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 15205 (epoch 25), train_loss = 2.725, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 15206 (epoch 25), train_loss = 2.089, time/batch = 0.022
Read data: 0.00015592575073242188
iter 15207 (epoch 25), train_loss = 2.390, time/batch = 0.028
Read data: 0.00010919570922851562
iter 15208 (epoch 25), train_loss = 2.957, time/batch = 0.023
Read data: 0.00010561943054199219
iter 15209 (epoch 25), train_loss = 2.327, time/batch = 0.026
Read data: 0.0001633167266845703
iter 15210 (epoch 25), train_loss = 2.618, time/batch = 0.023
Read data: 0.00010156631469726562
iter 15211 (epoch 25), train_loss = 2.337, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 15212 (epoch 25), train_loss = 2.793, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 15213 (epoch 25), train_loss = 2.782, time/batch = 0.024
Read data: 0.0001544952392578125
iter 15214 (epoch 25), train_loss = 2.595, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 15215 (epoch 25), train_loss = 2.547, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15216 (epoch 25), train_loss = 2.357, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 15217 (epoch 25), train_loss = 2.213, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 15218 (epoch 25), train_loss = 2.589, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 15219 (epoch 25), train_loss = 1.921, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 15220 (epoch 25), train_loss = 2.326, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 15221 (epoch 25), train_loss = 2.273, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 15222 (epoch 25), train_loss = 2.804, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 15223 (epoch 25), train_loss = 2.448, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 15224 (epoch 25), train_loss = 2.340, time/batch = 0.021
Read data: 0.00021266937255859375
iter 15225 (epoch 25), train_loss = 2.549, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 15226 (epoch 25), train_loss = 2.274, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 15227 (epoch 25), train_loss = 2.503, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 15228 (epoch 25), train_loss = 2.612, time/batch = 0.036
Read data: 8.535385131835938e-05
iter 15229 (epoch 25), train_loss = 2.340, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 15230 (epoch 25), train_loss = 2.016, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 15231 (epoch 25), train_loss = 2.075, time/batch = 0.021
Read data: 8.225440979003906e-05
iter 15232 (epoch 25), train_loss = 2.054, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 15233 (epoch 25), train_loss = 2.097, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 15234 (epoch 25), train_loss = 2.175, time/batch = 0.027
Read data: 0.00015306472778320312
iter 15235 (epoch 25), train_loss = 2.557, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 15236 (epoch 25), train_loss = 2.263, time/batch = 0.026
Read data: 0.00015592575073242188
iter 15237 (epoch 25), train_loss = 2.686, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 15238 (epoch 25), train_loss = 2.980, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 15239 (epoch 25), train_loss = 2.613, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 15240 (epoch 25), train_loss = 2.718, time/batch = 0.036
Read data: 8.058547973632812e-05
iter 15241 (epoch 25), train_loss = 2.618, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 15242 (epoch 25), train_loss = 2.802, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 15243 (epoch 25), train_loss = 2.673, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 15244 (epoch 25), train_loss = 2.508, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 15245 (epoch 25), train_loss = 2.644, time/batch = 0.036
Read data: 0.0001289844512939453
iter 15246 (epoch 25), train_loss = 2.778, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 15247 (epoch 25), train_loss = 2.643, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 15248 (epoch 25), train_loss = 2.261, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 15249 (epoch 25), train_loss = 2.327, time/batch = 0.034
Read data: 0.0002613067626953125
iter 15250 (epoch 25), train_loss = 2.484, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 15251 (epoch 25), train_loss = 2.358, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 15252 (epoch 25), train_loss = 2.628, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 15253 (epoch 25), train_loss = 2.649, time/batch = 0.027
Read data: 0.000133514404296875
iter 15254 (epoch 25), train_loss = 2.458, time/batch = 0.032
Read data: 0.00013494491577148438
iter 15255 (epoch 25), train_loss = 2.476, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 15256 (epoch 25), train_loss = 2.655, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 15257 (epoch 25), train_loss = 2.292, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 15258 (epoch 25), train_loss = 2.463, time/batch = 0.025
Read data: 7.534027099609375e-05
iter 15259 (epoch 25), train_loss = 2.432, time/batch = 0.021
Read data: 0.00012874603271484375
iter 15260 (epoch 25), train_loss = 2.639, time/batch = 0.029
Read data: 0.000156402587890625
iter 15261 (epoch 25), train_loss = 2.187, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 15262 (epoch 25), train_loss = 2.609, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 15263 (epoch 25), train_loss = 2.364, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 15264 (epoch 25), train_loss = 2.843, time/batch = 0.026
Read data: 0.00015282630920410156
iter 15265 (epoch 25), train_loss = 1.958, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 15266 (epoch 25), train_loss = 2.260, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 15267 (epoch 25), train_loss = 2.755, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 15268 (epoch 25), train_loss = 2.884, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 15269 (epoch 25), train_loss = 2.812, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 15270 (epoch 25), train_loss = 2.512, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 15271 (epoch 25), train_loss = 2.487, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 15272 (epoch 25), train_loss = 2.228, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 15273 (epoch 25), train_loss = 2.409, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 15274 (epoch 25), train_loss = 2.502, time/batch = 0.031
Read data: 8.940696716308594e-05
iter 15275 (epoch 25), train_loss = 2.553, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 15276 (epoch 25), train_loss = 2.383, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 15277 (epoch 25), train_loss = 2.599, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 15278 (epoch 25), train_loss = 2.560, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 15279 (epoch 25), train_loss = 2.537, time/batch = 0.027
Read data: 0.00010228157043457031
iter 15280 (epoch 25), train_loss = 2.218, time/batch = 0.035
Read data: 8.440017700195312e-05
iter 15281 (epoch 25), train_loss = 2.312, time/batch = 0.033
Read data: 9.083747863769531e-05
iter 15282 (epoch 25), train_loss = 2.608, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 15283 (epoch 25), train_loss = 2.086, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 15284 (epoch 25), train_loss = 2.437, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 15285 (epoch 25), train_loss = 2.482, time/batch = 0.036
Read data: 0.00015282630920410156
iter 15286 (epoch 25), train_loss = 2.866, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 15287 (epoch 25), train_loss = 2.515, time/batch = 0.027
Read data: 0.00011444091796875
iter 15288 (epoch 25), train_loss = 2.228, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 15289 (epoch 25), train_loss = 2.283, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 15290 (epoch 25), train_loss = 2.440, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 15291 (epoch 25), train_loss = 2.650, time/batch = 0.026
Read data: 9.918212890625e-05
iter 15292 (epoch 25), train_loss = 2.476, time/batch = 0.025
Read data: 0.0001201629638671875
iter 15293 (epoch 25), train_loss = 2.593, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 15294 (epoch 25), train_loss = 2.746, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 15295 (epoch 25), train_loss = 2.818, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 15296 (epoch 25), train_loss = 2.777, time/batch = 0.033
Read data: 0.00012230873107910156
iter 15297 (epoch 25), train_loss = 2.218, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 15298 (epoch 25), train_loss = 2.615, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 15299 (epoch 25), train_loss = 2.473, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 15300 (epoch 25), train_loss = 2.363, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 15301 (epoch 25), train_loss = 2.696, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 15302 (epoch 25), train_loss = 2.622, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 15303 (epoch 25), train_loss = 2.447, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 15304 (epoch 25), train_loss = 2.603, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 15305 (epoch 25), train_loss = 2.241, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 15306 (epoch 25), train_loss = 2.527, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 15307 (epoch 25), train_loss = 2.388, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 15308 (epoch 25), train_loss = 2.800, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 15309 (epoch 25), train_loss = 2.574, time/batch = 0.021
Read data: 9.870529174804688e-05
iter 15310 (epoch 25), train_loss = 2.309, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 15311 (epoch 25), train_loss = 2.665, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 15312 (epoch 25), train_loss = 2.725, time/batch = 0.033
Read data: 9.965896606445312e-05
iter 15313 (epoch 25), train_loss = 2.030, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 15314 (epoch 25), train_loss = 2.572, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 15315 (epoch 25), train_loss = 1.859, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 15316 (epoch 25), train_loss = 2.405, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 15317 (epoch 25), train_loss = 2.601, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 15318 (epoch 25), train_loss = 2.744, time/batch = 0.023
Read data: 0.00010895729064941406
iter 15319 (epoch 25), train_loss = 2.480, time/batch = 0.037
Read data: 9.369850158691406e-05
iter 15320 (epoch 25), train_loss = 2.390, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 15321 (epoch 25), train_loss = 2.463, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 15322 (epoch 25), train_loss = 2.626, time/batch = 0.021
Read data: 8.034706115722656e-05
iter 15323 (epoch 25), train_loss = 2.351, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 15324 (epoch 25), train_loss = 2.445, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 15325 (epoch 25), train_loss = 2.571, time/batch = 0.038
Read data: 8.487701416015625e-05
iter 15326 (epoch 25), train_loss = 2.687, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 15327 (epoch 25), train_loss = 2.390, time/batch = 0.023
Read data: 8.535385131835938e-05
iter 15328 (epoch 25), train_loss = 2.416, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 15329 (epoch 25), train_loss = 2.703, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 15330 (epoch 25), train_loss = 2.470, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 15331 (epoch 25), train_loss = 2.610, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 15332 (epoch 25), train_loss = 2.915, time/batch = 0.033
Read data: 8.177757263183594e-05
iter 15333 (epoch 25), train_loss = 2.629, time/batch = 0.040
Read data: 9.655952453613281e-05
iter 15334 (epoch 25), train_loss = 2.229, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 15335 (epoch 25), train_loss = 2.890, time/batch = 0.028
Read data: 0.00011968612670898438
iter 15336 (epoch 25), train_loss = 2.658, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 15337 (epoch 25), train_loss = 2.571, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 15338 (epoch 25), train_loss = 2.458, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 15339 (epoch 25), train_loss = 2.365, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 15340 (epoch 25), train_loss = 2.773, time/batch = 0.029
Read data: 0.00011467933654785156
iter 15341 (epoch 25), train_loss = 2.576, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 15342 (epoch 25), train_loss = 2.742, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 15343 (epoch 25), train_loss = 2.687, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 15344 (epoch 25), train_loss = 2.911, time/batch = 0.033
Read data: 8.177757263183594e-05
iter 15345 (epoch 25), train_loss = 2.613, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 15346 (epoch 25), train_loss = 2.288, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 15347 (epoch 25), train_loss = 2.504, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 15348 (epoch 25), train_loss = 2.755, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 15349 (epoch 25), train_loss = 2.194, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 15350 (epoch 25), train_loss = 2.614, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 15351 (epoch 25), train_loss = 2.522, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 15352 (epoch 25), train_loss = 2.745, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 15353 (epoch 25), train_loss = 2.968, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 15354 (epoch 25), train_loss = 2.770, time/batch = 0.029
Read data: 0.0001277923583984375
iter 15355 (epoch 25), train_loss = 2.240, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 15356 (epoch 25), train_loss = 2.873, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 15357 (epoch 25), train_loss = 2.714, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 15358 (epoch 25), train_loss = 2.263, time/batch = 0.025
Read data: 9.655952453613281e-05
iter 15359 (epoch 25), train_loss = 2.750, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 15360 (epoch 25), train_loss = 2.447, time/batch = 0.023
Read data: 0.0001246929168701172
iter 15361 (epoch 25), train_loss = 2.388, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 15362 (epoch 25), train_loss = 2.597, time/batch = 0.026
Read data: 9.72747802734375e-05
iter 15363 (epoch 25), train_loss = 2.193, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 15364 (epoch 25), train_loss = 2.540, time/batch = 0.022
Read data: 9.799003601074219e-05
iter 15365 (epoch 25), train_loss = 2.712, time/batch = 0.024
Read data: 9.799003601074219e-05
iter 15366 (epoch 25), train_loss = 2.879, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 15367 (epoch 25), train_loss = 2.324, time/batch = 0.021
Read data: 0.00012230873107910156
iter 15368 (epoch 25), train_loss = 2.588, time/batch = 0.027
Read data: 0.00011706352233886719
iter 15369 (epoch 25), train_loss = 2.647, time/batch = 0.035
Read data: 8.130073547363281e-05
iter 15370 (epoch 25), train_loss = 2.725, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 15371 (epoch 25), train_loss = 2.064, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 15372 (epoch 25), train_loss = 2.387, time/batch = 0.027
Read data: 0.00010061264038085938
iter 15373 (epoch 25), train_loss = 2.590, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 15374 (epoch 25), train_loss = 2.266, time/batch = 0.025
Read data: 9.1552734375e-05
iter 15375 (epoch 25), train_loss = 2.417, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 15376 (epoch 25), train_loss = 2.153, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 15377 (epoch 25), train_loss = 2.222, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 15378 (epoch 25), train_loss = 2.128, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 15379 (epoch 25), train_loss = 2.651, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 15380 (epoch 25), train_loss = 2.805, time/batch = 0.027
Read data: 0.00011801719665527344
iter 15381 (epoch 25), train_loss = 2.533, time/batch = 0.024
Read data: 9.799003601074219e-05
iter 15382 (epoch 25), train_loss = 2.759, time/batch = 0.031
Read data: 7.867813110351562e-05
iter 15383 (epoch 25), train_loss = 2.710, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 15384 (epoch 25), train_loss = 2.468, time/batch = 0.023
Read data: 9.989738464355469e-05
iter 15385 (epoch 25), train_loss = 2.595, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 15386 (epoch 25), train_loss = 2.634, time/batch = 0.021
Read data: 8.511543273925781e-05
iter 15387 (epoch 25), train_loss = 2.371, time/batch = 0.038
Read data: 8.058547973632812e-05
iter 15388 (epoch 25), train_loss = 2.402, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 15389 (epoch 25), train_loss = 3.201, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 15390 (epoch 25), train_loss = 2.592, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 15391 (epoch 25), train_loss = 2.445, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 15392 (epoch 25), train_loss = 2.248, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 15393 (epoch 25), train_loss = 2.283, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 15394 (epoch 25), train_loss = 2.692, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 15395 (epoch 25), train_loss = 2.821, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 15396 (epoch 25), train_loss = 2.666, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 15397 (epoch 25), train_loss = 2.972, time/batch = 0.029
Read data: 0.00013017654418945312
iter 15398 (epoch 25), train_loss = 2.367, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 15399 (epoch 25), train_loss = 3.325, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 15400 (epoch 25), train_loss = 2.809, time/batch = 0.033
Read data: 8.559226989746094e-05
iter 15401 (epoch 25), train_loss = 2.304, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 15402 (epoch 25), train_loss = 2.772, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 15403 (epoch 25), train_loss = 2.390, time/batch = 0.023
Read data: 9.1552734375e-05
iter 15404 (epoch 25), train_loss = 2.728, time/batch = 0.027
Read data: 0.00010228157043457031
iter 15405 (epoch 25), train_loss = 2.807, time/batch = 0.031
Read data: 9.775161743164062e-05
iter 15406 (epoch 25), train_loss = 2.532, time/batch = 0.032
Read data: 9.036064147949219e-05
iter 15407 (epoch 25), train_loss = 2.100, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 15408 (epoch 25), train_loss = 2.904, time/batch = 0.039
Read data: 8.96453857421875e-05
iter 15409 (epoch 25), train_loss = 2.401, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 15410 (epoch 25), train_loss = 2.707, time/batch = 0.029
Read data: 9.775161743164062e-05
iter 15411 (epoch 25), train_loss = 2.565, time/batch = 0.023
Read data: 0.00013184547424316406
iter 15412 (epoch 25), train_loss = 2.627, time/batch = 0.038
Read data: 8.893013000488281e-05
iter 15413 (epoch 25), train_loss = 2.599, time/batch = 0.030
Read data: 0.000125885009765625
iter 15414 (epoch 25), train_loss = 2.469, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 15415 (epoch 25), train_loss = 2.540, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 15416 (epoch 25), train_loss = 2.854, time/batch = 0.039
Read data: 8.916854858398438e-05
iter 15417 (epoch 25), train_loss = 2.554, time/batch = 0.036
Read data: 8.58306884765625e-05
iter 15418 (epoch 25), train_loss = 2.344, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 15419 (epoch 25), train_loss = 2.664, time/batch = 0.034
Read data: 0.00011849403381347656
iter 15420 (epoch 25), train_loss = 2.649, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 15421 (epoch 25), train_loss = 2.377, time/batch = 0.034
Read data: 8.7738037109375e-05
iter 15422 (epoch 25), train_loss = 2.565, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 15423 (epoch 25), train_loss = 2.245, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 15424 (epoch 25), train_loss = 2.376, time/batch = 0.021
Read data: 8.058547973632812e-05
iter 15425 (epoch 25), train_loss = 2.904, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 15426 (epoch 25), train_loss = 2.517, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 15427 (epoch 25), train_loss = 2.463, time/batch = 0.031
Read data: 9.226799011230469e-05
iter 15428 (epoch 25), train_loss = 2.652, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 15429 (epoch 25), train_loss = 2.634, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 15430 (epoch 25), train_loss = 2.320, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 15431 (epoch 25), train_loss = 2.332, time/batch = 0.029
Read data: 0.00010657310485839844
iter 15432 (epoch 25), train_loss = 2.331, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 15433 (epoch 25), train_loss = 2.504, time/batch = 0.021
Read data: 8.821487426757812e-05
iter 15434 (epoch 25), train_loss = 1.776, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 15435 (epoch 25), train_loss = 2.536, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 15436 (epoch 25), train_loss = 2.662, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 15437 (epoch 25), train_loss = 2.764, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 15438 (epoch 25), train_loss = 2.768, time/batch = 0.023
Read data: 0.00013256072998046875
iter 15439 (epoch 25), train_loss = 2.438, time/batch = 0.035
Read data: 8.845329284667969e-05
iter 15440 (epoch 25), train_loss = 2.607, time/batch = 0.031
Read data: 0.00013637542724609375
iter 15441 (epoch 25), train_loss = 2.568, time/batch = 0.028
Read data: 9.34600830078125e-05
iter 15442 (epoch 25), train_loss = 2.498, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 15443 (epoch 25), train_loss = 2.450, time/batch = 0.026
Read data: 0.0001614093780517578
iter 15444 (epoch 25), train_loss = 2.615, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 15445 (epoch 25), train_loss = 2.497, time/batch = 0.030
Read data: 8.511543273925781e-05
iter 15446 (epoch 25), train_loss = 2.083, time/batch = 0.025
Read data: 0.0025713443756103516
iter 15447 (epoch 25), train_loss = 2.429, time/batch = 0.029
Read data: 0.00016164779663085938
iter 15448 (epoch 25), train_loss = 2.422, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 15449 (epoch 25), train_loss = 2.331, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 15450 (epoch 25), train_loss = 2.692, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 15451 (epoch 25), train_loss = 2.692, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 15452 (epoch 25), train_loss = 2.138, time/batch = 0.024
Read data: 9.1552734375e-05
iter 15453 (epoch 25), train_loss = 2.681, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 15454 (epoch 25), train_loss = 2.756, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 15455 (epoch 25), train_loss = 2.652, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 15456 (epoch 25), train_loss = 2.721, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 15457 (epoch 25), train_loss = 2.830, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 15458 (epoch 25), train_loss = 2.564, time/batch = 0.025
Read data: 0.00010323524475097656
iter 15459 (epoch 25), train_loss = 2.645, time/batch = 0.025
Read data: 0.00019931793212890625
iter 15460 (epoch 25), train_loss = 2.534, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 15461 (epoch 25), train_loss = 2.631, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 15462 (epoch 25), train_loss = 2.536, time/batch = 0.023
Read data: 0.00014710426330566406
iter 15463 (epoch 25), train_loss = 2.622, time/batch = 0.035
Read data: 0.00014925003051757812
iter 15464 (epoch 25), train_loss = 2.600, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 15465 (epoch 25), train_loss = 2.099, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 15466 (epoch 25), train_loss = 2.403, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 15467 (epoch 25), train_loss = 2.434, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 15468 (epoch 25), train_loss = 2.446, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 15469 (epoch 25), train_loss = 2.604, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 15470 (epoch 25), train_loss = 2.524, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 15471 (epoch 25), train_loss = 2.495, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 15472 (epoch 25), train_loss = 2.672, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 15473 (epoch 25), train_loss = 2.753, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 15474 (epoch 25), train_loss = 2.475, time/batch = 0.024
Read data: 0.00010228157043457031
iter 15475 (epoch 25), train_loss = 2.607, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 15476 (epoch 25), train_loss = 2.231, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 15477 (epoch 25), train_loss = 2.965, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 15478 (epoch 25), train_loss = 2.531, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 15479 (epoch 25), train_loss = 2.693, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 15480 (epoch 25), train_loss = 2.785, time/batch = 0.028
Read data: 0.00010156631469726562
iter 15481 (epoch 25), train_loss = 2.248, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 15482 (epoch 25), train_loss = 2.346, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 15483 (epoch 25), train_loss = 2.412, time/batch = 0.030
Read data: 0.0001327991485595703
iter 15484 (epoch 25), train_loss = 2.674, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 15485 (epoch 25), train_loss = 2.184, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 15486 (epoch 25), train_loss = 2.706, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 15487 (epoch 25), train_loss = 2.629, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 15488 (epoch 25), train_loss = 2.158, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 15489 (epoch 25), train_loss = 2.595, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 15490 (epoch 25), train_loss = 2.807, time/batch = 0.027
Read data: 0.00011873245239257812
iter 15491 (epoch 25), train_loss = 2.618, time/batch = 0.025
Read data: 0.00013899803161621094
iter 15492 (epoch 25), train_loss = 2.627, time/batch = 0.023
Read data: 0.00010442733764648438
iter 15493 (epoch 25), train_loss = 2.659, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 15494 (epoch 25), train_loss = 2.403, time/batch = 0.032
Read data: 0.00014543533325195312
iter 15495 (epoch 25), train_loss = 2.405, time/batch = 0.027
Read data: 0.00015616416931152344
iter 15496 (epoch 25), train_loss = 2.185, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 15497 (epoch 25), train_loss = 2.471, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 15498 (epoch 25), train_loss = 2.377, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 15499 (epoch 25), train_loss = 2.674, time/batch = 0.027
Read data: 0.0003361701965332031
iter 15500 (epoch 25), train_loss = 2.112, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 15501 (epoch 25), train_loss = 2.584, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 15502 (epoch 25), train_loss = 2.291, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 15503 (epoch 25), train_loss = 2.262, time/batch = 0.027
Read data: 0.0001633167266845703
iter 15504 (epoch 25), train_loss = 2.367, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 15505 (epoch 25), train_loss = 2.069, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 15506 (epoch 25), train_loss = 2.899, time/batch = 0.023
Read data: 0.00014257431030273438
iter 15507 (epoch 25), train_loss = 2.606, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 15508 (epoch 25), train_loss = 2.294, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 15509 (epoch 25), train_loss = 2.480, time/batch = 0.033
Read data: 8.606910705566406e-05
iter 15510 (epoch 25), train_loss = 2.757, time/batch = 0.027
Read data: 0.00012946128845214844
iter 15511 (epoch 25), train_loss = 2.657, time/batch = 0.035
Read data: 0.00011205673217773438
iter 15512 (epoch 25), train_loss = 2.763, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 15513 (epoch 25), train_loss = 2.726, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 15514 (epoch 25), train_loss = 2.599, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 15515 (epoch 25), train_loss = 2.511, time/batch = 0.025
Read data: 0.00017380714416503906
iter 15516 (epoch 25), train_loss = 2.760, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 15517 (epoch 25), train_loss = 2.418, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 15518 (epoch 25), train_loss = 2.614, time/batch = 0.025
Read data: 0.00013589859008789062
iter 15519 (epoch 25), train_loss = 2.263, time/batch = 0.023
Read data: 0.00012087821960449219
iter 15520 (epoch 25), train_loss = 2.293, time/batch = 0.027
Read data: 9.72747802734375e-05
iter 15521 (epoch 25), train_loss = 2.188, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 15522 (epoch 25), train_loss = 3.084, time/batch = 0.030
Read data: 0.00012612342834472656
iter 15523 (epoch 25), train_loss = 2.686, time/batch = 0.031
Read data: 0.00011587142944335938
iter 15524 (epoch 25), train_loss = 2.384, time/batch = 0.025
Read data: 0.00021338462829589844
iter 15525 (epoch 25), train_loss = 2.447, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 15526 (epoch 25), train_loss = 2.590, time/batch = 0.025
Read data: 0.00014472007751464844
iter 15527 (epoch 25), train_loss = 2.644, time/batch = 0.025
Read data: 9.846687316894531e-05
iter 15528 (epoch 25), train_loss = 2.559, time/batch = 0.025
Read data: 0.00011706352233886719
iter 15529 (epoch 25), train_loss = 2.495, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 15530 (epoch 25), train_loss = 2.382, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 15531 (epoch 25), train_loss = 2.717, time/batch = 0.025
Read data: 0.0001385211944580078
iter 15532 (epoch 25), train_loss = 2.412, time/batch = 0.023
Read data: 0.00011920928955078125
iter 15533 (epoch 25), train_loss = 2.784, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 15534 (epoch 25), train_loss = 2.354, time/batch = 0.024
Read data: 0.00014829635620117188
iter 15535 (epoch 25), train_loss = 2.538, time/batch = 0.025
Read data: 0.00018024444580078125
iter 15536 (epoch 25), train_loss = 2.518, time/batch = 0.023
Read data: 0.0001201629638671875
iter 15537 (epoch 25), train_loss = 2.429, time/batch = 0.029
Read data: 0.0001068115234375
iter 15538 (epoch 25), train_loss = 2.442, time/batch = 0.028
Read data: 0.00013208389282226562
iter 15539 (epoch 25), train_loss = 2.761, time/batch = 0.021
Read data: 0.00010037422180175781
iter 15540 (epoch 25), train_loss = 2.559, time/batch = 0.022
Read data: 0.0001399517059326172
iter 15541 (epoch 25), train_loss = 2.548, time/batch = 0.031
Read data: 9.131431579589844e-05
iter 15542 (epoch 25), train_loss = 2.961, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 15543 (epoch 25), train_loss = 2.520, time/batch = 0.023
Read data: 0.00013566017150878906
iter 15544 (epoch 25), train_loss = 2.485, time/batch = 0.028
Read data: 0.00011849403381347656
iter 15545 (epoch 25), train_loss = 2.687, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 15546 (epoch 25), train_loss = 2.710, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 15547 (epoch 25), train_loss = 2.536, time/batch = 0.034
Read data: 0.00014400482177734375
iter 15548 (epoch 25), train_loss = 2.284, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 15549 (epoch 25), train_loss = 2.438, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 15550 (epoch 25), train_loss = 2.394, time/batch = 0.033
Read data: 9.107589721679688e-05
iter 15551 (epoch 25), train_loss = 2.647, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 15552 (epoch 25), train_loss = 2.927, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 15553 (epoch 25), train_loss = 2.703, time/batch = 0.034
Read data: 8.082389831542969e-05
iter 15554 (epoch 25), train_loss = 2.719, time/batch = 0.034
Read data: 8.463859558105469e-05
iter 15555 (epoch 25), train_loss = 2.657, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 15556 (epoch 25), train_loss = 2.959, time/batch = 0.035
Read data: 0.00013875961303710938
iter 15557 (epoch 25), train_loss = 2.634, time/batch = 0.028
Read data: 0.00011563301086425781
iter 15558 (epoch 25), train_loss = 2.795, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 15559 (epoch 25), train_loss = 3.065, time/batch = 0.031
Read data: 8.726119995117188e-05
iter 15560 (epoch 25), train_loss = 2.150, time/batch = 0.021
Read data: 8.440017700195312e-05
iter 15561 (epoch 25), train_loss = 2.558, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 15562 (epoch 25), train_loss = 2.472, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 15563 (epoch 25), train_loss = 2.293, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 15564 (epoch 25), train_loss = 2.802, time/batch = 0.024
Read data: 0.0001010894775390625
iter 15565 (epoch 25), train_loss = 2.435, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 15566 (epoch 25), train_loss = 2.567, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 15567 (epoch 25), train_loss = 2.696, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 15568 (epoch 25), train_loss = 2.316, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 15569 (epoch 25), train_loss = 2.273, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 15570 (epoch 25), train_loss = 2.259, time/batch = 0.034
Read data: 8.535385131835938e-05
iter 15571 (epoch 25), train_loss = 2.274, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 15572 (epoch 25), train_loss = 2.677, time/batch = 0.026
Read data: 0.00011587142944335938
iter 15573 (epoch 25), train_loss = 2.362, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 15574 (epoch 25), train_loss = 2.079, time/batch = 0.024
Read data: 7.343292236328125e-05
iter 15575 (epoch 25), train_loss = 2.394, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 15576 (epoch 25), train_loss = 2.276, time/batch = 0.030
Read data: 8.797645568847656e-05
iter 15577 (epoch 25), train_loss = 2.315, time/batch = 0.028
Read data: 0.00013828277587890625
iter 15578 (epoch 25), train_loss = 2.504, time/batch = 0.032
Read data: 0.00012063980102539062
iter 15579 (epoch 25), train_loss = 2.355, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 15580 (epoch 25), train_loss = 2.658, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 15581 (epoch 25), train_loss = 2.603, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 15582 (epoch 25), train_loss = 2.389, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 15583 (epoch 25), train_loss = 2.034, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 15584 (epoch 25), train_loss = 2.239, time/batch = 0.021
Read data: 0.0001285076141357422
iter 15585 (epoch 25), train_loss = 2.305, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 15586 (epoch 25), train_loss = 2.821, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 15587 (epoch 25), train_loss = 2.566, time/batch = 0.036
Read data: 8.988380432128906e-05
iter 15588 (epoch 25), train_loss = 2.247, time/batch = 0.023
Read data: 0.0001437664031982422
iter 15589 (epoch 25), train_loss = 2.314, time/batch = 0.029
Read data: 0.00011420249938964844
iter 15590 (epoch 25), train_loss = 2.438, time/batch = 0.033
Read data: 7.987022399902344e-05
iter 15591 (epoch 25), train_loss = 2.145, time/batch = 0.028
Read data: 0.000888824462890625
iter 15592 (epoch 25), train_loss = 2.825, time/batch = 0.036
Read data: 9.441375732421875e-05
iter 15593 (epoch 25), train_loss = 3.031, time/batch = 0.028
Read data: 0.00011086463928222656
iter 15594 (epoch 25), train_loss = 2.588, time/batch = 0.031
Read data: 8.7738037109375e-05
iter 15595 (epoch 25), train_loss = 2.404, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 15596 (epoch 25), train_loss = 2.268, time/batch = 0.022
Read data: 0.0001323223114013672
iter 15597 (epoch 25), train_loss = 2.616, time/batch = 0.033
Read data: 8.58306884765625e-05
iter 15598 (epoch 25), train_loss = 2.373, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 15599 (epoch 25), train_loss = 2.848, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 15600 (epoch 25), train_loss = 2.315, time/batch = 0.026
Read data: 0.00012159347534179688
iter 15601 (epoch 26), train_loss = 2.391, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 15602 (epoch 26), train_loss = 2.530, time/batch = 0.032
Read data: 9.846687316894531e-05
iter 15603 (epoch 26), train_loss = 2.868, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 15604 (epoch 26), train_loss = 2.257, time/batch = 0.026
Read data: 0.00011730194091796875
iter 15605 (epoch 26), train_loss = 2.359, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 15606 (epoch 26), train_loss = 2.383, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 15607 (epoch 26), train_loss = 2.318, time/batch = 0.023
Read data: 0.0017879009246826172
iter 15608 (epoch 26), train_loss = 2.659, time/batch = 0.024
Read data: 7.748603820800781e-05
iter 15609 (epoch 26), train_loss = 2.413, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 15610 (epoch 26), train_loss = 2.537, time/batch = 0.034
Read data: 7.748603820800781e-05
iter 15611 (epoch 26), train_loss = 2.903, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 15612 (epoch 26), train_loss = 2.407, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 15613 (epoch 26), train_loss = 2.159, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 15614 (epoch 26), train_loss = 2.383, time/batch = 0.023
Read data: 0.0017123222351074219
iter 15615 (epoch 26), train_loss = 2.722, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 15616 (epoch 26), train_loss = 2.161, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 15617 (epoch 26), train_loss = 2.455, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 15618 (epoch 26), train_loss = 2.355, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 15619 (epoch 26), train_loss = 2.769, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 15620 (epoch 26), train_loss = 2.579, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 15621 (epoch 26), train_loss = 2.570, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 15622 (epoch 26), train_loss = 2.397, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 15623 (epoch 26), train_loss = 2.408, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 15624 (epoch 26), train_loss = 2.657, time/batch = 0.034
Read data: 0.00016832351684570312
iter 15625 (epoch 26), train_loss = 2.749, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 15626 (epoch 26), train_loss = 2.550, time/batch = 0.030
Read data: 0.0001308917999267578
iter 15627 (epoch 26), train_loss = 2.247, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 15628 (epoch 26), train_loss = 2.517, time/batch = 0.026
Read data: 0.00010466575622558594
iter 15629 (epoch 26), train_loss = 2.610, time/batch = 0.025
Read data: 7.605552673339844e-05
iter 15630 (epoch 26), train_loss = 2.553, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 15631 (epoch 26), train_loss = 2.553, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 15632 (epoch 26), train_loss = 2.193, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 15633 (epoch 26), train_loss = 2.419, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 15634 (epoch 26), train_loss = 2.456, time/batch = 0.030
Read data: 0.00015878677368164062
iter 15635 (epoch 26), train_loss = 2.450, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 15636 (epoch 26), train_loss = 2.201, time/batch = 0.022
Read data: 7.963180541992188e-05
iter 15637 (epoch 26), train_loss = 2.580, time/batch = 0.021
Read data: 0.0016825199127197266
iter 15638 (epoch 26), train_loss = 2.263, time/batch = 0.020
Read data: 9.107589721679688e-05
iter 15639 (epoch 26), train_loss = 2.565, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 15640 (epoch 26), train_loss = 2.621, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 15641 (epoch 26), train_loss = 2.382, time/batch = 0.025
Read data: 9.1552734375e-05
iter 15642 (epoch 26), train_loss = 2.437, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 15643 (epoch 26), train_loss = 2.565, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 15644 (epoch 26), train_loss = 2.350, time/batch = 0.035
Read data: 8.177757263183594e-05
iter 15645 (epoch 26), train_loss = 2.735, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 15646 (epoch 26), train_loss = 2.385, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 15647 (epoch 26), train_loss = 2.602, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 15648 (epoch 26), train_loss = 2.841, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 15649 (epoch 26), train_loss = 2.558, time/batch = 0.030
Read data: 0.000186920166015625
iter 15650 (epoch 26), train_loss = 2.275, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 15651 (epoch 26), train_loss = 2.728, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 15652 (epoch 26), train_loss = 2.314, time/batch = 0.020
Read data: 9.441375732421875e-05
iter 15653 (epoch 26), train_loss = 2.747, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 15654 (epoch 26), train_loss = 2.872, time/batch = 0.030
Read data: 9.369850158691406e-05
iter 15655 (epoch 26), train_loss = 2.274, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 15656 (epoch 26), train_loss = 2.570, time/batch = 0.025
Read data: 9.655952453613281e-05
iter 15657 (epoch 26), train_loss = 2.750, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 15658 (epoch 26), train_loss = 2.416, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 15659 (epoch 26), train_loss = 2.247, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 15660 (epoch 26), train_loss = 2.638, time/batch = 0.020
Read data: 9.322166442871094e-05
iter 15661 (epoch 26), train_loss = 2.492, time/batch = 0.027
Read data: 0.00011086463928222656
iter 15662 (epoch 26), train_loss = 2.837, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 15663 (epoch 26), train_loss = 2.291, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 15664 (epoch 26), train_loss = 2.488, time/batch = 0.032
Read data: 8.535385131835938e-05
iter 15665 (epoch 26), train_loss = 2.598, time/batch = 0.032
Read data: 0.00012421607971191406
iter 15666 (epoch 26), train_loss = 2.425, time/batch = 0.034
Read data: 9.322166442871094e-05
iter 15667 (epoch 26), train_loss = 2.085, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 15668 (epoch 26), train_loss = 2.609, time/batch = 0.032
Read data: 8.797645568847656e-05
iter 15669 (epoch 26), train_loss = 2.647, time/batch = 0.030
Read data: 0.0001633167266845703
iter 15670 (epoch 26), train_loss = 2.548, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 15671 (epoch 26), train_loss = 2.519, time/batch = 0.022
Read data: 8.320808410644531e-05
iter 15672 (epoch 26), train_loss = 2.645, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 15673 (epoch 26), train_loss = 2.563, time/batch = 0.032
Read data: 8.320808410644531e-05
iter 15674 (epoch 26), train_loss = 2.171, time/batch = 0.024
Read data: 0.00021314620971679688
iter 15675 (epoch 26), train_loss = 2.536, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 15676 (epoch 26), train_loss = 2.295, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 15677 (epoch 26), train_loss = 2.249, time/batch = 0.019
Read data: 9.131431579589844e-05
iter 15678 (epoch 26), train_loss = 2.467, time/batch = 0.035
Read data: 7.772445678710938e-05
iter 15679 (epoch 26), train_loss = 2.196, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 15680 (epoch 26), train_loss = 2.087, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 15681 (epoch 26), train_loss = 2.821, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 15682 (epoch 26), train_loss = 2.551, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 15683 (epoch 26), train_loss = 2.623, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 15684 (epoch 26), train_loss = 2.335, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 15685 (epoch 26), train_loss = 2.895, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 15686 (epoch 26), train_loss = 2.190, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 15687 (epoch 26), train_loss = 2.262, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 15688 (epoch 26), train_loss = 2.617, time/batch = 0.028
Read data: 0.000102996826171875
iter 15689 (epoch 26), train_loss = 2.919, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 15690 (epoch 26), train_loss = 2.392, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 15691 (epoch 26), train_loss = 2.569, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 15692 (epoch 26), train_loss = 2.624, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 15693 (epoch 26), train_loss = 2.409, time/batch = 0.025
Read data: 0.0001316070556640625
iter 15694 (epoch 26), train_loss = 2.764, time/batch = 0.035
Read data: 7.891654968261719e-05
iter 15695 (epoch 26), train_loss = 2.677, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 15696 (epoch 26), train_loss = 2.465, time/batch = 0.029
Read data: 0.00018024444580078125
iter 15697 (epoch 26), train_loss = 3.001, time/batch = 0.035
Read data: 0.00012922286987304688
iter 15698 (epoch 26), train_loss = 2.382, time/batch = 0.041
Read data: 9.131431579589844e-05
iter 15699 (epoch 26), train_loss = 2.558, time/batch = 0.028
Read data: 0.00020194053649902344
iter 15700 (epoch 26), train_loss = 2.950, time/batch = 0.043
Read data: 0.00010466575622558594
iter 15701 (epoch 26), train_loss = 2.754, time/batch = 0.034
Read data: 9.870529174804688e-05
iter 15702 (epoch 26), train_loss = 2.236, time/batch = 0.024
Read data: 0.00010395050048828125
iter 15703 (epoch 26), train_loss = 2.468, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 15704 (epoch 26), train_loss = 2.114, time/batch = 0.033
Read data: 0.00010895729064941406
iter 15705 (epoch 26), train_loss = 2.244, time/batch = 0.024
Read data: 9.965896606445312e-05
iter 15706 (epoch 26), train_loss = 2.244, time/batch = 0.027
Read data: 0.00010919570922851562
iter 15707 (epoch 26), train_loss = 2.553, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 15708 (epoch 26), train_loss = 2.467, time/batch = 0.045
Read data: 0.00012755393981933594
iter 15709 (epoch 26), train_loss = 2.695, time/batch = 0.025
Read data: 0.00011467933654785156
iter 15710 (epoch 26), train_loss = 2.807, time/batch = 0.035
Read data: 0.00011301040649414062
iter 15711 (epoch 26), train_loss = 2.799, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 15712 (epoch 26), train_loss = 2.228, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 15713 (epoch 26), train_loss = 2.179, time/batch = 0.032
Read data: 0.00010991096496582031
iter 15714 (epoch 26), train_loss = 2.620, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 15715 (epoch 26), train_loss = 2.462, time/batch = 0.025
Read data: 0.00021147727966308594
iter 15716 (epoch 26), train_loss = 2.776, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 15717 (epoch 26), train_loss = 2.633, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 15718 (epoch 26), train_loss = 2.572, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 15719 (epoch 26), train_loss = 2.410, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 15720 (epoch 26), train_loss = 2.319, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 15721 (epoch 26), train_loss = 2.446, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 15722 (epoch 26), train_loss = 2.760, time/batch = 0.028
Read data: 0.00017333030700683594
iter 15723 (epoch 26), train_loss = 2.467, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 15724 (epoch 26), train_loss = 2.565, time/batch = 0.027
Read data: 0.0002117156982421875
iter 15725 (epoch 26), train_loss = 2.725, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 15726 (epoch 26), train_loss = 2.682, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 15727 (epoch 26), train_loss = 2.731, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 15728 (epoch 26), train_loss = 2.793, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 15729 (epoch 26), train_loss = 2.275, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 15730 (epoch 26), train_loss = 2.364, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 15731 (epoch 26), train_loss = 2.324, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 15732 (epoch 26), train_loss = 2.600, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 15733 (epoch 26), train_loss = 3.080, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 15734 (epoch 26), train_loss = 2.600, time/batch = 0.031
Read data: 0.0001595020294189453
iter 15735 (epoch 26), train_loss = 2.645, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 15736 (epoch 26), train_loss = 2.465, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 15737 (epoch 26), train_loss = 2.552, time/batch = 0.031
Read data: 9.202957153320312e-05
iter 15738 (epoch 26), train_loss = 2.369, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 15739 (epoch 26), train_loss = 2.525, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 15740 (epoch 26), train_loss = 2.274, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 15741 (epoch 26), train_loss = 2.779, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 15742 (epoch 26), train_loss = 2.742, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 15743 (epoch 26), train_loss = 2.403, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 15744 (epoch 26), train_loss = 1.943, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 15745 (epoch 26), train_loss = 2.746, time/batch = 0.032
Read data: 9.274482727050781e-05
iter 15746 (epoch 26), train_loss = 2.323, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 15747 (epoch 26), train_loss = 2.673, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 15748 (epoch 26), train_loss = 2.626, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 15749 (epoch 26), train_loss = 2.665, time/batch = 0.028
Read data: 0.00016355514526367188
iter 15750 (epoch 26), train_loss = 2.455, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 15751 (epoch 26), train_loss = 2.833, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 15752 (epoch 26), train_loss = 2.642, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 15753 (epoch 26), train_loss = 2.683, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 15754 (epoch 26), train_loss = 2.325, time/batch = 0.024
Read data: 0.00013756752014160156
iter 15755 (epoch 26), train_loss = 2.442, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 15756 (epoch 26), train_loss = 2.228, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 15757 (epoch 26), train_loss = 2.559, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 15758 (epoch 26), train_loss = 2.129, time/batch = 0.031
Read data: 0.00013375282287597656
iter 15759 (epoch 26), train_loss = 2.863, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 15760 (epoch 26), train_loss = 2.716, time/batch = 0.032
Read data: 9.107589721679688e-05
iter 15761 (epoch 26), train_loss = 2.167, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 15762 (epoch 26), train_loss = 2.196, time/batch = 0.023
Read data: 0.0001308917999267578
iter 15763 (epoch 26), train_loss = 2.662, time/batch = 0.036
Read data: 8.702278137207031e-05
iter 15764 (epoch 26), train_loss = 2.752, time/batch = 0.035
Read data: 8.869171142578125e-05
iter 15765 (epoch 26), train_loss = 2.554, time/batch = 0.030
Read data: 9.34600830078125e-05
iter 15766 (epoch 26), train_loss = 2.706, time/batch = 0.024
Read data: 0.00010395050048828125
iter 15767 (epoch 26), train_loss = 2.485, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 15768 (epoch 26), train_loss = 2.672, time/batch = 0.025
Read data: 8.392333984375e-05
iter 15769 (epoch 26), train_loss = 2.985, time/batch = 0.020
Read data: 8.7738037109375e-05
iter 15770 (epoch 26), train_loss = 2.205, time/batch = 0.028
Read data: 9.036064147949219e-05
iter 15771 (epoch 26), train_loss = 2.445, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 15772 (epoch 26), train_loss = 2.256, time/batch = 0.027
Read data: 0.0001232624053955078
iter 15773 (epoch 26), train_loss = 2.345, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 15774 (epoch 26), train_loss = 2.340, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 15775 (epoch 26), train_loss = 2.299, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 15776 (epoch 26), train_loss = 2.425, time/batch = 0.023
Read data: 0.00012445449829101562
iter 15777 (epoch 26), train_loss = 2.220, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 15778 (epoch 26), train_loss = 2.554, time/batch = 0.039
Read data: 8.487701416015625e-05
iter 15779 (epoch 26), train_loss = 2.603, time/batch = 0.043
Read data: 8.511543273925781e-05
iter 15780 (epoch 26), train_loss = 2.455, time/batch = 0.028
Read data: 0.00011968612670898438
iter 15781 (epoch 26), train_loss = 2.888, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 15782 (epoch 26), train_loss = 2.804, time/batch = 0.042
Read data: 8.988380432128906e-05
iter 15783 (epoch 26), train_loss = 2.452, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 15784 (epoch 26), train_loss = 2.852, time/batch = 0.025
Read data: 0.0001518726348876953
iter 15785 (epoch 26), train_loss = 2.265, time/batch = 0.029
Read data: 9.393692016601562e-05
iter 15786 (epoch 26), train_loss = 2.179, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 15787 (epoch 26), train_loss = 2.404, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 15788 (epoch 26), train_loss = 2.793, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 15789 (epoch 26), train_loss = 2.855, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 15790 (epoch 26), train_loss = 2.509, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 15791 (epoch 26), train_loss = 2.124, time/batch = 0.024
Read data: 9.1552734375e-05
iter 15792 (epoch 26), train_loss = 2.777, time/batch = 0.033
Read data: 0.00011992454528808594
iter 15793 (epoch 26), train_loss = 2.183, time/batch = 0.029
Read data: 0.00014972686767578125
iter 15794 (epoch 26), train_loss = 2.719, time/batch = 0.031
Read data: 8.7738037109375e-05
iter 15795 (epoch 26), train_loss = 2.628, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 15796 (epoch 26), train_loss = 2.229, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 15797 (epoch 26), train_loss = 2.719, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 15798 (epoch 26), train_loss = 2.567, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 15799 (epoch 26), train_loss = 2.306, time/batch = 0.026
Read data: 0.00016736984252929688
iter 15800 (epoch 26), train_loss = 2.465, time/batch = 0.023
Read data: 0.0001227855682373047
iter 15801 (epoch 26), train_loss = 2.317, time/batch = 0.024
Read data: 9.5367431640625e-05
iter 15802 (epoch 26), train_loss = 1.996, time/batch = 0.024
Read data: 8.487701416015625e-05
iter 15803 (epoch 26), train_loss = 2.337, time/batch = 0.032
Read data: 9.560585021972656e-05
iter 15804 (epoch 26), train_loss = 2.519, time/batch = 0.025
Read data: 0.00010967254638671875
iter 15805 (epoch 26), train_loss = 2.539, time/batch = 0.030
Read data: 9.608268737792969e-05
iter 15806 (epoch 26), train_loss = 2.248, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 15807 (epoch 26), train_loss = 2.258, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 15808 (epoch 26), train_loss = 2.678, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 15809 (epoch 26), train_loss = 2.512, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 15810 (epoch 26), train_loss = 2.469, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15811 (epoch 26), train_loss = 2.345, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15812 (epoch 26), train_loss = 2.450, time/batch = 0.025
Read data: 0.0001308917999267578
iter 15813 (epoch 26), train_loss = 2.492, time/batch = 0.035
Read data: 0.00010752677917480469
iter 15814 (epoch 26), train_loss = 2.196, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 15815 (epoch 26), train_loss = 2.700, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 15816 (epoch 26), train_loss = 2.760, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 15817 (epoch 26), train_loss = 2.652, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 15818 (epoch 26), train_loss = 2.146, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 15819 (epoch 26), train_loss = 2.520, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 15820 (epoch 26), train_loss = 2.247, time/batch = 0.025
Read data: 0.00012731552124023438
iter 15821 (epoch 26), train_loss = 2.480, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 15822 (epoch 26), train_loss = 2.372, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 15823 (epoch 26), train_loss = 2.679, time/batch = 0.030
Read data: 9.274482727050781e-05
iter 15824 (epoch 26), train_loss = 2.665, time/batch = 0.026
Read data: 0.00016999244689941406
iter 15825 (epoch 26), train_loss = 2.673, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 15826 (epoch 26), train_loss = 2.457, time/batch = 0.034
Read data: 8.273124694824219e-05
iter 15827 (epoch 26), train_loss = 2.630, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 15828 (epoch 26), train_loss = 2.241, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 15829 (epoch 26), train_loss = 2.568, time/batch = 0.027
Read data: 0.000102996826171875
iter 15830 (epoch 26), train_loss = 2.551, time/batch = 0.037
Read data: 9.083747863769531e-05
iter 15831 (epoch 26), train_loss = 2.602, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 15832 (epoch 26), train_loss = 2.516, time/batch = 0.023
Read data: 0.00014400482177734375
iter 15833 (epoch 26), train_loss = 2.783, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 15834 (epoch 26), train_loss = 2.172, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 15835 (epoch 26), train_loss = 2.703, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 15836 (epoch 26), train_loss = 2.302, time/batch = 0.023
Read data: 0.00017571449279785156
iter 15837 (epoch 26), train_loss = 2.447, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 15838 (epoch 26), train_loss = 2.414, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 15839 (epoch 26), train_loss = 2.355, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 15840 (epoch 26), train_loss = 2.201, time/batch = 0.022
Read data: 0.00017213821411132812
iter 15841 (epoch 26), train_loss = 2.638, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 15842 (epoch 26), train_loss = 2.809, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 15843 (epoch 26), train_loss = 2.235, time/batch = 0.043
Read data: 8.416175842285156e-05
iter 15844 (epoch 26), train_loss = 2.106, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 15845 (epoch 26), train_loss = 2.291, time/batch = 0.032
Read data: 9.584426879882812e-05
iter 15846 (epoch 26), train_loss = 2.587, time/batch = 0.033
Read data: 0.0001220703125
iter 15847 (epoch 26), train_loss = 2.761, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 15848 (epoch 26), train_loss = 2.631, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 15849 (epoch 26), train_loss = 2.525, time/batch = 0.026
Read data: 0.0001735687255859375
iter 15850 (epoch 26), train_loss = 2.583, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 15851 (epoch 26), train_loss = 2.512, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 15852 (epoch 26), train_loss = 2.311, time/batch = 0.026
Read data: 0.0001270771026611328
iter 15853 (epoch 26), train_loss = 2.756, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 15854 (epoch 26), train_loss = 2.496, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 15855 (epoch 26), train_loss = 2.198, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 15856 (epoch 26), train_loss = 2.444, time/batch = 0.024
Read data: 0.00012612342834472656
iter 15857 (epoch 26), train_loss = 2.421, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 15858 (epoch 26), train_loss = 2.729, time/batch = 0.026
Read data: 0.00010538101196289062
iter 15859 (epoch 26), train_loss = 2.758, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 15860 (epoch 26), train_loss = 2.342, time/batch = 0.024
Read data: 0.0001583099365234375
iter 15861 (epoch 26), train_loss = 2.513, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 15862 (epoch 26), train_loss = 2.339, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 15863 (epoch 26), train_loss = 2.954, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 15864 (epoch 26), train_loss = 2.785, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 15865 (epoch 26), train_loss = 2.573, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 15866 (epoch 26), train_loss = 2.864, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 15867 (epoch 26), train_loss = 2.487, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 15868 (epoch 26), train_loss = 2.303, time/batch = 0.023
Read data: 0.00012683868408203125
iter 15869 (epoch 26), train_loss = 2.619, time/batch = 0.026
Read data: 8.392333984375e-05
iter 15870 (epoch 26), train_loss = 1.744, time/batch = 0.021
Read data: 8.606910705566406e-05
iter 15871 (epoch 26), train_loss = 2.504, time/batch = 0.032
Read data: 0.00010275840759277344
iter 15872 (epoch 26), train_loss = 2.656, time/batch = 0.029
Read data: 0.00014019012451171875
iter 15873 (epoch 26), train_loss = 2.495, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 15874 (epoch 26), train_loss = 2.359, time/batch = 0.023
Read data: 0.00016570091247558594
iter 15875 (epoch 26), train_loss = 2.621, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 15876 (epoch 26), train_loss = 2.451, time/batch = 0.025
Read data: 0.0001437664031982422
iter 15877 (epoch 26), train_loss = 2.886, time/batch = 0.030
Read data: 0.00011348724365234375
iter 15878 (epoch 26), train_loss = 2.476, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 15879 (epoch 26), train_loss = 2.518, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15880 (epoch 26), train_loss = 2.787, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 15881 (epoch 26), train_loss = 2.461, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 15882 (epoch 26), train_loss = 2.502, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 15883 (epoch 26), train_loss = 2.800, time/batch = 0.032
Read data: 8.511543273925781e-05
iter 15884 (epoch 26), train_loss = 2.246, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 15885 (epoch 26), train_loss = 2.943, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 15886 (epoch 26), train_loss = 2.358, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 15887 (epoch 26), train_loss = 2.450, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 15888 (epoch 26), train_loss = 2.503, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 15889 (epoch 26), train_loss = 2.472, time/batch = 0.035
Read data: 8.606910705566406e-05
iter 15890 (epoch 26), train_loss = 2.276, time/batch = 0.032
Read data: 8.511543273925781e-05
iter 15891 (epoch 26), train_loss = 2.605, time/batch = 0.034
Read data: 8.869171142578125e-05
iter 15892 (epoch 26), train_loss = 2.498, time/batch = 0.031
Read data: 8.916854858398438e-05
iter 15893 (epoch 26), train_loss = 2.412, time/batch = 0.028
Read data: 0.00012969970703125
iter 15894 (epoch 26), train_loss = 2.978, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 15895 (epoch 26), train_loss = 2.623, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 15896 (epoch 26), train_loss = 2.439, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 15897 (epoch 26), train_loss = 2.472, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 15898 (epoch 26), train_loss = 2.374, time/batch = 0.035
Read data: 8.225440979003906e-05
iter 15899 (epoch 26), train_loss = 2.863, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 15900 (epoch 26), train_loss = 2.304, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 15901 (epoch 26), train_loss = 2.647, time/batch = 0.032
Read data: 0.00015163421630859375
iter 15902 (epoch 26), train_loss = 2.517, time/batch = 0.031
Read data: 9.107589721679688e-05
iter 15903 (epoch 26), train_loss = 2.044, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 15904 (epoch 26), train_loss = 2.398, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 15905 (epoch 26), train_loss = 2.513, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 15906 (epoch 26), train_loss = 2.455, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 15907 (epoch 26), train_loss = 2.265, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 15908 (epoch 26), train_loss = 2.559, time/batch = 0.027
Read data: 0.00014519691467285156
iter 15909 (epoch 26), train_loss = 2.691, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 15910 (epoch 26), train_loss = 2.627, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 15911 (epoch 26), train_loss = 2.263, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 15912 (epoch 26), train_loss = 2.815, time/batch = 0.030
Read data: 0.0001575946807861328
iter 15913 (epoch 26), train_loss = 2.264, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 15914 (epoch 26), train_loss = 2.215, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 15915 (epoch 26), train_loss = 2.450, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 15916 (epoch 26), train_loss = 2.508, time/batch = 0.025
Read data: 0.00016951560974121094
iter 15917 (epoch 26), train_loss = 2.332, time/batch = 0.027
Read data: 0.00010323524475097656
iter 15918 (epoch 26), train_loss = 2.501, time/batch = 0.034
Read data: 8.034706115722656e-05
iter 15919 (epoch 26), train_loss = 2.978, time/batch = 0.041
Read data: 8.440017700195312e-05
iter 15920 (epoch 26), train_loss = 2.586, time/batch = 0.024
Read data: 0.00017070770263671875
iter 15921 (epoch 26), train_loss = 2.341, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 15922 (epoch 26), train_loss = 2.510, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 15923 (epoch 26), train_loss = 2.842, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 15924 (epoch 26), train_loss = 2.552, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 15925 (epoch 26), train_loss = 2.278, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 15926 (epoch 26), train_loss = 2.194, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 15927 (epoch 26), train_loss = 2.602, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 15928 (epoch 26), train_loss = 2.470, time/batch = 0.024
Read data: 0.0001728534698486328
iter 15929 (epoch 26), train_loss = 2.379, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 15930 (epoch 26), train_loss = 2.587, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 15931 (epoch 26), train_loss = 2.604, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 15932 (epoch 26), train_loss = 2.049, time/batch = 0.022
Read data: 0.00013518333435058594
iter 15933 (epoch 26), train_loss = 2.352, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 15934 (epoch 26), train_loss = 2.646, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 15935 (epoch 26), train_loss = 2.268, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 15936 (epoch 26), train_loss = 2.740, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 15937 (epoch 26), train_loss = 2.714, time/batch = 0.033
Read data: 0.00015974044799804688
iter 15938 (epoch 26), train_loss = 2.647, time/batch = 0.028
Read data: 0.00016021728515625
iter 15939 (epoch 26), train_loss = 2.677, time/batch = 0.037
Read data: 8.630752563476562e-05
iter 15940 (epoch 26), train_loss = 2.567, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 15941 (epoch 26), train_loss = 2.168, time/batch = 0.029
Read data: 8.893013000488281e-05
iter 15942 (epoch 26), train_loss = 2.354, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 15943 (epoch 26), train_loss = 2.225, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 15944 (epoch 26), train_loss = 2.568, time/batch = 0.028
Read data: 0.00013256072998046875
iter 15945 (epoch 26), train_loss = 2.355, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 15946 (epoch 26), train_loss = 2.483, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 15947 (epoch 26), train_loss = 2.391, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 15948 (epoch 26), train_loss = 2.422, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 15949 (epoch 26), train_loss = 2.490, time/batch = 0.034
Read data: 0.000179290771484375
iter 15950 (epoch 26), train_loss = 2.147, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 15951 (epoch 26), train_loss = 2.179, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 15952 (epoch 26), train_loss = 2.525, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 15953 (epoch 26), train_loss = 2.884, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 15954 (epoch 26), train_loss = 2.263, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 15955 (epoch 26), train_loss = 2.158, time/batch = 0.039
Read data: 8.368492126464844e-05
iter 15956 (epoch 26), train_loss = 2.331, time/batch = 0.021
Read data: 0.0001456737518310547
iter 15957 (epoch 26), train_loss = 2.962, time/batch = 0.038
Read data: 8.320808410644531e-05
iter 15958 (epoch 26), train_loss = 2.299, time/batch = 0.032
Read data: 8.511543273925781e-05
iter 15959 (epoch 26), train_loss = 2.719, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 15960 (epoch 26), train_loss = 2.543, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 15961 (epoch 26), train_loss = 2.339, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15962 (epoch 26), train_loss = 2.448, time/batch = 0.035
Read data: 8.869171142578125e-05
iter 15963 (epoch 26), train_loss = 2.162, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 15964 (epoch 26), train_loss = 2.400, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 15965 (epoch 26), train_loss = 2.311, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 15966 (epoch 26), train_loss = 2.428, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 15967 (epoch 26), train_loss = 2.584, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 15968 (epoch 26), train_loss = 2.502, time/batch = 0.028
Read data: 0.0001430511474609375
iter 15969 (epoch 26), train_loss = 2.625, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 15970 (epoch 26), train_loss = 2.502, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 15971 (epoch 26), train_loss = 2.132, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 15972 (epoch 26), train_loss = 2.002, time/batch = 0.026
Read data: 0.00017833709716796875
iter 15973 (epoch 26), train_loss = 2.414, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 15974 (epoch 26), train_loss = 2.633, time/batch = 0.030
Read data: 0.00020265579223632812
iter 15975 (epoch 26), train_loss = 2.342, time/batch = 0.030
Read data: 8.606910705566406e-05
iter 15976 (epoch 26), train_loss = 2.490, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 15977 (epoch 26), train_loss = 2.685, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 15978 (epoch 26), train_loss = 2.208, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 15979 (epoch 26), train_loss = 3.074, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 15980 (epoch 26), train_loss = 2.374, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 15981 (epoch 26), train_loss = 2.239, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 15982 (epoch 26), train_loss = 2.717, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 15983 (epoch 26), train_loss = 2.437, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 15984 (epoch 26), train_loss = 2.413, time/batch = 0.025
Read data: 0.00012087821960449219
iter 15985 (epoch 26), train_loss = 2.522, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 15986 (epoch 26), train_loss = 2.658, time/batch = 0.040
Read data: 8.320808410644531e-05
iter 15987 (epoch 26), train_loss = 2.523, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 15988 (epoch 26), train_loss = 1.983, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 15989 (epoch 26), train_loss = 2.274, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 15990 (epoch 26), train_loss = 2.758, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 15991 (epoch 26), train_loss = 2.702, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 15992 (epoch 26), train_loss = 2.905, time/batch = 0.024
Read data: 0.00014162063598632812
iter 15993 (epoch 26), train_loss = 2.291, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 15994 (epoch 26), train_loss = 2.296, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 15995 (epoch 26), train_loss = 2.708, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 15996 (epoch 26), train_loss = 2.672, time/batch = 0.021
Read data: 0.00013756752014160156
iter 15997 (epoch 26), train_loss = 2.518, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 15998 (epoch 26), train_loss = 2.535, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 15999 (epoch 26), train_loss = 2.364, time/batch = 0.023
image 976:    
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:     
image 2375:      
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.589205)
image 2798:    
image 5884:    
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.201652)
image 6903:    
image 3301:    
image 2019:    
image 5535:    
image 7680:     
image 5527:      
image 2568:    
image 160:    
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.514731)
image 4604:    
image 5745:    
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.026187)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:    
image 5629:    
image 7130:     
image 1679:     
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.537700)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.822076)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:  
image 5641:     
evaluating validation preformance... 70/1000 (2.596222)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.591771)
image 3276:      
image 3812:     
image 1400:    
image 3443:    
image 5027:     
image 7251:    
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.105158)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.922472)
image 2800:    
image 7249:    
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    UNK
image 150:      
evaluating validation preformance... 110/1000 (2.788587)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:     
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     UNK
evaluating validation preformance... 120/1000 (2.344769)
image 3477:     
image 1212:      
image 3809:     UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.928122)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:     
image 2867:     
evaluating validation preformance... 140/1000 (2.654155)
image 1738:     
image 1455:     
image 4198:     
image 2180:   
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    UNK
evaluating validation preformance... 150/1000 (2.906220)
image 1865:     
image 3830:      
image 360:     
image 5097:      
image 4455:     
image 1153:    
image 1248:    
image 7688:    
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.823861)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.594685)
image 7922:     
image 2353:    
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    UNK
image 3687:    
evaluating validation preformance... 180/1000 (2.751655)
image 2313:    
image 6289:    
image 8084:      
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.389043)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:    
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.325624)
image 5159:     
image 1199:    
image 2456:    
image 3402:    
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.429944)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.505381)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.291577)
image 1917:    
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.126517)
image 7143:     
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:   
image 528:    
evaluating validation preformance... 250/1000 (2.511428)
image 3028:    
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.524586)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.034914)
image 833:    
image 5483:     
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:     
image 2054:      
evaluating validation preformance... 280/1000 (2.547471)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.345077)
image 6835:     
image 4698:    
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.159945)
image 2805:    
image 4374:     
image 25:    
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.777360)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:    
image 6423:    
evaluating validation preformance... 320/1000 (2.289909)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:     
image 6267:    UNK
image 2203:     
image 5727:    
image 1159:    
evaluating validation preformance... 330/1000 (2.753991)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:    
image 2601:    
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.428896)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.479227)
image 6881:    UNK
image 942:     
image 2775:   
image 3311:     
image 4587:     
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.014374)
image 2905:    UNK
image 7814:      
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:     
image 6607:    
image 4866:     
evaluating validation preformance... 370/1000 (2.617329)
image 4351:      
image 1054:     
image 129:    
image 2849:     
image 725:   UNK
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.656942)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:     
image 6255:    
image 5255:    
image 3598:    
image 2997:    
image 60:    
evaluating validation preformance... 390/1000 (2.856869)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:    
image 1117:    
image 5817:     
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.220982)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:     
image 670:     
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.145397)
image 4359:     
image 2372:     
image 4472:     
image 6810:     
image 1592:     
image 7864:     
image 4286:     
image 6688:    
image 5697:    
image 7020:     
evaluating validation preformance... 420/1000 (2.370895)
image 30:     
image 5540:     
image 2445:      
image 5896:      
image 7607:     
image 1426:     
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     UNK
evaluating validation preformance... 430/1000 (2.753914)
image 385:    
image 6938:      
image 2381:    
image 5796:    
image 4010:     
image 3452:    
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.928436)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:      
image 4790:     
image 5855:    UNK
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.129225)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:     
image 2466:    UNK
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.687773)
image 7979:    UNK
image 1618:    UNK
image 7608:    
image 6393:    
image 5100:    
image 4480:     
image 1440:    
image 5886:    UNK
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.297914)
image 4503:    
image 7112:    
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (2.916952)
image 358:      
image 4663:    
image 5541:     
image 4485:     
image 2727:     
image 1040:    
image 3823:    UNK
image 1595:  UNK  
image 4757:     
image 205:    
evaluating validation preformance... 490/1000 (3.412317)
image 2044:    
image 4349:    
image 3855:      
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.506840)
image 1797:    
image 4670:     
image 4846:    
image 5907:     
image 3321:      
image 1700:    UNK
image 438:    
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.973553)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.630414)
image 6806:        UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:    
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.460989)
image 5619:     
image 4391:    UNK
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:      
image 6034:    
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.444353)
image 5292:    
image 2901:    
image 3568:    
image 690:     
image 3345:     
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.589855)
image 5439:    
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:     
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.589634)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:    
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.589126)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.611825)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:     
evaluating validation preformance... 590/1000 (2.552519)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.456141)
image 353:     
image 1095:     
image 3583:      
image 3264:    UNK
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.649474)
image 69:     
image 3465:    
image 6179:    
image 552:    
image 511:    
image 761:    
image 5742:    
image 359:    
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.387137)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.481199)
image 8074:    
image 1904:     
image 7917:      
image 2394:    
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.458868)
image 5313:      
image 2377:    
image 6058:    
image 4661:     
image 2955:   
image 3333:    
image 7124:    
image 4278:      
image 953:     
image 4037:    
evaluating validation preformance... 650/1000 (2.566495)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.651537)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:      
image 1972:     
evaluating validation preformance... 670/1000 (2.824335)
image 7877:    
image 6761:     
image 6880:   
image 4914:    
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:      
evaluating validation preformance... 680/1000 (3.003648)
image 1445:     UNK
image 6841:     
image 2896:    
image 6947:     
image 4782:    
image 7669:        
image 4382:    UNK
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.849289)
image 6860:     
image 576:     
image 6580:     
image 1497:     
image 3360:    
image 4939:      
image 6225:    
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (3.002525)
image 5343:      
image 68:     
image 3184:    
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.481348)
image 7368:    
image 709:     
image 3197:    
image 5214:    
image 445:     
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.621887)
image 5729:     
image 6395:     
image 516:      
image 1026:     
image 2972:      
image 3005:     
image 1241:      
image 2743:      
image 3665:    UNK
image 1290:    UNK
evaluating validation preformance... 730/1000 (2.270760)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:    
image 5092:      
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.379785)
image 2239:     
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.651763)
image 3279:    
image 6380:    
image 2663:     
image 3815:    
image 512:      
image 5899:      
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.997296)
image 4582:    
image 5484:    
image 3049:      
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.129882)
image 6220:     
image 6238:    UNK
image 4534:    
image 2732:     
image 7003:     
image 1739:     
image 5503:     
image 2329:    
image 1201:    
image 5956:     
evaluating validation preformance... 780/1000 (2.811752)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:    
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.145533)
image 5047:      
image 325:      
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.225346)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:      
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.432774)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.922457)
image 7204:      
image 4428:     
image 7825:      
image 5890:      
image 4334:    
image 5514:    UNK
image 7147:    
image 6348:     
image 580:    
image 2531:    
evaluating validation preformance... 830/1000 (2.377603)
image 5107:    
image 3973:    UNK
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:   
evaluating validation preformance... 840/1000 (2.453736)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.755445)
image 4404:      
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:      
image 3596:      
image 1921:     
image 6261:    
image 2166:     
evaluating validation preformance... 860/1000 (2.741518)
image 4254:      
image 6842:    
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:    
evaluating validation preformance... 870/1000 (2.347598)
image 4934:    
image 6487:     
image 4217:    
image 6355:     
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:    
image 28:      
evaluating validation preformance... 880/1000 (2.579072)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:    
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.962979)
image 7485:    
image 6102:    
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:    UNK
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.570542)
image 5664:     
image 4985:  UNK  
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:    
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.233228)
image 1368:     
image 1925:     
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.623071)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:       
image 7102:    
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.483614)
image 5636:      
image 7799:      
image 6025:     
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.687562)
image 5860:  UNK  
image 3275:    
image 1935:    
image 3520:     UNK
image 5452:    
image 2446:     
image 5984:    
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.952487)
image 1081:    
image 1179:     
image 4316:    UNK
image 3588:    
image 1085:      
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:    
evaluating validation preformance... 960/1000 (2.748539)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:     
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.276920)
image 5688:     
image 5448:    
image 5871:     
image 7516:      
image 3734:    
image 2921:      
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.764080)
image 7352:    
image 5113:     
image 7822:    UNK
image 4858:    
image 658:    
image 2982:     
image 5843:    
image 1822:      
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.458117)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.352210)
average loss on validation: 2.593
model saved to ./log_Att2in_sc/model.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2869720458984375
Cider scores: 0.6390504109806169
Read data: 0.36431288719177246
Cider scores: 0.6594548287102465
Read data: 0.31369996070861816
Cider scores: 0.5525437417562669
Read data: 0.23000407218933105
Cider scores: 0.620862249535481
Read data: 0.21304082870483398
Cider scores: 0.6214013954265497
Read data: 0.1818385124206543
Cider scores: 0.5077956848503643
Read data: 0.19439148902893066
Cider scores: 0.523333280266208
Read data: 0.17947959899902344
Cider scores: 0.6154285568690635
Read data: 0.1800832748413086
Cider scores: 0.5822843072612018
Read data: 0.17882418632507324
Cider scores: 0.6575562954502933
Read data: 0.17929887771606445
Cider scores: 0.6139271594145728
Read data: 0.24004602432250977
Cider scores: 0.676167484883106
Read data: 0.18768954277038574
Cider scores: 0.5296052441824686
Read data: 0.17841434478759766
Cider scores: 0.5411738556829779
Read data: 0.18178915977478027
Cider scores: 0.5738749596562746
Read data: 0.16740918159484863
Cider scores: 0.6558695663632721
Read data: 0.16168832778930664
Cider scores: 0.4578454485213596
Read data: 0.15983343124389648
Cider scores: 0.6460599820083932
Read data: 0.16038155555725098
Cider scores: 0.5852404972619524
Read data: 0.15866518020629883
Cider scores: 0.773232376203427
Average cider score on test set: 0.602
End calculating cider score on TEST data set
===============================================
Read data: 0.15998172760009766
iter 16000 (epoch 26), train_loss = 2.310, time/batch = 0.025
Read data: 0.0001475811004638672
iter 16001 (epoch 26), train_loss = 2.674, time/batch = 0.030
Read data: 0.0001533031463623047
iter 16002 (epoch 26), train_loss = 2.211, time/batch = 0.030
Read data: 0.0001399517059326172
iter 16003 (epoch 26), train_loss = 2.417, time/batch = 0.033
Read data: 0.00011944770812988281
iter 16004 (epoch 26), train_loss = 2.389, time/batch = 0.034
Read data: 0.0001475811004638672
iter 16005 (epoch 26), train_loss = 2.517, time/batch = 0.023
Read data: 0.00013327598571777344
iter 16006 (epoch 26), train_loss = 2.415, time/batch = 0.026
Read data: 0.00010323524475097656
iter 16007 (epoch 26), train_loss = 2.556, time/batch = 0.030
Read data: 0.00011754035949707031
iter 16008 (epoch 26), train_loss = 2.449, time/batch = 0.030
Read data: 9.846687316894531e-05
iter 16009 (epoch 26), train_loss = 2.504, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 16010 (epoch 26), train_loss = 2.587, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 16011 (epoch 26), train_loss = 2.376, time/batch = 0.023
Read data: 0.00016164779663085938
iter 16012 (epoch 26), train_loss = 2.657, time/batch = 0.027
Read data: 0.00012493133544921875
iter 16013 (epoch 26), train_loss = 2.522, time/batch = 0.033
Read data: 8.392333984375e-05
iter 16014 (epoch 26), train_loss = 2.279, time/batch = 0.026
Read data: 0.0001266002655029297
iter 16015 (epoch 26), train_loss = 2.798, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 16016 (epoch 26), train_loss = 2.213, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 16017 (epoch 26), train_loss = 2.437, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 16018 (epoch 26), train_loss = 2.312, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 16019 (epoch 26), train_loss = 2.436, time/batch = 0.029
Read data: 0.0001590251922607422
iter 16020 (epoch 26), train_loss = 2.396, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 16021 (epoch 26), train_loss = 2.098, time/batch = 0.019
Read data: 9.655952453613281e-05
iter 16022 (epoch 26), train_loss = 2.571, time/batch = 0.033
Read data: 7.891654968261719e-05
iter 16023 (epoch 26), train_loss = 2.469, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 16024 (epoch 26), train_loss = 2.649, time/batch = 0.026
Read data: 0.00010609626770019531
iter 16025 (epoch 26), train_loss = 2.178, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 16026 (epoch 26), train_loss = 2.492, time/batch = 0.022
Read data: 9.679794311523438e-05
iter 16027 (epoch 26), train_loss = 2.197, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 16028 (epoch 26), train_loss = 2.232, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 16029 (epoch 26), train_loss = 2.250, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 16030 (epoch 26), train_loss = 1.937, time/batch = 0.021
Read data: 0.00010275840759277344
iter 16031 (epoch 26), train_loss = 2.274, time/batch = 0.026
Read data: 0.00015807151794433594
iter 16032 (epoch 26), train_loss = 2.521, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 16033 (epoch 26), train_loss = 2.334, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 16034 (epoch 26), train_loss = 2.374, time/batch = 0.035
Read data: 7.772445678710938e-05
iter 16035 (epoch 26), train_loss = 2.434, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 16036 (epoch 26), train_loss = 2.398, time/batch = 0.031
Read data: 8.845329284667969e-05
iter 16037 (epoch 26), train_loss = 2.564, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 16038 (epoch 26), train_loss = 2.472, time/batch = 0.024
Read data: 9.965896606445312e-05
iter 16039 (epoch 26), train_loss = 2.615, time/batch = 0.027
Read data: 0.00014448165893554688
iter 16040 (epoch 26), train_loss = 2.651, time/batch = 0.022
Read data: 9.179115295410156e-05
iter 16041 (epoch 26), train_loss = 2.407, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 16042 (epoch 26), train_loss = 2.793, time/batch = 0.038
Read data: 0.00010323524475097656
iter 16043 (epoch 26), train_loss = 2.814, time/batch = 0.023
Read data: 8.392333984375e-05
iter 16044 (epoch 26), train_loss = 2.580, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 16045 (epoch 26), train_loss = 2.212, time/batch = 0.022
Read data: 7.62939453125e-05
iter 16046 (epoch 26), train_loss = 2.379, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 16047 (epoch 26), train_loss = 2.575, time/batch = 0.025
Read data: 0.00017881393432617188
iter 16048 (epoch 26), train_loss = 2.479, time/batch = 0.034
Read data: 7.796287536621094e-05
iter 16049 (epoch 26), train_loss = 2.471, time/batch = 0.024
Read data: 0.0002110004425048828
iter 16050 (epoch 26), train_loss = 2.284, time/batch = 0.020
Read data: 0.00013566017150878906
iter 16051 (epoch 26), train_loss = 2.592, time/batch = 0.033
Read data: 9.036064147949219e-05
iter 16052 (epoch 26), train_loss = 2.695, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 16053 (epoch 26), train_loss = 2.468, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 16054 (epoch 26), train_loss = 2.515, time/batch = 0.033
Read data: 9.34600830078125e-05
iter 16055 (epoch 26), train_loss = 2.493, time/batch = 0.035
Read data: 8.344650268554688e-05
iter 16056 (epoch 26), train_loss = 2.675, time/batch = 0.033
Read data: 8.654594421386719e-05
iter 16057 (epoch 26), train_loss = 2.452, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 16058 (epoch 26), train_loss = 2.554, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 16059 (epoch 26), train_loss = 2.775, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 16060 (epoch 26), train_loss = 2.657, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 16061 (epoch 26), train_loss = 2.691, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 16062 (epoch 26), train_loss = 2.305, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 16063 (epoch 26), train_loss = 2.269, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 16064 (epoch 26), train_loss = 2.633, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 16065 (epoch 26), train_loss = 2.474, time/batch = 0.022
Read data: 8.440017700195312e-05
iter 16066 (epoch 26), train_loss = 2.351, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 16067 (epoch 26), train_loss = 2.330, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 16068 (epoch 26), train_loss = 2.533, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 16069 (epoch 26), train_loss = 2.663, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 16070 (epoch 26), train_loss = 2.118, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 16071 (epoch 26), train_loss = 2.573, time/batch = 0.036
Read data: 8.797645568847656e-05
iter 16072 (epoch 26), train_loss = 2.355, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 16073 (epoch 26), train_loss = 2.397, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 16074 (epoch 26), train_loss = 2.569, time/batch = 0.030
Read data: 0.00027561187744140625
iter 16075 (epoch 26), train_loss = 2.483, time/batch = 0.029
Read data: 0.0001456737518310547
iter 16076 (epoch 26), train_loss = 2.474, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 16077 (epoch 26), train_loss = 2.158, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 16078 (epoch 26), train_loss = 2.451, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 16079 (epoch 26), train_loss = 2.645, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 16080 (epoch 26), train_loss = 2.781, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 16081 (epoch 26), train_loss = 2.589, time/batch = 0.024
Read data: 0.002565622329711914
iter 16082 (epoch 26), train_loss = 2.527, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 16083 (epoch 26), train_loss = 2.543, time/batch = 0.021
Read data: 7.724761962890625e-05
iter 16084 (epoch 26), train_loss = 2.340, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 16085 (epoch 26), train_loss = 2.246, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 16086 (epoch 26), train_loss = 2.495, time/batch = 0.020
Read data: 0.0001437664031982422
iter 16087 (epoch 26), train_loss = 2.521, time/batch = 0.042
Read data: 8.58306884765625e-05
iter 16088 (epoch 26), train_loss = 2.564, time/batch = 0.029
Read data: 0.00011014938354492188
iter 16089 (epoch 26), train_loss = 2.613, time/batch = 0.034
Read data: 9.655952453613281e-05
iter 16090 (epoch 26), train_loss = 2.397, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 16091 (epoch 26), train_loss = 2.707, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 16092 (epoch 26), train_loss = 2.145, time/batch = 0.030
Read data: 8.535385131835938e-05
iter 16093 (epoch 26), train_loss = 2.570, time/batch = 0.035
Read data: 8.678436279296875e-05
iter 16094 (epoch 26), train_loss = 2.268, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 16095 (epoch 26), train_loss = 2.612, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 16096 (epoch 26), train_loss = 2.400, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 16097 (epoch 26), train_loss = 2.562, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 16098 (epoch 26), train_loss = 2.600, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 16099 (epoch 26), train_loss = 2.310, time/batch = 0.029
Read data: 0.0002434253692626953
iter 16100 (epoch 26), train_loss = 2.450, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 16101 (epoch 26), train_loss = 2.749, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 16102 (epoch 26), train_loss = 2.724, time/batch = 0.037
Read data: 8.273124694824219e-05
iter 16103 (epoch 26), train_loss = 2.365, time/batch = 0.025
Read data: 0.00015282630920410156
iter 16104 (epoch 26), train_loss = 2.545, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 16105 (epoch 26), train_loss = 2.640, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 16106 (epoch 26), train_loss = 2.543, time/batch = 0.027
Read data: 0.0001556873321533203
iter 16107 (epoch 26), train_loss = 2.343, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 16108 (epoch 26), train_loss = 2.626, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 16109 (epoch 26), train_loss = 2.113, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 16110 (epoch 26), train_loss = 2.491, time/batch = 0.020
Read data: 8.869171142578125e-05
iter 16111 (epoch 26), train_loss = 2.294, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 16112 (epoch 26), train_loss = 2.569, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 16113 (epoch 26), train_loss = 2.510, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 16114 (epoch 26), train_loss = 2.449, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 16115 (epoch 26), train_loss = 2.359, time/batch = 0.027
Read data: 0.0001404285430908203
iter 16116 (epoch 26), train_loss = 2.535, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 16117 (epoch 26), train_loss = 2.487, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 16118 (epoch 26), train_loss = 2.512, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 16119 (epoch 26), train_loss = 2.411, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 16120 (epoch 26), train_loss = 2.389, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 16121 (epoch 26), train_loss = 2.181, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 16122 (epoch 26), train_loss = 2.494, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 16123 (epoch 26), train_loss = 2.606, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 16124 (epoch 26), train_loss = 2.620, time/batch = 0.026
Read data: 0.00016450881958007812
iter 16125 (epoch 26), train_loss = 2.763, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 16126 (epoch 26), train_loss = 2.607, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 16127 (epoch 26), train_loss = 2.501, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 16128 (epoch 26), train_loss = 2.518, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 16129 (epoch 26), train_loss = 2.233, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 16130 (epoch 26), train_loss = 2.683, time/batch = 0.023
Read data: 0.00011897087097167969
iter 16131 (epoch 26), train_loss = 1.929, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 16132 (epoch 26), train_loss = 2.669, time/batch = 0.029
Read data: 9.489059448242188e-05
iter 16133 (epoch 26), train_loss = 2.720, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 16134 (epoch 26), train_loss = 2.449, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 16135 (epoch 26), train_loss = 2.731, time/batch = 0.030
Read data: 0.0001251697540283203
iter 16136 (epoch 26), train_loss = 2.521, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 16137 (epoch 26), train_loss = 3.038, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 16138 (epoch 26), train_loss = 2.904, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 16139 (epoch 26), train_loss = 1.885, time/batch = 0.028
Read data: 9.34600830078125e-05
iter 16140 (epoch 26), train_loss = 2.390, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 16141 (epoch 26), train_loss = 2.821, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 16142 (epoch 26), train_loss = 2.383, time/batch = 0.022
Read data: 0.00017881393432617188
iter 16143 (epoch 26), train_loss = 2.774, time/batch = 0.030
Read data: 9.489059448242188e-05
iter 16144 (epoch 26), train_loss = 2.301, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 16145 (epoch 26), train_loss = 2.943, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 16146 (epoch 26), train_loss = 2.520, time/batch = 0.029
Read data: 9.036064147949219e-05
iter 16147 (epoch 26), train_loss = 2.071, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 16148 (epoch 26), train_loss = 2.427, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 16149 (epoch 26), train_loss = 2.387, time/batch = 0.027
Read data: 0.0002624988555908203
iter 16150 (epoch 26), train_loss = 2.780, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 16151 (epoch 26), train_loss = 2.245, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 16152 (epoch 26), train_loss = 2.395, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 16153 (epoch 26), train_loss = 2.467, time/batch = 0.030
Read data: 8.96453857421875e-05
iter 16154 (epoch 26), train_loss = 2.343, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 16155 (epoch 26), train_loss = 2.408, time/batch = 0.033
Read data: 0.00010061264038085938
iter 16156 (epoch 26), train_loss = 2.593, time/batch = 0.028
Read data: 0.00011539459228515625
iter 16157 (epoch 26), train_loss = 2.406, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 16158 (epoch 26), train_loss = 2.680, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 16159 (epoch 26), train_loss = 2.269, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 16160 (epoch 26), train_loss = 2.456, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 16161 (epoch 26), train_loss = 2.341, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 16162 (epoch 26), train_loss = 2.460, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 16163 (epoch 26), train_loss = 2.717, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 16164 (epoch 26), train_loss = 2.643, time/batch = 0.021
Read data: 0.00010037422180175781
iter 16165 (epoch 26), train_loss = 2.678, time/batch = 0.024
Read data: 0.00032019615173339844
iter 16166 (epoch 26), train_loss = 2.379, time/batch = 0.027
Read data: 0.00018286705017089844
iter 16167 (epoch 26), train_loss = 2.476, time/batch = 0.030
Read data: 8.726119995117188e-05
iter 16168 (epoch 26), train_loss = 2.667, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 16169 (epoch 26), train_loss = 2.378, time/batch = 0.022
Read data: 7.915496826171875e-05
iter 16170 (epoch 26), train_loss = 2.745, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 16171 (epoch 26), train_loss = 2.372, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 16172 (epoch 26), train_loss = 2.325, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 16173 (epoch 26), train_loss = 2.240, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 16174 (epoch 26), train_loss = 2.312, time/batch = 0.027
Read data: 0.00027632713317871094
iter 16175 (epoch 26), train_loss = 2.715, time/batch = 0.030
Read data: 0.00011777877807617188
iter 16176 (epoch 26), train_loss = 2.368, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 16177 (epoch 26), train_loss = 2.500, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 16178 (epoch 26), train_loss = 2.851, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 16179 (epoch 26), train_loss = 2.343, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 16180 (epoch 26), train_loss = 2.579, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 16181 (epoch 26), train_loss = 2.071, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 16182 (epoch 26), train_loss = 2.582, time/batch = 0.027
Read data: 0.00015497207641601562
iter 16183 (epoch 26), train_loss = 2.432, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 16184 (epoch 26), train_loss = 2.743, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 16185 (epoch 26), train_loss = 2.588, time/batch = 0.024
Read data: 0.00012612342834472656
iter 16186 (epoch 26), train_loss = 2.798, time/batch = 0.026
Read data: 0.00010228157043457031
iter 16187 (epoch 26), train_loss = 2.296, time/batch = 0.022
Read data: 0.00018286705017089844
iter 16188 (epoch 26), train_loss = 3.011, time/batch = 0.028
Read data: 9.298324584960938e-05
iter 16189 (epoch 26), train_loss = 2.566, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 16190 (epoch 26), train_loss = 2.474, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 16191 (epoch 26), train_loss = 2.764, time/batch = 0.029
Read data: 0.0009448528289794922
iter 16192 (epoch 26), train_loss = 2.521, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 16193 (epoch 26), train_loss = 2.248, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 16194 (epoch 26), train_loss = 2.374, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 16195 (epoch 26), train_loss = 3.135, time/batch = 0.027
Read data: 9.1552734375e-05
iter 16196 (epoch 26), train_loss = 2.751, time/batch = 0.032
Read data: 7.843971252441406e-05
iter 16197 (epoch 26), train_loss = 2.779, time/batch = 0.022
Read data: 7.843971252441406e-05
iter 16198 (epoch 26), train_loss = 2.239, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 16199 (epoch 26), train_loss = 2.594, time/batch = 0.026
Read data: 0.00024819374084472656
iter 16200 (epoch 26), train_loss = 2.389, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 16201 (epoch 27), train_loss = 2.411, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 16202 (epoch 27), train_loss = 2.666, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 16203 (epoch 27), train_loss = 2.421, time/batch = 0.025
Read data: 0.00014519691467285156
iter 16204 (epoch 27), train_loss = 2.562, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 16205 (epoch 27), train_loss = 2.642, time/batch = 0.030
Read data: 7.557868957519531e-05
iter 16206 (epoch 27), train_loss = 2.627, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 16207 (epoch 27), train_loss = 2.477, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 16208 (epoch 27), train_loss = 1.934, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 16209 (epoch 27), train_loss = 2.077, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 16210 (epoch 27), train_loss = 3.082, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 16211 (epoch 27), train_loss = 2.701, time/batch = 0.030
Read data: 0.00011229515075683594
iter 16212 (epoch 27), train_loss = 2.542, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 16213 (epoch 27), train_loss = 2.223, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 16214 (epoch 27), train_loss = 2.642, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 16215 (epoch 27), train_loss = 2.328, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 16216 (epoch 27), train_loss = 2.601, time/batch = 0.030
Read data: 9.322166442871094e-05
iter 16217 (epoch 27), train_loss = 2.633, time/batch = 0.033
Read data: 8.845329284667969e-05
iter 16218 (epoch 27), train_loss = 2.521, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 16219 (epoch 27), train_loss = 2.627, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 16220 (epoch 27), train_loss = 2.865, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 16221 (epoch 27), train_loss = 2.614, time/batch = 0.022
Read data: 9.799003601074219e-05
iter 16222 (epoch 27), train_loss = 2.436, time/batch = 0.027
Read data: 7.62939453125e-05
iter 16223 (epoch 27), train_loss = 2.265, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 16224 (epoch 27), train_loss = 2.630, time/batch = 0.032
Read data: 0.0001995563507080078
iter 16225 (epoch 27), train_loss = 2.468, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 16226 (epoch 27), train_loss = 2.606, time/batch = 0.032
Read data: 0.0001232624053955078
iter 16227 (epoch 27), train_loss = 2.281, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 16228 (epoch 27), train_loss = 2.556, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 16229 (epoch 27), train_loss = 2.410, time/batch = 0.020
Read data: 7.653236389160156e-05
iter 16230 (epoch 27), train_loss = 2.608, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 16231 (epoch 27), train_loss = 2.679, time/batch = 0.025
Read data: 9.131431579589844e-05
iter 16232 (epoch 27), train_loss = 2.267, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 16233 (epoch 27), train_loss = 2.880, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 16234 (epoch 27), train_loss = 2.395, time/batch = 0.020
Read data: 8.630752563476562e-05
iter 16235 (epoch 27), train_loss = 2.431, time/batch = 0.022
Read data: 0.00015544891357421875
iter 16236 (epoch 27), train_loss = 2.474, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 16237 (epoch 27), train_loss = 2.541, time/batch = 0.026
Read data: 0.0001595020294189453
iter 16238 (epoch 27), train_loss = 2.636, time/batch = 0.035
Read data: 7.748603820800781e-05
iter 16239 (epoch 27), train_loss = 2.315, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 16240 (epoch 27), train_loss = 2.464, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 16241 (epoch 27), train_loss = 2.194, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 16242 (epoch 27), train_loss = 2.120, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 16243 (epoch 27), train_loss = 2.788, time/batch = 0.036
Read data: 0.00011801719665527344
iter 16244 (epoch 27), train_loss = 2.502, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 16245 (epoch 27), train_loss = 2.318, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 16246 (epoch 27), train_loss = 2.329, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 16247 (epoch 27), train_loss = 2.483, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 16248 (epoch 27), train_loss = 2.718, time/batch = 0.032
Read data: 9.608268737792969e-05
iter 16249 (epoch 27), train_loss = 2.000, time/batch = 0.021
Read data: 8.130073547363281e-05
iter 16250 (epoch 27), train_loss = 2.443, time/batch = 0.024
Read data: 8.511543273925781e-05
iter 16251 (epoch 27), train_loss = 2.637, time/batch = 0.026
Read data: 0.00010156631469726562
iter 16252 (epoch 27), train_loss = 2.896, time/batch = 0.024
Read data: 9.5367431640625e-05
iter 16253 (epoch 27), train_loss = 2.634, time/batch = 0.032
Read data: 7.700920104980469e-05
iter 16254 (epoch 27), train_loss = 2.561, time/batch = 0.034
Read data: 0.00012302398681640625
iter 16255 (epoch 27), train_loss = 2.673, time/batch = 0.024
Read data: 8.273124694824219e-05
iter 16256 (epoch 27), train_loss = 3.067, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 16257 (epoch 27), train_loss = 2.580, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 16258 (epoch 27), train_loss = 2.454, time/batch = 0.026
Read data: 0.00016236305236816406
iter 16259 (epoch 27), train_loss = 2.167, time/batch = 0.028
Read data: 0.0001595020294189453
iter 16260 (epoch 27), train_loss = 2.638, time/batch = 0.028
Read data: 8.392333984375e-05
iter 16261 (epoch 27), train_loss = 2.617, time/batch = 0.029
Read data: 0.0001232624053955078
iter 16262 (epoch 27), train_loss = 2.141, time/batch = 0.029
Read data: 9.274482727050781e-05
iter 16263 (epoch 27), train_loss = 2.716, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 16264 (epoch 27), train_loss = 2.409, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 16265 (epoch 27), train_loss = 2.023, time/batch = 0.027
Read data: 0.00017452239990234375
iter 16266 (epoch 27), train_loss = 2.464, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 16267 (epoch 27), train_loss = 2.608, time/batch = 0.035
Read data: 0.0001232624053955078
iter 16268 (epoch 27), train_loss = 2.552, time/batch = 0.043
Read data: 8.797645568847656e-05
iter 16269 (epoch 27), train_loss = 2.377, time/batch = 0.023
Read data: 0.00014734268188476562
iter 16270 (epoch 27), train_loss = 2.173, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 16271 (epoch 27), train_loss = 2.274, time/batch = 0.027
Read data: 0.0001087188720703125
iter 16272 (epoch 27), train_loss = 2.157, time/batch = 0.024
Read data: 0.00012302398681640625
iter 16273 (epoch 27), train_loss = 2.436, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 16274 (epoch 27), train_loss = 2.381, time/batch = 0.028
Read data: 0.00024890899658203125
iter 16275 (epoch 27), train_loss = 2.281, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 16276 (epoch 27), train_loss = 2.548, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 16277 (epoch 27), train_loss = 2.379, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 16278 (epoch 27), train_loss = 2.197, time/batch = 0.042
Read data: 7.390975952148438e-05
iter 16279 (epoch 27), train_loss = 2.156, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 16280 (epoch 27), train_loss = 2.397, time/batch = 0.033
Read data: 8.749961853027344e-05
iter 16281 (epoch 27), train_loss = 2.282, time/batch = 0.033
Read data: 8.869171142578125e-05
iter 16282 (epoch 27), train_loss = 2.242, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 16283 (epoch 27), train_loss = 2.106, time/batch = 0.027
Read data: 9.965896606445312e-05
iter 16284 (epoch 27), train_loss = 2.532, time/batch = 0.034
Read data: 8.20159912109375e-05
iter 16285 (epoch 27), train_loss = 2.509, time/batch = 0.024
Read data: 0.00016045570373535156
iter 16286 (epoch 27), train_loss = 2.871, time/batch = 0.028
Read data: 8.392333984375e-05
iter 16287 (epoch 27), train_loss = 2.104, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 16288 (epoch 27), train_loss = 2.515, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 16289 (epoch 27), train_loss = 2.718, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 16290 (epoch 27), train_loss = 2.586, time/batch = 0.039
Read data: 8.749961853027344e-05
iter 16291 (epoch 27), train_loss = 2.156, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 16292 (epoch 27), train_loss = 2.593, time/batch = 0.029
Read data: 0.00012040138244628906
iter 16293 (epoch 27), train_loss = 2.304, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 16294 (epoch 27), train_loss = 2.329, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 16295 (epoch 27), train_loss = 2.432, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 16296 (epoch 27), train_loss = 2.079, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 16297 (epoch 27), train_loss = 2.734, time/batch = 0.022
Read data: 0.00012040138244628906
iter 16298 (epoch 27), train_loss = 2.611, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 16299 (epoch 27), train_loss = 2.502, time/batch = 0.035
Read data: 8.106231689453125e-05
iter 16300 (epoch 27), train_loss = 2.694, time/batch = 0.032
Read data: 8.559226989746094e-05
iter 16301 (epoch 27), train_loss = 2.363, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 16302 (epoch 27), train_loss = 2.320, time/batch = 0.032
Read data: 0.0001323223114013672
iter 16303 (epoch 27), train_loss = 2.426, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 16304 (epoch 27), train_loss = 2.410, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 16305 (epoch 27), train_loss = 2.530, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 16306 (epoch 27), train_loss = 2.484, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 16307 (epoch 27), train_loss = 2.663, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 16308 (epoch 27), train_loss = 2.555, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 16309 (epoch 27), train_loss = 2.346, time/batch = 0.025
Read data: 0.00012302398681640625
iter 16310 (epoch 27), train_loss = 2.404, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 16311 (epoch 27), train_loss = 2.481, time/batch = 0.025
Read data: 9.846687316894531e-05
iter 16312 (epoch 27), train_loss = 2.346, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 16313 (epoch 27), train_loss = 2.624, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 16314 (epoch 27), train_loss = 2.169, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 16315 (epoch 27), train_loss = 2.239, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 16316 (epoch 27), train_loss = 2.822, time/batch = 0.026
Read data: 9.1552734375e-05
iter 16317 (epoch 27), train_loss = 2.759, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 16318 (epoch 27), train_loss = 2.478, time/batch = 0.024
Read data: 9.1552734375e-05
iter 16319 (epoch 27), train_loss = 2.364, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 16320 (epoch 27), train_loss = 2.493, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 16321 (epoch 27), train_loss = 2.189, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 16322 (epoch 27), train_loss = 2.192, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 16323 (epoch 27), train_loss = 2.270, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 16324 (epoch 27), train_loss = 2.987, time/batch = 0.032
Read data: 0.00019812583923339844
iter 16325 (epoch 27), train_loss = 2.099, time/batch = 0.030
Read data: 8.392333984375e-05
iter 16326 (epoch 27), train_loss = 2.126, time/batch = 0.021
Read data: 8.368492126464844e-05
iter 16327 (epoch 27), train_loss = 2.519, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 16328 (epoch 27), train_loss = 2.720, time/batch = 0.035
Read data: 8.177757263183594e-05
iter 16329 (epoch 27), train_loss = 2.417, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 16330 (epoch 27), train_loss = 2.111, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 16331 (epoch 27), train_loss = 2.433, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 16332 (epoch 27), train_loss = 2.335, time/batch = 0.021
Read data: 0.0001289844512939453
iter 16333 (epoch 27), train_loss = 2.299, time/batch = 0.023
Read data: 0.0001723766326904297
iter 16334 (epoch 27), train_loss = 2.440, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 16335 (epoch 27), train_loss = 2.443, time/batch = 0.028
Read data: 9.059906005859375e-05
iter 16336 (epoch 27), train_loss = 2.608, time/batch = 0.026
Read data: 0.00014638900756835938
iter 16337 (epoch 27), train_loss = 3.043, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 16338 (epoch 27), train_loss = 2.602, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 16339 (epoch 27), train_loss = 2.622, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 16340 (epoch 27), train_loss = 2.415, time/batch = 0.024
Read data: 0.00013303756713867188
iter 16341 (epoch 27), train_loss = 2.533, time/batch = 0.026
Read data: 0.00012755393981933594
iter 16342 (epoch 27), train_loss = 2.572, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 16343 (epoch 27), train_loss = 2.540, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 16344 (epoch 27), train_loss = 2.220, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 16345 (epoch 27), train_loss = 2.292, time/batch = 0.032
Read data: 7.891654968261719e-05
iter 16346 (epoch 27), train_loss = 2.644, time/batch = 0.030
Read data: 0.0001285076141357422
iter 16347 (epoch 27), train_loss = 2.574, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 16348 (epoch 27), train_loss = 2.538, time/batch = 0.035
Read data: 8.7738037109375e-05
iter 16349 (epoch 27), train_loss = 2.236, time/batch = 0.028
Read data: 0.00016570091247558594
iter 16350 (epoch 27), train_loss = 2.787, time/batch = 0.028
Read data: 0.0002033710479736328
iter 16351 (epoch 27), train_loss = 2.592, time/batch = 0.029
Read data: 8.392333984375e-05
iter 16352 (epoch 27), train_loss = 2.413, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 16353 (epoch 27), train_loss = 2.476, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 16354 (epoch 27), train_loss = 2.048, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 16355 (epoch 27), train_loss = 2.860, time/batch = 0.025
Read data: 0.00010085105895996094
iter 16356 (epoch 27), train_loss = 2.507, time/batch = 0.029
Read data: 7.653236389160156e-05
iter 16357 (epoch 27), train_loss = 2.615, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 16358 (epoch 27), train_loss = 2.756, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 16359 (epoch 27), train_loss = 2.133, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 16360 (epoch 27), train_loss = 2.598, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 16361 (epoch 27), train_loss = 2.539, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 16362 (epoch 27), train_loss = 2.677, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 16363 (epoch 27), train_loss = 2.382, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 16364 (epoch 27), train_loss = 2.281, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 16365 (epoch 27), train_loss = 2.840, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 16366 (epoch 27), train_loss = 2.496, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 16367 (epoch 27), train_loss = 2.539, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 16368 (epoch 27), train_loss = 2.414, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 16369 (epoch 27), train_loss = 2.501, time/batch = 0.026
Read data: 0.00015854835510253906
iter 16370 (epoch 27), train_loss = 2.768, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 16371 (epoch 27), train_loss = 2.381, time/batch = 0.023
Read data: 0.00010323524475097656
iter 16372 (epoch 27), train_loss = 2.492, time/batch = 0.022
Read data: 9.846687316894531e-05
iter 16373 (epoch 27), train_loss = 2.482, time/batch = 0.029
Read data: 8.988380432128906e-05
iter 16374 (epoch 27), train_loss = 2.783, time/batch = 0.035
Read data: 0.00012636184692382812
iter 16375 (epoch 27), train_loss = 2.402, time/batch = 0.027
Read data: 0.00012135505676269531
iter 16376 (epoch 27), train_loss = 2.634, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 16377 (epoch 27), train_loss = 2.617, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 16378 (epoch 27), train_loss = 2.222, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 16379 (epoch 27), train_loss = 2.425, time/batch = 0.025
Read data: 0.00011038780212402344
iter 16380 (epoch 27), train_loss = 2.525, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 16381 (epoch 27), train_loss = 2.094, time/batch = 0.029
Read data: 0.0001246929168701172
iter 16382 (epoch 27), train_loss = 2.114, time/batch = 0.023
Read data: 0.00012826919555664062
iter 16383 (epoch 27), train_loss = 2.334, time/batch = 0.029
Read data: 9.393692016601562e-05
iter 16384 (epoch 27), train_loss = 2.256, time/batch = 0.021
Read data: 0.00014281272888183594
iter 16385 (epoch 27), train_loss = 2.445, time/batch = 0.026
Read data: 0.00013113021850585938
iter 16386 (epoch 27), train_loss = 2.559, time/batch = 0.031
Read data: 7.581710815429688e-05
iter 16387 (epoch 27), train_loss = 2.277, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 16388 (epoch 27), train_loss = 2.543, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 16389 (epoch 27), train_loss = 1.907, time/batch = 0.020
Read data: 8.988380432128906e-05
iter 16390 (epoch 27), train_loss = 2.867, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 16391 (epoch 27), train_loss = 2.580, time/batch = 0.023
Read data: 0.00013017654418945312
iter 16392 (epoch 27), train_loss = 2.337, time/batch = 0.036
Read data: 0.00012445449829101562
iter 16393 (epoch 27), train_loss = 2.328, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 16394 (epoch 27), train_loss = 2.442, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 16395 (epoch 27), train_loss = 2.422, time/batch = 0.021
Read data: 8.106231689453125e-05
iter 16396 (epoch 27), train_loss = 2.634, time/batch = 0.026
Read data: 9.202957153320312e-05
iter 16397 (epoch 27), train_loss = 2.300, time/batch = 0.024
Read data: 0.00012135505676269531
iter 16398 (epoch 27), train_loss = 2.077, time/batch = 0.029
Read data: 9.465217590332031e-05
iter 16399 (epoch 27), train_loss = 2.707, time/batch = 0.025
Read data: 0.00018906593322753906
iter 16400 (epoch 27), train_loss = 1.961, time/batch = 0.020
Read data: 9.870529174804688e-05
iter 16401 (epoch 27), train_loss = 2.535, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 16402 (epoch 27), train_loss = 2.407, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 16403 (epoch 27), train_loss = 2.577, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 16404 (epoch 27), train_loss = 2.394, time/batch = 0.026
Read data: 0.00010037422180175781
iter 16405 (epoch 27), train_loss = 2.802, time/batch = 0.034
Read data: 0.00013518333435058594
iter 16406 (epoch 27), train_loss = 2.519, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 16407 (epoch 27), train_loss = 2.293, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 16408 (epoch 27), train_loss = 2.266, time/batch = 0.026
Read data: 0.00013399124145507812
iter 16409 (epoch 27), train_loss = 2.319, time/batch = 0.026
Read data: 0.00010132789611816406
iter 16410 (epoch 27), train_loss = 2.622, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 16411 (epoch 27), train_loss = 2.580, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 16412 (epoch 27), train_loss = 2.556, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 16413 (epoch 27), train_loss = 2.781, time/batch = 0.035
Read data: 8.58306884765625e-05
iter 16414 (epoch 27), train_loss = 2.184, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 16415 (epoch 27), train_loss = 2.336, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 16416 (epoch 27), train_loss = 2.492, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 16417 (epoch 27), train_loss = 2.496, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 16418 (epoch 27), train_loss = 2.708, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 16419 (epoch 27), train_loss = 2.534, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 16420 (epoch 27), train_loss = 2.275, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 16421 (epoch 27), train_loss = 2.216, time/batch = 0.024
Read data: 9.34600830078125e-05
iter 16422 (epoch 27), train_loss = 2.505, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 16423 (epoch 27), train_loss = 2.537, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 16424 (epoch 27), train_loss = 2.340, time/batch = 0.026
Read data: 0.000209808349609375
iter 16425 (epoch 27), train_loss = 2.679, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 16426 (epoch 27), train_loss = 2.200, time/batch = 0.021
Read data: 9.083747863769531e-05
iter 16427 (epoch 27), train_loss = 2.241, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 16428 (epoch 27), train_loss = 2.395, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 16429 (epoch 27), train_loss = 2.334, time/batch = 0.025
Read data: 0.00013685226440429688
iter 16430 (epoch 27), train_loss = 2.491, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 16431 (epoch 27), train_loss = 2.546, time/batch = 0.036
Read data: 0.0001437664031982422
iter 16432 (epoch 27), train_loss = 2.406, time/batch = 0.032
Read data: 9.298324584960938e-05
iter 16433 (epoch 27), train_loss = 2.535, time/batch = 0.039
Read data: 7.462501525878906e-05
iter 16434 (epoch 27), train_loss = 2.540, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 16435 (epoch 27), train_loss = 2.134, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 16436 (epoch 27), train_loss = 2.640, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 16437 (epoch 27), train_loss = 2.565, time/batch = 0.027
Read data: 0.00012373924255371094
iter 16438 (epoch 27), train_loss = 2.516, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 16439 (epoch 27), train_loss = 2.151, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 16440 (epoch 27), train_loss = 2.395, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 16441 (epoch 27), train_loss = 2.465, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 16442 (epoch 27), train_loss = 2.520, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 16443 (epoch 27), train_loss = 2.604, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 16444 (epoch 27), train_loss = 2.530, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 16445 (epoch 27), train_loss = 2.722, time/batch = 0.025
Read data: 0.00011873245239257812
iter 16446 (epoch 27), train_loss = 2.436, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 16447 (epoch 27), train_loss = 2.159, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 16448 (epoch 27), train_loss = 2.410, time/batch = 0.030
Read data: 0.00015425682067871094
iter 16449 (epoch 27), train_loss = 2.678, time/batch = 0.022
Read data: 0.0003457069396972656
iter 16450 (epoch 27), train_loss = 2.713, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 16451 (epoch 27), train_loss = 2.078, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 16452 (epoch 27), train_loss = 2.607, time/batch = 0.027
Read data: 0.0017921924591064453
iter 16453 (epoch 27), train_loss = 2.453, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 16454 (epoch 27), train_loss = 2.265, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 16455 (epoch 27), train_loss = 1.980, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 16456 (epoch 27), train_loss = 2.756, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 16457 (epoch 27), train_loss = 2.577, time/batch = 0.029
Read data: 0.00015926361083984375
iter 16458 (epoch 27), train_loss = 2.766, time/batch = 0.021
Read data: 9.202957153320312e-05
iter 16459 (epoch 27), train_loss = 2.304, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 16460 (epoch 27), train_loss = 2.459, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 16461 (epoch 27), train_loss = 2.355, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 16462 (epoch 27), train_loss = 2.479, time/batch = 0.029
Read data: 7.605552673339844e-05
iter 16463 (epoch 27), train_loss = 2.458, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 16464 (epoch 27), train_loss = 2.712, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 16465 (epoch 27), train_loss = 2.397, time/batch = 0.025
Read data: 0.00012683868408203125
iter 16466 (epoch 27), train_loss = 2.561, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 16467 (epoch 27), train_loss = 2.295, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 16468 (epoch 27), train_loss = 2.600, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 16469 (epoch 27), train_loss = 2.498, time/batch = 0.029
Read data: 7.653236389160156e-05
iter 16470 (epoch 27), train_loss = 2.554, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 16471 (epoch 27), train_loss = 1.903, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 16472 (epoch 27), train_loss = 2.595, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 16473 (epoch 27), train_loss = 2.445, time/batch = 0.034
Read data: 8.0108642578125e-05
iter 16474 (epoch 27), train_loss = 2.427, time/batch = 0.025
Read data: 0.00021910667419433594
iter 16475 (epoch 27), train_loss = 2.533, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 16476 (epoch 27), train_loss = 2.578, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 16477 (epoch 27), train_loss = 2.705, time/batch = 0.038
Read data: 8.368492126464844e-05
iter 16478 (epoch 27), train_loss = 2.004, time/batch = 0.024
Read data: 0.00014066696166992188
iter 16479 (epoch 27), train_loss = 2.738, time/batch = 0.030
Read data: 9.393692016601562e-05
iter 16480 (epoch 27), train_loss = 2.706, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 16481 (epoch 27), train_loss = 2.791, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 16482 (epoch 27), train_loss = 2.691, time/batch = 0.028
Read data: 8.392333984375e-05
iter 16483 (epoch 27), train_loss = 2.407, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 16484 (epoch 27), train_loss = 2.182, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 16485 (epoch 27), train_loss = 2.495, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 16486 (epoch 27), train_loss = 2.568, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 16487 (epoch 27), train_loss = 2.513, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 16488 (epoch 27), train_loss = 2.381, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 16489 (epoch 27), train_loss = 2.578, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 16490 (epoch 27), train_loss = 2.693, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 16491 (epoch 27), train_loss = 2.448, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 16492 (epoch 27), train_loss = 2.449, time/batch = 0.021
Read data: 0.00010514259338378906
iter 16493 (epoch 27), train_loss = 2.404, time/batch = 0.033
Read data: 0.00012087821960449219
iter 16494 (epoch 27), train_loss = 2.330, time/batch = 0.034
Read data: 0.00011324882507324219
iter 16495 (epoch 27), train_loss = 2.610, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 16496 (epoch 27), train_loss = 2.901, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 16497 (epoch 27), train_loss = 2.636, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 16498 (epoch 27), train_loss = 2.455, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 16499 (epoch 27), train_loss = 2.575, time/batch = 0.029
Read data: 0.00019884109497070312
iter 16500 (epoch 27), train_loss = 2.523, time/batch = 0.026
Read data: 7.62939453125e-05
iter 16501 (epoch 27), train_loss = 2.186, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 16502 (epoch 27), train_loss = 2.421, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 16503 (epoch 27), train_loss = 2.286, time/batch = 0.025
Read data: 7.62939453125e-05
iter 16504 (epoch 27), train_loss = 2.825, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 16505 (epoch 27), train_loss = 1.903, time/batch = 0.025
Read data: 0.00013971328735351562
iter 16506 (epoch 27), train_loss = 2.472, time/batch = 0.022
Read data: 0.0001685619354248047
iter 16507 (epoch 27), train_loss = 2.092, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 16508 (epoch 27), train_loss = 2.358, time/batch = 0.029
Read data: 9.655952453613281e-05
iter 16509 (epoch 27), train_loss = 2.566, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 16510 (epoch 27), train_loss = 2.463, time/batch = 0.034
Read data: 7.843971252441406e-05
iter 16511 (epoch 27), train_loss = 2.464, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 16512 (epoch 27), train_loss = 2.641, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 16513 (epoch 27), train_loss = 2.669, time/batch = 0.026
Read data: 0.00012731552124023438
iter 16514 (epoch 27), train_loss = 2.488, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 16515 (epoch 27), train_loss = 2.409, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 16516 (epoch 27), train_loss = 2.440, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 16517 (epoch 27), train_loss = 2.511, time/batch = 0.026
Read data: 0.00012683868408203125
iter 16518 (epoch 27), train_loss = 2.462, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 16519 (epoch 27), train_loss = 2.737, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 16520 (epoch 27), train_loss = 2.525, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 16521 (epoch 27), train_loss = 2.407, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 16522 (epoch 27), train_loss = 2.523, time/batch = 0.027
Read data: 7.653236389160156e-05
iter 16523 (epoch 27), train_loss = 2.417, time/batch = 0.025
Read data: 0.00010061264038085938
iter 16524 (epoch 27), train_loss = 2.385, time/batch = 0.021
Read data: 0.0002300739288330078
iter 16525 (epoch 27), train_loss = 3.034, time/batch = 0.036
Read data: 8.630752563476562e-05
iter 16526 (epoch 27), train_loss = 2.236, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 16527 (epoch 27), train_loss = 2.514, time/batch = 0.027
Read data: 0.00013494491577148438
iter 16528 (epoch 27), train_loss = 2.869, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 16529 (epoch 27), train_loss = 2.334, time/batch = 0.025
Read data: 0.00015807151794433594
iter 16530 (epoch 27), train_loss = 2.538, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 16531 (epoch 27), train_loss = 2.563, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 16532 (epoch 27), train_loss = 2.500, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 16533 (epoch 27), train_loss = 2.410, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 16534 (epoch 27), train_loss = 2.480, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 16535 (epoch 27), train_loss = 2.546, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 16536 (epoch 27), train_loss = 2.550, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 16537 (epoch 27), train_loss = 2.597, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 16538 (epoch 27), train_loss = 2.818, time/batch = 0.026
Read data: 0.00010180473327636719
iter 16539 (epoch 27), train_loss = 2.464, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 16540 (epoch 27), train_loss = 2.439, time/batch = 0.025
Read data: 0.00011992454528808594
iter 16541 (epoch 27), train_loss = 2.381, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 16542 (epoch 27), train_loss = 2.443, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 16543 (epoch 27), train_loss = 2.490, time/batch = 0.031
Read data: 8.7738037109375e-05
iter 16544 (epoch 27), train_loss = 1.917, time/batch = 0.027
Read data: 0.00013685226440429688
iter 16545 (epoch 27), train_loss = 1.927, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 16546 (epoch 27), train_loss = 2.817, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 16547 (epoch 27), train_loss = 2.432, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 16548 (epoch 27), train_loss = 2.431, time/batch = 0.026
Read data: 0.00010895729064941406
iter 16549 (epoch 27), train_loss = 2.391, time/batch = 0.029
Read data: 0.0002551078796386719
iter 16550 (epoch 27), train_loss = 2.762, time/batch = 0.026
Read data: 0.00017547607421875
iter 16551 (epoch 27), train_loss = 2.532, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 16552 (epoch 27), train_loss = 2.722, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 16553 (epoch 27), train_loss = 2.381, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 16554 (epoch 27), train_loss = 2.644, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 16555 (epoch 27), train_loss = 2.424, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 16556 (epoch 27), train_loss = 2.375, time/batch = 0.030
Read data: 0.00013709068298339844
iter 16557 (epoch 27), train_loss = 2.120, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 16558 (epoch 27), train_loss = 2.487, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 16559 (epoch 27), train_loss = 2.247, time/batch = 0.023
Read data: 0.00010776519775390625
iter 16560 (epoch 27), train_loss = 1.972, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 16561 (epoch 27), train_loss = 1.938, time/batch = 0.025
Read data: 0.0001506805419921875
iter 16562 (epoch 27), train_loss = 2.217, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 16563 (epoch 27), train_loss = 2.210, time/batch = 0.023
Read data: 9.918212890625e-05
iter 16564 (epoch 27), train_loss = 2.719, time/batch = 0.026
Read data: 0.00010180473327636719
iter 16565 (epoch 27), train_loss = 2.420, time/batch = 0.032
Read data: 9.012222290039062e-05
iter 16566 (epoch 27), train_loss = 2.684, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 16567 (epoch 27), train_loss = 2.147, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 16568 (epoch 27), train_loss = 2.666, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 16569 (epoch 27), train_loss = 2.478, time/batch = 0.034
Read data: 7.82012939453125e-05
iter 16570 (epoch 27), train_loss = 2.821, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 16571 (epoch 27), train_loss = 2.699, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 16572 (epoch 27), train_loss = 2.294, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 16573 (epoch 27), train_loss = 2.678, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 16574 (epoch 27), train_loss = 2.744, time/batch = 0.031
Read data: 0.0003192424774169922
iter 16575 (epoch 27), train_loss = 2.414, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 16576 (epoch 27), train_loss = 2.658, time/batch = 0.034
Read data: 8.511543273925781e-05
iter 16577 (epoch 27), train_loss = 2.386, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 16578 (epoch 27), train_loss = 2.291, time/batch = 0.026
Read data: 8.654594421386719e-05
iter 16579 (epoch 27), train_loss = 2.896, time/batch = 0.037
Read data: 8.893013000488281e-05
iter 16580 (epoch 27), train_loss = 2.235, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 16581 (epoch 27), train_loss = 2.422, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 16582 (epoch 27), train_loss = 2.811, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 16583 (epoch 27), train_loss = 1.914, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 16584 (epoch 27), train_loss = 2.568, time/batch = 0.039
Read data: 0.00013899803161621094
iter 16585 (epoch 27), train_loss = 2.488, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 16586 (epoch 27), train_loss = 2.459, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 16587 (epoch 27), train_loss = 2.423, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 16588 (epoch 27), train_loss = 2.489, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 16589 (epoch 27), train_loss = 2.322, time/batch = 0.034
Read data: 8.440017700195312e-05
iter 16590 (epoch 27), train_loss = 2.509, time/batch = 0.022
Read data: 0.00020384788513183594
iter 16591 (epoch 27), train_loss = 2.648, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 16592 (epoch 27), train_loss = 2.424, time/batch = 0.029
Read data: 0.00013065338134765625
iter 16593 (epoch 27), train_loss = 2.719, time/batch = 0.020
Read data: 0.00013637542724609375
iter 16594 (epoch 27), train_loss = 2.607, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 16595 (epoch 27), train_loss = 2.570, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 16596 (epoch 27), train_loss = 2.829, time/batch = 0.032
Read data: 8.988380432128906e-05
iter 16597 (epoch 27), train_loss = 2.466, time/batch = 0.022
Read data: 0.00013589859008789062
iter 16598 (epoch 27), train_loss = 2.213, time/batch = 0.028
Read data: 0.00014901161193847656
iter 16599 (epoch 27), train_loss = 2.808, time/batch = 0.025
Read data: 0.00020051002502441406
iter 16600 (epoch 27), train_loss = 2.115, time/batch = 0.032
Read data: 7.796287536621094e-05
iter 16601 (epoch 27), train_loss = 2.432, time/batch = 0.036
Read data: 9.226799011230469e-05
iter 16602 (epoch 27), train_loss = 2.456, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 16603 (epoch 27), train_loss = 2.754, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 16604 (epoch 27), train_loss = 2.751, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 16605 (epoch 27), train_loss = 2.659, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 16606 (epoch 27), train_loss = 2.409, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 16607 (epoch 27), train_loss = 2.548, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 16608 (epoch 27), train_loss = 2.636, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 16609 (epoch 27), train_loss = 2.724, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 16610 (epoch 27), train_loss = 1.970, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 16611 (epoch 27), train_loss = 2.263, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 16612 (epoch 27), train_loss = 2.371, time/batch = 0.030
Read data: 0.0001742839813232422
iter 16613 (epoch 27), train_loss = 2.581, time/batch = 0.025
Read data: 0.0001347064971923828
iter 16614 (epoch 27), train_loss = 2.309, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 16615 (epoch 27), train_loss = 2.537, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 16616 (epoch 27), train_loss = 2.574, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 16617 (epoch 27), train_loss = 2.594, time/batch = 0.028
Read data: 0.00013208389282226562
iter 16618 (epoch 27), train_loss = 2.460, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 16619 (epoch 27), train_loss = 2.009, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 16620 (epoch 27), train_loss = 2.284, time/batch = 0.022
Read data: 9.584426879882812e-05
iter 16621 (epoch 27), train_loss = 2.479, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 16622 (epoch 27), train_loss = 2.564, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 16623 (epoch 27), train_loss = 2.471, time/batch = 0.034
Read data: 7.987022399902344e-05
iter 16624 (epoch 27), train_loss = 2.019, time/batch = 0.026
Read data: 0.0002567768096923828
iter 16625 (epoch 27), train_loss = 2.517, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 16626 (epoch 27), train_loss = 2.189, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 16627 (epoch 27), train_loss = 2.868, time/batch = 0.036
Read data: 8.702278137207031e-05
iter 16628 (epoch 27), train_loss = 2.445, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 16629 (epoch 27), train_loss = 2.500, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 16630 (epoch 27), train_loss = 2.797, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 16631 (epoch 27), train_loss = 2.950, time/batch = 0.032
Read data: 8.058547973632812e-05
iter 16632 (epoch 27), train_loss = 2.702, time/batch = 0.026
Read data: 0.0002117156982421875
iter 16633 (epoch 27), train_loss = 2.350, time/batch = 0.024
Read data: 0.00017213821411132812
iter 16634 (epoch 27), train_loss = 2.707, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 16635 (epoch 27), train_loss = 2.630, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 16636 (epoch 27), train_loss = 2.635, time/batch = 0.037
Read data: 0.00015997886657714844
iter 16637 (epoch 27), train_loss = 2.855, time/batch = 0.030
Read data: 9.226799011230469e-05
iter 16638 (epoch 27), train_loss = 1.962, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 16639 (epoch 27), train_loss = 2.420, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 16640 (epoch 27), train_loss = 2.490, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 16641 (epoch 27), train_loss = 2.611, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 16642 (epoch 27), train_loss = 2.379, time/batch = 0.026
Read data: 7.534027099609375e-05
iter 16643 (epoch 27), train_loss = 2.697, time/batch = 0.029
Read data: 7.700920104980469e-05
iter 16644 (epoch 27), train_loss = 3.006, time/batch = 0.028
Read data: 0.00013375282287597656
iter 16645 (epoch 27), train_loss = 2.315, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 16646 (epoch 27), train_loss = 2.077, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 16647 (epoch 27), train_loss = 2.571, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 16648 (epoch 27), train_loss = 2.021, time/batch = 0.022
Read data: 0.00013375282287597656
iter 16649 (epoch 27), train_loss = 2.834, time/batch = 0.041
Read data: 0.0002815723419189453
iter 16650 (epoch 27), train_loss = 2.637, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 16651 (epoch 27), train_loss = 2.354, time/batch = 0.022
Read data: 0.00011229515075683594
iter 16652 (epoch 27), train_loss = 2.551, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 16653 (epoch 27), train_loss = 2.519, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 16654 (epoch 27), train_loss = 2.278, time/batch = 0.038
Read data: 7.605552673339844e-05
iter 16655 (epoch 27), train_loss = 2.018, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 16656 (epoch 27), train_loss = 2.398, time/batch = 0.024
Read data: 0.00013113021850585938
iter 16657 (epoch 27), train_loss = 2.556, time/batch = 0.024
Read data: 0.00013208389282226562
iter 16658 (epoch 27), train_loss = 2.177, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 16659 (epoch 27), train_loss = 2.734, time/batch = 0.032
Read data: 7.653236389160156e-05
iter 16660 (epoch 27), train_loss = 2.036, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 16661 (epoch 27), train_loss = 2.390, time/batch = 0.024
Read data: 0.00014281272888183594
iter 16662 (epoch 27), train_loss = 2.147, time/batch = 0.023
Read data: 0.0001010894775390625
iter 16663 (epoch 27), train_loss = 2.694, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 16664 (epoch 27), train_loss = 2.568, time/batch = 0.026
Read data: 0.00015473365783691406
iter 16665 (epoch 27), train_loss = 2.604, time/batch = 0.030
Read data: 0.00013589859008789062
iter 16666 (epoch 27), train_loss = 2.479, time/batch = 0.029
Read data: 8.392333984375e-05
iter 16667 (epoch 27), train_loss = 2.456, time/batch = 0.032
Read data: 0.00010013580322265625
iter 16668 (epoch 27), train_loss = 2.589, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 16669 (epoch 27), train_loss = 2.512, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 16670 (epoch 27), train_loss = 2.164, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 16671 (epoch 27), train_loss = 2.480, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 16672 (epoch 27), train_loss = 2.457, time/batch = 0.031
Read data: 0.00014328956604003906
iter 16673 (epoch 27), train_loss = 2.497, time/batch = 0.034
Read data: 8.749961853027344e-05
iter 16674 (epoch 27), train_loss = 2.530, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 16675 (epoch 27), train_loss = 2.802, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 16676 (epoch 27), train_loss = 2.361, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 16677 (epoch 27), train_loss = 2.182, time/batch = 0.029
Read data: 7.724761962890625e-05
iter 16678 (epoch 27), train_loss = 2.409, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 16679 (epoch 27), train_loss = 3.087, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 16680 (epoch 27), train_loss = 2.506, time/batch = 0.025
Read data: 0.0001354217529296875
iter 16681 (epoch 27), train_loss = 2.109, time/batch = 0.029
Read data: 0.00013875961303710938
iter 16682 (epoch 27), train_loss = 2.240, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 16683 (epoch 27), train_loss = 2.419, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 16684 (epoch 27), train_loss = 2.649, time/batch = 0.028
Read data: 0.00012993812561035156
iter 16685 (epoch 27), train_loss = 2.490, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 16686 (epoch 27), train_loss = 2.811, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 16687 (epoch 27), train_loss = 2.687, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 16688 (epoch 27), train_loss = 2.345, time/batch = 0.027
Read data: 0.00015854835510253906
iter 16689 (epoch 27), train_loss = 2.585, time/batch = 0.025
Read data: 0.00015664100646972656
iter 16690 (epoch 27), train_loss = 2.784, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 16691 (epoch 27), train_loss = 2.421, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 16692 (epoch 27), train_loss = 2.570, time/batch = 0.027
Read data: 0.0001552104949951172
iter 16693 (epoch 27), train_loss = 2.353, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 16694 (epoch 27), train_loss = 2.355, time/batch = 0.026
Read data: 0.0001316070556640625
iter 16695 (epoch 27), train_loss = 2.408, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 16696 (epoch 27), train_loss = 2.517, time/batch = 0.021
Read data: 0.00010442733764648438
iter 16697 (epoch 27), train_loss = 2.731, time/batch = 0.027
Read data: 0.0001399517059326172
iter 16698 (epoch 27), train_loss = 2.546, time/batch = 0.032
Read data: 9.608268737792969e-05
iter 16699 (epoch 27), train_loss = 2.328, time/batch = 0.024
Read data: 0.0001575946807861328
iter 16700 (epoch 27), train_loss = 2.886, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 16701 (epoch 27), train_loss = 2.232, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 16702 (epoch 27), train_loss = 2.947, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 16703 (epoch 27), train_loss = 2.735, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 16704 (epoch 27), train_loss = 2.685, time/batch = 0.028
Read data: 8.392333984375e-05
iter 16705 (epoch 27), train_loss = 2.332, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 16706 (epoch 27), train_loss = 2.224, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 16707 (epoch 27), train_loss = 2.404, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 16708 (epoch 27), train_loss = 2.584, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 16709 (epoch 27), train_loss = 2.452, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 16710 (epoch 27), train_loss = 2.152, time/batch = 0.021
Read data: 8.821487426757812e-05
iter 16711 (epoch 27), train_loss = 2.698, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 16712 (epoch 27), train_loss = 2.561, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 16713 (epoch 27), train_loss = 2.358, time/batch = 0.021
Read data: 0.0017592906951904297
iter 16714 (epoch 27), train_loss = 2.270, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 16715 (epoch 27), train_loss = 2.286, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 16716 (epoch 27), train_loss = 2.221, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 16717 (epoch 27), train_loss = 2.402, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 16718 (epoch 27), train_loss = 2.338, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 16719 (epoch 27), train_loss = 2.768, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 16720 (epoch 27), train_loss = 2.503, time/batch = 0.028
Read data: 9.942054748535156e-05
iter 16721 (epoch 27), train_loss = 2.835, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 16722 (epoch 27), train_loss = 2.463, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 16723 (epoch 27), train_loss = 2.715, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 16724 (epoch 27), train_loss = 2.606, time/batch = 0.023
Read data: 0.000209808349609375
iter 16725 (epoch 27), train_loss = 2.192, time/batch = 0.025
Read data: 9.417533874511719e-05
iter 16726 (epoch 27), train_loss = 2.682, time/batch = 0.025
Read data: 0.00010037422180175781
iter 16727 (epoch 27), train_loss = 2.090, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 16728 (epoch 27), train_loss = 2.616, time/batch = 0.025
Read data: 0.00012373924255371094
iter 16729 (epoch 27), train_loss = 2.041, time/batch = 0.020
Read data: 9.083747863769531e-05
iter 16730 (epoch 27), train_loss = 2.141, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 16731 (epoch 27), train_loss = 2.851, time/batch = 0.030
Read data: 9.179115295410156e-05
iter 16732 (epoch 27), train_loss = 3.042, time/batch = 0.030
Read data: 0.0001556873321533203
iter 16733 (epoch 27), train_loss = 2.425, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 16734 (epoch 27), train_loss = 2.790, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 16735 (epoch 27), train_loss = 2.360, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 16736 (epoch 27), train_loss = 2.067, time/batch = 0.019
Read data: 0.00012493133544921875
iter 16737 (epoch 27), train_loss = 2.328, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 16738 (epoch 27), train_loss = 2.196, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 16739 (epoch 27), train_loss = 2.315, time/batch = 0.031
Read data: 9.846687316894531e-05
iter 16740 (epoch 27), train_loss = 2.924, time/batch = 0.023
Read data: 0.0001671314239501953
iter 16741 (epoch 27), train_loss = 2.623, time/batch = 0.037
Read data: 8.440017700195312e-05
iter 16742 (epoch 27), train_loss = 2.262, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 16743 (epoch 27), train_loss = 2.834, time/batch = 0.027
Read data: 0.00010037422180175781
iter 16744 (epoch 27), train_loss = 2.487, time/batch = 0.020
Read data: 0.00017023086547851562
iter 16745 (epoch 27), train_loss = 2.113, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 16746 (epoch 27), train_loss = 2.250, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 16747 (epoch 27), train_loss = 2.367, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 16748 (epoch 27), train_loss = 2.679, time/batch = 0.029
Read data: 0.0001227855682373047
iter 16749 (epoch 27), train_loss = 2.572, time/batch = 0.025
Read data: 0.0002720355987548828
iter 16750 (epoch 27), train_loss = 2.617, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 16751 (epoch 27), train_loss = 2.583, time/batch = 0.022
Read data: 9.632110595703125e-05
iter 16752 (epoch 27), train_loss = 2.550, time/batch = 0.025
Read data: 9.822845458984375e-05
iter 16753 (epoch 27), train_loss = 2.742, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 16754 (epoch 27), train_loss = 2.405, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 16755 (epoch 27), train_loss = 2.446, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 16756 (epoch 27), train_loss = 2.590, time/batch = 0.024
Read data: 0.00014925003051757812
iter 16757 (epoch 27), train_loss = 2.238, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 16758 (epoch 27), train_loss = 2.541, time/batch = 0.031
Read data: 8.702278137207031e-05
iter 16759 (epoch 27), train_loss = 2.625, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 16760 (epoch 27), train_loss = 2.626, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 16761 (epoch 27), train_loss = 2.603, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 16762 (epoch 27), train_loss = 2.467, time/batch = 0.025
Read data: 9.417533874511719e-05
iter 16763 (epoch 27), train_loss = 2.534, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 16764 (epoch 27), train_loss = 2.074, time/batch = 0.027
Read data: 0.0001232624053955078
iter 16765 (epoch 27), train_loss = 2.929, time/batch = 0.024
Read data: 0.00012612342834472656
iter 16766 (epoch 27), train_loss = 2.568, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 16767 (epoch 27), train_loss = 2.646, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 16768 (epoch 27), train_loss = 1.960, time/batch = 0.028
Read data: 0.00012230873107910156
iter 16769 (epoch 27), train_loss = 2.568, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 16770 (epoch 27), train_loss = 2.417, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 16771 (epoch 27), train_loss = 2.718, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 16772 (epoch 27), train_loss = 2.573, time/batch = 0.027
Read data: 0.00013256072998046875
iter 16773 (epoch 27), train_loss = 2.687, time/batch = 0.023
Read data: 0.00012373924255371094
iter 16774 (epoch 27), train_loss = 2.343, time/batch = 0.026
Read data: 0.0002315044403076172
iter 16775 (epoch 27), train_loss = 2.338, time/batch = 0.029
Read data: 9.822845458984375e-05
iter 16776 (epoch 27), train_loss = 2.632, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 16777 (epoch 27), train_loss = 2.232, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 16778 (epoch 27), train_loss = 2.504, time/batch = 0.033
Read data: 8.797645568847656e-05
iter 16779 (epoch 27), train_loss = 2.324, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 16780 (epoch 27), train_loss = 2.302, time/batch = 0.028
Read data: 0.00013494491577148438
iter 16781 (epoch 27), train_loss = 2.435, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 16782 (epoch 27), train_loss = 2.414, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 16783 (epoch 27), train_loss = 2.759, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 16784 (epoch 27), train_loss = 2.706, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 16785 (epoch 27), train_loss = 2.710, time/batch = 0.022
Read data: 9.870529174804688e-05
iter 16786 (epoch 27), train_loss = 2.109, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 16787 (epoch 27), train_loss = 2.698, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 16788 (epoch 27), train_loss = 2.773, time/batch = 0.025
Read data: 0.00013971328735351562
iter 16789 (epoch 27), train_loss = 2.716, time/batch = 0.027
Read data: 0.00014472007751464844
iter 16790 (epoch 27), train_loss = 2.670, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 16791 (epoch 27), train_loss = 2.419, time/batch = 0.027
Read data: 0.0009865760803222656
iter 16792 (epoch 27), train_loss = 2.437, time/batch = 0.023
Read data: 0.0001480579376220703
iter 16793 (epoch 27), train_loss = 2.249, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 16794 (epoch 27), train_loss = 2.587, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 16795 (epoch 27), train_loss = 2.369, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 16796 (epoch 27), train_loss = 2.774, time/batch = 0.035
Read data: 0.00014638900756835938
iter 16797 (epoch 27), train_loss = 2.262, time/batch = 0.026
Read data: 0.0001289844512939453
iter 16798 (epoch 27), train_loss = 2.224, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 16799 (epoch 27), train_loss = 2.482, time/batch = 0.028
Read data: 0.0001900196075439453
iter 16800 (epoch 27), train_loss = 2.711, time/batch = 0.027
Read data: 0.00011777877807617188
iter 16801 (epoch 28), train_loss = 2.083, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 16802 (epoch 28), train_loss = 2.280, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 16803 (epoch 28), train_loss = 2.241, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 16804 (epoch 28), train_loss = 2.328, time/batch = 0.027
Read data: 0.00015354156494140625
iter 16805 (epoch 28), train_loss = 2.396, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 16806 (epoch 28), train_loss = 2.680, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 16807 (epoch 28), train_loss = 2.665, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 16808 (epoch 28), train_loss = 2.230, time/batch = 0.031
Read data: 0.00012373924255371094
iter 16809 (epoch 28), train_loss = 2.764, time/batch = 0.027
Read data: 0.00015282630920410156
iter 16810 (epoch 28), train_loss = 1.989, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 16811 (epoch 28), train_loss = 2.342, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 16812 (epoch 28), train_loss = 2.356, time/batch = 0.022
Read data: 0.00014710426330566406
iter 16813 (epoch 28), train_loss = 2.405, time/batch = 0.035
Read data: 8.20159912109375e-05
iter 16814 (epoch 28), train_loss = 2.958, time/batch = 0.033
Read data: 8.869171142578125e-05
iter 16815 (epoch 28), train_loss = 2.224, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 16816 (epoch 28), train_loss = 2.010, time/batch = 0.023
Read data: 0.00017404556274414062
iter 16817 (epoch 28), train_loss = 2.408, time/batch = 0.028
Read data: 7.605552673339844e-05
iter 16818 (epoch 28), train_loss = 2.097, time/batch = 0.030
Read data: 7.963180541992188e-05
iter 16819 (epoch 28), train_loss = 2.529, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 16820 (epoch 28), train_loss = 2.605, time/batch = 0.025
Read data: 0.00013184547424316406
iter 16821 (epoch 28), train_loss = 2.414, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 16822 (epoch 28), train_loss = 2.507, time/batch = 0.027
Read data: 9.989738464355469e-05
iter 16823 (epoch 28), train_loss = 2.247, time/batch = 0.026
Read data: 9.274482727050781e-05
iter 16824 (epoch 28), train_loss = 2.344, time/batch = 0.025
Read data: 0.0002334117889404297
iter 16825 (epoch 28), train_loss = 2.147, time/batch = 0.023
Read data: 0.00014138221740722656
iter 16826 (epoch 28), train_loss = 2.071, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 16827 (epoch 28), train_loss = 2.732, time/batch = 0.035
Read data: 8.106231689453125e-05
iter 16828 (epoch 28), train_loss = 2.624, time/batch = 0.025
Read data: 0.00013446807861328125
iter 16829 (epoch 28), train_loss = 2.955, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 16830 (epoch 28), train_loss = 2.216, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 16831 (epoch 28), train_loss = 2.909, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 16832 (epoch 28), train_loss = 2.277, time/batch = 0.027
Read data: 0.00010061264038085938
iter 16833 (epoch 28), train_loss = 2.451, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 16834 (epoch 28), train_loss = 2.438, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 16835 (epoch 28), train_loss = 2.924, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 16836 (epoch 28), train_loss = 2.515, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 16837 (epoch 28), train_loss = 2.255, time/batch = 0.025
Read data: 9.131431579589844e-05
iter 16838 (epoch 28), train_loss = 2.503, time/batch = 0.027
Read data: 0.00013399124145507812
iter 16839 (epoch 28), train_loss = 2.323, time/batch = 0.039
Read data: 8.749961853027344e-05
iter 16840 (epoch 28), train_loss = 2.397, time/batch = 0.032
Read data: 8.869171142578125e-05
iter 16841 (epoch 28), train_loss = 2.451, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 16842 (epoch 28), train_loss = 2.162, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 16843 (epoch 28), train_loss = 2.673, time/batch = 0.026
Read data: 8.392333984375e-05
iter 16844 (epoch 28), train_loss = 1.994, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 16845 (epoch 28), train_loss = 2.321, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 16846 (epoch 28), train_loss = 2.736, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 16847 (epoch 28), train_loss = 2.278, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 16848 (epoch 28), train_loss = 2.305, time/batch = 0.025
Read data: 0.00012922286987304688
iter 16849 (epoch 28), train_loss = 2.510, time/batch = 0.035
Read data: 0.00022125244140625
iter 16850 (epoch 28), train_loss = 2.684, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 16851 (epoch 28), train_loss = 2.371, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 16852 (epoch 28), train_loss = 2.189, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 16853 (epoch 28), train_loss = 2.673, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 16854 (epoch 28), train_loss = 2.758, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 16855 (epoch 28), train_loss = 2.287, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 16856 (epoch 28), train_loss = 2.317, time/batch = 0.021
Read data: 9.202957153320312e-05
iter 16857 (epoch 28), train_loss = 2.356, time/batch = 0.029
Read data: 9.775161743164062e-05
iter 16858 (epoch 28), train_loss = 2.709, time/batch = 0.038
Read data: 0.0001671314239501953
iter 16859 (epoch 28), train_loss = 2.321, time/batch = 0.025
Read data: 9.965896606445312e-05
iter 16860 (epoch 28), train_loss = 2.173, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 16861 (epoch 28), train_loss = 2.438, time/batch = 0.030
Read data: 8.678436279296875e-05
iter 16862 (epoch 28), train_loss = 2.435, time/batch = 0.026
Read data: 0.00010132789611816406
iter 16863 (epoch 28), train_loss = 2.523, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 16864 (epoch 28), train_loss = 2.522, time/batch = 0.031
Read data: 0.00013494491577148438
iter 16865 (epoch 28), train_loss = 2.544, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 16866 (epoch 28), train_loss = 2.236, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 16867 (epoch 28), train_loss = 2.705, time/batch = 0.024
Read data: 0.00010609626770019531
iter 16868 (epoch 28), train_loss = 2.885, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 16869 (epoch 28), train_loss = 2.362, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 16870 (epoch 28), train_loss = 2.449, time/batch = 0.029
Read data: 0.0001266002655029297
iter 16871 (epoch 28), train_loss = 2.230, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 16872 (epoch 28), train_loss = 2.595, time/batch = 0.027
Read data: 0.00012683868408203125
iter 16873 (epoch 28), train_loss = 2.390, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 16874 (epoch 28), train_loss = 2.478, time/batch = 0.032
Read data: 0.00024056434631347656
iter 16875 (epoch 28), train_loss = 2.688, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 16876 (epoch 28), train_loss = 1.990, time/batch = 0.023
Read data: 0.00016117095947265625
iter 16877 (epoch 28), train_loss = 2.585, time/batch = 0.023
Read data: 9.918212890625e-05
iter 16878 (epoch 28), train_loss = 2.107, time/batch = 0.026
Read data: 0.00010752677917480469
iter 16879 (epoch 28), train_loss = 2.436, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 16880 (epoch 28), train_loss = 2.317, time/batch = 0.023
Read data: 0.00014543533325195312
iter 16881 (epoch 28), train_loss = 2.839, time/batch = 0.026
Read data: 0.00013303756713867188
iter 16882 (epoch 28), train_loss = 2.618, time/batch = 0.025
Read data: 0.00017142295837402344
iter 16883 (epoch 28), train_loss = 2.040, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 16884 (epoch 28), train_loss = 2.588, time/batch = 0.030
Read data: 8.821487426757812e-05
iter 16885 (epoch 28), train_loss = 2.277, time/batch = 0.024
Read data: 0.00014448165893554688
iter 16886 (epoch 28), train_loss = 2.063, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 16887 (epoch 28), train_loss = 2.783, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 16888 (epoch 28), train_loss = 2.537, time/batch = 0.033
Read data: 0.00014472007751464844
iter 16889 (epoch 28), train_loss = 2.738, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 16890 (epoch 28), train_loss = 2.590, time/batch = 0.023
Read data: 0.000141143798828125
iter 16891 (epoch 28), train_loss = 2.487, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 16892 (epoch 28), train_loss = 2.629, time/batch = 0.028
Read data: 0.00012731552124023438
iter 16893 (epoch 28), train_loss = 2.632, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 16894 (epoch 28), train_loss = 2.303, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 16895 (epoch 28), train_loss = 2.374, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 16896 (epoch 28), train_loss = 2.431, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 16897 (epoch 28), train_loss = 2.321, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 16898 (epoch 28), train_loss = 2.267, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 16899 (epoch 28), train_loss = 2.231, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 16900 (epoch 28), train_loss = 2.461, time/batch = 0.025
Read data: 0.0001266002655029297
iter 16901 (epoch 28), train_loss = 2.758, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 16902 (epoch 28), train_loss = 2.313, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 16903 (epoch 28), train_loss = 2.670, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 16904 (epoch 28), train_loss = 2.375, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 16905 (epoch 28), train_loss = 3.012, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 16906 (epoch 28), train_loss = 2.429, time/batch = 0.025
Read data: 0.0001475811004638672
iter 16907 (epoch 28), train_loss = 2.017, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 16908 (epoch 28), train_loss = 2.306, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 16909 (epoch 28), train_loss = 2.453, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 16910 (epoch 28), train_loss = 2.237, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 16911 (epoch 28), train_loss = 2.322, time/batch = 0.035
Read data: 9.870529174804688e-05
iter 16912 (epoch 28), train_loss = 2.635, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 16913 (epoch 28), train_loss = 2.349, time/batch = 0.027
Read data: 0.00023484230041503906
iter 16914 (epoch 28), train_loss = 2.505, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 16915 (epoch 28), train_loss = 2.159, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 16916 (epoch 28), train_loss = 2.819, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 16917 (epoch 28), train_loss = 2.352, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 16918 (epoch 28), train_loss = 2.300, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 16919 (epoch 28), train_loss = 2.469, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 16920 (epoch 28), train_loss = 2.101, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 16921 (epoch 28), train_loss = 2.367, time/batch = 0.025
Read data: 0.00013947486877441406
iter 16922 (epoch 28), train_loss = 2.335, time/batch = 0.029
Read data: 9.846687316894531e-05
iter 16923 (epoch 28), train_loss = 2.196, time/batch = 0.022
Read data: 9.799003601074219e-05
iter 16924 (epoch 28), train_loss = 2.493, time/batch = 0.029
Read data: 0.0002467632293701172
iter 16925 (epoch 28), train_loss = 2.204, time/batch = 0.025
Read data: 0.00015735626220703125
iter 16926 (epoch 28), train_loss = 2.444, time/batch = 0.024
Read data: 0.00010061264038085938
iter 16927 (epoch 28), train_loss = 2.750, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 16928 (epoch 28), train_loss = 2.208, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 16929 (epoch 28), train_loss = 2.142, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 16930 (epoch 28), train_loss = 2.452, time/batch = 0.027
Read data: 0.00018072128295898438
iter 16931 (epoch 28), train_loss = 2.296, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 16932 (epoch 28), train_loss = 2.611, time/batch = 0.025
Read data: 0.00013136863708496094
iter 16933 (epoch 28), train_loss = 2.301, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 16934 (epoch 28), train_loss = 2.590, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 16935 (epoch 28), train_loss = 2.550, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 16936 (epoch 28), train_loss = 2.198, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 16937 (epoch 28), train_loss = 2.664, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 16938 (epoch 28), train_loss = 2.226, time/batch = 0.028
Read data: 0.0001494884490966797
iter 16939 (epoch 28), train_loss = 2.345, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 16940 (epoch 28), train_loss = 2.414, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 16941 (epoch 28), train_loss = 2.450, time/batch = 0.022
Read data: 9.703636169433594e-05
iter 16942 (epoch 28), train_loss = 2.762, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 16943 (epoch 28), train_loss = 2.251, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 16944 (epoch 28), train_loss = 2.653, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 16945 (epoch 28), train_loss = 2.507, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 16946 (epoch 28), train_loss = 2.501, time/batch = 0.025
Read data: 0.0001304149627685547
iter 16947 (epoch 28), train_loss = 2.493, time/batch = 0.028
Read data: 9.918212890625e-05
iter 16948 (epoch 28), train_loss = 2.457, time/batch = 0.038
Read data: 0.00013685226440429688
iter 16949 (epoch 28), train_loss = 2.621, time/batch = 0.033
Read data: 0.0002753734588623047
iter 16950 (epoch 28), train_loss = 2.726, time/batch = 0.030
Read data: 7.510185241699219e-05
iter 16951 (epoch 28), train_loss = 2.568, time/batch = 0.024
Read data: 0.00013017654418945312
iter 16952 (epoch 28), train_loss = 2.619, time/batch = 0.032
Read data: 8.606910705566406e-05
iter 16953 (epoch 28), train_loss = 2.130, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 16954 (epoch 28), train_loss = 2.515, time/batch = 0.023
Read data: 0.00013518333435058594
iter 16955 (epoch 28), train_loss = 2.641, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 16956 (epoch 28), train_loss = 2.657, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 16957 (epoch 28), train_loss = 2.202, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 16958 (epoch 28), train_loss = 2.329, time/batch = 0.027
Read data: 9.942054748535156e-05
iter 16959 (epoch 28), train_loss = 2.695, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 16960 (epoch 28), train_loss = 2.632, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 16961 (epoch 28), train_loss = 2.498, time/batch = 0.027
Read data: 8.392333984375e-05
iter 16962 (epoch 28), train_loss = 2.339, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 16963 (epoch 28), train_loss = 2.450, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 16964 (epoch 28), train_loss = 2.458, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 16965 (epoch 28), train_loss = 2.129, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 16966 (epoch 28), train_loss = 2.576, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 16967 (epoch 28), train_loss = 2.519, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 16968 (epoch 28), train_loss = 2.364, time/batch = 0.025
Read data: 0.00010514259338378906
iter 16969 (epoch 28), train_loss = 2.394, time/batch = 0.027
Read data: 0.00012421607971191406
iter 16970 (epoch 28), train_loss = 2.622, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 16971 (epoch 28), train_loss = 2.805, time/batch = 0.040
Read data: 8.463859558105469e-05
iter 16972 (epoch 28), train_loss = 2.179, time/batch = 0.026
Read data: 9.417533874511719e-05
iter 16973 (epoch 28), train_loss = 2.261, time/batch = 0.022
Read data: 0.00010585784912109375
iter 16974 (epoch 28), train_loss = 2.393, time/batch = 0.019
Read data: 0.0002110004425048828
iter 16975 (epoch 28), train_loss = 2.301, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 16976 (epoch 28), train_loss = 2.285, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 16977 (epoch 28), train_loss = 2.428, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 16978 (epoch 28), train_loss = 2.131, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 16979 (epoch 28), train_loss = 2.486, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 16980 (epoch 28), train_loss = 2.652, time/batch = 0.028
Read data: 7.653236389160156e-05
iter 16981 (epoch 28), train_loss = 2.333, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 16982 (epoch 28), train_loss = 2.610, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 16983 (epoch 28), train_loss = 2.202, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 16984 (epoch 28), train_loss = 2.743, time/batch = 0.023
Read data: 0.00014519691467285156
iter 16985 (epoch 28), train_loss = 2.150, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 16986 (epoch 28), train_loss = 2.419, time/batch = 0.029
Read data: 8.988380432128906e-05
iter 16987 (epoch 28), train_loss = 2.715, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 16988 (epoch 28), train_loss = 2.444, time/batch = 0.026
Read data: 0.00012087821960449219
iter 16989 (epoch 28), train_loss = 2.457, time/batch = 0.029
Read data: 0.0001239776611328125
iter 16990 (epoch 28), train_loss = 2.429, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 16991 (epoch 28), train_loss = 2.211, time/batch = 0.023
Read data: 9.989738464355469e-05
iter 16992 (epoch 28), train_loss = 2.107, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 16993 (epoch 28), train_loss = 2.603, time/batch = 0.025
Read data: 0.00014162063598632812
iter 16994 (epoch 28), train_loss = 2.521, time/batch = 0.026
Read data: 9.465217590332031e-05
iter 16995 (epoch 28), train_loss = 2.402, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 16996 (epoch 28), train_loss = 2.290, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 16997 (epoch 28), train_loss = 2.290, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 16998 (epoch 28), train_loss = 2.464, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 16999 (epoch 28), train_loss = 2.408, time/batch = 0.030
image 976:      
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:     
image 2375:    
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.635367)
image 2798:    
image 5884:     
image 2067:     
image 3600:    
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:     
evaluating validation preformance... 20/1000 (2.210585)
image 6903:    UNK
image 3301:    
image 2019:     
image 5535:     
image 7680:      
image 5527:      
image 2568:      
image 160:    
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.546085)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:     
image 1684:     
evaluating validation preformance... 40/1000 (3.016512)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:     
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.500502)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    UNK
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.817625)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:  
image 5641:     
evaluating validation preformance... 70/1000 (2.581259)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.615179)
image 3276:      
image 3812:    
image 1400:    
image 3443:     
image 5027:     
image 7251:     
image 7305:     
image 1480:      
image 4806:      
image 766:     
evaluating validation preformance... 90/1000 (2.136308)
image 6124:      
image 5415:     
image 369:    
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.904539)
image 2800:    
image 7249:      
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    UNK
image 150:      
evaluating validation preformance... 110/1000 (2.785021)
image 1122:    
image 509:     
image 4091:     
image 5761:     
image 16:    
image 231:    
image 6505:     
image 1450:    
image 3979:      
image 5302:     UNK
evaluating validation preformance... 120/1000 (2.360917)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.885181)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:    
image 2867:    
evaluating validation preformance... 140/1000 (2.673597)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    UNK
evaluating validation preformance... 150/1000 (2.925748)
image 1865:      
image 3830:      
image 360:      
image 5097:    
image 4455:    
image 1153:    
image 1248:    UNK
image 7688:      
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.822734)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.558228)
image 7922:     
image 2353:    
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.706606)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:      
image 4541:     
image 2813:     
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.405523)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:   
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.318096)
image 5159:     
image 1199:    
image 2456:     
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.476906)
image 2599:     
image 822:    
image 3926:     
image 6942:     
image 1942:    
image 618:    
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.551204)
image 4024:    
image 1894:    
image 7297:    
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:   
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.205681)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:    
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.105115)
image 7143:    
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:   
image 528:    
evaluating validation preformance... 250/1000 (2.508920)
image 3028:      
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.492583)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.985272)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:    
image 2054:     
evaluating validation preformance... 280/1000 (2.561952)
image 2481:    
image 1860:    
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.370972)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:    
evaluating validation preformance... 300/1000 (2.167991)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.765481)
image 3553:    
image 5971:     
image 122:    
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:    
evaluating validation preformance... 320/1000 (2.307462)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.766332)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:      
image 2601:    
image 4524:     
image 3972:    
evaluating validation preformance... 340/1000 (2.408737)
image 4542:      
image 1878:      
image 5329:     
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.484551)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:     
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.035478)
image 2905:    UNK
image 7814:      
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:    
image 6607:     
image 4866:     
evaluating validation preformance... 370/1000 (2.576825)
image 4351:      
image 1054:     
image 129:     
image 2849:    
image 725:   UNK
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.650265)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:     
image 60:    
evaluating validation preformance... 390/1000 (2.821824)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:    
image 1117:      
image 5817:      
image 1231:    
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.228002)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.116080)
image 4359:     
image 2372:     
image 4472:     
image 6810:    
image 1592:     
image 7864:     
image 4286:    
image 6688:    
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.351530)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:     
image 6977:    
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.811615)
image 385:    
image 6938:      
image 2381:    
image 5796:    
image 4010:    
image 3452:     
image 2023:     
image 3052:    
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.921423)
image 1731:       
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:     
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.140878)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:     
image 2466:     
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.656385)
image 7979:    
image 1618:    UNK
image 7608:    
image 6393:    
image 5100:      
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.270531)
image 4503:    
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:    
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.898315)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:    UNK
image 1595:     
image 4757:     
image 205:    
evaluating validation preformance... 490/1000 (3.294756)
image 2044:    
image 4349:    
image 3855:     
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:    
image 5744:      
evaluating validation preformance... 500/1000 (2.439118)
image 1797:    
image 4670:     
image 4846:    
image 5907:     
image 3321:    
image 1700:     
image 438:    
image 5980:     
image 408:     
image 5403:      
evaluating validation preformance... 510/1000 (2.975804)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:     UNK
evaluating validation preformance... 520/1000 (2.636548)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:   
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.454507)
image 5619:     
image 4391:  
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:    
image 6034:    
image 6062:    
image 3170:    
evaluating validation preformance... 540/1000 (2.439170)
image 5292:    
image 2901:     
image 3568:     
image 690:     
image 3345:    
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.572344)
image 5439:    
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.533300)
image 6056:    
image 6419:    
image 275:     
image 7441:    UNK
image 7893:    
image 3623:    
image 7232:    
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.551669)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:     
evaluating validation preformance... 580/1000 (2.590359)
image 2135:      
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.593715)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.445855)
image 353:     
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.659458)
image 69:    
image 3465:    
image 6179:    
image 552:    
image 511:    
image 761:    
image 5742:     
image 359:      
image 4170:    
image 7915:     
evaluating validation preformance... 620/1000 (2.389828)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.476433)
image 8074:    
image 1904:     
image 7917:    
image 2394:     
image 4406:     
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.472465)
image 5313:      
image 2377:    
image 6058:    
image 4661:    
image 2955:   
image 3333:    
image 7124:     
image 4278:    
image 953:      
image 4037:    
evaluating validation preformance... 650/1000 (2.592734)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:     
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.624874)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (2.776362)
image 7877:    
image 6761:     
image 6880:   
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK  
image 7784:    
evaluating validation preformance... 680/1000 (3.005449)
image 1445:     UNK
image 6841:     
image 2896:     
image 6947:   
image 4782:    
image 7669:     
image 4382:    UNK
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.830070)
image 6860:     
image 576:     
image 6580:     
image 1497:     
image 3360:    
image 4939:      
image 6225:     
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.993947)
image 5343:      
image 68:    
image 3184:     
image 5637:      
image 2041:     
image 650:     UNK
image 4911:     
image 34:    UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.455945)
image 7368:    
image 709:     
image 3197:    
image 5214:    
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.632084)
image 5729:     
image 6395:     
image 516:      
image 1026:     
image 2972:      
image 3005:     
image 1241:      
image 2743:      
image 3665:    
image 1290:     UNK
evaluating validation preformance... 730/1000 (2.271250)
image 2527:     
image 6266:     
image 4161:      
image 1139:    
image 3781:     
image 6081:      
image 997:    
image 5092:     
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.374113)
image 2239:     
image 120:       
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.650177)
image 3279:    
image 6380:    
image 2663:     
image 3815:    
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     UNK
image 7174:    
evaluating validation preformance... 760/1000 (2.977258)
image 4582:    
image 5484:    
image 3049:    
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.114082)
image 6220:    
image 6238:     
image 4534:    
image 2732:     
image 7003:     
image 1739:     
image 5503:     
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.811955)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:    
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.113986)
image 5047:      
image 325:       
image 7626:    
image 4552:     
image 983:    
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.212528)
image 7288:      
image 7302:     
image 3055:     
image 5250:     
image 1158:    
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.414641)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.912001)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:     
image 7147:    
image 6348:     
image 580:     UNK
image 2531:    
evaluating validation preformance... 830/1000 (2.371088)
image 5107:    
image 3973:     
image 4233:     
image 3593:      
image 5872:     
image 2074:      
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.429760)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.735765)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:    
image 3596:      
image 1921:      
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.742135)
image 4254:     
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:     
evaluating validation preformance... 870/1000 (2.309386)
image 4934:    
image 6487:     UNK
image 4217:    
image 6355:    
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.592264)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.905965)
image 7485:    
image 6102:    
image 1001:      
image 7167:    
image 4168:    
image 187:    
image 7798:    
image 4813:    
image 7753:    
image 210:    
evaluating validation preformance... 900/1000 (3.593909)
image 5664:     
image 4985:    UNK
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:    
image 7205:     
evaluating validation preformance... 910/1000 (2.175742)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:    
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.594872)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:      
image 7102:    
image 5532:    UNK
image 2516:     
evaluating validation preformance... 930/1000 (2.506432)
image 5636:      
image 7799:      
image 6025:    
image 6907:      
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.673078)
image 5860:    
image 3275:     
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:    
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.916093)
image 1081:    
image 1179:     
image 4316:    
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:    
image 2915:    
image 1550:    
evaluating validation preformance... 960/1000 (2.733041)
image 4935:     
image 1930:     
image 6850:    
image 5310:     
image 177:     
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.308057)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:     
image 7800:    UNK
image 3999:    
image 6317:    
image 5931:     
evaluating validation preformance... 980/1000 (2.745181)
image 7352:     
image 5113:     
image 7822:     
image 4858:    
image 658:    
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.446225)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.330800)
average loss on validation: 2.584
model saved to ./log_Att2in_sc/model.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3571033477783203
Cider scores: 0.602767090340639
Read data: 0.3143317699432373
Cider scores: 0.5608616550939638
Read data: 0.23369956016540527
Cider scores: 0.5975389968970993
Read data: 0.21602654457092285
Cider scores: 0.5651825021609072
Read data: 0.22204160690307617
Cider scores: 0.5802568513651177
Read data: 0.18431591987609863
Cider scores: 0.5474872310830077
Read data: 0.22161388397216797
Cider scores: 0.5310775378109632
Read data: 0.20171737670898438
Cider scores: 0.6313721525942505
Read data: 0.1718583106994629
Cider scores: 0.5358093125886633
Read data: 0.20631718635559082
Cider scores: 0.7457218963149157
Read data: 0.19744586944580078
Cider scores: 0.6036546520441908
Read data: 0.23645401000976562
Cider scores: 0.6890229501889482
Read data: 0.18036794662475586
Cider scores: 0.5782257404469788
Read data: 0.1942751407623291
Cider scores: 0.6579694322505012
Read data: 0.20467710494995117
Cider scores: 0.6334063449985015
Read data: 0.16639208793640137
Cider scores: 0.6713409767616932
Read data: 0.1631317138671875
Cider scores: 0.48229707446176406
Read data: 0.17643380165100098
Cider scores: 0.6815742920016947
Read data: 0.16803383827209473
Cider scores: 0.583398239496942
Read data: 0.16470694541931152
Cider scores: 0.8046354680709221
Average cider score on test set: 0.614
End calculating cider score on TEST data set
===============================================
Read data: 0.16303300857543945
iter 17000 (epoch 28), train_loss = 2.446, time/batch = 0.024
Read data: 0.00010251998901367188
iter 17001 (epoch 28), train_loss = 2.228, time/batch = 0.024
Read data: 0.00011277198791503906
iter 17002 (epoch 28), train_loss = 2.659, time/batch = 0.026
Read data: 0.00011444091796875
iter 17003 (epoch 28), train_loss = 2.692, time/batch = 0.029
Read data: 0.00010776519775390625
iter 17004 (epoch 28), train_loss = 1.985, time/batch = 0.026
Read data: 0.00014472007751464844
iter 17005 (epoch 28), train_loss = 2.527, time/batch = 0.036
Read data: 0.0001068115234375
iter 17006 (epoch 28), train_loss = 2.399, time/batch = 0.028
Read data: 0.00014281272888183594
iter 17007 (epoch 28), train_loss = 2.501, time/batch = 0.033
Read data: 0.00010442733764648438
iter 17008 (epoch 28), train_loss = 2.501, time/batch = 0.028
Read data: 9.822845458984375e-05
iter 17009 (epoch 28), train_loss = 2.302, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 17010 (epoch 28), train_loss = 2.561, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 17011 (epoch 28), train_loss = 2.657, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 17012 (epoch 28), train_loss = 2.639, time/batch = 0.036
Read data: 9.1552734375e-05
iter 17013 (epoch 28), train_loss = 2.229, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 17014 (epoch 28), train_loss = 2.326, time/batch = 0.026
Read data: 0.00013375282287597656
iter 17015 (epoch 28), train_loss = 2.857, time/batch = 0.037
Read data: 8.082389831542969e-05
iter 17016 (epoch 28), train_loss = 2.633, time/batch = 0.041
Read data: 0.00015091896057128906
iter 17017 (epoch 28), train_loss = 2.546, time/batch = 0.028
Read data: 0.00011587142944335938
iter 17018 (epoch 28), train_loss = 2.293, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 17019 (epoch 28), train_loss = 2.270, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 17020 (epoch 28), train_loss = 2.528, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 17021 (epoch 28), train_loss = 2.207, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 17022 (epoch 28), train_loss = 2.457, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 17023 (epoch 28), train_loss = 2.640, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 17024 (epoch 28), train_loss = 2.625, time/batch = 0.026
Read data: 0.00029468536376953125
iter 17025 (epoch 28), train_loss = 2.525, time/batch = 0.028
Read data: 0.00012636184692382812
iter 17026 (epoch 28), train_loss = 2.403, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 17027 (epoch 28), train_loss = 2.477, time/batch = 0.028
Read data: 0.00011563301086425781
iter 17028 (epoch 28), train_loss = 2.902, time/batch = 0.025
Read data: 0.00012183189392089844
iter 17029 (epoch 28), train_loss = 2.490, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 17030 (epoch 28), train_loss = 2.546, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 17031 (epoch 28), train_loss = 2.581, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 17032 (epoch 28), train_loss = 2.455, time/batch = 0.028
Read data: 9.322166442871094e-05
iter 17033 (epoch 28), train_loss = 2.329, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 17034 (epoch 28), train_loss = 2.590, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 17035 (epoch 28), train_loss = 2.561, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 17036 (epoch 28), train_loss = 2.242, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 17037 (epoch 28), train_loss = 2.389, time/batch = 0.025
Read data: 0.00019812583923339844
iter 17038 (epoch 28), train_loss = 2.150, time/batch = 0.027
Read data: 9.512901306152344e-05
iter 17039 (epoch 28), train_loss = 2.223, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 17040 (epoch 28), train_loss = 2.695, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 17041 (epoch 28), train_loss = 2.947, time/batch = 0.029
Read data: 0.0001881122589111328
iter 17042 (epoch 28), train_loss = 2.464, time/batch = 0.023
Read data: 7.510185241699219e-05
iter 17043 (epoch 28), train_loss = 2.590, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 17044 (epoch 28), train_loss = 2.510, time/batch = 0.025
Read data: 7.62939453125e-05
iter 17045 (epoch 28), train_loss = 2.570, time/batch = 0.031
Read data: 7.62939453125e-05
iter 17046 (epoch 28), train_loss = 2.706, time/batch = 0.030
Read data: 8.153915405273438e-05
iter 17047 (epoch 28), train_loss = 2.335, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 17048 (epoch 28), train_loss = 2.339, time/batch = 0.021
Read data: 8.440017700195312e-05
iter 17049 (epoch 28), train_loss = 2.392, time/batch = 0.029
Read data: 0.00025916099548339844
iter 17050 (epoch 28), train_loss = 2.346, time/batch = 0.027
Read data: 7.510185241699219e-05
iter 17051 (epoch 28), train_loss = 2.668, time/batch = 0.032
Read data: 0.00011277198791503906
iter 17052 (epoch 28), train_loss = 2.234, time/batch = 0.032
Read data: 8.702278137207031e-05
iter 17053 (epoch 28), train_loss = 2.175, time/batch = 0.033
Read data: 0.00015044212341308594
iter 17054 (epoch 28), train_loss = 1.900, time/batch = 0.021
Read data: 8.535385131835938e-05
iter 17055 (epoch 28), train_loss = 2.591, time/batch = 0.032
Read data: 8.344650268554688e-05
iter 17056 (epoch 28), train_loss = 2.934, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 17057 (epoch 28), train_loss = 2.816, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 17058 (epoch 28), train_loss = 2.267, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 17059 (epoch 28), train_loss = 2.393, time/batch = 0.028
Read data: 7.534027099609375e-05
iter 17060 (epoch 28), train_loss = 2.550, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 17061 (epoch 28), train_loss = 2.393, time/batch = 0.034
Read data: 0.000125885009765625
iter 17062 (epoch 28), train_loss = 2.456, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 17063 (epoch 28), train_loss = 2.645, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 17064 (epoch 28), train_loss = 2.052, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 17065 (epoch 28), train_loss = 2.621, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 17066 (epoch 28), train_loss = 2.761, time/batch = 0.034
Read data: 0.0001342296600341797
iter 17067 (epoch 28), train_loss = 2.625, time/batch = 0.036
Read data: 0.00012183189392089844
iter 17068 (epoch 28), train_loss = 2.406, time/batch = 0.031
Read data: 8.654594421386719e-05
iter 17069 (epoch 28), train_loss = 2.518, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 17070 (epoch 28), train_loss = 2.772, time/batch = 0.029
Read data: 0.00016999244689941406
iter 17071 (epoch 28), train_loss = 2.084, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 17072 (epoch 28), train_loss = 2.624, time/batch = 0.021
Read data: 7.700920104980469e-05
iter 17073 (epoch 28), train_loss = 2.763, time/batch = 0.025
Read data: 0.00014090538024902344
iter 17074 (epoch 28), train_loss = 2.083, time/batch = 0.025
Read data: 0.00022792816162109375
iter 17075 (epoch 28), train_loss = 2.498, time/batch = 0.031
Read data: 0.00015211105346679688
iter 17076 (epoch 28), train_loss = 2.505, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 17077 (epoch 28), train_loss = 2.807, time/batch = 0.028
Read data: 7.62939453125e-05
iter 17078 (epoch 28), train_loss = 2.512, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 17079 (epoch 28), train_loss = 2.377, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 17080 (epoch 28), train_loss = 2.289, time/batch = 0.025
Read data: 0.00012969970703125
iter 17081 (epoch 28), train_loss = 2.390, time/batch = 0.029
Read data: 0.00012564659118652344
iter 17082 (epoch 28), train_loss = 2.518, time/batch = 0.027
Read data: 7.62939453125e-05
iter 17083 (epoch 28), train_loss = 2.575, time/batch = 0.027
Read data: 0.0002079010009765625
iter 17084 (epoch 28), train_loss = 2.533, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 17085 (epoch 28), train_loss = 2.190, time/batch = 0.026
Read data: 0.00017642974853515625
iter 17086 (epoch 28), train_loss = 2.475, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 17087 (epoch 28), train_loss = 2.243, time/batch = 0.025
Read data: 0.0001468658447265625
iter 17088 (epoch 28), train_loss = 2.676, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 17089 (epoch 28), train_loss = 2.285, time/batch = 0.026
Read data: 0.0001270771026611328
iter 17090 (epoch 28), train_loss = 2.375, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 17091 (epoch 28), train_loss = 2.695, time/batch = 0.032
Read data: 0.00012254714965820312
iter 17092 (epoch 28), train_loss = 2.312, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 17093 (epoch 28), train_loss = 2.671, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 17094 (epoch 28), train_loss = 2.024, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 17095 (epoch 28), train_loss = 2.715, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 17096 (epoch 28), train_loss = 2.423, time/batch = 0.026
Read data: 7.510185241699219e-05
iter 17097 (epoch 28), train_loss = 2.529, time/batch = 0.024
Read data: 0.00012826919555664062
iter 17098 (epoch 28), train_loss = 2.532, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 17099 (epoch 28), train_loss = 2.344, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 17100 (epoch 28), train_loss = 2.559, time/batch = 0.029
Read data: 0.0001544952392578125
iter 17101 (epoch 28), train_loss = 2.313, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 17102 (epoch 28), train_loss = 2.357, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 17103 (epoch 28), train_loss = 2.518, time/batch = 0.028
Read data: 0.00011706352233886719
iter 17104 (epoch 28), train_loss = 2.832, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 17105 (epoch 28), train_loss = 2.334, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 17106 (epoch 28), train_loss = 2.652, time/batch = 0.023
Read data: 7.62939453125e-05
iter 17107 (epoch 28), train_loss = 2.383, time/batch = 0.022
Read data: 0.00018835067749023438
iter 17108 (epoch 28), train_loss = 2.237, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 17109 (epoch 28), train_loss = 2.139, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 17110 (epoch 28), train_loss = 2.145, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 17111 (epoch 28), train_loss = 2.345, time/batch = 0.030
Read data: 0.00012040138244628906
iter 17112 (epoch 28), train_loss = 2.902, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 17113 (epoch 28), train_loss = 2.181, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 17114 (epoch 28), train_loss = 2.252, time/batch = 0.025
Read data: 0.00012755393981933594
iter 17115 (epoch 28), train_loss = 3.030, time/batch = 0.034
Read data: 0.00012350082397460938
iter 17116 (epoch 28), train_loss = 2.333, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 17117 (epoch 28), train_loss = 2.398, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 17118 (epoch 28), train_loss = 2.323, time/batch = 0.026
Read data: 7.700920104980469e-05
iter 17119 (epoch 28), train_loss = 2.350, time/batch = 0.029
Read data: 0.00011157989501953125
iter 17120 (epoch 28), train_loss = 2.367, time/batch = 0.026
Read data: 0.00011849403381347656
iter 17121 (epoch 28), train_loss = 2.151, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 17122 (epoch 28), train_loss = 2.068, time/batch = 0.023
Read data: 7.462501525878906e-05
iter 17123 (epoch 28), train_loss = 2.618, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 17124 (epoch 28), train_loss = 2.239, time/batch = 0.025
Read data: 0.0002758502960205078
iter 17125 (epoch 28), train_loss = 2.671, time/batch = 0.030
Read data: 0.0001251697540283203
iter 17126 (epoch 28), train_loss = 2.414, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 17127 (epoch 28), train_loss = 2.336, time/batch = 0.024
Read data: 0.00011897087097167969
iter 17128 (epoch 28), train_loss = 2.654, time/batch = 0.025
Read data: 0.00015401840209960938
iter 17129 (epoch 28), train_loss = 2.944, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 17130 (epoch 28), train_loss = 2.596, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 17131 (epoch 28), train_loss = 2.611, time/batch = 0.039
Read data: 8.535385131835938e-05
iter 17132 (epoch 28), train_loss = 2.455, time/batch = 0.026
Read data: 0.00013184547424316406
iter 17133 (epoch 28), train_loss = 2.558, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 17134 (epoch 28), train_loss = 2.265, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 17135 (epoch 28), train_loss = 2.279, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 17136 (epoch 28), train_loss = 2.148, time/batch = 0.022
Read data: 0.000148773193359375
iter 17137 (epoch 28), train_loss = 2.229, time/batch = 0.023
Read data: 8.702278137207031e-05
iter 17138 (epoch 28), train_loss = 2.535, time/batch = 0.025
Read data: 0.00014591217041015625
iter 17139 (epoch 28), train_loss = 2.591, time/batch = 0.033
Read data: 0.00011563301086425781
iter 17140 (epoch 28), train_loss = 2.500, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 17141 (epoch 28), train_loss = 2.368, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 17142 (epoch 28), train_loss = 2.549, time/batch = 0.025
Read data: 7.462501525878906e-05
iter 17143 (epoch 28), train_loss = 2.673, time/batch = 0.022
Read data: 0.00019550323486328125
iter 17144 (epoch 28), train_loss = 2.692, time/batch = 0.027
Read data: 0.0001316070556640625
iter 17145 (epoch 28), train_loss = 2.295, time/batch = 0.024
Read data: 0.00016736984252929688
iter 17146 (epoch 28), train_loss = 2.632, time/batch = 0.027
Read data: 0.0001609325408935547
iter 17147 (epoch 28), train_loss = 2.185, time/batch = 0.028
Read data: 0.00011801719665527344
iter 17148 (epoch 28), train_loss = 2.261, time/batch = 0.026
Read data: 0.0001537799835205078
iter 17149 (epoch 28), train_loss = 2.548, time/batch = 0.029
Read data: 0.00021004676818847656
iter 17150 (epoch 28), train_loss = 2.584, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 17151 (epoch 28), train_loss = 2.330, time/batch = 0.024
Read data: 0.0002009868621826172
iter 17152 (epoch 28), train_loss = 2.230, time/batch = 0.027
Read data: 0.0001499652862548828
iter 17153 (epoch 28), train_loss = 2.364, time/batch = 0.022
Read data: 0.00016021728515625
iter 17154 (epoch 28), train_loss = 2.628, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 17155 (epoch 28), train_loss = 2.681, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 17156 (epoch 28), train_loss = 2.672, time/batch = 0.029
Read data: 0.00012564659118652344
iter 17157 (epoch 28), train_loss = 2.390, time/batch = 0.038
Read data: 8.797645568847656e-05
iter 17158 (epoch 28), train_loss = 2.489, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 17159 (epoch 28), train_loss = 2.275, time/batch = 0.024
Read data: 0.00010704994201660156
iter 17160 (epoch 28), train_loss = 2.902, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 17161 (epoch 28), train_loss = 2.627, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 17162 (epoch 28), train_loss = 2.682, time/batch = 0.024
Read data: 0.00012922286987304688
iter 17163 (epoch 28), train_loss = 2.800, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 17164 (epoch 28), train_loss = 2.199, time/batch = 0.028
Read data: 9.512901306152344e-05
iter 17165 (epoch 28), train_loss = 1.836, time/batch = 0.022
Read data: 0.00016689300537109375
iter 17166 (epoch 28), train_loss = 2.176, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 17167 (epoch 28), train_loss = 2.513, time/batch = 0.031
Read data: 0.00014591217041015625
iter 17168 (epoch 28), train_loss = 2.450, time/batch = 0.034
Read data: 0.00016427040100097656
iter 17169 (epoch 28), train_loss = 2.342, time/batch = 0.031
Read data: 0.00014591217041015625
iter 17170 (epoch 28), train_loss = 2.494, time/batch = 0.021
Read data: 0.00010442733764648438
iter 17171 (epoch 28), train_loss = 2.259, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 17172 (epoch 28), train_loss = 2.698, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 17173 (epoch 28), train_loss = 2.464, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 17174 (epoch 28), train_loss = 2.420, time/batch = 0.026
Read data: 0.00021004676818847656
iter 17175 (epoch 28), train_loss = 2.676, time/batch = 0.025
Read data: 0.0001480579376220703
iter 17176 (epoch 28), train_loss = 2.472, time/batch = 0.022
Read data: 0.00018310546875
iter 17177 (epoch 28), train_loss = 2.577, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 17178 (epoch 28), train_loss = 2.636, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 17179 (epoch 28), train_loss = 2.169, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 17180 (epoch 28), train_loss = 2.294, time/batch = 0.025
Read data: 0.00014352798461914062
iter 17181 (epoch 28), train_loss = 1.997, time/batch = 0.021
Read data: 0.0001430511474609375
iter 17182 (epoch 28), train_loss = 2.358, time/batch = 0.027
Read data: 0.00016808509826660156
iter 17183 (epoch 28), train_loss = 2.748, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 17184 (epoch 28), train_loss = 2.497, time/batch = 0.032
Read data: 0.0001709461212158203
iter 17185 (epoch 28), train_loss = 2.481, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 17186 (epoch 28), train_loss = 2.729, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 17187 (epoch 28), train_loss = 2.273, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 17188 (epoch 28), train_loss = 2.771, time/batch = 0.023
Read data: 0.00014328956604003906
iter 17189 (epoch 28), train_loss = 2.605, time/batch = 0.024
Read data: 8.797645568847656e-05
iter 17190 (epoch 28), train_loss = 2.173, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 17191 (epoch 28), train_loss = 2.647, time/batch = 0.029
Read data: 0.00015044212341308594
iter 17192 (epoch 28), train_loss = 2.400, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 17193 (epoch 28), train_loss = 2.777, time/batch = 0.027
Read data: 0.00015807151794433594
iter 17194 (epoch 28), train_loss = 2.501, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 17195 (epoch 28), train_loss = 2.900, time/batch = 0.026
Read data: 0.00011181831359863281
iter 17196 (epoch 28), train_loss = 2.563, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 17197 (epoch 28), train_loss = 2.297, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 17198 (epoch 28), train_loss = 2.506, time/batch = 0.038
Read data: 8.368492126464844e-05
iter 17199 (epoch 28), train_loss = 2.410, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 17200 (epoch 28), train_loss = 2.589, time/batch = 0.025
Read data: 0.00011610984802246094
iter 17201 (epoch 28), train_loss = 2.330, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 17202 (epoch 28), train_loss = 2.576, time/batch = 0.023
Read data: 0.00017333030700683594
iter 17203 (epoch 28), train_loss = 2.476, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 17204 (epoch 28), train_loss = 2.014, time/batch = 0.027
Read data: 0.00014090538024902344
iter 17205 (epoch 28), train_loss = 2.506, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 17206 (epoch 28), train_loss = 2.462, time/batch = 0.022
Read data: 9.369850158691406e-05
iter 17207 (epoch 28), train_loss = 2.695, time/batch = 0.026
Read data: 9.584426879882812e-05
iter 17208 (epoch 28), train_loss = 2.551, time/batch = 0.023
Read data: 0.00016188621520996094
iter 17209 (epoch 28), train_loss = 2.630, time/batch = 0.036
Read data: 7.843971252441406e-05
iter 17210 (epoch 28), train_loss = 2.511, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 17211 (epoch 28), train_loss = 2.361, time/batch = 0.027
Read data: 0.0001430511474609375
iter 17212 (epoch 28), train_loss = 2.273, time/batch = 0.026
Read data: 0.000164031982421875
iter 17213 (epoch 28), train_loss = 2.442, time/batch = 0.022
Read data: 8.749961853027344e-05
iter 17214 (epoch 28), train_loss = 1.887, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 17215 (epoch 28), train_loss = 2.585, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 17216 (epoch 28), train_loss = 2.499, time/batch = 0.033
Read data: 0.00020313262939453125
iter 17217 (epoch 28), train_loss = 2.428, time/batch = 0.032
Read data: 9.012222290039062e-05
iter 17218 (epoch 28), train_loss = 2.433, time/batch = 0.034
Read data: 9.5367431640625e-05
iter 17219 (epoch 28), train_loss = 2.272, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 17220 (epoch 28), train_loss = 2.743, time/batch = 0.030
Read data: 8.368492126464844e-05
iter 17221 (epoch 28), train_loss = 2.739, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 17222 (epoch 28), train_loss = 2.294, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 17223 (epoch 28), train_loss = 2.436, time/batch = 0.028
Read data: 0.0001552104949951172
iter 17224 (epoch 28), train_loss = 2.504, time/batch = 0.023
Read data: 0.00025844573974609375
iter 17225 (epoch 28), train_loss = 2.284, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 17226 (epoch 28), train_loss = 2.628, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 17227 (epoch 28), train_loss = 2.725, time/batch = 0.033
Read data: 0.00014662742614746094
iter 17228 (epoch 28), train_loss = 2.771, time/batch = 0.023
Read data: 0.00015616416931152344
iter 17229 (epoch 28), train_loss = 2.543, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 17230 (epoch 28), train_loss = 2.375, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 17231 (epoch 28), train_loss = 2.481, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 17232 (epoch 28), train_loss = 2.643, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 17233 (epoch 28), train_loss = 2.572, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 17234 (epoch 28), train_loss = 2.627, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 17235 (epoch 28), train_loss = 2.363, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 17236 (epoch 28), train_loss = 2.647, time/batch = 0.024
Read data: 0.00017213821411132812
iter 17237 (epoch 28), train_loss = 1.817, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 17238 (epoch 28), train_loss = 2.882, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 17239 (epoch 28), train_loss = 2.718, time/batch = 0.030
Read data: 0.00014519691467285156
iter 17240 (epoch 28), train_loss = 2.329, time/batch = 0.030
Read data: 7.82012939453125e-05
iter 17241 (epoch 28), train_loss = 2.511, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 17242 (epoch 28), train_loss = 2.511, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 17243 (epoch 28), train_loss = 2.605, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 17244 (epoch 28), train_loss = 2.193, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 17245 (epoch 28), train_loss = 2.434, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 17246 (epoch 28), train_loss = 2.192, time/batch = 0.031
Read data: 7.62939453125e-05
iter 17247 (epoch 28), train_loss = 2.385, time/batch = 0.021
Read data: 9.584426879882812e-05
iter 17248 (epoch 28), train_loss = 2.681, time/batch = 0.023
Read data: 0.001821279525756836
iter 17249 (epoch 28), train_loss = 2.592, time/batch = 0.022
Read data: 0.0002646446228027344
iter 17250 (epoch 28), train_loss = 2.182, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 17251 (epoch 28), train_loss = 2.203, time/batch = 0.034
Read data: 0.0001513957977294922
iter 17252 (epoch 28), train_loss = 2.349, time/batch = 0.023
Read data: 0.0001347064971923828
iter 17253 (epoch 28), train_loss = 2.427, time/batch = 0.023
Read data: 9.822845458984375e-05
iter 17254 (epoch 28), train_loss = 2.758, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 17255 (epoch 28), train_loss = 2.612, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 17256 (epoch 28), train_loss = 2.188, time/batch = 0.023
Read data: 0.0001819133758544922
iter 17257 (epoch 28), train_loss = 2.256, time/batch = 0.022
Read data: 0.00014328956604003906
iter 17258 (epoch 28), train_loss = 3.020, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 17259 (epoch 28), train_loss = 2.902, time/batch = 0.032
Read data: 0.00014662742614746094
iter 17260 (epoch 28), train_loss = 2.501, time/batch = 0.023
Read data: 0.00019741058349609375
iter 17261 (epoch 28), train_loss = 2.551, time/batch = 0.025
Read data: 0.0001590251922607422
iter 17262 (epoch 28), train_loss = 2.376, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 17263 (epoch 28), train_loss = 2.664, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 17264 (epoch 28), train_loss = 2.553, time/batch = 0.025
Read data: 0.00015163421630859375
iter 17265 (epoch 28), train_loss = 2.471, time/batch = 0.026
Read data: 0.0001232624053955078
iter 17266 (epoch 28), train_loss = 2.198, time/batch = 0.028
Read data: 7.700920104980469e-05
iter 17267 (epoch 28), train_loss = 2.565, time/batch = 0.026
Read data: 0.00011301040649414062
iter 17268 (epoch 28), train_loss = 2.823, time/batch = 0.024
Read data: 0.0001220703125
iter 17269 (epoch 28), train_loss = 2.947, time/batch = 0.025
Read data: 0.00014519691467285156
iter 17270 (epoch 28), train_loss = 2.316, time/batch = 0.026
Read data: 0.00015473365783691406
iter 17271 (epoch 28), train_loss = 2.505, time/batch = 0.025
Read data: 9.226799011230469e-05
iter 17272 (epoch 28), train_loss = 2.438, time/batch = 0.033
Read data: 0.0001289844512939453
iter 17273 (epoch 28), train_loss = 2.499, time/batch = 0.023
Read data: 0.0001270771026611328
iter 17274 (epoch 28), train_loss = 2.654, time/batch = 0.032
Read data: 0.000133514404296875
iter 17275 (epoch 28), train_loss = 2.498, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 17276 (epoch 28), train_loss = 2.473, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 17277 (epoch 28), train_loss = 2.607, time/batch = 0.023
Read data: 0.00012755393981933594
iter 17278 (epoch 28), train_loss = 2.394, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 17279 (epoch 28), train_loss = 2.377, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 17280 (epoch 28), train_loss = 1.992, time/batch = 0.028
Read data: 0.00018072128295898438
iter 17281 (epoch 28), train_loss = 2.290, time/batch = 0.033
Read data: 8.130073547363281e-05
iter 17282 (epoch 28), train_loss = 2.118, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 17283 (epoch 28), train_loss = 2.441, time/batch = 0.021
Read data: 9.655952453613281e-05
iter 17284 (epoch 28), train_loss = 2.494, time/batch = 0.026
Read data: 9.846687316894531e-05
iter 17285 (epoch 28), train_loss = 2.416, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 17286 (epoch 28), train_loss = 2.070, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 17287 (epoch 28), train_loss = 2.267, time/batch = 0.029
Read data: 0.00011467933654785156
iter 17288 (epoch 28), train_loss = 2.711, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 17289 (epoch 28), train_loss = 2.497, time/batch = 0.026
Read data: 0.00015664100646972656
iter 17290 (epoch 28), train_loss = 2.548, time/batch = 0.025
Read data: 0.00010514259338378906
iter 17291 (epoch 28), train_loss = 2.612, time/batch = 0.032
Read data: 0.00011849403381347656
iter 17292 (epoch 28), train_loss = 2.593, time/batch = 0.026
Read data: 0.00012803077697753906
iter 17293 (epoch 28), train_loss = 2.497, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 17294 (epoch 28), train_loss = 2.223, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 17295 (epoch 28), train_loss = 2.172, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 17296 (epoch 28), train_loss = 2.524, time/batch = 0.026
Read data: 0.00014472007751464844
iter 17297 (epoch 28), train_loss = 2.588, time/batch = 0.032
Read data: 7.796287536621094e-05
iter 17298 (epoch 28), train_loss = 2.292, time/batch = 0.023
Read data: 0.00010371208190917969
iter 17299 (epoch 28), train_loss = 2.565, time/batch = 0.025
Read data: 0.0001957416534423828
iter 17300 (epoch 28), train_loss = 2.060, time/batch = 0.021
Read data: 0.00017499923706054688
iter 17301 (epoch 28), train_loss = 2.586, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 17302 (epoch 28), train_loss = 3.076, time/batch = 0.023
Read data: 8.678436279296875e-05
iter 17303 (epoch 28), train_loss = 2.313, time/batch = 0.026
Read data: 0.000110626220703125
iter 17304 (epoch 28), train_loss = 2.437, time/batch = 0.026
Read data: 8.58306884765625e-05
iter 17305 (epoch 28), train_loss = 2.401, time/batch = 0.024
Read data: 0.0001556873321533203
iter 17306 (epoch 28), train_loss = 2.238, time/batch = 0.027
Read data: 7.581710815429688e-05
iter 17307 (epoch 28), train_loss = 2.351, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 17308 (epoch 28), train_loss = 2.203, time/batch = 0.036
Read data: 0.00016355514526367188
iter 17309 (epoch 28), train_loss = 2.640, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 17310 (epoch 28), train_loss = 2.747, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 17311 (epoch 28), train_loss = 2.532, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 17312 (epoch 28), train_loss = 2.177, time/batch = 0.025
Read data: 0.00012493133544921875
iter 17313 (epoch 28), train_loss = 2.329, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 17314 (epoch 28), train_loss = 2.471, time/batch = 0.031
Read data: 0.00013589859008789062
iter 17315 (epoch 28), train_loss = 2.236, time/batch = 0.020
Read data: 9.179115295410156e-05
iter 17316 (epoch 28), train_loss = 2.611, time/batch = 0.032
Read data: 0.00012803077697753906
iter 17317 (epoch 28), train_loss = 2.295, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 17318 (epoch 28), train_loss = 2.533, time/batch = 0.030
Read data: 0.00012946128845214844
iter 17319 (epoch 28), train_loss = 2.417, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 17320 (epoch 28), train_loss = 2.375, time/batch = 0.025
Read data: 0.0001354217529296875
iter 17321 (epoch 28), train_loss = 2.655, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 17322 (epoch 28), train_loss = 2.589, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 17323 (epoch 28), train_loss = 2.859, time/batch = 0.026
Read data: 0.0001277923583984375
iter 17324 (epoch 28), train_loss = 2.625, time/batch = 0.022
Read data: 0.000209808349609375
iter 17325 (epoch 28), train_loss = 2.546, time/batch = 0.020
Read data: 8.988380432128906e-05
iter 17326 (epoch 28), train_loss = 2.106, time/batch = 0.027
Read data: 0.0001323223114013672
iter 17327 (epoch 28), train_loss = 2.164, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 17328 (epoch 28), train_loss = 2.173, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 17329 (epoch 28), train_loss = 2.638, time/batch = 0.025
Read data: 0.00010204315185546875
iter 17330 (epoch 28), train_loss = 2.347, time/batch = 0.028
Read data: 9.822845458984375e-05
iter 17331 (epoch 28), train_loss = 2.632, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 17332 (epoch 28), train_loss = 2.114, time/batch = 0.021
Read data: 0.0001728534698486328
iter 17333 (epoch 28), train_loss = 2.591, time/batch = 0.032
Read data: 0.00012803077697753906
iter 17334 (epoch 28), train_loss = 2.620, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 17335 (epoch 28), train_loss = 2.544, time/batch = 0.025
Read data: 0.0001513957977294922
iter 17336 (epoch 28), train_loss = 2.379, time/batch = 0.024
Read data: 0.0001742839813232422
iter 17337 (epoch 28), train_loss = 2.808, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 17338 (epoch 28), train_loss = 2.529, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 17339 (epoch 28), train_loss = 2.332, time/batch = 0.026
Read data: 0.00015687942504882812
iter 17340 (epoch 28), train_loss = 2.450, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 17341 (epoch 28), train_loss = 1.954, time/batch = 0.021
Read data: 0.00016427040100097656
iter 17342 (epoch 28), train_loss = 2.641, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 17343 (epoch 28), train_loss = 2.743, time/batch = 0.029
Read data: 0.00010895729064941406
iter 17344 (epoch 28), train_loss = 2.470, time/batch = 0.029
Read data: 0.0001392364501953125
iter 17345 (epoch 28), train_loss = 2.079, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 17346 (epoch 28), train_loss = 2.464, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 17347 (epoch 28), train_loss = 2.385, time/batch = 0.025
Read data: 8.392333984375e-05
iter 17348 (epoch 28), train_loss = 2.273, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 17349 (epoch 28), train_loss = 2.089, time/batch = 0.023
Read data: 0.00024962425231933594
iter 17350 (epoch 28), train_loss = 2.638, time/batch = 0.024
Read data: 9.560585021972656e-05
iter 17351 (epoch 28), train_loss = 2.828, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 17352 (epoch 28), train_loss = 2.768, time/batch = 0.032
Read data: 0.00013566017150878906
iter 17353 (epoch 28), train_loss = 2.559, time/batch = 0.028
Read data: 0.0001323223114013672
iter 17354 (epoch 28), train_loss = 2.171, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 17355 (epoch 28), train_loss = 2.207, time/batch = 0.024
Read data: 0.00011229515075683594
iter 17356 (epoch 28), train_loss = 2.433, time/batch = 0.021
Read data: 0.00013136863708496094
iter 17357 (epoch 28), train_loss = 2.495, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 17358 (epoch 28), train_loss = 2.492, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 17359 (epoch 28), train_loss = 2.529, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 17360 (epoch 28), train_loss = 2.500, time/batch = 0.028
Read data: 0.00015735626220703125
iter 17361 (epoch 28), train_loss = 2.577, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 17362 (epoch 28), train_loss = 2.296, time/batch = 0.036
Read data: 0.000133514404296875
iter 17363 (epoch 28), train_loss = 2.896, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 17364 (epoch 28), train_loss = 2.268, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 17365 (epoch 28), train_loss = 2.293, time/batch = 0.021
Read data: 7.915496826171875e-05
iter 17366 (epoch 28), train_loss = 2.257, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 17367 (epoch 28), train_loss = 2.350, time/batch = 0.022
Read data: 8.893013000488281e-05
iter 17368 (epoch 28), train_loss = 2.165, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 17369 (epoch 28), train_loss = 2.365, time/batch = 0.027
Read data: 0.00011873245239257812
iter 17370 (epoch 28), train_loss = 2.710, time/batch = 0.021
Read data: 9.72747802734375e-05
iter 17371 (epoch 28), train_loss = 2.290, time/batch = 0.025
Read data: 0.0001163482666015625
iter 17372 (epoch 28), train_loss = 2.891, time/batch = 0.031
Read data: 0.00012993812561035156
iter 17373 (epoch 28), train_loss = 2.418, time/batch = 0.025
Read data: 9.799003601074219e-05
iter 17374 (epoch 28), train_loss = 2.852, time/batch = 0.023
Read data: 0.0002548694610595703
iter 17375 (epoch 28), train_loss = 2.154, time/batch = 0.025
Read data: 0.00012636184692382812
iter 17376 (epoch 28), train_loss = 2.731, time/batch = 0.030
Read data: 0.00012445449829101562
iter 17377 (epoch 28), train_loss = 2.509, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 17378 (epoch 28), train_loss = 2.313, time/batch = 0.027
Read data: 0.0001285076141357422
iter 17379 (epoch 28), train_loss = 2.520, time/batch = 0.027
Read data: 0.00012183189392089844
iter 17380 (epoch 28), train_loss = 2.417, time/batch = 0.032
Read data: 8.678436279296875e-05
iter 17381 (epoch 28), train_loss = 2.271, time/batch = 0.033
Read data: 8.368492126464844e-05
iter 17382 (epoch 28), train_loss = 2.521, time/batch = 0.029
Read data: 0.0001239776611328125
iter 17383 (epoch 28), train_loss = 2.482, time/batch = 0.042
Read data: 0.0001361370086669922
iter 17384 (epoch 28), train_loss = 2.553, time/batch = 0.020
Read data: 8.869171142578125e-05
iter 17385 (epoch 28), train_loss = 2.496, time/batch = 0.032
Read data: 8.749961853027344e-05
iter 17386 (epoch 28), train_loss = 2.163, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 17387 (epoch 28), train_loss = 2.527, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 17388 (epoch 28), train_loss = 2.612, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 17389 (epoch 28), train_loss = 2.619, time/batch = 0.021
Read data: 0.0001308917999267578
iter 17390 (epoch 28), train_loss = 2.479, time/batch = 0.021
Read data: 8.678436279296875e-05
iter 17391 (epoch 28), train_loss = 2.150, time/batch = 0.027
Read data: 0.001603841781616211
iter 17392 (epoch 28), train_loss = 2.572, time/batch = 0.026
Read data: 0.0001685619354248047
iter 17393 (epoch 28), train_loss = 1.831, time/batch = 0.027
Read data: 0.00010013580322265625
iter 17394 (epoch 28), train_loss = 2.340, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 17395 (epoch 28), train_loss = 2.268, time/batch = 0.025
Read data: 0.0001423358917236328
iter 17396 (epoch 28), train_loss = 2.431, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 17397 (epoch 28), train_loss = 2.080, time/batch = 0.029
Read data: 7.557868957519531e-05
iter 17398 (epoch 28), train_loss = 2.308, time/batch = 0.021
Read data: 0.00013303756713867188
iter 17399 (epoch 28), train_loss = 2.580, time/batch = 0.030
Read data: 0.00010657310485839844
iter 17400 (epoch 28), train_loss = 2.200, time/batch = 0.021
Read data: 7.82012939453125e-05
iter 17401 (epoch 29), train_loss = 2.455, time/batch = 0.021
Read data: 0.0001761913299560547
iter 17402 (epoch 29), train_loss = 2.496, time/batch = 0.034
Read data: 7.748603820800781e-05
iter 17403 (epoch 29), train_loss = 2.432, time/batch = 0.023
Read data: 0.00011563301086425781
iter 17404 (epoch 29), train_loss = 2.396, time/batch = 0.031
Read data: 7.939338684082031e-05
iter 17405 (epoch 29), train_loss = 2.562, time/batch = 0.025
Read data: 7.62939453125e-05
iter 17406 (epoch 29), train_loss = 2.357, time/batch = 0.027
Read data: 0.0001513957977294922
iter 17407 (epoch 29), train_loss = 2.578, time/batch = 0.025
Read data: 7.534027099609375e-05
iter 17408 (epoch 29), train_loss = 2.434, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 17409 (epoch 29), train_loss = 2.495, time/batch = 0.027
Read data: 0.00013685226440429688
iter 17410 (epoch 29), train_loss = 2.326, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 17411 (epoch 29), train_loss = 2.518, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 17412 (epoch 29), train_loss = 2.947, time/batch = 0.030
Read data: 0.00016641616821289062
iter 17413 (epoch 29), train_loss = 2.657, time/batch = 0.024
Read data: 7.462501525878906e-05
iter 17414 (epoch 29), train_loss = 2.369, time/batch = 0.023
Read data: 0.00012183189392089844
iter 17415 (epoch 29), train_loss = 2.447, time/batch = 0.023
Read data: 0.00011730194091796875
iter 17416 (epoch 29), train_loss = 2.364, time/batch = 0.028
Read data: 9.1552734375e-05
iter 17417 (epoch 29), train_loss = 2.011, time/batch = 0.027
Read data: 0.00013399124145507812
iter 17418 (epoch 29), train_loss = 2.586, time/batch = 0.031
Read data: 7.748603820800781e-05
iter 17419 (epoch 29), train_loss = 2.393, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 17420 (epoch 29), train_loss = 2.592, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 17421 (epoch 29), train_loss = 2.797, time/batch = 0.029
Read data: 0.00013828277587890625
iter 17422 (epoch 29), train_loss = 2.547, time/batch = 0.034
Read data: 8.416175842285156e-05
iter 17423 (epoch 29), train_loss = 2.181, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 17424 (epoch 29), train_loss = 2.327, time/batch = 0.026
Read data: 0.0002646446228027344
iter 17425 (epoch 29), train_loss = 2.243, time/batch = 0.025
Read data: 0.00012755393981933594
iter 17426 (epoch 29), train_loss = 2.381, time/batch = 0.034
Read data: 0.0001304149627685547
iter 17427 (epoch 29), train_loss = 2.533, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 17428 (epoch 29), train_loss = 2.884, time/batch = 0.026
Read data: 0.00011229515075683594
iter 17429 (epoch 29), train_loss = 2.096, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 17430 (epoch 29), train_loss = 2.458, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 17431 (epoch 29), train_loss = 2.641, time/batch = 0.027
Read data: 9.560585021972656e-05
iter 17432 (epoch 29), train_loss = 2.367, time/batch = 0.028
Read data: 8.678436279296875e-05
iter 17433 (epoch 29), train_loss = 2.311, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 17434 (epoch 29), train_loss = 2.377, time/batch = 0.023
Read data: 0.0001232624053955078
iter 17435 (epoch 29), train_loss = 2.278, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 17436 (epoch 29), train_loss = 2.082, time/batch = 0.025
Read data: 0.00012373924255371094
iter 17437 (epoch 29), train_loss = 2.295, time/batch = 0.027
Read data: 0.00011610984802246094
iter 17438 (epoch 29), train_loss = 2.124, time/batch = 0.032
Read data: 0.00013113021850585938
iter 17439 (epoch 29), train_loss = 2.476, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 17440 (epoch 29), train_loss = 2.173, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 17441 (epoch 29), train_loss = 3.040, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 17442 (epoch 29), train_loss = 2.662, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 17443 (epoch 29), train_loss = 2.212, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 17444 (epoch 29), train_loss = 2.540, time/batch = 0.022
Read data: 9.1552734375e-05
iter 17445 (epoch 29), train_loss = 2.255, time/batch = 0.023
Read data: 0.00011563301086425781
iter 17446 (epoch 29), train_loss = 2.206, time/batch = 0.035
Read data: 7.82012939453125e-05
iter 17447 (epoch 29), train_loss = 2.280, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 17448 (epoch 29), train_loss = 2.318, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 17449 (epoch 29), train_loss = 2.641, time/batch = 0.025
Read data: 0.00026869773864746094
iter 17450 (epoch 29), train_loss = 2.197, time/batch = 0.033
Read data: 0.00015974044799804688
iter 17451 (epoch 29), train_loss = 2.174, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 17452 (epoch 29), train_loss = 2.124, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 17453 (epoch 29), train_loss = 2.012, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 17454 (epoch 29), train_loss = 2.802, time/batch = 0.021
Read data: 0.000125885009765625
iter 17455 (epoch 29), train_loss = 2.603, time/batch = 0.023
Read data: 0.00010466575622558594
iter 17456 (epoch 29), train_loss = 2.380, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 17457 (epoch 29), train_loss = 2.679, time/batch = 0.028
Read data: 0.00012111663818359375
iter 17458 (epoch 29), train_loss = 2.227, time/batch = 0.026
Read data: 7.43865966796875e-05
iter 17459 (epoch 29), train_loss = 2.342, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 17460 (epoch 29), train_loss = 2.422, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 17461 (epoch 29), train_loss = 2.617, time/batch = 0.025
Read data: 0.00014019012451171875
iter 17462 (epoch 29), train_loss = 2.362, time/batch = 0.022
Read data: 0.00019478797912597656
iter 17463 (epoch 29), train_loss = 2.258, time/batch = 0.025
Read data: 0.00011992454528808594
iter 17464 (epoch 29), train_loss = 2.356, time/batch = 0.038
Read data: 8.153915405273438e-05
iter 17465 (epoch 29), train_loss = 2.200, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 17466 (epoch 29), train_loss = 2.625, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 17467 (epoch 29), train_loss = 2.479, time/batch = 0.025
Read data: 8.392333984375e-05
iter 17468 (epoch 29), train_loss = 2.504, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 17469 (epoch 29), train_loss = 2.541, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 17470 (epoch 29), train_loss = 2.650, time/batch = 0.021
Read data: 9.179115295410156e-05
iter 17471 (epoch 29), train_loss = 2.528, time/batch = 0.033
Read data: 7.462501525878906e-05
iter 17472 (epoch 29), train_loss = 2.468, time/batch = 0.021
Read data: 9.822845458984375e-05
iter 17473 (epoch 29), train_loss = 2.334, time/batch = 0.025
Read data: 0.00011515617370605469
iter 17474 (epoch 29), train_loss = 2.552, time/batch = 0.027
Read data: 0.0002071857452392578
iter 17475 (epoch 29), train_loss = 2.630, time/batch = 0.025
Read data: 0.0001125335693359375
iter 17476 (epoch 29), train_loss = 2.545, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 17477 (epoch 29), train_loss = 2.333, time/batch = 0.024
Read data: 0.00011205673217773438
iter 17478 (epoch 29), train_loss = 2.489, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 17479 (epoch 29), train_loss = 2.165, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 17480 (epoch 29), train_loss = 2.284, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 17481 (epoch 29), train_loss = 2.347, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 17482 (epoch 29), train_loss = 2.560, time/batch = 0.031
Read data: 0.0001380443572998047
iter 17483 (epoch 29), train_loss = 2.237, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 17484 (epoch 29), train_loss = 2.458, time/batch = 0.027
Read data: 0.00011205673217773438
iter 17485 (epoch 29), train_loss = 2.015, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 17486 (epoch 29), train_loss = 2.529, time/batch = 0.030
Read data: 0.00012373924255371094
iter 17487 (epoch 29), train_loss = 2.315, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 17488 (epoch 29), train_loss = 2.255, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 17489 (epoch 29), train_loss = 2.644, time/batch = 0.027
Read data: 0.00011706352233886719
iter 17490 (epoch 29), train_loss = 2.498, time/batch = 0.026
Read data: 7.677078247070312e-05
iter 17491 (epoch 29), train_loss = 2.223, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 17492 (epoch 29), train_loss = 2.698, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 17493 (epoch 29), train_loss = 2.499, time/batch = 0.023
Read data: 0.00010991096496582031
iter 17494 (epoch 29), train_loss = 2.282, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 17495 (epoch 29), train_loss = 2.358, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 17496 (epoch 29), train_loss = 2.312, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 17497 (epoch 29), train_loss = 2.693, time/batch = 0.031
Read data: 0.00011563301086425781
iter 17498 (epoch 29), train_loss = 2.694, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 17499 (epoch 29), train_loss = 2.556, time/batch = 0.032
Read data: 0.00017571449279785156
iter 17500 (epoch 29), train_loss = 2.578, time/batch = 0.038
Read data: 0.00011038780212402344
iter 17501 (epoch 29), train_loss = 2.208, time/batch = 0.028
Read data: 9.560585021972656e-05
iter 17502 (epoch 29), train_loss = 1.927, time/batch = 0.022
Read data: 0.00017571449279785156
iter 17503 (epoch 29), train_loss = 2.059, time/batch = 0.033
Read data: 8.296966552734375e-05
iter 17504 (epoch 29), train_loss = 2.274, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 17505 (epoch 29), train_loss = 2.190, time/batch = 0.025
Read data: 0.00011539459228515625
iter 17506 (epoch 29), train_loss = 2.336, time/batch = 0.031
Read data: 8.106231689453125e-05
iter 17507 (epoch 29), train_loss = 2.458, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 17508 (epoch 29), train_loss = 2.351, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 17509 (epoch 29), train_loss = 2.669, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17510 (epoch 29), train_loss = 2.294, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 17511 (epoch 29), train_loss = 2.896, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 17512 (epoch 29), train_loss = 2.285, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 17513 (epoch 29), train_loss = 2.134, time/batch = 0.026
Read data: 0.000110626220703125
iter 17514 (epoch 29), train_loss = 2.514, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 17515 (epoch 29), train_loss = 2.382, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 17516 (epoch 29), train_loss = 2.371, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 17517 (epoch 29), train_loss = 2.665, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 17518 (epoch 29), train_loss = 2.569, time/batch = 0.028
Read data: 0.00012683868408203125
iter 17519 (epoch 29), train_loss = 2.801, time/batch = 0.027
Read data: 7.653236389160156e-05
iter 17520 (epoch 29), train_loss = 2.477, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 17521 (epoch 29), train_loss = 2.255, time/batch = 0.036
Read data: 8.463859558105469e-05
iter 17522 (epoch 29), train_loss = 2.633, time/batch = 0.032
Read data: 0.0001499652862548828
iter 17523 (epoch 29), train_loss = 2.368, time/batch = 0.030
Read data: 9.179115295410156e-05
iter 17524 (epoch 29), train_loss = 2.350, time/batch = 0.024
Read data: 0.00021791458129882812
iter 17525 (epoch 29), train_loss = 2.623, time/batch = 0.028
Read data: 0.00014781951904296875
iter 17526 (epoch 29), train_loss = 2.717, time/batch = 0.022
Read data: 7.724761962890625e-05
iter 17527 (epoch 29), train_loss = 2.326, time/batch = 0.025
Read data: 0.00011348724365234375
iter 17528 (epoch 29), train_loss = 2.603, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 17529 (epoch 29), train_loss = 2.321, time/batch = 0.025
Read data: 0.0001163482666015625
iter 17530 (epoch 29), train_loss = 2.491, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 17531 (epoch 29), train_loss = 2.817, time/batch = 0.026
Read data: 7.724761962890625e-05
iter 17532 (epoch 29), train_loss = 2.377, time/batch = 0.024
Read data: 0.00015163421630859375
iter 17533 (epoch 29), train_loss = 2.275, time/batch = 0.027
Read data: 0.00011754035949707031
iter 17534 (epoch 29), train_loss = 2.616, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 17535 (epoch 29), train_loss = 2.523, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 17536 (epoch 29), train_loss = 2.660, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 17537 (epoch 29), train_loss = 2.533, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 17538 (epoch 29), train_loss = 2.267, time/batch = 0.023
Read data: 0.00012874603271484375
iter 17539 (epoch 29), train_loss = 2.779, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 17540 (epoch 29), train_loss = 2.817, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 17541 (epoch 29), train_loss = 2.310, time/batch = 0.026
Read data: 0.00011134147644042969
iter 17542 (epoch 29), train_loss = 2.428, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 17543 (epoch 29), train_loss = 2.332, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 17544 (epoch 29), train_loss = 2.475, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 17545 (epoch 29), train_loss = 2.548, time/batch = 0.035
Read data: 0.0001227855682373047
iter 17546 (epoch 29), train_loss = 2.380, time/batch = 0.027
Read data: 0.00012969970703125
iter 17547 (epoch 29), train_loss = 2.664, time/batch = 0.026
Read data: 0.0001385211944580078
iter 17548 (epoch 29), train_loss = 2.748, time/batch = 0.040
Read data: 0.00012111663818359375
iter 17549 (epoch 29), train_loss = 2.406, time/batch = 0.028
Read data: 0.00025844573974609375
iter 17550 (epoch 29), train_loss = 2.575, time/batch = 0.038
Read data: 7.915496826171875e-05
iter 17551 (epoch 29), train_loss = 2.668, time/batch = 0.022
Read data: 0.00011706352233886719
iter 17552 (epoch 29), train_loss = 2.440, time/batch = 0.024
Read data: 0.00014019012451171875
iter 17553 (epoch 29), train_loss = 2.480, time/batch = 0.026
Read data: 0.00012969970703125
iter 17554 (epoch 29), train_loss = 2.366, time/batch = 0.022
Read data: 0.00014448165893554688
iter 17555 (epoch 29), train_loss = 2.331, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 17556 (epoch 29), train_loss = 2.216, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 17557 (epoch 29), train_loss = 2.443, time/batch = 0.023
Read data: 0.00010609626770019531
iter 17558 (epoch 29), train_loss = 2.435, time/batch = 0.022
Read data: 0.000171661376953125
iter 17559 (epoch 29), train_loss = 2.377, time/batch = 0.023
Read data: 0.00011229515075683594
iter 17560 (epoch 29), train_loss = 2.196, time/batch = 0.031
Read data: 9.369850158691406e-05
iter 17561 (epoch 29), train_loss = 2.341, time/batch = 0.027
Read data: 0.00011301040649414062
iter 17562 (epoch 29), train_loss = 2.457, time/batch = 0.026
Read data: 7.915496826171875e-05
iter 17563 (epoch 29), train_loss = 2.495, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 17564 (epoch 29), train_loss = 2.639, time/batch = 0.036
Read data: 0.00011229515075683594
iter 17565 (epoch 29), train_loss = 2.703, time/batch = 0.033
Read data: 8.96453857421875e-05
iter 17566 (epoch 29), train_loss = 2.588, time/batch = 0.025
Read data: 0.00011563301086425781
iter 17567 (epoch 29), train_loss = 2.522, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 17568 (epoch 29), train_loss = 2.100, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 17569 (epoch 29), train_loss = 2.141, time/batch = 0.021
Read data: 0.00011467933654785156
iter 17570 (epoch 29), train_loss = 2.498, time/batch = 0.034
Read data: 7.915496826171875e-05
iter 17571 (epoch 29), train_loss = 2.686, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 17572 (epoch 29), train_loss = 2.797, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17573 (epoch 29), train_loss = 2.449, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 17574 (epoch 29), train_loss = 2.435, time/batch = 0.021
Read data: 0.0002193450927734375
iter 17575 (epoch 29), train_loss = 2.218, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 17576 (epoch 29), train_loss = 2.540, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 17577 (epoch 29), train_loss = 2.252, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 17578 (epoch 29), train_loss = 2.258, time/batch = 0.030
Read data: 7.677078247070312e-05
iter 17579 (epoch 29), train_loss = 2.708, time/batch = 0.031
Read data: 0.00011873245239257812
iter 17580 (epoch 29), train_loss = 2.506, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 17581 (epoch 29), train_loss = 2.239, time/batch = 0.025
Read data: 0.0001163482666015625
iter 17582 (epoch 29), train_loss = 2.272, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 17583 (epoch 29), train_loss = 2.228, time/batch = 0.023
Read data: 0.00010061264038085938
iter 17584 (epoch 29), train_loss = 2.301, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 17585 (epoch 29), train_loss = 2.094, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 17586 (epoch 29), train_loss = 2.366, time/batch = 0.023
Read data: 0.0001380443572998047
iter 17587 (epoch 29), train_loss = 2.403, time/batch = 0.035
Read data: 8.106231689453125e-05
iter 17588 (epoch 29), train_loss = 2.614, time/batch = 0.023
Read data: 7.700920104980469e-05
iter 17589 (epoch 29), train_loss = 2.129, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 17590 (epoch 29), train_loss = 2.687, time/batch = 0.023
Read data: 0.0001316070556640625
iter 17591 (epoch 29), train_loss = 2.400, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 17592 (epoch 29), train_loss = 2.298, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 17593 (epoch 29), train_loss = 2.358, time/batch = 0.031
Read data: 0.00012993812561035156
iter 17594 (epoch 29), train_loss = 2.295, time/batch = 0.024
Read data: 0.00012993812561035156
iter 17595 (epoch 29), train_loss = 2.439, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 17596 (epoch 29), train_loss = 2.338, time/batch = 0.039
Read data: 0.00010895729064941406
iter 17597 (epoch 29), train_loss = 2.259, time/batch = 0.028
Read data: 9.441375732421875e-05
iter 17598 (epoch 29), train_loss = 2.600, time/batch = 0.027
Read data: 0.0001850128173828125
iter 17599 (epoch 29), train_loss = 2.406, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 17600 (epoch 29), train_loss = 2.376, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 17601 (epoch 29), train_loss = 2.804, time/batch = 0.023
Read data: 0.00011301040649414062
iter 17602 (epoch 29), train_loss = 2.329, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 17603 (epoch 29), train_loss = 2.474, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 17604 (epoch 29), train_loss = 2.425, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 17605 (epoch 29), train_loss = 2.012, time/batch = 0.029
Read data: 0.00011205673217773438
iter 17606 (epoch 29), train_loss = 2.359, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 17607 (epoch 29), train_loss = 2.444, time/batch = 0.025
Read data: 7.724761962890625e-05
iter 17608 (epoch 29), train_loss = 2.087, time/batch = 0.026
Read data: 8.893013000488281e-05
iter 17609 (epoch 29), train_loss = 2.156, time/batch = 0.024
Read data: 0.00010967254638671875
iter 17610 (epoch 29), train_loss = 2.329, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 17611 (epoch 29), train_loss = 2.127, time/batch = 0.023
Read data: 0.00010251998901367188
iter 17612 (epoch 29), train_loss = 2.505, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 17613 (epoch 29), train_loss = 2.407, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 17614 (epoch 29), train_loss = 2.671, time/batch = 0.037
Read data: 8.20159912109375e-05
iter 17615 (epoch 29), train_loss = 2.182, time/batch = 0.028
Read data: 9.393692016601562e-05
iter 17616 (epoch 29), train_loss = 2.236, time/batch = 0.027
Read data: 0.00011134147644042969
iter 17617 (epoch 29), train_loss = 2.153, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 17618 (epoch 29), train_loss = 1.959, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 17619 (epoch 29), train_loss = 2.358, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 17620 (epoch 29), train_loss = 2.321, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 17621 (epoch 29), train_loss = 2.641, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 17622 (epoch 29), train_loss = 2.250, time/batch = 0.022
Read data: 0.00010609626770019531
iter 17623 (epoch 29), train_loss = 2.495, time/batch = 0.025
Read data: 0.00010347366333007812
iter 17624 (epoch 29), train_loss = 2.435, time/batch = 0.030
Read data: 0.0002377033233642578
iter 17625 (epoch 29), train_loss = 2.412, time/batch = 0.023
Read data: 0.00012159347534179688
iter 17626 (epoch 29), train_loss = 2.304, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 17627 (epoch 29), train_loss = 2.738, time/batch = 0.033
Read data: 8.463859558105469e-05
iter 17628 (epoch 29), train_loss = 2.758, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17629 (epoch 29), train_loss = 2.611, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 17630 (epoch 29), train_loss = 2.494, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 17631 (epoch 29), train_loss = 2.594, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 17632 (epoch 29), train_loss = 2.418, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 17633 (epoch 29), train_loss = 2.572, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 17634 (epoch 29), train_loss = 2.581, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 17635 (epoch 29), train_loss = 2.389, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 17636 (epoch 29), train_loss = 2.734, time/batch = 0.031
Read data: 0.00011610984802246094
iter 17637 (epoch 29), train_loss = 2.170, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 17638 (epoch 29), train_loss = 2.768, time/batch = 0.021
Read data: 7.724761962890625e-05
iter 17639 (epoch 29), train_loss = 2.288, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 17640 (epoch 29), train_loss = 2.681, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 17641 (epoch 29), train_loss = 2.414, time/batch = 0.031
Read data: 9.822845458984375e-05
iter 17642 (epoch 29), train_loss = 2.379, time/batch = 0.030
Read data: 0.0001251697540283203
iter 17643 (epoch 29), train_loss = 2.503, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 17644 (epoch 29), train_loss = 2.550, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 17645 (epoch 29), train_loss = 2.426, time/batch = 0.030
Read data: 0.0001506805419921875
iter 17646 (epoch 29), train_loss = 2.118, time/batch = 0.026
Read data: 0.0001437664031982422
iter 17647 (epoch 29), train_loss = 2.660, time/batch = 0.033
Read data: 0.0001366138458251953
iter 17648 (epoch 29), train_loss = 2.482, time/batch = 0.036
Read data: 0.00011587142944335938
iter 17649 (epoch 29), train_loss = 2.253, time/batch = 0.024
Read data: 0.00023031234741210938
iter 17650 (epoch 29), train_loss = 2.137, time/batch = 0.030
Read data: 0.0001671314239501953
iter 17651 (epoch 29), train_loss = 2.380, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 17652 (epoch 29), train_loss = 2.585, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 17653 (epoch 29), train_loss = 2.395, time/batch = 0.026
Read data: 0.00011229515075683594
iter 17654 (epoch 29), train_loss = 2.269, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 17655 (epoch 29), train_loss = 2.395, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 17656 (epoch 29), train_loss = 2.249, time/batch = 0.027
Read data: 8.702278137207031e-05
iter 17657 (epoch 29), train_loss = 2.497, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 17658 (epoch 29), train_loss = 2.629, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 17659 (epoch 29), train_loss = 1.718, time/batch = 0.021
Read data: 0.00012159347534179688
iter 17660 (epoch 29), train_loss = 2.231, time/batch = 0.027
Read data: 9.775161743164062e-05
iter 17661 (epoch 29), train_loss = 2.407, time/batch = 0.028
Read data: 9.799003601074219e-05
iter 17662 (epoch 29), train_loss = 2.401, time/batch = 0.024
Read data: 0.00014257431030273438
iter 17663 (epoch 29), train_loss = 2.303, time/batch = 0.022
Read data: 9.846687316894531e-05
iter 17664 (epoch 29), train_loss = 2.762, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 17665 (epoch 29), train_loss = 2.559, time/batch = 0.025
Read data: 0.00011277198791503906
iter 17666 (epoch 29), train_loss = 2.266, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 17667 (epoch 29), train_loss = 2.623, time/batch = 0.024
Read data: 0.00011420249938964844
iter 17668 (epoch 29), train_loss = 2.883, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 17669 (epoch 29), train_loss = 2.712, time/batch = 0.021
Read data: 0.00012040138244628906
iter 17670 (epoch 29), train_loss = 2.381, time/batch = 0.025
Read data: 0.00018453598022460938
iter 17671 (epoch 29), train_loss = 2.071, time/batch = 0.028
Read data: 0.00012350082397460938
iter 17672 (epoch 29), train_loss = 1.917, time/batch = 0.029
Read data: 9.918212890625e-05
iter 17673 (epoch 29), train_loss = 2.463, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 17674 (epoch 29), train_loss = 2.442, time/batch = 0.030
Read data: 0.00022268295288085938
iter 17675 (epoch 29), train_loss = 2.633, time/batch = 0.024
Read data: 0.0001480579376220703
iter 17676 (epoch 29), train_loss = 2.393, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 17677 (epoch 29), train_loss = 2.975, time/batch = 0.026
Read data: 0.0001342296600341797
iter 17678 (epoch 29), train_loss = 2.437, time/batch = 0.027
Read data: 0.00013637542724609375
iter 17679 (epoch 29), train_loss = 2.797, time/batch = 0.025
Read data: 0.00011587142944335938
iter 17680 (epoch 29), train_loss = 2.462, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 17681 (epoch 29), train_loss = 2.487, time/batch = 0.026
Read data: 9.1552734375e-05
iter 17682 (epoch 29), train_loss = 2.252, time/batch = 0.031
Read data: 0.00012683868408203125
iter 17683 (epoch 29), train_loss = 2.741, time/batch = 0.023
Read data: 0.00015020370483398438
iter 17684 (epoch 29), train_loss = 2.904, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 17685 (epoch 29), train_loss = 1.895, time/batch = 0.023
Read data: 0.0001285076141357422
iter 17686 (epoch 29), train_loss = 2.699, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 17687 (epoch 29), train_loss = 2.379, time/batch = 0.027
Read data: 0.0001266002655029297
iter 17688 (epoch 29), train_loss = 2.206, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 17689 (epoch 29), train_loss = 2.354, time/batch = 0.023
Read data: 0.0001366138458251953
iter 17690 (epoch 29), train_loss = 2.554, time/batch = 0.025
Read data: 0.00013899803161621094
iter 17691 (epoch 29), train_loss = 2.348, time/batch = 0.028
Read data: 0.00010037422180175781
iter 17692 (epoch 29), train_loss = 2.229, time/batch = 0.023
Read data: 0.00010943412780761719
iter 17693 (epoch 29), train_loss = 2.587, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 17694 (epoch 29), train_loss = 2.308, time/batch = 0.028
Read data: 0.00012731552124023438
iter 17695 (epoch 29), train_loss = 2.747, time/batch = 0.025
Read data: 0.00014591217041015625
iter 17696 (epoch 29), train_loss = 2.351, time/batch = 0.024
Read data: 0.00010013580322265625
iter 17697 (epoch 29), train_loss = 2.306, time/batch = 0.020
Read data: 0.00017571449279785156
iter 17698 (epoch 29), train_loss = 2.281, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 17699 (epoch 29), train_loss = 2.389, time/batch = 0.031
Read data: 0.0002002716064453125
iter 17700 (epoch 29), train_loss = 2.504, time/batch = 0.029
Read data: 0.00010228157043457031
iter 17701 (epoch 29), train_loss = 2.271, time/batch = 0.027
Read data: 0.00013399124145507812
iter 17702 (epoch 29), train_loss = 2.494, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 17703 (epoch 29), train_loss = 2.541, time/batch = 0.021
Read data: 0.00011849403381347656
iter 17704 (epoch 29), train_loss = 2.046, time/batch = 0.026
Read data: 0.00010776519775390625
iter 17705 (epoch 29), train_loss = 2.602, time/batch = 0.030
Read data: 0.00015592575073242188
iter 17706 (epoch 29), train_loss = 2.536, time/batch = 0.033
Read data: 0.00013899803161621094
iter 17707 (epoch 29), train_loss = 2.019, time/batch = 0.021
Read data: 7.939338684082031e-05
iter 17708 (epoch 29), train_loss = 2.146, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 17709 (epoch 29), train_loss = 2.601, time/batch = 0.029
Read data: 0.0001347064971923828
iter 17710 (epoch 29), train_loss = 2.355, time/batch = 0.027
Read data: 0.0001220703125
iter 17711 (epoch 29), train_loss = 2.561, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 17712 (epoch 29), train_loss = 2.308, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 17713 (epoch 29), train_loss = 2.775, time/batch = 0.021
Read data: 0.00010132789611816406
iter 17714 (epoch 29), train_loss = 2.329, time/batch = 0.023
Read data: 0.0001590251922607422
iter 17715 (epoch 29), train_loss = 2.791, time/batch = 0.023
Read data: 0.00013113021850585938
iter 17716 (epoch 29), train_loss = 2.696, time/batch = 0.033
Read data: 9.083747863769531e-05
iter 17717 (epoch 29), train_loss = 2.316, time/batch = 0.031
Read data: 0.00015425682067871094
iter 17718 (epoch 29), train_loss = 2.166, time/batch = 0.021
Read data: 7.772445678710938e-05
iter 17719 (epoch 29), train_loss = 2.275, time/batch = 0.028
Read data: 0.00014710426330566406
iter 17720 (epoch 29), train_loss = 2.590, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 17721 (epoch 29), train_loss = 2.233, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 17722 (epoch 29), train_loss = 2.372, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 17723 (epoch 29), train_loss = 2.669, time/batch = 0.031
Read data: 0.00015115737915039062
iter 17724 (epoch 29), train_loss = 2.416, time/batch = 0.027
Read data: 0.00016951560974121094
iter 17725 (epoch 29), train_loss = 2.248, time/batch = 0.023
Read data: 0.00010228157043457031
iter 17726 (epoch 29), train_loss = 2.292, time/batch = 0.028
Read data: 0.0001552104949951172
iter 17727 (epoch 29), train_loss = 2.046, time/batch = 0.034
Read data: 9.1552734375e-05
iter 17728 (epoch 29), train_loss = 2.164, time/batch = 0.027
Read data: 0.00011014938354492188
iter 17729 (epoch 29), train_loss = 2.712, time/batch = 0.026
Read data: 0.0001342296600341797
iter 17730 (epoch 29), train_loss = 2.378, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 17731 (epoch 29), train_loss = 2.593, time/batch = 0.024
Read data: 0.0001251697540283203
iter 17732 (epoch 29), train_loss = 2.638, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 17733 (epoch 29), train_loss = 2.507, time/batch = 0.022
Read data: 9.107589721679688e-05
iter 17734 (epoch 29), train_loss = 2.729, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 17735 (epoch 29), train_loss = 2.399, time/batch = 0.031
Read data: 0.00014662742614746094
iter 17736 (epoch 29), train_loss = 2.018, time/batch = 0.023
Read data: 0.00012636184692382812
iter 17737 (epoch 29), train_loss = 2.471, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 17738 (epoch 29), train_loss = 2.641, time/batch = 0.033
Read data: 0.00016117095947265625
iter 17739 (epoch 29), train_loss = 2.179, time/batch = 0.022
Read data: 0.00011658668518066406
iter 17740 (epoch 29), train_loss = 2.546, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 17741 (epoch 29), train_loss = 2.760, time/batch = 0.033
Read data: 8.416175842285156e-05
iter 17742 (epoch 29), train_loss = 2.679, time/batch = 0.029
Read data: 0.00014138221740722656
iter 17743 (epoch 29), train_loss = 2.347, time/batch = 0.028
Read data: 0.00012111663818359375
iter 17744 (epoch 29), train_loss = 2.437, time/batch = 0.026
Read data: 8.535385131835938e-05
iter 17745 (epoch 29), train_loss = 2.227, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 17746 (epoch 29), train_loss = 2.131, time/batch = 0.023
Read data: 0.0001556873321533203
iter 17747 (epoch 29), train_loss = 2.171, time/batch = 0.026
Read data: 0.0001418590545654297
iter 17748 (epoch 29), train_loss = 2.367, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 17749 (epoch 29), train_loss = 2.686, time/batch = 0.025
Read data: 0.00016951560974121094
iter 17750 (epoch 29), train_loss = 2.342, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 17751 (epoch 29), train_loss = 2.483, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 17752 (epoch 29), train_loss = 2.332, time/batch = 0.024
Read data: 0.00015497207641601562
iter 17753 (epoch 29), train_loss = 2.084, time/batch = 0.023
Read data: 0.00016880035400390625
iter 17754 (epoch 29), train_loss = 2.692, time/batch = 0.030
Read data: 0.0001609325408935547
iter 17755 (epoch 29), train_loss = 2.385, time/batch = 0.026
Read data: 7.62939453125e-05
iter 17756 (epoch 29), train_loss = 2.450, time/batch = 0.026
Read data: 0.00015401840209960938
iter 17757 (epoch 29), train_loss = 2.325, time/batch = 0.022
Read data: 9.5367431640625e-05
iter 17758 (epoch 29), train_loss = 2.363, time/batch = 0.030
Read data: 0.0001246929168701172
iter 17759 (epoch 29), train_loss = 2.404, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 17760 (epoch 29), train_loss = 2.402, time/batch = 0.024
Read data: 0.00011086463928222656
iter 17761 (epoch 29), train_loss = 2.568, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 17762 (epoch 29), train_loss = 2.274, time/batch = 0.021
Read data: 0.00014734268188476562
iter 17763 (epoch 29), train_loss = 2.444, time/batch = 0.037
Read data: 7.700920104980469e-05
iter 17764 (epoch 29), train_loss = 2.179, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 17765 (epoch 29), train_loss = 2.768, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 17766 (epoch 29), train_loss = 2.259, time/batch = 0.031
Read data: 0.00011658668518066406
iter 17767 (epoch 29), train_loss = 2.179, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 17768 (epoch 29), train_loss = 2.792, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 17769 (epoch 29), train_loss = 2.294, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 17770 (epoch 29), train_loss = 2.382, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 17771 (epoch 29), train_loss = 2.555, time/batch = 0.030
Read data: 0.00013518333435058594
iter 17772 (epoch 29), train_loss = 2.042, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 17773 (epoch 29), train_loss = 2.324, time/batch = 0.021
Read data: 8.463859558105469e-05
iter 17774 (epoch 29), train_loss = 2.460, time/batch = 0.022
Read data: 0.0002753734588623047
iter 17775 (epoch 29), train_loss = 2.643, time/batch = 0.035
Read data: 7.605552673339844e-05
iter 17776 (epoch 29), train_loss = 2.679, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 17777 (epoch 29), train_loss = 2.618, time/batch = 0.036
Read data: 9.131431579589844e-05
iter 17778 (epoch 29), train_loss = 2.897, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 17779 (epoch 29), train_loss = 2.437, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 17780 (epoch 29), train_loss = 2.188, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 17781 (epoch 29), train_loss = 2.236, time/batch = 0.027
Read data: 0.00012421607971191406
iter 17782 (epoch 29), train_loss = 2.691, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 17783 (epoch 29), train_loss = 2.474, time/batch = 0.021
Read data: 7.843971252441406e-05
iter 17784 (epoch 29), train_loss = 2.595, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 17785 (epoch 29), train_loss = 2.478, time/batch = 0.034
Read data: 7.867813110351562e-05
iter 17786 (epoch 29), train_loss = 2.077, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17787 (epoch 29), train_loss = 2.378, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 17788 (epoch 29), train_loss = 2.361, time/batch = 0.026
Read data: 7.605552673339844e-05
iter 17789 (epoch 29), train_loss = 2.338, time/batch = 0.024
Read data: 0.00016164779663085938
iter 17790 (epoch 29), train_loss = 2.075, time/batch = 0.026
Read data: 0.00015974044799804688
iter 17791 (epoch 29), train_loss = 2.431, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 17792 (epoch 29), train_loss = 2.539, time/batch = 0.024
Read data: 0.00015664100646972656
iter 17793 (epoch 29), train_loss = 2.543, time/batch = 0.025
Read data: 0.0001468658447265625
iter 17794 (epoch 29), train_loss = 2.461, time/batch = 0.030
Read data: 0.00012612342834472656
iter 17795 (epoch 29), train_loss = 1.975, time/batch = 0.035
Read data: 0.0001323223114013672
iter 17796 (epoch 29), train_loss = 2.487, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 17797 (epoch 29), train_loss = 2.342, time/batch = 0.031
Read data: 8.893013000488281e-05
iter 17798 (epoch 29), train_loss = 2.667, time/batch = 0.033
Read data: 0.0001418590545654297
iter 17799 (epoch 29), train_loss = 2.264, time/batch = 0.028
Read data: 0.00017213821411132812
iter 17800 (epoch 29), train_loss = 2.783, time/batch = 0.025
Read data: 0.00014328956604003906
iter 17801 (epoch 29), train_loss = 2.241, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 17802 (epoch 29), train_loss = 2.515, time/batch = 0.026
Read data: 0.00015473365783691406
iter 17803 (epoch 29), train_loss = 2.504, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 17804 (epoch 29), train_loss = 2.655, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 17805 (epoch 29), train_loss = 2.737, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 17806 (epoch 29), train_loss = 2.264, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 17807 (epoch 29), train_loss = 2.215, time/batch = 0.024
Read data: 0.00015473365783691406
iter 17808 (epoch 29), train_loss = 2.256, time/batch = 0.026
Read data: 0.000164031982421875
iter 17809 (epoch 29), train_loss = 2.440, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 17810 (epoch 29), train_loss = 2.606, time/batch = 0.036
Read data: 7.987022399902344e-05
iter 17811 (epoch 29), train_loss = 2.337, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 17812 (epoch 29), train_loss = 2.492, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 17813 (epoch 29), train_loss = 2.485, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 17814 (epoch 29), train_loss = 2.320, time/batch = 0.023
Read data: 0.0001285076141357422
iter 17815 (epoch 29), train_loss = 2.667, time/batch = 0.037
Read data: 0.00012612342834472656
iter 17816 (epoch 29), train_loss = 2.570, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 17817 (epoch 29), train_loss = 2.576, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 17818 (epoch 29), train_loss = 2.529, time/batch = 0.026
Read data: 8.463859558105469e-05
iter 17819 (epoch 29), train_loss = 2.340, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 17820 (epoch 29), train_loss = 2.511, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 17821 (epoch 29), train_loss = 2.365, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 17822 (epoch 29), train_loss = 2.643, time/batch = 0.033
Read data: 7.653236389160156e-05
iter 17823 (epoch 29), train_loss = 2.401, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 17824 (epoch 29), train_loss = 2.586, time/batch = 0.024
Read data: 0.00017523765563964844
iter 17825 (epoch 29), train_loss = 2.281, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 17826 (epoch 29), train_loss = 2.418, time/batch = 0.036
Read data: 0.0001461505889892578
iter 17827 (epoch 29), train_loss = 2.397, time/batch = 0.021
Read data: 8.296966552734375e-05
iter 17828 (epoch 29), train_loss = 2.535, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 17829 (epoch 29), train_loss = 2.523, time/batch = 0.029
Read data: 7.700920104980469e-05
iter 17830 (epoch 29), train_loss = 2.482, time/batch = 0.027
Read data: 0.00013875961303710938
iter 17831 (epoch 29), train_loss = 2.604, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 17832 (epoch 29), train_loss = 2.438, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 17833 (epoch 29), train_loss = 2.417, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 17834 (epoch 29), train_loss = 2.216, time/batch = 0.030
Read data: 0.00016307830810546875
iter 17835 (epoch 29), train_loss = 2.595, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 17836 (epoch 29), train_loss = 2.272, time/batch = 0.027
Read data: 0.00010371208190917969
iter 17837 (epoch 29), train_loss = 2.502, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 17838 (epoch 29), train_loss = 2.607, time/batch = 0.023
Read data: 9.5367431640625e-05
iter 17839 (epoch 29), train_loss = 2.559, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 17840 (epoch 29), train_loss = 2.383, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 17841 (epoch 29), train_loss = 2.472, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 17842 (epoch 29), train_loss = 2.253, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 17843 (epoch 29), train_loss = 2.310, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 17844 (epoch 29), train_loss = 2.641, time/batch = 0.025
Read data: 0.00010919570922851562
iter 17845 (epoch 29), train_loss = 2.132, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 17846 (epoch 29), train_loss = 2.192, time/batch = 0.027
Read data: 9.417533874511719e-05
iter 17847 (epoch 29), train_loss = 2.393, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 17848 (epoch 29), train_loss = 1.834, time/batch = 0.022
Read data: 8.0108642578125e-05
iter 17849 (epoch 29), train_loss = 2.177, time/batch = 0.026
Read data: 0.0001971721649169922
iter 17850 (epoch 29), train_loss = 2.324, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 17851 (epoch 29), train_loss = 2.843, time/batch = 0.030
Read data: 8.392333984375e-05
iter 17852 (epoch 29), train_loss = 2.163, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 17853 (epoch 29), train_loss = 2.269, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 17854 (epoch 29), train_loss = 2.439, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 17855 (epoch 29), train_loss = 2.223, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 17856 (epoch 29), train_loss = 2.413, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 17857 (epoch 29), train_loss = 2.600, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 17858 (epoch 29), train_loss = 2.420, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 17859 (epoch 29), train_loss = 2.387, time/batch = 0.021
Read data: 0.00013494491577148438
iter 17860 (epoch 29), train_loss = 2.557, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 17861 (epoch 29), train_loss = 2.547, time/batch = 0.029
Read data: 0.00010132789611816406
iter 17862 (epoch 29), train_loss = 2.132, time/batch = 0.031
Read data: 0.00010275840759277344
iter 17863 (epoch 29), train_loss = 2.468, time/batch = 0.032
Read data: 0.0001494884490966797
iter 17864 (epoch 29), train_loss = 2.350, time/batch = 0.024
Read data: 0.0001380443572998047
iter 17865 (epoch 29), train_loss = 2.819, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 17866 (epoch 29), train_loss = 2.894, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 17867 (epoch 29), train_loss = 2.767, time/batch = 0.021
Read data: 9.751319885253906e-05
iter 17868 (epoch 29), train_loss = 2.701, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 17869 (epoch 29), train_loss = 2.675, time/batch = 0.031
Read data: 0.00011754035949707031
iter 17870 (epoch 29), train_loss = 2.159, time/batch = 0.025
Read data: 0.0001232624053955078
iter 17871 (epoch 29), train_loss = 1.961, time/batch = 0.023
Read data: 0.00010848045349121094
iter 17872 (epoch 29), train_loss = 2.597, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 17873 (epoch 29), train_loss = 2.414, time/batch = 0.025
Read data: 0.0001232624053955078
iter 17874 (epoch 29), train_loss = 2.463, time/batch = 0.027
Read data: 0.00019979476928710938
iter 17875 (epoch 29), train_loss = 2.438, time/batch = 0.022
Read data: 0.00010395050048828125
iter 17876 (epoch 29), train_loss = 2.809, time/batch = 0.031
Read data: 0.00010538101196289062
iter 17877 (epoch 29), train_loss = 2.346, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 17878 (epoch 29), train_loss = 2.336, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 17879 (epoch 29), train_loss = 2.563, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 17880 (epoch 29), train_loss = 2.075, time/batch = 0.021
Read data: 0.00010085105895996094
iter 17881 (epoch 29), train_loss = 2.358, time/batch = 0.027
Read data: 0.00011897087097167969
iter 17882 (epoch 29), train_loss = 2.499, time/batch = 0.025
Read data: 0.00011444091796875
iter 17883 (epoch 29), train_loss = 2.585, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 17884 (epoch 29), train_loss = 2.482, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 17885 (epoch 29), train_loss = 2.621, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 17886 (epoch 29), train_loss = 2.205, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 17887 (epoch 29), train_loss = 2.400, time/batch = 0.029
Read data: 8.392333984375e-05
iter 17888 (epoch 29), train_loss = 2.491, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 17889 (epoch 29), train_loss = 2.496, time/batch = 0.032
Read data: 7.915496826171875e-05
iter 17890 (epoch 29), train_loss = 2.298, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 17891 (epoch 29), train_loss = 2.403, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 17892 (epoch 29), train_loss = 2.676, time/batch = 0.033
Read data: 0.00013947486877441406
iter 17893 (epoch 29), train_loss = 2.304, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17894 (epoch 29), train_loss = 2.182, time/batch = 0.034
Read data: 0.00014090538024902344
iter 17895 (epoch 29), train_loss = 2.373, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 17896 (epoch 29), train_loss = 2.613, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 17897 (epoch 29), train_loss = 2.111, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 17898 (epoch 29), train_loss = 2.300, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 17899 (epoch 29), train_loss = 2.639, time/batch = 0.030
Read data: 0.0001697540283203125
iter 17900 (epoch 29), train_loss = 2.720, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 17901 (epoch 29), train_loss = 2.389, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 17902 (epoch 29), train_loss = 2.296, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 17903 (epoch 29), train_loss = 2.524, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 17904 (epoch 29), train_loss = 2.430, time/batch = 0.023
Read data: 9.918212890625e-05
iter 17905 (epoch 29), train_loss = 2.061, time/batch = 0.022
Read data: 0.00011730194091796875
iter 17906 (epoch 29), train_loss = 2.052, time/batch = 0.022
Read data: 8.392333984375e-05
iter 17907 (epoch 29), train_loss = 2.187, time/batch = 0.031
Read data: 9.632110595703125e-05
iter 17908 (epoch 29), train_loss = 2.440, time/batch = 0.033
Read data: 8.273124694824219e-05
iter 17909 (epoch 29), train_loss = 2.217, time/batch = 0.025
Read data: 0.0016963481903076172
iter 17910 (epoch 29), train_loss = 2.313, time/batch = 0.019
Read data: 0.0001266002655029297
iter 17911 (epoch 29), train_loss = 2.435, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 17912 (epoch 29), train_loss = 2.345, time/batch = 0.022
Read data: 9.322166442871094e-05
iter 17913 (epoch 29), train_loss = 2.271, time/batch = 0.027
Read data: 0.00011730194091796875
iter 17914 (epoch 29), train_loss = 2.851, time/batch = 0.028
Read data: 0.00011491775512695312
iter 17915 (epoch 29), train_loss = 2.314, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 17916 (epoch 29), train_loss = 2.621, time/batch = 0.029
Read data: 0.00012874603271484375
iter 17917 (epoch 29), train_loss = 2.794, time/batch = 0.023
Read data: 9.012222290039062e-05
iter 17918 (epoch 29), train_loss = 2.393, time/batch = 0.041
Read data: 0.00011610984802246094
iter 17919 (epoch 29), train_loss = 2.319, time/batch = 0.022
Read data: 0.00010919570922851562
iter 17920 (epoch 29), train_loss = 2.274, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 17921 (epoch 29), train_loss = 2.453, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 17922 (epoch 29), train_loss = 2.055, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 17923 (epoch 29), train_loss = 2.409, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 17924 (epoch 29), train_loss = 2.389, time/batch = 0.024
Read data: 0.00016880035400390625
iter 17925 (epoch 29), train_loss = 2.229, time/batch = 0.025
Read data: 0.00012969970703125
iter 17926 (epoch 29), train_loss = 2.236, time/batch = 0.029
Read data: 9.489059448242188e-05
iter 17927 (epoch 29), train_loss = 2.554, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 17928 (epoch 29), train_loss = 2.138, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 17929 (epoch 29), train_loss = 2.511, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 17930 (epoch 29), train_loss = 2.396, time/batch = 0.025
Read data: 0.00010418891906738281
iter 17931 (epoch 29), train_loss = 2.618, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 17932 (epoch 29), train_loss = 2.318, time/batch = 0.021
Read data: 9.512901306152344e-05
iter 17933 (epoch 29), train_loss = 2.730, time/batch = 0.027
Read data: 9.799003601074219e-05
iter 17934 (epoch 29), train_loss = 2.451, time/batch = 0.024
Read data: 0.00011444091796875
iter 17935 (epoch 29), train_loss = 2.515, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 17936 (epoch 29), train_loss = 2.212, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 17937 (epoch 29), train_loss = 2.190, time/batch = 0.027
Read data: 0.00011563301086425781
iter 17938 (epoch 29), train_loss = 2.313, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 17939 (epoch 29), train_loss = 2.523, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 17940 (epoch 29), train_loss = 2.519, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 17941 (epoch 29), train_loss = 2.494, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 17942 (epoch 29), train_loss = 2.823, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 17943 (epoch 29), train_loss = 2.485, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 17944 (epoch 29), train_loss = 2.436, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 17945 (epoch 29), train_loss = 2.154, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 17946 (epoch 29), train_loss = 2.354, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 17947 (epoch 29), train_loss = 2.570, time/batch = 0.026
Read data: 8.869171142578125e-05
iter 17948 (epoch 29), train_loss = 2.346, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 17949 (epoch 29), train_loss = 2.507, time/batch = 0.028
Read data: 0.000171661376953125
iter 17950 (epoch 29), train_loss = 2.806, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 17951 (epoch 29), train_loss = 2.688, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 17952 (epoch 29), train_loss = 2.315, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 17953 (epoch 29), train_loss = 2.504, time/batch = 0.029
Read data: 9.274482727050781e-05
iter 17954 (epoch 29), train_loss = 2.344, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 17955 (epoch 29), train_loss = 2.360, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 17956 (epoch 29), train_loss = 2.012, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 17957 (epoch 29), train_loss = 2.490, time/batch = 0.022
Read data: 0.00012922286987304688
iter 17958 (epoch 29), train_loss = 2.254, time/batch = 0.025
Read data: 0.00013208389282226562
iter 17959 (epoch 29), train_loss = 2.540, time/batch = 0.036
Read data: 8.153915405273438e-05
iter 17960 (epoch 29), train_loss = 2.785, time/batch = 0.030
Read data: 8.702278137207031e-05
iter 17961 (epoch 29), train_loss = 2.458, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 17962 (epoch 29), train_loss = 2.341, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 17963 (epoch 29), train_loss = 2.750, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 17964 (epoch 29), train_loss = 2.615, time/batch = 0.023
Read data: 0.00010323524475097656
iter 17965 (epoch 29), train_loss = 2.307, time/batch = 0.030
Read data: 9.822845458984375e-05
iter 17966 (epoch 29), train_loss = 2.684, time/batch = 0.026
Read data: 0.0001125335693359375
iter 17967 (epoch 29), train_loss = 2.490, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 17968 (epoch 29), train_loss = 2.314, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 17969 (epoch 29), train_loss = 2.087, time/batch = 0.023
Read data: 9.1552734375e-05
iter 17970 (epoch 29), train_loss = 2.417, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 17971 (epoch 29), train_loss = 2.867, time/batch = 0.025
Read data: 0.00011157989501953125
iter 17972 (epoch 29), train_loss = 2.158, time/batch = 0.029
Read data: 9.822845458984375e-05
iter 17973 (epoch 29), train_loss = 2.622, time/batch = 0.026
Read data: 0.00010776519775390625
iter 17974 (epoch 29), train_loss = 2.391, time/batch = 0.026
Read data: 0.0001685619354248047
iter 17975 (epoch 29), train_loss = 2.787, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 17976 (epoch 29), train_loss = 2.394, time/batch = 0.023
Read data: 9.870529174804688e-05
iter 17977 (epoch 29), train_loss = 2.212, time/batch = 0.023
Read data: 0.00011992454528808594
iter 17978 (epoch 29), train_loss = 2.224, time/batch = 0.029
Read data: 9.894371032714844e-05
iter 17979 (epoch 29), train_loss = 2.466, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 17980 (epoch 29), train_loss = 2.765, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 17981 (epoch 29), train_loss = 2.894, time/batch = 0.032
Read data: 0.00011610984802246094
iter 17982 (epoch 29), train_loss = 2.438, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 17983 (epoch 29), train_loss = 2.784, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 17984 (epoch 29), train_loss = 2.419, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 17985 (epoch 29), train_loss = 2.287, time/batch = 0.025
Read data: 0.00010013580322265625
iter 17986 (epoch 29), train_loss = 2.500, time/batch = 0.024
Read data: 0.00011730194091796875
iter 17987 (epoch 29), train_loss = 2.408, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 17988 (epoch 29), train_loss = 2.698, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 17989 (epoch 29), train_loss = 2.704, time/batch = 0.025
Read data: 0.00010824203491210938
iter 17990 (epoch 29), train_loss = 2.453, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 17991 (epoch 29), train_loss = 2.652, time/batch = 0.023
Read data: 0.0009222030639648438
iter 17992 (epoch 29), train_loss = 2.225, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 17993 (epoch 29), train_loss = 2.402, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 17994 (epoch 29), train_loss = 2.433, time/batch = 0.023
Read data: 0.00011324882507324219
iter 17995 (epoch 29), train_loss = 2.648, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 17996 (epoch 29), train_loss = 2.621, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 17997 (epoch 29), train_loss = 2.453, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 17998 (epoch 29), train_loss = 2.520, time/batch = 0.025
Read data: 0.00011515617370605469
iter 17999 (epoch 29), train_loss = 2.518, time/batch = 0.036
image 976:     
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:      
image 2375:    
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.616149)
image 2798:    
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:    
evaluating validation preformance... 20/1000 (2.175914)
image 6903:    UNK
image 3301:    
image 2019:     
image 5535:     
image 7680:      
image 5527:      
image 2568:    
image 160:      
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.500527)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.052444)
image 2938:    UNK
image 5183:     
image 2380:     
image 6973:   
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.484802)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:     
image 6329:    UNK
image 1729:     
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.793224)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:  
image 5641:     
evaluating validation preformance... 70/1000 (2.556908)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.582124)
image 3276:      
image 3812:   
image 1400:     
image 3443:    
image 5027:     
image 7251:     
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.144951)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:     
image 6612:     
image 7701:    
image 7379:     
image 1165:    
image 6553:       
evaluating validation preformance... 100/1000 (2.874809)
image 2800:     
image 7249:     
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     UNK
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.773814)
image 1122:    
image 509:     
image 4091:    
image 5761:     
image 16:     
image 231:    
image 6505:   
image 1450:    
image 3979:      
image 5302:      UNK
evaluating validation preformance... 120/1000 (2.350898)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.884048)
image 6214:     
image 429:    
image 7743:    
image 3657:      
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:     
image 2867:    
evaluating validation preformance... 140/1000 (2.671423)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:    UNK
evaluating validation preformance... 150/1000 (2.914216)
image 1865:     
image 3830:      
image 360:      
image 5097:      
image 4455:     
image 1153:    UNK
image 1248:     
image 7688:     
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.813460)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:     
evaluating validation preformance... 170/1000 (2.560504)
image 7922:      
image 2353:    
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.709478)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:      
image 4541:     UNK
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.363968)
image 5372:    
image 7529:    UNK
image 875:     
image 2107:      
image 8015:   
image 6565:     
image 6174:      
image 6894:    
image 4164:     
image 7049:      
evaluating validation preformance... 200/1000 (2.254179)
image 5159:     
image 1199:    
image 2456:     
image 3402:    
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:      
image 4023:     
evaluating validation preformance... 210/1000 (2.414695)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.502591)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.235057)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:    
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.120507)
image 7143:    
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:     
image 1724:   
image 528:     
evaluating validation preformance... 250/1000 (2.497022)
image 3028:    
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:     
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.511919)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.978249)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:     
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:     
evaluating validation preformance... 280/1000 (2.526686)
image 2481:    
image 1860:     
image 1464:      
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.367510)
image 6835:     
image 4698:    
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.170037)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:    
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.748116)
image 3553:    
image 5971:     
image 122:    
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.307571)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:     UNK
image 2203:     
image 5727:    
image 1159:      
evaluating validation preformance... 330/1000 (2.722495)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:      
image 2601:    
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.408752)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:     
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.468784)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.028766)
image 2905:     
image 7814:      
image 56:    UNK
image 5034:     
image 7946:      
image 3470:      
image 4655:     
image 818:    
image 6607:    
image 4866:      
evaluating validation preformance... 370/1000 (2.578488)
image 4351:     
image 1054:     
image 129:    
image 2849:     
image 725:   UNK
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.616778)
image 2458:     
image 1084:      
image 4835:    UNK
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:    
image 60:    
evaluating validation preformance... 390/1000 (2.817386)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:    
image 1117:      
image 5817:      
image 1231:    
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.217864)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:     
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.139813)
image 4359:     
image 2372:     
image 4472:      
image 6810:    
image 1592:     
image 7864:    
image 4286:    UNK
image 6688:    
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.302444)
image 30:     
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:     
image 6977:    
image 877:   
image 2408:    
image 7706:     UNK
evaluating validation preformance... 430/1000 (2.771209)
image 385:    
image 6938:       
image 2381:    
image 5796:     
image 4010:     
image 3452:     
image 2023:     
image 3052:    
image 6215:     
image 4092:    
evaluating validation preformance... 440/1000 (2.897966)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:      
image 4790:     
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.144930)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:      
image 2466:     
image 975:      
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.625595)
image 7979:     
image 1618:    UNK
image 7608:     
image 6393:    
image 5100:      
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.212923)
image 4503:     UNK
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.909139)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:    UNK
image 1595:  UNK  
image 4757:    
image 205:     
evaluating validation preformance... 490/1000 (3.337648)
image 2044:    
image 4349:    
image 3855:     
image 1846:     
image 3724:     
image 606:      
image 6577:      
image 6820:       
image 1485:     
image 5744:      
evaluating validation preformance... 500/1000 (2.437417)
image 1797:    
image 4670:   
image 4846:    
image 5907:     
image 3321:      
image 1700:     
image 438:    
image 5980:     
image 408:     
image 5403:      
evaluating validation preformance... 510/1000 (2.956411)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:     UNK
evaluating validation preformance... 520/1000 (2.576840)
image 6806:        UNK
image 6464:     
image 1872:     
image 1575:    
image 3045:      
image 303:   
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.470574)
image 5619:     
image 4391:  
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:    
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.412138)
image 5292:    
image 2901:     
image 3568:    
image 690:     
image 3345:    
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.551869)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.537094)
image 6056:    
image 6419:    
image 275:     
image 7441:    
image 7893:    
image 3623:    
image 7232:    
image 4778:     
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.538086)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:    UNK
image 3267:    
evaluating validation preformance... 580/1000 (2.617589)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:     
evaluating validation preformance... 590/1000 (2.541220)
image 4420:    
image 1734:     
image 7239:     
image 7447:    
image 8009:     
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.435084)
image 353:     
image 1095:     
image 3583:      
image 3264:    UNK
image 5668:     
image 7189:     
image 6573:    
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.608534)
image 69:     
image 3465:    
image 6179:    
image 552:     
image 511:     
image 761:    
image 5742:     
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.369997)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.488832)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.432897)
image 5313:      
image 2377:    
image 6058:    
image 4661:    
image 2955:   
image 3333:    
image 7124:     
image 4278:    
image 953:      
image 4037:    
evaluating validation preformance... 650/1000 (2.512657)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:      
image 2824:    
image 1639:    
image 1475:     
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.642700)
image 5701:    
image 1709:     
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:    
image 1972:   
evaluating validation preformance... 670/1000 (2.763278)
image 7877:    
image 6761:     
image 6880:   
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK UNK  
image 7784:    
evaluating validation preformance... 680/1000 (2.980631)
image 1445:     
image 6841:     
image 2896:     
image 6947:     
image 4782:    
image 7669:     
image 4382:    
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.812233)
image 6860:     
image 576:     
image 6580:     
image 1497:    
image 3360:     
image 4939:      
image 6225:     
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.984246)
image 5343:      
image 68:    UNK
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.493604)
image 7368:     
image 709:     
image 3197:    
image 5214:     
image 445:    
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.597948)
image 5729:     
image 6395:     
image 516:      
image 1026:     
image 2972:      
image 3005:    
image 1241:      
image 2743:      
image 3665:    UNK
image 1290:     UNK
evaluating validation preformance... 730/1000 (2.271038)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:     
image 5092:      
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.400144)
image 2239:     
image 120:     
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.643363)
image 3279:    
image 6380:    
image 2663:     
image 3815:     
image 512:      
image 5899:     
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.962353)
image 4582:    
image 5484:     
image 3049:     
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:      
image 3449:     
evaluating validation preformance... 770/1000 (2.118661)
image 6220:    
image 6238:      
image 4534:    
image 2732:     
image 7003:     
image 1739:     
image 5503:     
image 2329:     
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.801708)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:     
image 6978:    
image 3450:     
image 3312:    UNK
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.032056)
image 5047:      
image 325:       
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    UNK
evaluating validation preformance... 800/1000 (2.230855)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:    
image 290:     
image 159:     
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.390695)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:     
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.926793)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:     
image 7147:      
image 6348:     
image 580:     UNK
image 2531:    
evaluating validation preformance... 830/1000 (2.349461)
image 5107:    
image 3973:    UNK
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:   
evaluating validation preformance... 840/1000 (2.423374)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.716700)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:     
image 3596:    
image 1921:     
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.721926)
image 4254:    
image 6842:    
image 1644:   
image 7371:    UNK
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:     
evaluating validation preformance... 870/1000 (2.329884)
image 4934:    
image 6487:      
image 4217:     
image 6355:      
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.601586)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    UNK
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.880392)
image 7485:    
image 6102:     
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.573475)
image 5664:     
image 4985:     
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.197948)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.586288)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:    
image 6274:      
image 7102:    
image 5532:    UNK
image 2516:     
evaluating validation preformance... 930/1000 (2.489518)
image 5636:      
image 7799:      
image 6025:    
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.695576)
image 5860:    
image 3275:    
image 1935:    
image 3520:     
image 5452:    
image 2446:    
image 5984:   
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.898472)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:      
image 3923:     
image 4229:     
image 3336:     
image 2915:    
image 1550:    
evaluating validation preformance... 960/1000 (2.709298)
image 4935:     
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.280840)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:      
image 7800:    UNK UNK
image 3999:    
image 6317:    
image 5931:      
evaluating validation preformance... 980/1000 (2.718864)
image 7352:     
image 5113:     
image 7822:     
image 4858:    UNK
image 658:    
image 2982:     
image 5843:     
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.431446)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.320349)
average loss on validation: 2.571
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3717107772827148
Cider scores: 0.5590172874795168
Read data: 0.36343884468078613
Cider scores: 0.583601928433535
Read data: 0.23793244361877441
Cider scores: 0.6152273131895598
Read data: 0.2392129898071289
Cider scores: 0.553201245524886
Read data: 0.20111465454101562
Cider scores: 0.6199712641026265
Read data: 0.19102025032043457
Cider scores: 0.4903394142440468
Read data: 0.19578957557678223
Cider scores: 0.4971357161888708
Read data: 0.17978572845458984
Cider scores: 0.5836771706005726
Read data: 0.20370149612426758
Cider scores: 0.5411685860483695
Read data: 0.1828153133392334
Cider scores: 0.6365012582039437
Read data: 0.1803421974182129
Cider scores: 0.63277501186379
Read data: 0.23578310012817383
Cider scores: 0.6517502008832431
Read data: 0.19704747200012207
Cider scores: 0.5458150315510188
Read data: 0.17936944961547852
Cider scores: 0.5900707642843808
Read data: 0.18074679374694824
Cider scores: 0.6362518711300188
Read data: 0.1689765453338623
Cider scores: 0.5784733144066821
Read data: 0.16275739669799805
Cider scores: 0.4072364690206643
Read data: 0.1619107723236084
Cider scores: 0.676809719589502
Read data: 0.16708111763000488
Cider scores: 0.605957118937887
Read data: 0.16459870338439941
Cider scores: 0.8098373760676522
Average cider score on test set: 0.591
End calculating cider score on TEST data set
===============================================
Read data: 0.16683650016784668
iter 18000 (epoch 29), train_loss = 2.545, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 18001 (epoch 30), train_loss = 2.535, time/batch = 0.034
Read data: 0.00010752677917480469
iter 18002 (epoch 30), train_loss = 2.225, time/batch = 0.020
Read data: 0.00012826919555664062
iter 18003 (epoch 30), train_loss = 2.411, time/batch = 0.027
Read data: 0.00011324882507324219
iter 18004 (epoch 30), train_loss = 2.199, time/batch = 0.025
Read data: 0.0001246929168701172
iter 18005 (epoch 30), train_loss = 2.616, time/batch = 0.026
Read data: 0.00016999244689941406
iter 18006 (epoch 30), train_loss = 2.184, time/batch = 0.031
Read data: 9.059906005859375e-05
iter 18007 (epoch 30), train_loss = 2.629, time/batch = 0.029
Read data: 0.0001380443572998047
iter 18008 (epoch 30), train_loss = 2.217, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 18009 (epoch 30), train_loss = 2.187, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 18010 (epoch 30), train_loss = 2.248, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 18011 (epoch 30), train_loss = 2.905, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 18012 (epoch 30), train_loss = 2.463, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 18013 (epoch 30), train_loss = 2.281, time/batch = 0.024
Read data: 0.00010061264038085938
iter 18014 (epoch 30), train_loss = 2.460, time/batch = 0.028
Read data: 7.319450378417969e-05
iter 18015 (epoch 30), train_loss = 2.228, time/batch = 0.024
Read data: 0.00010633468627929688
iter 18016 (epoch 30), train_loss = 1.988, time/batch = 0.025
Read data: 0.00010204315185546875
iter 18017 (epoch 30), train_loss = 2.286, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 18018 (epoch 30), train_loss = 2.682, time/batch = 0.031
Read data: 0.0001068115234375
iter 18019 (epoch 30), train_loss = 2.472, time/batch = 0.025
Read data: 9.417533874511719e-05
iter 18020 (epoch 30), train_loss = 2.151, time/batch = 0.031
Read data: 9.942054748535156e-05
iter 18021 (epoch 30), train_loss = 2.316, time/batch = 0.030
Read data: 0.00016546249389648438
iter 18022 (epoch 30), train_loss = 2.644, time/batch = 0.025
Read data: 6.985664367675781e-05
iter 18023 (epoch 30), train_loss = 2.283, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 18024 (epoch 30), train_loss = 2.479, time/batch = 0.027
Read data: 0.0001823902130126953
iter 18025 (epoch 30), train_loss = 2.045, time/batch = 0.020
Read data: 0.00016951560974121094
iter 18026 (epoch 30), train_loss = 2.203, time/batch = 0.030
Read data: 9.298324584960938e-05
iter 18027 (epoch 30), train_loss = 2.501, time/batch = 0.038
Read data: 8.296966552734375e-05
iter 18028 (epoch 30), train_loss = 2.211, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 18029 (epoch 30), train_loss = 2.179, time/batch = 0.027
Read data: 0.0001494884490966797
iter 18030 (epoch 30), train_loss = 2.376, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 18031 (epoch 30), train_loss = 2.163, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 18032 (epoch 30), train_loss = 2.105, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 18033 (epoch 30), train_loss = 2.613, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 18034 (epoch 30), train_loss = 2.306, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 18035 (epoch 30), train_loss = 2.314, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 18036 (epoch 30), train_loss = 2.236, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 18037 (epoch 30), train_loss = 2.205, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 18038 (epoch 30), train_loss = 2.157, time/batch = 0.024
Read data: 0.0001800060272216797
iter 18039 (epoch 30), train_loss = 2.343, time/batch = 0.030
Read data: 9.584426879882812e-05
iter 18040 (epoch 30), train_loss = 2.147, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 18041 (epoch 30), train_loss = 2.567, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 18042 (epoch 30), train_loss = 2.108, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 18043 (epoch 30), train_loss = 2.481, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 18044 (epoch 30), train_loss = 2.453, time/batch = 0.030
Read data: 7.62939453125e-05
iter 18045 (epoch 30), train_loss = 2.239, time/batch = 0.022
Read data: 0.0001380443572998047
iter 18046 (epoch 30), train_loss = 2.303, time/batch = 0.038
Read data: 8.988380432128906e-05
iter 18047 (epoch 30), train_loss = 2.548, time/batch = 0.029
Read data: 0.00013446807861328125
iter 18048 (epoch 30), train_loss = 1.868, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 18049 (epoch 30), train_loss = 2.627, time/batch = 0.022
Read data: 0.00017404556274414062
iter 18050 (epoch 30), train_loss = 2.373, time/batch = 0.032
Read data: 8.20159912109375e-05
iter 18051 (epoch 30), train_loss = 2.337, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 18052 (epoch 30), train_loss = 2.544, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 18053 (epoch 30), train_loss = 2.302, time/batch = 0.021
Read data: 0.0001404285430908203
iter 18054 (epoch 30), train_loss = 2.312, time/batch = 0.028
Read data: 0.00018286705017089844
iter 18055 (epoch 30), train_loss = 2.677, time/batch = 0.030
Read data: 0.000102996826171875
iter 18056 (epoch 30), train_loss = 2.519, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 18057 (epoch 30), train_loss = 2.132, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 18058 (epoch 30), train_loss = 2.389, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 18059 (epoch 30), train_loss = 2.712, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 18060 (epoch 30), train_loss = 2.837, time/batch = 0.029
Read data: 9.632110595703125e-05
iter 18061 (epoch 30), train_loss = 2.118, time/batch = 0.025
Read data: 0.00014543533325195312
iter 18062 (epoch 30), train_loss = 2.485, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 18063 (epoch 30), train_loss = 2.494, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 18064 (epoch 30), train_loss = 1.967, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 18065 (epoch 30), train_loss = 2.598, time/batch = 0.028
Read data: 0.00018739700317382812
iter 18066 (epoch 30), train_loss = 2.191, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 18067 (epoch 30), train_loss = 2.295, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 18068 (epoch 30), train_loss = 2.469, time/batch = 0.029
Read data: 9.512901306152344e-05
iter 18069 (epoch 30), train_loss = 2.258, time/batch = 0.020
Read data: 8.821487426757812e-05
iter 18070 (epoch 30), train_loss = 2.611, time/batch = 0.026
Read data: 9.226799011230469e-05
iter 18071 (epoch 30), train_loss = 1.704, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 18072 (epoch 30), train_loss = 2.198, time/batch = 0.024
Read data: 9.393692016601562e-05
iter 18073 (epoch 30), train_loss = 2.965, time/batch = 0.026
Read data: 0.0001685619354248047
iter 18074 (epoch 30), train_loss = 2.655, time/batch = 0.026
Read data: 8.96453857421875e-05
iter 18075 (epoch 30), train_loss = 2.680, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 18076 (epoch 30), train_loss = 2.367, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 18077 (epoch 30), train_loss = 2.676, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 18078 (epoch 30), train_loss = 2.213, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 18079 (epoch 30), train_loss = 2.828, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 18080 (epoch 30), train_loss = 2.290, time/batch = 0.031
Read data: 9.655952453613281e-05
iter 18081 (epoch 30), train_loss = 2.182, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 18082 (epoch 30), train_loss = 2.156, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 18083 (epoch 30), train_loss = 2.370, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 18084 (epoch 30), train_loss = 2.344, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 18085 (epoch 30), train_loss = 2.442, time/batch = 0.030
Read data: 9.417533874511719e-05
iter 18086 (epoch 30), train_loss = 2.123, time/batch = 0.035
Read data: 8.630752563476562e-05
iter 18087 (epoch 30), train_loss = 2.155, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 18088 (epoch 30), train_loss = 2.442, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 18089 (epoch 30), train_loss = 2.104, time/batch = 0.029
Read data: 9.846687316894531e-05
iter 18090 (epoch 30), train_loss = 2.382, time/batch = 0.021
Read data: 0.00011229515075683594
iter 18091 (epoch 30), train_loss = 2.363, time/batch = 0.030
Read data: 9.512901306152344e-05
iter 18092 (epoch 30), train_loss = 2.041, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 18093 (epoch 30), train_loss = 2.515, time/batch = 0.024
Read data: 0.0001857280731201172
iter 18094 (epoch 30), train_loss = 2.435, time/batch = 0.038
Read data: 0.00014591217041015625
iter 18095 (epoch 30), train_loss = 2.868, time/batch = 0.027
Read data: 0.00010156631469726562
iter 18096 (epoch 30), train_loss = 2.466, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 18097 (epoch 30), train_loss = 2.475, time/batch = 0.027
Read data: 0.00016117095947265625
iter 18098 (epoch 30), train_loss = 2.259, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 18099 (epoch 30), train_loss = 2.658, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 18100 (epoch 30), train_loss = 2.256, time/batch = 0.027
Read data: 8.392333984375e-05
iter 18101 (epoch 30), train_loss = 2.579, time/batch = 0.027
Read data: 0.00012421607971191406
iter 18102 (epoch 30), train_loss = 2.430, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 18103 (epoch 30), train_loss = 2.520, time/batch = 0.027
Read data: 9.584426879882812e-05
iter 18104 (epoch 30), train_loss = 2.392, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 18105 (epoch 30), train_loss = 2.512, time/batch = 0.030
Read data: 9.703636169433594e-05
iter 18106 (epoch 30), train_loss = 2.504, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 18107 (epoch 30), train_loss = 2.436, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 18108 (epoch 30), train_loss = 2.239, time/batch = 0.037
Read data: 8.249282836914062e-05
iter 18109 (epoch 30), train_loss = 2.450, time/batch = 0.028
Read data: 0.0001373291015625
iter 18110 (epoch 30), train_loss = 2.331, time/batch = 0.028
Read data: 8.726119995117188e-05
iter 18111 (epoch 30), train_loss = 2.334, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 18112 (epoch 30), train_loss = 2.312, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 18113 (epoch 30), train_loss = 2.210, time/batch = 0.028
Read data: 0.00012159347534179688
iter 18114 (epoch 30), train_loss = 2.328, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 18115 (epoch 30), train_loss = 2.470, time/batch = 0.034
Read data: 9.918212890625e-05
iter 18116 (epoch 30), train_loss = 2.543, time/batch = 0.031
Read data: 0.00010037422180175781
iter 18117 (epoch 30), train_loss = 2.237, time/batch = 0.027
Read data: 0.00013327598571777344
iter 18118 (epoch 30), train_loss = 2.231, time/batch = 0.027
Read data: 0.0001583099365234375
iter 18119 (epoch 30), train_loss = 2.160, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 18120 (epoch 30), train_loss = 2.737, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 18121 (epoch 30), train_loss = 2.687, time/batch = 0.026
Read data: 0.00010275840759277344
iter 18122 (epoch 30), train_loss = 2.257, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 18123 (epoch 30), train_loss = 2.390, time/batch = 0.028
Read data: 9.012222290039062e-05
iter 18124 (epoch 30), train_loss = 2.258, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 18125 (epoch 30), train_loss = 1.983, time/batch = 0.023
Read data: 0.0001575946807861328
iter 18126 (epoch 30), train_loss = 2.658, time/batch = 0.045
Read data: 8.58306884765625e-05
iter 18127 (epoch 30), train_loss = 2.656, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 18128 (epoch 30), train_loss = 2.263, time/batch = 0.033
Read data: 8.7738037109375e-05
iter 18129 (epoch 30), train_loss = 1.899, time/batch = 0.022
Read data: 0.00015616416931152344
iter 18130 (epoch 30), train_loss = 2.147, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 18131 (epoch 30), train_loss = 2.679, time/batch = 0.029
Read data: 9.679794311523438e-05
iter 18132 (epoch 30), train_loss = 2.638, time/batch = 0.032
Read data: 9.608268737792969e-05
iter 18133 (epoch 30), train_loss = 2.425, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 18134 (epoch 30), train_loss = 2.390, time/batch = 0.029
Read data: 0.00016736984252929688
iter 18135 (epoch 30), train_loss = 2.686, time/batch = 0.031
Read data: 0.000102996826171875
iter 18136 (epoch 30), train_loss = 2.180, time/batch = 0.023
Read data: 9.751319885253906e-05
iter 18137 (epoch 30), train_loss = 2.417, time/batch = 0.036
Read data: 0.0001533031463623047
iter 18138 (epoch 30), train_loss = 2.656, time/batch = 0.033
Read data: 0.00013399124145507812
iter 18139 (epoch 30), train_loss = 2.346, time/batch = 0.029
Read data: 8.893013000488281e-05
iter 18140 (epoch 30), train_loss = 2.448, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 18141 (epoch 30), train_loss = 2.434, time/batch = 0.021
Read data: 0.00015854835510253906
iter 18142 (epoch 30), train_loss = 1.912, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 18143 (epoch 30), train_loss = 2.436, time/batch = 0.025
Read data: 0.00011014938354492188
iter 18144 (epoch 30), train_loss = 2.625, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 18145 (epoch 30), train_loss = 2.334, time/batch = 0.031
Read data: 0.00024628639221191406
iter 18146 (epoch 30), train_loss = 1.925, time/batch = 0.033
Read data: 0.00013566017150878906
iter 18147 (epoch 30), train_loss = 2.673, time/batch = 0.029
Read data: 9.512901306152344e-05
iter 18148 (epoch 30), train_loss = 2.453, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 18149 (epoch 30), train_loss = 2.236, time/batch = 0.024
Read data: 0.0002262592315673828
iter 18150 (epoch 30), train_loss = 2.407, time/batch = 0.038
Read data: 0.00010371208190917969
iter 18151 (epoch 30), train_loss = 2.425, time/batch = 0.027
Read data: 0.00011229515075683594
iter 18152 (epoch 30), train_loss = 2.464, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 18153 (epoch 30), train_loss = 2.372, time/batch = 0.029
Read data: 0.00014901161193847656
iter 18154 (epoch 30), train_loss = 2.488, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 18155 (epoch 30), train_loss = 2.319, time/batch = 0.032
Read data: 9.918212890625e-05
iter 18156 (epoch 30), train_loss = 2.573, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 18157 (epoch 30), train_loss = 2.637, time/batch = 0.023
Read data: 0.00022339820861816406
iter 18158 (epoch 30), train_loss = 2.270, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 18159 (epoch 30), train_loss = 2.346, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 18160 (epoch 30), train_loss = 2.386, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 18161 (epoch 30), train_loss = 2.573, time/batch = 0.027
Read data: 0.00017952919006347656
iter 18162 (epoch 30), train_loss = 2.484, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 18163 (epoch 30), train_loss = 2.489, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 18164 (epoch 30), train_loss = 2.019, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 18165 (epoch 30), train_loss = 2.264, time/batch = 0.030
Read data: 0.00015425682067871094
iter 18166 (epoch 30), train_loss = 2.524, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 18167 (epoch 30), train_loss = 2.220, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 18168 (epoch 30), train_loss = 2.345, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 18169 (epoch 30), train_loss = 2.360, time/batch = 0.027
Read data: 0.00015020370483398438
iter 18170 (epoch 30), train_loss = 2.785, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 18171 (epoch 30), train_loss = 2.076, time/batch = 0.037
Read data: 0.00010204315185546875
iter 18172 (epoch 30), train_loss = 2.262, time/batch = 0.025
Read data: 0.00010228157043457031
iter 18173 (epoch 30), train_loss = 2.105, time/batch = 0.025
Read data: 0.00018143653869628906
iter 18174 (epoch 30), train_loss = 2.721, time/batch = 0.030
Read data: 0.00026106834411621094
iter 18175 (epoch 30), train_loss = 2.384, time/batch = 0.027
Read data: 9.5367431640625e-05
iter 18176 (epoch 30), train_loss = 2.403, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 18177 (epoch 30), train_loss = 2.451, time/batch = 0.023
Read data: 0.0002453327178955078
iter 18178 (epoch 30), train_loss = 2.170, time/batch = 0.023
Read data: 9.1552734375e-05
iter 18179 (epoch 30), train_loss = 2.006, time/batch = 0.033
Read data: 9.441375732421875e-05
iter 18180 (epoch 30), train_loss = 2.814, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 18181 (epoch 30), train_loss = 3.021, time/batch = 0.040
Read data: 9.131431579589844e-05
iter 18182 (epoch 30), train_loss = 2.668, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 18183 (epoch 30), train_loss = 2.399, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 18184 (epoch 30), train_loss = 2.512, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 18185 (epoch 30), train_loss = 2.389, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 18186 (epoch 30), train_loss = 2.986, time/batch = 0.035
Read data: 9.775161743164062e-05
iter 18187 (epoch 30), train_loss = 2.714, time/batch = 0.026
Read data: 9.846687316894531e-05
iter 18188 (epoch 30), train_loss = 2.428, time/batch = 0.033
Read data: 9.942054748535156e-05
iter 18189 (epoch 30), train_loss = 2.448, time/batch = 0.021
Read data: 0.0001418590545654297
iter 18190 (epoch 30), train_loss = 2.543, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 18191 (epoch 30), train_loss = 2.567, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 18192 (epoch 30), train_loss = 2.452, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 18193 (epoch 30), train_loss = 2.842, time/batch = 0.021
Read data: 0.00012755393981933594
iter 18194 (epoch 30), train_loss = 2.100, time/batch = 0.022
Read data: 9.965896606445312e-05
iter 18195 (epoch 30), train_loss = 2.413, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 18196 (epoch 30), train_loss = 2.358, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 18197 (epoch 30), train_loss = 2.679, time/batch = 0.037
Read data: 0.0001506805419921875
iter 18198 (epoch 30), train_loss = 2.345, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 18199 (epoch 30), train_loss = 2.476, time/batch = 0.039
Read data: 8.344650268554688e-05
iter 18200 (epoch 30), train_loss = 2.404, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 18201 (epoch 30), train_loss = 2.176, time/batch = 0.023
Read data: 0.00017714500427246094
iter 18202 (epoch 30), train_loss = 2.311, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 18203 (epoch 30), train_loss = 2.659, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 18204 (epoch 30), train_loss = 2.557, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 18205 (epoch 30), train_loss = 2.513, time/batch = 0.029
Read data: 0.00012993812561035156
iter 18206 (epoch 30), train_loss = 2.763, time/batch = 0.027
Read data: 9.942054748535156e-05
iter 18207 (epoch 30), train_loss = 2.145, time/batch = 0.023
Read data: 0.00010085105895996094
iter 18208 (epoch 30), train_loss = 2.410, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 18209 (epoch 30), train_loss = 2.377, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 18210 (epoch 30), train_loss = 1.959, time/batch = 0.031
Read data: 9.560585021972656e-05
iter 18211 (epoch 30), train_loss = 2.623, time/batch = 0.037
Read data: 8.630752563476562e-05
iter 18212 (epoch 30), train_loss = 2.625, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 18213 (epoch 30), train_loss = 2.689, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 18214 (epoch 30), train_loss = 2.416, time/batch = 0.027
Read data: 9.775161743164062e-05
iter 18215 (epoch 30), train_loss = 2.344, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 18216 (epoch 30), train_loss = 2.021, time/batch = 0.023
Read data: 0.0001125335693359375
iter 18217 (epoch 30), train_loss = 3.037, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 18218 (epoch 30), train_loss = 2.414, time/batch = 0.035
Read data: 8.034706115722656e-05
iter 18219 (epoch 30), train_loss = 2.396, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 18220 (epoch 30), train_loss = 2.249, time/batch = 0.022
Read data: 8.392333984375e-05
iter 18221 (epoch 30), train_loss = 2.539, time/batch = 0.031
Read data: 0.00012946128845214844
iter 18222 (epoch 30), train_loss = 2.692, time/batch = 0.034
Read data: 9.584426879882812e-05
iter 18223 (epoch 30), train_loss = 1.914, time/batch = 0.030
Read data: 0.00010633468627929688
iter 18224 (epoch 30), train_loss = 2.764, time/batch = 0.035
Read data: 0.0001308917999267578
iter 18225 (epoch 30), train_loss = 2.454, time/batch = 0.027
Read data: 0.00018095970153808594
iter 18226 (epoch 30), train_loss = 2.039, time/batch = 0.023
Read data: 0.0001423358917236328
iter 18227 (epoch 30), train_loss = 2.427, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 18228 (epoch 30), train_loss = 3.025, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 18229 (epoch 30), train_loss = 3.011, time/batch = 0.030
Read data: 0.0001304149627685547
iter 18230 (epoch 30), train_loss = 2.426, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 18231 (epoch 30), train_loss = 2.199, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 18232 (epoch 30), train_loss = 2.412, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 18233 (epoch 30), train_loss = 2.662, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 18234 (epoch 30), train_loss = 2.178, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 18235 (epoch 30), train_loss = 2.346, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 18236 (epoch 30), train_loss = 2.274, time/batch = 0.021
Read data: 8.96453857421875e-05
iter 18237 (epoch 30), train_loss = 2.301, time/batch = 0.029
Read data: 0.00010633468627929688
iter 18238 (epoch 30), train_loss = 2.654, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 18239 (epoch 30), train_loss = 2.635, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 18240 (epoch 30), train_loss = 2.536, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 18241 (epoch 30), train_loss = 2.594, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 18242 (epoch 30), train_loss = 2.070, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 18243 (epoch 30), train_loss = 2.610, time/batch = 0.021
Read data: 8.249282836914062e-05
iter 18244 (epoch 30), train_loss = 2.285, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 18245 (epoch 30), train_loss = 2.546, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 18246 (epoch 30), train_loss = 2.393, time/batch = 0.029
Read data: 9.560585021972656e-05
iter 18247 (epoch 30), train_loss = 2.433, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 18248 (epoch 30), train_loss = 2.486, time/batch = 0.023
Read data: 9.274482727050781e-05
iter 18249 (epoch 30), train_loss = 2.295, time/batch = 0.021
Read data: 0.0001361370086669922
iter 18250 (epoch 30), train_loss = 2.540, time/batch = 0.021
Read data: 8.058547973632812e-05
iter 18251 (epoch 30), train_loss = 2.526, time/batch = 0.034
Read data: 8.916854858398438e-05
iter 18252 (epoch 30), train_loss = 2.543, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 18253 (epoch 30), train_loss = 2.612, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 18254 (epoch 30), train_loss = 2.633, time/batch = 0.027
Read data: 9.1552734375e-05
iter 18255 (epoch 30), train_loss = 2.507, time/batch = 0.027
Read data: 9.465217590332031e-05
iter 18256 (epoch 30), train_loss = 2.581, time/batch = 0.026
Read data: 0.00010371208190917969
iter 18257 (epoch 30), train_loss = 2.448, time/batch = 0.031
Read data: 0.0001430511474609375
iter 18258 (epoch 30), train_loss = 2.511, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 18259 (epoch 30), train_loss = 2.248, time/batch = 0.023
Read data: 0.00012087821960449219
iter 18260 (epoch 30), train_loss = 2.780, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 18261 (epoch 30), train_loss = 2.189, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 18262 (epoch 30), train_loss = 2.558, time/batch = 0.022
Read data: 0.00010085105895996094
iter 18263 (epoch 30), train_loss = 2.226, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 18264 (epoch 30), train_loss = 2.285, time/batch = 0.025
Read data: 0.00010609626770019531
iter 18265 (epoch 30), train_loss = 2.232, time/batch = 0.024
Read data: 0.0001399517059326172
iter 18266 (epoch 30), train_loss = 2.641, time/batch = 0.033
Read data: 0.00014710426330566406
iter 18267 (epoch 30), train_loss = 2.122, time/batch = 0.024
Read data: 0.0001437664031982422
iter 18268 (epoch 30), train_loss = 2.679, time/batch = 0.023
Read data: 0.00011992454528808594
iter 18269 (epoch 30), train_loss = 2.337, time/batch = 0.028
Read data: 0.0001785755157470703
iter 18270 (epoch 30), train_loss = 2.314, time/batch = 0.037
Read data: 0.00013208389282226562
iter 18271 (epoch 30), train_loss = 2.416, time/batch = 0.033
Read data: 9.369850158691406e-05
iter 18272 (epoch 30), train_loss = 2.431, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 18273 (epoch 30), train_loss = 2.384, time/batch = 0.025
Read data: 0.0001385211944580078
iter 18274 (epoch 30), train_loss = 2.110, time/batch = 0.026
Read data: 0.00016427040100097656
iter 18275 (epoch 30), train_loss = 2.366, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 18276 (epoch 30), train_loss = 2.518, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 18277 (epoch 30), train_loss = 2.794, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 18278 (epoch 30), train_loss = 2.065, time/batch = 0.025
Read data: 0.00011944770812988281
iter 18279 (epoch 30), train_loss = 2.517, time/batch = 0.029
Read data: 0.00011754035949707031
iter 18280 (epoch 30), train_loss = 2.275, time/batch = 0.021
Read data: 9.72747802734375e-05
iter 18281 (epoch 30), train_loss = 2.277, time/batch = 0.021
Read data: 0.00015544891357421875
iter 18282 (epoch 30), train_loss = 2.257, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 18283 (epoch 30), train_loss = 2.403, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 18284 (epoch 30), train_loss = 2.415, time/batch = 0.031
Read data: 0.00011324882507324219
iter 18285 (epoch 30), train_loss = 2.147, time/batch = 0.022
Read data: 9.632110595703125e-05
iter 18286 (epoch 30), train_loss = 2.520, time/batch = 0.026
Read data: 0.00010013580322265625
iter 18287 (epoch 30), train_loss = 2.361, time/batch = 0.021
Read data: 8.845329284667969e-05
iter 18288 (epoch 30), train_loss = 2.436, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 18289 (epoch 30), train_loss = 2.398, time/batch = 0.027
Read data: 0.0001575946807861328
iter 18290 (epoch 30), train_loss = 2.343, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 18291 (epoch 30), train_loss = 2.403, time/batch = 0.021
Read data: 8.225440979003906e-05
iter 18292 (epoch 30), train_loss = 2.133, time/batch = 0.031
Read data: 0.00011730194091796875
iter 18293 (epoch 30), train_loss = 2.150, time/batch = 0.029
Read data: 0.0001544952392578125
iter 18294 (epoch 30), train_loss = 2.087, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 18295 (epoch 30), train_loss = 2.023, time/batch = 0.023
Read data: 0.00011992454528808594
iter 18296 (epoch 30), train_loss = 2.529, time/batch = 0.029
Read data: 8.392333984375e-05
iter 18297 (epoch 30), train_loss = 2.024, time/batch = 0.027
Read data: 0.00012683868408203125
iter 18298 (epoch 30), train_loss = 2.540, time/batch = 0.022
Read data: 8.916854858398438e-05
iter 18299 (epoch 30), train_loss = 2.491, time/batch = 0.029
Read data: 0.00026702880859375
iter 18300 (epoch 30), train_loss = 2.479, time/batch = 0.019
Read data: 8.96453857421875e-05
iter 18301 (epoch 30), train_loss = 2.244, time/batch = 0.027
Read data: 9.5367431640625e-05
iter 18302 (epoch 30), train_loss = 2.151, time/batch = 0.022
Read data: 0.00012159347534179688
iter 18303 (epoch 30), train_loss = 2.502, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 18304 (epoch 30), train_loss = 2.648, time/batch = 0.036
Read data: 0.0001270771026611328
iter 18305 (epoch 30), train_loss = 2.654, time/batch = 0.023
Read data: 0.00013327598571777344
iter 18306 (epoch 30), train_loss = 2.443, time/batch = 0.033
Read data: 0.00013446807861328125
iter 18307 (epoch 30), train_loss = 2.793, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 18308 (epoch 30), train_loss = 2.357, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 18309 (epoch 30), train_loss = 2.628, time/batch = 0.021
Read data: 0.00012731552124023438
iter 18310 (epoch 30), train_loss = 2.663, time/batch = 0.025
Read data: 0.00012755393981933594
iter 18311 (epoch 30), train_loss = 2.671, time/batch = 0.024
Read data: 8.726119995117188e-05
iter 18312 (epoch 30), train_loss = 2.674, time/batch = 0.030
Read data: 9.298324584960938e-05
iter 18313 (epoch 30), train_loss = 2.465, time/batch = 0.034
Read data: 0.00018095970153808594
iter 18314 (epoch 30), train_loss = 2.405, time/batch = 0.029
Read data: 0.00012922286987304688
iter 18315 (epoch 30), train_loss = 2.466, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 18316 (epoch 30), train_loss = 2.436, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 18317 (epoch 30), train_loss = 2.373, time/batch = 0.023
Read data: 0.00012803077697753906
iter 18318 (epoch 30), train_loss = 2.807, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 18319 (epoch 30), train_loss = 2.499, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 18320 (epoch 30), train_loss = 2.625, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 18321 (epoch 30), train_loss = 1.977, time/batch = 0.021
Read data: 9.322166442871094e-05
iter 18322 (epoch 30), train_loss = 2.535, time/batch = 0.032
Read data: 0.00011467933654785156
iter 18323 (epoch 30), train_loss = 2.845, time/batch = 0.027
Read data: 0.00011968612670898438
iter 18324 (epoch 30), train_loss = 2.383, time/batch = 0.033
Read data: 0.0002105236053466797
iter 18325 (epoch 30), train_loss = 2.101, time/batch = 0.026
Read data: 0.000164031982421875
iter 18326 (epoch 30), train_loss = 2.358, time/batch = 0.025
Read data: 0.00012135505676269531
iter 18327 (epoch 30), train_loss = 2.831, time/batch = 0.027
Read data: 0.00012731552124023438
iter 18328 (epoch 30), train_loss = 2.222, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 18329 (epoch 30), train_loss = 2.194, time/batch = 0.029
Read data: 0.0001323223114013672
iter 18330 (epoch 30), train_loss = 1.948, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 18331 (epoch 30), train_loss = 2.180, time/batch = 0.028
Read data: 8.630752563476562e-05
iter 18332 (epoch 30), train_loss = 2.501, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 18333 (epoch 30), train_loss = 2.844, time/batch = 0.023
Read data: 0.0001308917999267578
iter 18334 (epoch 30), train_loss = 2.119, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 18335 (epoch 30), train_loss = 1.920, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 18336 (epoch 30), train_loss = 2.547, time/batch = 0.030
Read data: 0.00011444091796875
iter 18337 (epoch 30), train_loss = 2.394, time/batch = 0.025
Read data: 0.00015997886657714844
iter 18338 (epoch 30), train_loss = 2.466, time/batch = 0.038
Read data: 8.869171142578125e-05
iter 18339 (epoch 30), train_loss = 1.989, time/batch = 0.024
Read data: 0.00015974044799804688
iter 18340 (epoch 30), train_loss = 2.237, time/batch = 0.031
Read data: 8.916854858398438e-05
iter 18341 (epoch 30), train_loss = 2.496, time/batch = 0.026
Read data: 0.00013494491577148438
iter 18342 (epoch 30), train_loss = 2.114, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 18343 (epoch 30), train_loss = 1.873, time/batch = 0.027
Read data: 0.00012230873107910156
iter 18344 (epoch 30), train_loss = 2.446, time/batch = 0.027
Read data: 0.00011467933654785156
iter 18345 (epoch 30), train_loss = 2.513, time/batch = 0.027
Read data: 0.00012373924255371094
iter 18346 (epoch 30), train_loss = 2.744, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 18347 (epoch 30), train_loss = 2.125, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 18348 (epoch 30), train_loss = 2.446, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 18349 (epoch 30), train_loss = 2.389, time/batch = 0.032
Read data: 0.0002808570861816406
iter 18350 (epoch 30), train_loss = 2.154, time/batch = 0.022
Read data: 9.489059448242188e-05
iter 18351 (epoch 30), train_loss = 2.805, time/batch = 0.027
Read data: 0.00014853477478027344
iter 18352 (epoch 30), train_loss = 2.162, time/batch = 0.023
Read data: 0.00011944770812988281
iter 18353 (epoch 30), train_loss = 2.173, time/batch = 0.024
Read data: 0.00010418891906738281
iter 18354 (epoch 30), train_loss = 2.117, time/batch = 0.024
Read data: 0.00010895729064941406
iter 18355 (epoch 30), train_loss = 2.483, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 18356 (epoch 30), train_loss = 2.785, time/batch = 0.021
Read data: 9.846687316894531e-05
iter 18357 (epoch 30), train_loss = 2.629, time/batch = 0.031
Read data: 0.00010061264038085938
iter 18358 (epoch 30), train_loss = 2.449, time/batch = 0.023
Read data: 0.0001220703125
iter 18359 (epoch 30), train_loss = 2.154, time/batch = 0.027
Read data: 0.00014591217041015625
iter 18360 (epoch 30), train_loss = 2.519, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 18361 (epoch 30), train_loss = 2.483, time/batch = 0.026
Read data: 0.00010919570922851562
iter 18362 (epoch 30), train_loss = 2.456, time/batch = 0.028
Read data: 0.00011205673217773438
iter 18363 (epoch 30), train_loss = 2.072, time/batch = 0.026
Read data: 0.00012111663818359375
iter 18364 (epoch 30), train_loss = 2.233, time/batch = 0.023
Read data: 0.00010395050048828125
iter 18365 (epoch 30), train_loss = 2.051, time/batch = 0.021
Read data: 9.465217590332031e-05
iter 18366 (epoch 30), train_loss = 2.382, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 18367 (epoch 30), train_loss = 2.380, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 18368 (epoch 30), train_loss = 2.603, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 18369 (epoch 30), train_loss = 2.356, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 18370 (epoch 30), train_loss = 2.394, time/batch = 0.026
Read data: 0.00010085105895996094
iter 18371 (epoch 30), train_loss = 2.364, time/batch = 0.022
Read data: 9.059906005859375e-05
iter 18372 (epoch 30), train_loss = 2.436, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 18373 (epoch 30), train_loss = 2.490, time/batch = 0.020
Read data: 0.00011801719665527344
iter 18374 (epoch 30), train_loss = 2.453, time/batch = 0.028
Read data: 0.00012087821960449219
iter 18375 (epoch 30), train_loss = 2.312, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 18376 (epoch 30), train_loss = 2.137, time/batch = 0.024
Read data: 0.0001327991485595703
iter 18377 (epoch 30), train_loss = 2.513, time/batch = 0.024
Read data: 0.00014543533325195312
iter 18378 (epoch 30), train_loss = 2.797, time/batch = 0.028
Read data: 0.00012087821960449219
iter 18379 (epoch 30), train_loss = 2.795, time/batch = 0.031
Read data: 0.00012612342834472656
iter 18380 (epoch 30), train_loss = 2.166, time/batch = 0.025
Read data: 0.00012063980102539062
iter 18381 (epoch 30), train_loss = 2.357, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 18382 (epoch 30), train_loss = 2.615, time/batch = 0.029
Read data: 0.00011587142944335938
iter 18383 (epoch 30), train_loss = 2.261, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 18384 (epoch 30), train_loss = 2.341, time/batch = 0.027
Read data: 9.655952453613281e-05
iter 18385 (epoch 30), train_loss = 2.359, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 18386 (epoch 30), train_loss = 2.376, time/batch = 0.030
Read data: 0.00012350082397460938
iter 18387 (epoch 30), train_loss = 2.331, time/batch = 0.029
Read data: 0.00012230873107910156
iter 18388 (epoch 30), train_loss = 2.169, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 18389 (epoch 30), train_loss = 2.451, time/batch = 0.031
Read data: 8.296966552734375e-05
iter 18390 (epoch 30), train_loss = 2.447, time/batch = 0.027
Read data: 8.392333984375e-05
iter 18391 (epoch 30), train_loss = 2.499, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 18392 (epoch 30), train_loss = 2.239, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 18393 (epoch 30), train_loss = 2.077, time/batch = 0.023
Read data: 0.00012087821960449219
iter 18394 (epoch 30), train_loss = 2.465, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 18395 (epoch 30), train_loss = 2.529, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18396 (epoch 30), train_loss = 2.508, time/batch = 0.025
Read data: 0.00010013580322265625
iter 18397 (epoch 30), train_loss = 2.747, time/batch = 0.028
Read data: 7.963180541992188e-05
iter 18398 (epoch 30), train_loss = 2.558, time/batch = 0.024
Read data: 0.00012540817260742188
iter 18399 (epoch 30), train_loss = 2.443, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 18400 (epoch 30), train_loss = 2.335, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 18401 (epoch 30), train_loss = 2.324, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 18402 (epoch 30), train_loss = 2.432, time/batch = 0.032
Read data: 8.130073547363281e-05
iter 18403 (epoch 30), train_loss = 2.436, time/batch = 0.040
Read data: 9.393692016601562e-05
iter 18404 (epoch 30), train_loss = 2.262, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 18405 (epoch 30), train_loss = 2.520, time/batch = 0.028
Read data: 0.00011515617370605469
iter 18406 (epoch 30), train_loss = 2.521, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 18407 (epoch 30), train_loss = 2.381, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 18408 (epoch 30), train_loss = 2.516, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 18409 (epoch 30), train_loss = 2.792, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 18410 (epoch 30), train_loss = 2.113, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 18411 (epoch 30), train_loss = 2.681, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 18412 (epoch 30), train_loss = 2.300, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 18413 (epoch 30), train_loss = 2.549, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 18414 (epoch 30), train_loss = 1.995, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 18415 (epoch 30), train_loss = 2.436, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 18416 (epoch 30), train_loss = 2.278, time/batch = 0.025
Read data: 9.1552734375e-05
iter 18417 (epoch 30), train_loss = 2.000, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 18418 (epoch 30), train_loss = 2.850, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 18419 (epoch 30), train_loss = 2.305, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 18420 (epoch 30), train_loss = 2.359, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 18421 (epoch 30), train_loss = 2.668, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 18422 (epoch 30), train_loss = 2.697, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 18423 (epoch 30), train_loss = 2.384, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 18424 (epoch 30), train_loss = 2.710, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 18425 (epoch 30), train_loss = 2.290, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 18426 (epoch 30), train_loss = 2.549, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 18427 (epoch 30), train_loss = 2.501, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 18428 (epoch 30), train_loss = 1.978, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 18429 (epoch 30), train_loss = 2.333, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 18430 (epoch 30), train_loss = 2.243, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 18431 (epoch 30), train_loss = 2.173, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 18432 (epoch 30), train_loss = 2.195, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 18433 (epoch 30), train_loss = 2.765, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 18434 (epoch 30), train_loss = 2.374, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 18435 (epoch 30), train_loss = 2.353, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 18436 (epoch 30), train_loss = 2.465, time/batch = 0.026
Read data: 9.512901306152344e-05
iter 18437 (epoch 30), train_loss = 2.425, time/batch = 0.031
Read data: 8.273124694824219e-05
iter 18438 (epoch 30), train_loss = 2.653, time/batch = 0.036
Read data: 8.7738037109375e-05
iter 18439 (epoch 30), train_loss = 2.251, time/batch = 0.033
Read data: 0.00013899803161621094
iter 18440 (epoch 30), train_loss = 2.648, time/batch = 0.024
Read data: 0.00013899803161621094
iter 18441 (epoch 30), train_loss = 2.676, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 18442 (epoch 30), train_loss = 2.156, time/batch = 0.033
Read data: 9.775161743164062e-05
iter 18443 (epoch 30), train_loss = 2.766, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 18444 (epoch 30), train_loss = 2.221, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 18445 (epoch 30), train_loss = 2.677, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18446 (epoch 30), train_loss = 2.914, time/batch = 0.025
Read data: 0.00011944770812988281
iter 18447 (epoch 30), train_loss = 2.386, time/batch = 0.034
Read data: 9.179115295410156e-05
iter 18448 (epoch 30), train_loss = 2.631, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 18449 (epoch 30), train_loss = 2.253, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 18450 (epoch 30), train_loss = 2.738, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 18451 (epoch 30), train_loss = 2.220, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 18452 (epoch 30), train_loss = 2.426, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 18453 (epoch 30), train_loss = 2.777, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 18454 (epoch 30), train_loss = 2.675, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 18455 (epoch 30), train_loss = 2.564, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 18456 (epoch 30), train_loss = 2.261, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 18457 (epoch 30), train_loss = 2.328, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 18458 (epoch 30), train_loss = 2.308, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 18459 (epoch 30), train_loss = 2.323, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 18460 (epoch 30), train_loss = 2.430, time/batch = 0.034
Read data: 8.416175842285156e-05
iter 18461 (epoch 30), train_loss = 2.270, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 18462 (epoch 30), train_loss = 2.718, time/batch = 0.038
Read data: 8.988380432128906e-05
iter 18463 (epoch 30), train_loss = 2.643, time/batch = 0.035
Read data: 9.012222290039062e-05
iter 18464 (epoch 30), train_loss = 2.554, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 18465 (epoch 30), train_loss = 2.262, time/batch = 0.028
Read data: 0.00011014938354492188
iter 18466 (epoch 30), train_loss = 2.394, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 18467 (epoch 30), train_loss = 1.932, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 18468 (epoch 30), train_loss = 2.507, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 18469 (epoch 30), train_loss = 2.229, time/batch = 0.025
Read data: 8.296966552734375e-05
iter 18470 (epoch 30), train_loss = 2.465, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 18471 (epoch 30), train_loss = 2.114, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 18472 (epoch 30), train_loss = 2.670, time/batch = 0.034
Read data: 8.177757263183594e-05
iter 18473 (epoch 30), train_loss = 2.245, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 18474 (epoch 30), train_loss = 2.473, time/batch = 0.030
Read data: 0.00013327598571777344
iter 18475 (epoch 30), train_loss = 2.789, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 18476 (epoch 30), train_loss = 2.160, time/batch = 0.022
Read data: 9.799003601074219e-05
iter 18477 (epoch 30), train_loss = 2.520, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 18478 (epoch 30), train_loss = 2.682, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 18479 (epoch 30), train_loss = 2.747, time/batch = 0.024
Read data: 9.560585021972656e-05
iter 18480 (epoch 30), train_loss = 2.653, time/batch = 0.038
Read data: 9.274482727050781e-05
iter 18481 (epoch 30), train_loss = 2.399, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 18482 (epoch 30), train_loss = 1.937, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 18483 (epoch 30), train_loss = 2.351, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 18484 (epoch 30), train_loss = 2.385, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 18485 (epoch 30), train_loss = 2.194, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 18486 (epoch 30), train_loss = 2.369, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 18487 (epoch 30), train_loss = 2.016, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 18488 (epoch 30), train_loss = 2.283, time/batch = 0.021
Read data: 0.00010514259338378906
iter 18489 (epoch 30), train_loss = 2.476, time/batch = 0.027
Read data: 7.724761962890625e-05
iter 18490 (epoch 30), train_loss = 2.201, time/batch = 0.025
Read data: 0.00010180473327636719
iter 18491 (epoch 30), train_loss = 2.537, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 18492 (epoch 30), train_loss = 2.215, time/batch = 0.037
Read data: 8.749961853027344e-05
iter 18493 (epoch 30), train_loss = 2.401, time/batch = 0.034
Read data: 8.749961853027344e-05
iter 18494 (epoch 30), train_loss = 2.550, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 18495 (epoch 30), train_loss = 2.248, time/batch = 0.023
Read data: 8.392333984375e-05
iter 18496 (epoch 30), train_loss = 2.161, time/batch = 0.040
Read data: 0.00013971328735351562
iter 18497 (epoch 30), train_loss = 2.902, time/batch = 0.031
Read data: 8.58306884765625e-05
iter 18498 (epoch 30), train_loss = 2.026, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 18499 (epoch 30), train_loss = 2.444, time/batch = 0.030
Read data: 0.0001690387725830078
iter 18500 (epoch 30), train_loss = 2.475, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 18501 (epoch 30), train_loss = 2.444, time/batch = 0.027
Read data: 8.392333984375e-05
iter 18502 (epoch 30), train_loss = 2.525, time/batch = 0.027
Read data: 8.392333984375e-05
iter 18503 (epoch 30), train_loss = 2.444, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 18504 (epoch 30), train_loss = 2.459, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 18505 (epoch 30), train_loss = 1.979, time/batch = 0.021
Read data: 8.368492126464844e-05
iter 18506 (epoch 30), train_loss = 2.426, time/batch = 0.024
Read data: 0.00010085105895996094
iter 18507 (epoch 30), train_loss = 2.284, time/batch = 0.029
Read data: 8.893013000488281e-05
iter 18508 (epoch 30), train_loss = 2.377, time/batch = 0.025
Read data: 9.799003601074219e-05
iter 18509 (epoch 30), train_loss = 2.307, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 18510 (epoch 30), train_loss = 2.192, time/batch = 0.031
Read data: 9.417533874511719e-05
iter 18511 (epoch 30), train_loss = 2.827, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 18512 (epoch 30), train_loss = 2.112, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 18513 (epoch 30), train_loss = 2.127, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18514 (epoch 30), train_loss = 2.332, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 18515 (epoch 30), train_loss = 2.551, time/batch = 0.024
Read data: 8.749961853027344e-05
iter 18516 (epoch 30), train_loss = 2.344, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 18517 (epoch 30), train_loss = 2.823, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 18518 (epoch 30), train_loss = 2.382, time/batch = 0.027
Read data: 0.0001518726348876953
iter 18519 (epoch 30), train_loss = 3.014, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 18520 (epoch 30), train_loss = 2.679, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 18521 (epoch 30), train_loss = 2.189, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 18522 (epoch 30), train_loss = 2.440, time/batch = 0.036
Read data: 0.00015544891357421875
iter 18523 (epoch 30), train_loss = 2.528, time/batch = 0.029
Read data: 8.726119995117188e-05
iter 18524 (epoch 30), train_loss = 2.816, time/batch = 0.031
Read data: 0.00013709068298339844
iter 18525 (epoch 30), train_loss = 2.401, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 18526 (epoch 30), train_loss = 2.596, time/batch = 0.023
Read data: 8.296966552734375e-05
iter 18527 (epoch 30), train_loss = 2.551, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 18528 (epoch 30), train_loss = 2.517, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 18529 (epoch 30), train_loss = 2.619, time/batch = 0.026
Read data: 0.0001423358917236328
iter 18530 (epoch 30), train_loss = 2.174, time/batch = 0.031
Read data: 9.465217590332031e-05
iter 18531 (epoch 30), train_loss = 2.403, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 18532 (epoch 30), train_loss = 2.217, time/batch = 0.023
Read data: 7.915496826171875e-05
iter 18533 (epoch 30), train_loss = 2.369, time/batch = 0.023
Read data: 0.00012636184692382812
iter 18534 (epoch 30), train_loss = 2.913, time/batch = 0.026
Read data: 9.083747863769531e-05
iter 18535 (epoch 30), train_loss = 2.014, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 18536 (epoch 30), train_loss = 2.366, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 18537 (epoch 30), train_loss = 2.582, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 18538 (epoch 30), train_loss = 2.298, time/batch = 0.029
Read data: 9.250640869140625e-05
iter 18539 (epoch 30), train_loss = 2.465, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 18540 (epoch 30), train_loss = 2.159, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 18541 (epoch 30), train_loss = 2.371, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 18542 (epoch 30), train_loss = 2.403, time/batch = 0.030
Read data: 0.00011968612670898438
iter 18543 (epoch 30), train_loss = 2.292, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 18544 (epoch 30), train_loss = 3.035, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 18545 (epoch 30), train_loss = 2.733, time/batch = 0.024
Read data: 0.00010585784912109375
iter 18546 (epoch 30), train_loss = 2.266, time/batch = 0.031
Read data: 0.0001404285430908203
iter 18547 (epoch 30), train_loss = 2.268, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 18548 (epoch 30), train_loss = 2.633, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 18549 (epoch 30), train_loss = 2.305, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 18550 (epoch 30), train_loss = 2.931, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 18551 (epoch 30), train_loss = 2.162, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 18552 (epoch 30), train_loss = 2.184, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 18553 (epoch 30), train_loss = 2.537, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 18554 (epoch 30), train_loss = 2.438, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 18555 (epoch 30), train_loss = 2.167, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 18556 (epoch 30), train_loss = 2.488, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 18557 (epoch 30), train_loss = 2.422, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 18558 (epoch 30), train_loss = 2.441, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 18559 (epoch 30), train_loss = 2.524, time/batch = 0.025
Read data: 9.179115295410156e-05
iter 18560 (epoch 30), train_loss = 2.446, time/batch = 0.025
Read data: 9.560585021972656e-05
iter 18561 (epoch 30), train_loss = 2.554, time/batch = 0.022
Read data: 0.0001747608184814453
iter 18562 (epoch 30), train_loss = 2.153, time/batch = 0.036
Read data: 0.00010251998901367188
iter 18563 (epoch 30), train_loss = 2.418, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 18564 (epoch 30), train_loss = 2.583, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 18565 (epoch 30), train_loss = 2.569, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 18566 (epoch 30), train_loss = 2.588, time/batch = 0.023
Read data: 9.250640869140625e-05
iter 18567 (epoch 30), train_loss = 2.321, time/batch = 0.023
Read data: 8.702278137207031e-05
iter 18568 (epoch 30), train_loss = 2.166, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 18569 (epoch 30), train_loss = 2.457, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 18570 (epoch 30), train_loss = 2.246, time/batch = 0.026
Read data: 0.00014710426330566406
iter 18571 (epoch 30), train_loss = 2.297, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 18572 (epoch 30), train_loss = 2.422, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 18573 (epoch 30), train_loss = 2.244, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 18574 (epoch 30), train_loss = 2.562, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 18575 (epoch 30), train_loss = 2.326, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 18576 (epoch 30), train_loss = 2.552, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 18577 (epoch 30), train_loss = 2.616, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 18578 (epoch 30), train_loss = 2.352, time/batch = 0.028
Read data: 9.894371032714844e-05
iter 18579 (epoch 30), train_loss = 2.225, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 18580 (epoch 30), train_loss = 2.341, time/batch = 0.023
Read data: 0.00012874603271484375
iter 18581 (epoch 30), train_loss = 2.339, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 18582 (epoch 30), train_loss = 2.325, time/batch = 0.033
Read data: 8.034706115722656e-05
iter 18583 (epoch 30), train_loss = 2.248, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 18584 (epoch 30), train_loss = 2.245, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 18585 (epoch 30), train_loss = 2.685, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 18586 (epoch 30), train_loss = 2.399, time/batch = 0.031
Read data: 9.608268737792969e-05
iter 18587 (epoch 30), train_loss = 2.843, time/batch = 0.027
Read data: 0.00013327598571777344
iter 18588 (epoch 30), train_loss = 2.094, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 18589 (epoch 30), train_loss = 2.670, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 18590 (epoch 30), train_loss = 2.105, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 18591 (epoch 30), train_loss = 2.574, time/batch = 0.023
Read data: 0.0009746551513671875
iter 18592 (epoch 30), train_loss = 1.802, time/batch = 0.021
Read data: 0.0001010894775390625
iter 18593 (epoch 30), train_loss = 2.663, time/batch = 0.028
Read data: 9.918212890625e-05
iter 18594 (epoch 30), train_loss = 2.416, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 18595 (epoch 30), train_loss = 2.744, time/batch = 0.027
Read data: 0.0001380443572998047
iter 18596 (epoch 30), train_loss = 2.188, time/batch = 0.028
Read data: 7.677078247070312e-05
iter 18597 (epoch 30), train_loss = 2.683, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 18598 (epoch 30), train_loss = 2.639, time/batch = 0.023
Read data: 0.00012993812561035156
iter 18599 (epoch 30), train_loss = 2.515, time/batch = 0.025
Read data: 7.534027099609375e-05
iter 18600 (epoch 30), train_loss = 2.511, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 18601 (epoch 31), train_loss = 2.499, time/batch = 0.026
Read data: 0.00012612342834472656
iter 18602 (epoch 31), train_loss = 2.585, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 18603 (epoch 31), train_loss = 2.289, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 18604 (epoch 31), train_loss = 2.611, time/batch = 0.022
Read data: 7.772445678710938e-05
iter 18605 (epoch 31), train_loss = 2.428, time/batch = 0.028
Read data: 0.00012636184692382812
iter 18606 (epoch 31), train_loss = 2.345, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 18607 (epoch 31), train_loss = 2.136, time/batch = 0.028
Read data: 0.0001609325408935547
iter 18608 (epoch 31), train_loss = 2.482, time/batch = 0.029
Read data: 0.00015354156494140625
iter 18609 (epoch 31), train_loss = 2.471, time/batch = 0.026
Read data: 0.00012826919555664062
iter 18610 (epoch 31), train_loss = 2.465, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 18611 (epoch 31), train_loss = 2.648, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 18612 (epoch 31), train_loss = 2.595, time/batch = 0.030
Read data: 0.00012350082397460938
iter 18613 (epoch 31), train_loss = 1.956, time/batch = 0.025
Read data: 0.00013017654418945312
iter 18614 (epoch 31), train_loss = 2.358, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 18615 (epoch 31), train_loss = 2.493, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 18616 (epoch 31), train_loss = 2.174, time/batch = 0.026
Read data: 0.00017690658569335938
iter 18617 (epoch 31), train_loss = 2.022, time/batch = 0.026
Read data: 0.0001308917999267578
iter 18618 (epoch 31), train_loss = 2.205, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 18619 (epoch 31), train_loss = 2.318, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 18620 (epoch 31), train_loss = 2.494, time/batch = 0.026
Read data: 0.000156402587890625
iter 18621 (epoch 31), train_loss = 2.878, time/batch = 0.025
Read data: 0.0001323223114013672
iter 18622 (epoch 31), train_loss = 2.491, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 18623 (epoch 31), train_loss = 2.622, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 18624 (epoch 31), train_loss = 2.665, time/batch = 0.027
Read data: 0.00021791458129882812
iter 18625 (epoch 31), train_loss = 2.657, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 18626 (epoch 31), train_loss = 2.470, time/batch = 0.035
Read data: 8.845329284667969e-05
iter 18627 (epoch 31), train_loss = 2.727, time/batch = 0.028
Read data: 0.0001220703125
iter 18628 (epoch 31), train_loss = 2.386, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 18629 (epoch 31), train_loss = 2.725, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 18630 (epoch 31), train_loss = 2.273, time/batch = 0.021
Read data: 7.867813110351562e-05
iter 18631 (epoch 31), train_loss = 2.314, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 18632 (epoch 31), train_loss = 2.444, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 18633 (epoch 31), train_loss = 2.834, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 18634 (epoch 31), train_loss = 2.611, time/batch = 0.023
Read data: 8.845329284667969e-05
iter 18635 (epoch 31), train_loss = 2.441, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 18636 (epoch 31), train_loss = 2.881, time/batch = 0.036
Read data: 7.891654968261719e-05
iter 18637 (epoch 31), train_loss = 2.735, time/batch = 0.026
Read data: 0.0001671314239501953
iter 18638 (epoch 31), train_loss = 2.242, time/batch = 0.021
Read data: 7.963180541992188e-05
iter 18639 (epoch 31), train_loss = 1.939, time/batch = 0.023
Read data: 0.00010132789611816406
iter 18640 (epoch 31), train_loss = 2.024, time/batch = 0.022
Read data: 0.00013327598571777344
iter 18641 (epoch 31), train_loss = 2.031, time/batch = 0.021
Read data: 9.393692016601562e-05
iter 18642 (epoch 31), train_loss = 2.526, time/batch = 0.025
Read data: 0.000133514404296875
iter 18643 (epoch 31), train_loss = 2.354, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 18644 (epoch 31), train_loss = 2.808, time/batch = 0.024
Read data: 0.0001671314239501953
iter 18645 (epoch 31), train_loss = 2.527, time/batch = 0.026
Read data: 0.00011110305786132812
iter 18646 (epoch 31), train_loss = 2.524, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 18647 (epoch 31), train_loss = 2.109, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 18648 (epoch 31), train_loss = 2.144, time/batch = 0.031
Read data: 8.702278137207031e-05
iter 18649 (epoch 31), train_loss = 2.350, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 18650 (epoch 31), train_loss = 1.940, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 18651 (epoch 31), train_loss = 2.127, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 18652 (epoch 31), train_loss = 2.358, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 18653 (epoch 31), train_loss = 2.498, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 18654 (epoch 31), train_loss = 1.793, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 18655 (epoch 31), train_loss = 2.855, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 18656 (epoch 31), train_loss = 2.418, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 18657 (epoch 31), train_loss = 2.249, time/batch = 0.020
Read data: 9.34600830078125e-05
iter 18658 (epoch 31), train_loss = 2.267, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 18659 (epoch 31), train_loss = 2.182, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 18660 (epoch 31), train_loss = 2.329, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 18661 (epoch 31), train_loss = 2.563, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 18662 (epoch 31), train_loss = 2.431, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 18663 (epoch 31), train_loss = 2.614, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 18664 (epoch 31), train_loss = 2.653, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 18665 (epoch 31), train_loss = 2.298, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 18666 (epoch 31), train_loss = 2.612, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 18667 (epoch 31), train_loss = 2.301, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 18668 (epoch 31), train_loss = 2.770, time/batch = 0.029
Read data: 0.00013875961303710938
iter 18669 (epoch 31), train_loss = 2.254, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 18670 (epoch 31), train_loss = 2.257, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 18671 (epoch 31), train_loss = 2.639, time/batch = 0.034
Read data: 0.0001392364501953125
iter 18672 (epoch 31), train_loss = 2.531, time/batch = 0.035
Read data: 9.202957153320312e-05
iter 18673 (epoch 31), train_loss = 2.621, time/batch = 0.040
Read data: 7.843971252441406e-05
iter 18674 (epoch 31), train_loss = 2.168, time/batch = 0.027
Read data: 0.0002002716064453125
iter 18675 (epoch 31), train_loss = 2.614, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 18676 (epoch 31), train_loss = 2.416, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 18677 (epoch 31), train_loss = 2.659, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18678 (epoch 31), train_loss = 1.969, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 18679 (epoch 31), train_loss = 2.243, time/batch = 0.034
Read data: 0.00017547607421875
iter 18680 (epoch 31), train_loss = 2.508, time/batch = 0.025
Read data: 0.00010347366333007812
iter 18681 (epoch 31), train_loss = 2.215, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 18682 (epoch 31), train_loss = 2.535, time/batch = 0.032
Read data: 8.0108642578125e-05
iter 18683 (epoch 31), train_loss = 2.609, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 18684 (epoch 31), train_loss = 2.130, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 18685 (epoch 31), train_loss = 2.221, time/batch = 0.031
Read data: 0.00013375282287597656
iter 18686 (epoch 31), train_loss = 2.661, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 18687 (epoch 31), train_loss = 2.231, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 18688 (epoch 31), train_loss = 2.073, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 18689 (epoch 31), train_loss = 2.245, time/batch = 0.025
Read data: 0.00012946128845214844
iter 18690 (epoch 31), train_loss = 3.009, time/batch = 0.029
Read data: 8.392333984375e-05
iter 18691 (epoch 31), train_loss = 2.510, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 18692 (epoch 31), train_loss = 2.432, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 18693 (epoch 31), train_loss = 2.355, time/batch = 0.034
Read data: 0.0001068115234375
iter 18694 (epoch 31), train_loss = 2.305, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 18695 (epoch 31), train_loss = 2.450, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 18696 (epoch 31), train_loss = 2.114, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 18697 (epoch 31), train_loss = 2.100, time/batch = 0.027
Read data: 0.00012350082397460938
iter 18698 (epoch 31), train_loss = 2.452, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 18699 (epoch 31), train_loss = 2.508, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 18700 (epoch 31), train_loss = 2.481, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 18701 (epoch 31), train_loss = 2.991, time/batch = 0.030
Read data: 0.00017714500427246094
iter 18702 (epoch 31), train_loss = 2.459, time/batch = 0.028
Read data: 0.0001304149627685547
iter 18703 (epoch 31), train_loss = 2.220, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 18704 (epoch 31), train_loss = 2.764, time/batch = 0.040
Read data: 8.487701416015625e-05
iter 18705 (epoch 31), train_loss = 2.275, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 18706 (epoch 31), train_loss = 2.735, time/batch = 0.026
Read data: 8.606910705566406e-05
iter 18707 (epoch 31), train_loss = 2.439, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 18708 (epoch 31), train_loss = 2.271, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 18709 (epoch 31), train_loss = 2.589, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 18710 (epoch 31), train_loss = 2.223, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 18711 (epoch 31), train_loss = 2.074, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 18712 (epoch 31), train_loss = 2.728, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 18713 (epoch 31), train_loss = 2.490, time/batch = 0.026
Read data: 0.00013208389282226562
iter 18714 (epoch 31), train_loss = 2.588, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 18715 (epoch 31), train_loss = 2.422, time/batch = 0.028
Read data: 0.000171661376953125
iter 18716 (epoch 31), train_loss = 2.470, time/batch = 0.026
Read data: 0.00014591217041015625
iter 18717 (epoch 31), train_loss = 2.381, time/batch = 0.034
Read data: 9.632110595703125e-05
iter 18718 (epoch 31), train_loss = 2.495, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 18719 (epoch 31), train_loss = 2.416, time/batch = 0.023
Read data: 0.0001277923583984375
iter 18720 (epoch 31), train_loss = 2.239, time/batch = 0.024
Read data: 0.00011301040649414062
iter 18721 (epoch 31), train_loss = 2.220, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 18722 (epoch 31), train_loss = 2.282, time/batch = 0.030
Read data: 7.724761962890625e-05
iter 18723 (epoch 31), train_loss = 2.121, time/batch = 0.030
Read data: 0.000133514404296875
iter 18724 (epoch 31), train_loss = 2.252, time/batch = 0.027
Read data: 0.00036597251892089844
iter 18725 (epoch 31), train_loss = 2.657, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 18726 (epoch 31), train_loss = 2.439, time/batch = 0.023
Read data: 7.605552673339844e-05
iter 18727 (epoch 31), train_loss = 2.255, time/batch = 0.020
Read data: 9.274482727050781e-05
iter 18728 (epoch 31), train_loss = 2.420, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 18729 (epoch 31), train_loss = 2.521, time/batch = 0.029
Read data: 0.00017833709716796875
iter 18730 (epoch 31), train_loss = 2.159, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 18731 (epoch 31), train_loss = 2.229, time/batch = 0.022
Read data: 8.940696716308594e-05
iter 18732 (epoch 31), train_loss = 2.060, time/batch = 0.024
Read data: 9.369850158691406e-05
iter 18733 (epoch 31), train_loss = 2.073, time/batch = 0.038
Read data: 8.058547973632812e-05
iter 18734 (epoch 31), train_loss = 2.516, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 18735 (epoch 31), train_loss = 2.422, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 18736 (epoch 31), train_loss = 2.427, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 18737 (epoch 31), train_loss = 2.214, time/batch = 0.024
Read data: 7.939338684082031e-05
iter 18738 (epoch 31), train_loss = 2.468, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 18739 (epoch 31), train_loss = 2.723, time/batch = 0.031
Read data: 0.00011920928955078125
iter 18740 (epoch 31), train_loss = 2.277, time/batch = 0.036
Read data: 9.632110595703125e-05
iter 18741 (epoch 31), train_loss = 2.278, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 18742 (epoch 31), train_loss = 2.313, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 18743 (epoch 31), train_loss = 2.273, time/batch = 0.023
Read data: 0.0001556873321533203
iter 18744 (epoch 31), train_loss = 2.006, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 18745 (epoch 31), train_loss = 2.488, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 18746 (epoch 31), train_loss = 2.630, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 18747 (epoch 31), train_loss = 2.645, time/batch = 0.025
Read data: 0.00017452239990234375
iter 18748 (epoch 31), train_loss = 2.215, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 18749 (epoch 31), train_loss = 2.686, time/batch = 0.025
Read data: 0.00020956993103027344
iter 18750 (epoch 31), train_loss = 2.514, time/batch = 0.027
Read data: 0.00013136863708496094
iter 18751 (epoch 31), train_loss = 2.354, time/batch = 0.030
Read data: 0.00017523765563964844
iter 18752 (epoch 31), train_loss = 2.546, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 18753 (epoch 31), train_loss = 2.365, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 18754 (epoch 31), train_loss = 2.204, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 18755 (epoch 31), train_loss = 2.847, time/batch = 0.025
Read data: 0.00013136863708496094
iter 18756 (epoch 31), train_loss = 1.866, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 18757 (epoch 31), train_loss = 2.495, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 18758 (epoch 31), train_loss = 2.496, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 18759 (epoch 31), train_loss = 2.405, time/batch = 0.030
Read data: 0.00013494491577148438
iter 18760 (epoch 31), train_loss = 2.586, time/batch = 0.021
Read data: 9.369850158691406e-05
iter 18761 (epoch 31), train_loss = 2.430, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 18762 (epoch 31), train_loss = 2.231, time/batch = 0.028
Read data: 0.00010180473327636719
iter 18763 (epoch 31), train_loss = 2.377, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 18764 (epoch 31), train_loss = 1.837, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 18765 (epoch 31), train_loss = 2.174, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 18766 (epoch 31), train_loss = 2.265, time/batch = 0.026
Read data: 9.965896606445312e-05
iter 18767 (epoch 31), train_loss = 2.492, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 18768 (epoch 31), train_loss = 2.131, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 18769 (epoch 31), train_loss = 2.196, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 18770 (epoch 31), train_loss = 2.350, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 18771 (epoch 31), train_loss = 2.331, time/batch = 0.026
Read data: 0.0001494884490966797
iter 18772 (epoch 31), train_loss = 2.266, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 18773 (epoch 31), train_loss = 2.413, time/batch = 0.026
Read data: 7.987022399902344e-05
iter 18774 (epoch 31), train_loss = 2.125, time/batch = 0.021
Read data: 0.0002422332763671875
iter 18775 (epoch 31), train_loss = 2.522, time/batch = 0.028
Read data: 0.00016236305236816406
iter 18776 (epoch 31), train_loss = 2.892, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 18777 (epoch 31), train_loss = 2.068, time/batch = 0.024
Read data: 7.653236389160156e-05
iter 18778 (epoch 31), train_loss = 2.318, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 18779 (epoch 31), train_loss = 2.412, time/batch = 0.030
Read data: 0.00016021728515625
iter 18780 (epoch 31), train_loss = 2.494, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 18781 (epoch 31), train_loss = 2.291, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 18782 (epoch 31), train_loss = 1.944, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 18783 (epoch 31), train_loss = 2.549, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 18784 (epoch 31), train_loss = 2.430, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 18785 (epoch 31), train_loss = 1.983, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 18786 (epoch 31), train_loss = 2.380, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 18787 (epoch 31), train_loss = 2.365, time/batch = 0.025
Read data: 0.00015401840209960938
iter 18788 (epoch 31), train_loss = 2.508, time/batch = 0.025
Read data: 0.00010204315185546875
iter 18789 (epoch 31), train_loss = 2.285, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 18790 (epoch 31), train_loss = 2.435, time/batch = 0.025
Read data: 9.846687316894531e-05
iter 18791 (epoch 31), train_loss = 2.522, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 18792 (epoch 31), train_loss = 2.259, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 18793 (epoch 31), train_loss = 2.215, time/batch = 0.022
Read data: 8.654594421386719e-05
iter 18794 (epoch 31), train_loss = 2.317, time/batch = 0.027
Read data: 8.96453857421875e-05
iter 18795 (epoch 31), train_loss = 2.569, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 18796 (epoch 31), train_loss = 2.072, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 18797 (epoch 31), train_loss = 2.182, time/batch = 0.032
Read data: 8.249282836914062e-05
iter 18798 (epoch 31), train_loss = 2.457, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 18799 (epoch 31), train_loss = 2.833, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 18800 (epoch 31), train_loss = 2.453, time/batch = 0.025
Read data: 9.298324584960938e-05
iter 18801 (epoch 31), train_loss = 2.529, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 18802 (epoch 31), train_loss = 2.610, time/batch = 0.033
Read data: 7.939338684082031e-05
iter 18803 (epoch 31), train_loss = 2.450, time/batch = 0.035
Read data: 0.00011610984802246094
iter 18804 (epoch 31), train_loss = 2.669, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 18805 (epoch 31), train_loss = 2.726, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 18806 (epoch 31), train_loss = 2.620, time/batch = 0.030
Read data: 8.130073547363281e-05
iter 18807 (epoch 31), train_loss = 2.132, time/batch = 0.025
Read data: 0.0001342296600341797
iter 18808 (epoch 31), train_loss = 2.294, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 18809 (epoch 31), train_loss = 2.213, time/batch = 0.024
Read data: 7.915496826171875e-05
iter 18810 (epoch 31), train_loss = 2.417, time/batch = 0.023
Read data: 9.417533874511719e-05
iter 18811 (epoch 31), train_loss = 2.539, time/batch = 0.031
Read data: 0.00012874603271484375
iter 18812 (epoch 31), train_loss = 2.429, time/batch = 0.020
Read data: 0.00012040138244628906
iter 18813 (epoch 31), train_loss = 1.933, time/batch = 0.023
Read data: 9.489059448242188e-05
iter 18814 (epoch 31), train_loss = 2.293, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 18815 (epoch 31), train_loss = 2.616, time/batch = 0.028
Read data: 0.00018477439880371094
iter 18816 (epoch 31), train_loss = 2.275, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 18817 (epoch 31), train_loss = 2.594, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 18818 (epoch 31), train_loss = 2.307, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 18819 (epoch 31), train_loss = 2.263, time/batch = 0.028
Read data: 0.00013303756713867188
iter 18820 (epoch 31), train_loss = 2.557, time/batch = 0.029
Read data: 8.392333984375e-05
iter 18821 (epoch 31), train_loss = 2.486, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18822 (epoch 31), train_loss = 2.423, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 18823 (epoch 31), train_loss = 2.216, time/batch = 0.025
Read data: 0.0001270771026611328
iter 18824 (epoch 31), train_loss = 2.409, time/batch = 0.025
Read data: 0.00024628639221191406
iter 18825 (epoch 31), train_loss = 2.124, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 18826 (epoch 31), train_loss = 2.460, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 18827 (epoch 31), train_loss = 2.085, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 18828 (epoch 31), train_loss = 2.277, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 18829 (epoch 31), train_loss = 2.427, time/batch = 0.027
Read data: 7.62939453125e-05
iter 18830 (epoch 31), train_loss = 2.229, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 18831 (epoch 31), train_loss = 2.471, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 18832 (epoch 31), train_loss = 2.414, time/batch = 0.024
Read data: 7.843971252441406e-05
iter 18833 (epoch 31), train_loss = 2.150, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 18834 (epoch 31), train_loss = 2.284, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 18835 (epoch 31), train_loss = 2.103, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 18836 (epoch 31), train_loss = 2.354, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 18837 (epoch 31), train_loss = 2.060, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 18838 (epoch 31), train_loss = 2.481, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 18839 (epoch 31), train_loss = 2.508, time/batch = 0.035
Read data: 0.00011420249938964844
iter 18840 (epoch 31), train_loss = 2.514, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 18841 (epoch 31), train_loss = 2.429, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 18842 (epoch 31), train_loss = 2.187, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 18843 (epoch 31), train_loss = 2.538, time/batch = 0.025
Read data: 0.00012063980102539062
iter 18844 (epoch 31), train_loss = 2.605, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 18845 (epoch 31), train_loss = 2.173, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 18846 (epoch 31), train_loss = 2.128, time/batch = 0.029
Read data: 9.298324584960938e-05
iter 18847 (epoch 31), train_loss = 2.503, time/batch = 0.023
Read data: 0.00014066696166992188
iter 18848 (epoch 31), train_loss = 2.375, time/batch = 0.026
Read data: 0.00011658668518066406
iter 18849 (epoch 31), train_loss = 2.169, time/batch = 0.025
Read data: 0.00025200843811035156
iter 18850 (epoch 31), train_loss = 2.187, time/batch = 0.025
Read data: 9.5367431640625e-05
iter 18851 (epoch 31), train_loss = 2.841, time/batch = 0.032
Read data: 0.00016164779663085938
iter 18852 (epoch 31), train_loss = 2.596, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 18853 (epoch 31), train_loss = 2.861, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 18854 (epoch 31), train_loss = 2.480, time/batch = 0.023
Read data: 0.0001304149627685547
iter 18855 (epoch 31), train_loss = 2.307, time/batch = 0.030
Read data: 0.00013184547424316406
iter 18856 (epoch 31), train_loss = 2.199, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 18857 (epoch 31), train_loss = 2.624, time/batch = 0.035
Read data: 9.322166442871094e-05
iter 18858 (epoch 31), train_loss = 2.204, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 18859 (epoch 31), train_loss = 2.210, time/batch = 0.021
Read data: 0.00012993812561035156
iter 18860 (epoch 31), train_loss = 2.234, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 18861 (epoch 31), train_loss = 2.233, time/batch = 0.024
Read data: 9.298324584960938e-05
iter 18862 (epoch 31), train_loss = 2.535, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 18863 (epoch 31), train_loss = 2.368, time/batch = 0.027
Read data: 0.00010347366333007812
iter 18864 (epoch 31), train_loss = 2.286, time/batch = 0.021
Read data: 0.00011539459228515625
iter 18865 (epoch 31), train_loss = 2.228, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 18866 (epoch 31), train_loss = 2.111, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 18867 (epoch 31), train_loss = 2.507, time/batch = 0.025
Read data: 0.0001285076141357422
iter 18868 (epoch 31), train_loss = 2.629, time/batch = 0.021
Read data: 9.441375732421875e-05
iter 18869 (epoch 31), train_loss = 2.530, time/batch = 0.027
Read data: 9.036064147949219e-05
iter 18870 (epoch 31), train_loss = 2.683, time/batch = 0.034
Read data: 8.153915405273438e-05
iter 18871 (epoch 31), train_loss = 2.566, time/batch = 0.025
Read data: 0.0001621246337890625
iter 18872 (epoch 31), train_loss = 2.035, time/batch = 0.025
Read data: 0.00010275840759277344
iter 18873 (epoch 31), train_loss = 2.451, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 18874 (epoch 31), train_loss = 2.393, time/batch = 0.023
Read data: 0.00026607513427734375
iter 18875 (epoch 31), train_loss = 2.670, time/batch = 0.030
Read data: 0.00012493133544921875
iter 18876 (epoch 31), train_loss = 2.743, time/batch = 0.033
Read data: 0.00014019012451171875
iter 18877 (epoch 31), train_loss = 1.863, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 18878 (epoch 31), train_loss = 2.581, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 18879 (epoch 31), train_loss = 2.227, time/batch = 0.029
Read data: 0.00012445449829101562
iter 18880 (epoch 31), train_loss = 2.733, time/batch = 0.021
Read data: 0.00010967254638671875
iter 18881 (epoch 31), train_loss = 2.411, time/batch = 0.027
Read data: 9.560585021972656e-05
iter 18882 (epoch 31), train_loss = 1.992, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 18883 (epoch 31), train_loss = 2.050, time/batch = 0.023
Read data: 0.00017571449279785156
iter 18884 (epoch 31), train_loss = 2.456, time/batch = 0.029
Read data: 0.00011086463928222656
iter 18885 (epoch 31), train_loss = 2.078, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 18886 (epoch 31), train_loss = 2.468, time/batch = 0.023
Read data: 8.153915405273438e-05
iter 18887 (epoch 31), train_loss = 2.445, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 18888 (epoch 31), train_loss = 2.171, time/batch = 0.024
Read data: 0.00010085105895996094
iter 18889 (epoch 31), train_loss = 2.852, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 18890 (epoch 31), train_loss = 1.957, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 18891 (epoch 31), train_loss = 2.587, time/batch = 0.027
Read data: 0.00012946128845214844
iter 18892 (epoch 31), train_loss = 2.451, time/batch = 0.023
Read data: 7.677078247070312e-05
iter 18893 (epoch 31), train_loss = 2.341, time/batch = 0.020
Read data: 8.678436279296875e-05
iter 18894 (epoch 31), train_loss = 2.549, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 18895 (epoch 31), train_loss = 2.321, time/batch = 0.036
Read data: 0.00013327598571777344
iter 18896 (epoch 31), train_loss = 2.151, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 18897 (epoch 31), train_loss = 2.515, time/batch = 0.031
Read data: 8.893013000488281e-05
iter 18898 (epoch 31), train_loss = 2.759, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 18899 (epoch 31), train_loss = 2.269, time/batch = 0.026
Read data: 0.00013327598571777344
iter 18900 (epoch 31), train_loss = 2.272, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 18901 (epoch 31), train_loss = 2.456, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 18902 (epoch 31), train_loss = 2.404, time/batch = 0.023
Read data: 7.700920104980469e-05
iter 18903 (epoch 31), train_loss = 2.482, time/batch = 0.030
Read data: 0.00016880035400390625
iter 18904 (epoch 31), train_loss = 2.260, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 18905 (epoch 31), train_loss = 2.710, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 18906 (epoch 31), train_loss = 2.547, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 18907 (epoch 31), train_loss = 2.236, time/batch = 0.026
Read data: 0.00015926361083984375
iter 18908 (epoch 31), train_loss = 2.217, time/batch = 0.024
Read data: 0.00010037422180175781
iter 18909 (epoch 31), train_loss = 2.360, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 18910 (epoch 31), train_loss = 2.679, time/batch = 0.038
Read data: 8.177757263183594e-05
iter 18911 (epoch 31), train_loss = 2.571, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 18912 (epoch 31), train_loss = 2.676, time/batch = 0.032
Read data: 0.00011444091796875
iter 18913 (epoch 31), train_loss = 2.023, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 18914 (epoch 31), train_loss = 2.188, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 18915 (epoch 31), train_loss = 2.632, time/batch = 0.023
Read data: 0.00017261505126953125
iter 18916 (epoch 31), train_loss = 2.104, time/batch = 0.019
Read data: 0.0001227855682373047
iter 18917 (epoch 31), train_loss = 2.301, time/batch = 0.026
Read data: 9.632110595703125e-05
iter 18918 (epoch 31), train_loss = 2.486, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 18919 (epoch 31), train_loss = 2.307, time/batch = 0.038
Read data: 8.225440979003906e-05
iter 18920 (epoch 31), train_loss = 2.288, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 18921 (epoch 31), train_loss = 2.406, time/batch = 0.025
Read data: 0.00011181831359863281
iter 18922 (epoch 31), train_loss = 2.502, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 18923 (epoch 31), train_loss = 2.281, time/batch = 0.027
Read data: 0.00013494491577148438
iter 18924 (epoch 31), train_loss = 2.084, time/batch = 0.025
Read data: 0.0002808570861816406
iter 18925 (epoch 31), train_loss = 2.196, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 18926 (epoch 31), train_loss = 2.386, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 18927 (epoch 31), train_loss = 2.389, time/batch = 0.025
Read data: 0.00018787384033203125
iter 18928 (epoch 31), train_loss = 2.348, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 18929 (epoch 31), train_loss = 2.356, time/batch = 0.028
Read data: 7.939338684082031e-05
iter 18930 (epoch 31), train_loss = 2.828, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 18931 (epoch 31), train_loss = 2.688, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 18932 (epoch 31), train_loss = 2.603, time/batch = 0.021
Read data: 0.00012230873107910156
iter 18933 (epoch 31), train_loss = 2.442, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 18934 (epoch 31), train_loss = 2.655, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 18935 (epoch 31), train_loss = 2.523, time/batch = 0.027
Read data: 0.00015544891357421875
iter 18936 (epoch 31), train_loss = 2.403, time/batch = 0.029
Read data: 9.059906005859375e-05
iter 18937 (epoch 31), train_loss = 3.090, time/batch = 0.029
Read data: 8.559226989746094e-05
iter 18938 (epoch 31), train_loss = 2.371, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 18939 (epoch 31), train_loss = 2.387, time/batch = 0.026
Read data: 0.00016021728515625
iter 18940 (epoch 31), train_loss = 2.464, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 18941 (epoch 31), train_loss = 2.369, time/batch = 0.024
Read data: 9.989738464355469e-05
iter 18942 (epoch 31), train_loss = 2.485, time/batch = 0.028
Read data: 9.775161743164062e-05
iter 18943 (epoch 31), train_loss = 2.206, time/batch = 0.024
Read data: 0.0001499652862548828
iter 18944 (epoch 31), train_loss = 2.176, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 18945 (epoch 31), train_loss = 2.678, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 18946 (epoch 31), train_loss = 1.917, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 18947 (epoch 31), train_loss = 2.566, time/batch = 0.032
Read data: 0.00016164779663085938
iter 18948 (epoch 31), train_loss = 2.500, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 18949 (epoch 31), train_loss = 2.264, time/batch = 0.025
Read data: 0.000244140625
iter 18950 (epoch 31), train_loss = 2.459, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 18951 (epoch 31), train_loss = 2.890, time/batch = 0.027
Read data: 0.0001323223114013672
iter 18952 (epoch 31), train_loss = 2.728, time/batch = 0.023
Read data: 0.00010085105895996094
iter 18953 (epoch 31), train_loss = 2.413, time/batch = 0.026
Read data: 0.00010275840759277344
iter 18954 (epoch 31), train_loss = 2.216, time/batch = 0.028
Read data: 8.0108642578125e-05
iter 18955 (epoch 31), train_loss = 2.185, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 18956 (epoch 31), train_loss = 2.284, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 18957 (epoch 31), train_loss = 2.544, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 18958 (epoch 31), train_loss = 2.516, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 18959 (epoch 31), train_loss = 2.141, time/batch = 0.025
Read data: 0.0001246929168701172
iter 18960 (epoch 31), train_loss = 2.310, time/batch = 0.021
Read data: 9.560585021972656e-05
iter 18961 (epoch 31), train_loss = 2.240, time/batch = 0.023
Read data: 9.584426879882812e-05
iter 18962 (epoch 31), train_loss = 2.379, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 18963 (epoch 31), train_loss = 2.233, time/batch = 0.023
Read data: 0.0001697540283203125
iter 18964 (epoch 31), train_loss = 2.225, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 18965 (epoch 31), train_loss = 2.111, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 18966 (epoch 31), train_loss = 2.345, time/batch = 0.023
Read data: 9.226799011230469e-05
iter 18967 (epoch 31), train_loss = 2.428, time/batch = 0.029
Read data: 0.0002067089080810547
iter 18968 (epoch 31), train_loss = 2.434, time/batch = 0.033
Read data: 8.153915405273438e-05
iter 18969 (epoch 31), train_loss = 2.481, time/batch = 0.021
Read data: 8.630752563476562e-05
iter 18970 (epoch 31), train_loss = 2.214, time/batch = 0.036
Read data: 9.822845458984375e-05
iter 18971 (epoch 31), train_loss = 2.328, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 18972 (epoch 31), train_loss = 2.434, time/batch = 0.028
Read data: 7.724761962890625e-05
iter 18973 (epoch 31), train_loss = 2.801, time/batch = 0.026
Read data: 8.034706115722656e-05
iter 18974 (epoch 31), train_loss = 2.412, time/batch = 0.026
Read data: 0.000209808349609375
iter 18975 (epoch 31), train_loss = 2.546, time/batch = 0.028
Read data: 0.0001270771026611328
iter 18976 (epoch 31), train_loss = 2.464, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 18977 (epoch 31), train_loss = 2.349, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 18978 (epoch 31), train_loss = 2.016, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 18979 (epoch 31), train_loss = 2.374, time/batch = 0.028
Read data: 0.0001780986785888672
iter 18980 (epoch 31), train_loss = 2.357, time/batch = 0.024
Read data: 0.00010156631469726562
iter 18981 (epoch 31), train_loss = 2.289, time/batch = 0.027
Read data: 0.00012350082397460938
iter 18982 (epoch 31), train_loss = 2.503, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 18983 (epoch 31), train_loss = 2.212, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 18984 (epoch 31), train_loss = 2.353, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 18985 (epoch 31), train_loss = 2.530, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 18986 (epoch 31), train_loss = 2.605, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 18987 (epoch 31), train_loss = 2.843, time/batch = 0.034
Read data: 0.0001277923583984375
iter 18988 (epoch 31), train_loss = 2.320, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 18989 (epoch 31), train_loss = 2.640, time/batch = 0.028
Read data: 0.0001010894775390625
iter 18990 (epoch 31), train_loss = 1.964, time/batch = 0.023
Read data: 7.939338684082031e-05
iter 18991 (epoch 31), train_loss = 2.470, time/batch = 0.029
Read data: 0.000118255615234375
iter 18992 (epoch 31), train_loss = 2.307, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 18993 (epoch 31), train_loss = 2.419, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 18994 (epoch 31), train_loss = 2.102, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 18995 (epoch 31), train_loss = 2.372, time/batch = 0.023
Read data: 8.130073547363281e-05
iter 18996 (epoch 31), train_loss = 2.362, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 18997 (epoch 31), train_loss = 1.949, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 18998 (epoch 31), train_loss = 2.233, time/batch = 0.033
Read data: 9.632110595703125e-05
iter 18999 (epoch 31), train_loss = 2.646, time/batch = 0.025
image 976:     
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:      
image 2375:      
image 2494:    
image 6381:     
evaluating validation preformance... 10/1000 (2.644181)
image 2798:     
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:     
image 6023:     
image 6550:     
image 6718:     
evaluating validation preformance... 20/1000 (2.170155)
image 6903:    UNK
image 3301:    
image 2019:    
image 5535:     
image 7680:      
image 5527:      
image 2568:     
image 160:      
image 8085:      
image 7670:    
evaluating validation preformance... 30/1000 (2.514824)
image 4604:    
image 5745:    
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.043514)
image 2938:    UNK
image 5183:     
image 2380:     
image 6973:   
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.515960)
image 4940:      
image 4905:    UNK
image 469:      
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    UNK
image 1729:     
image 4444:      
image 6070:     
evaluating validation preformance... 60/1000 (2.835758)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:  
image 5641:     
evaluating validation preformance... 70/1000 (2.554825)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.574315)
image 3276:     
image 3812:   
image 1400:     
image 3443:     
image 5027:     
image 7251:     
image 7305:   
image 1480:      
image 4806:      
image 766:     
evaluating validation preformance... 90/1000 (2.114272)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:         
evaluating validation preformance... 100/1000 (2.883791)
image 2800:     
image 7249:      
image 3211:    
image 686:     
image 3986:     
image 2518:     
image 7399:      
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.793366)
image 1122:     
image 509:     
image 4091:     
image 5761:     
image 16:     
image 231:     
image 6505:     
image 1450:    
image 3979:      
image 5302:      UNK
evaluating validation preformance... 120/1000 (2.334622)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:     
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.866509)
image 6214:     
image 429:    
image 7743:    
image 3657:      
image 4535:    
image 5542:     
image 8068:    
image 4450:     
image 1524:     
image 2867:    
evaluating validation preformance... 140/1000 (2.662442)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:    
image 519:     
image 8070:     
image 4287:    
image 1266:     
evaluating validation preformance... 150/1000 (2.908071)
image 1865:      
image 3830:      
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:    
image 7688:    
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.834773)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.552154)
image 7922:      
image 2353:    
image 4580:    
image 5905:    
image 6488:     
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.722199)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:     
image 4541:     UNK
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.368788)
image 5372:     
image 7529:    UNK
image 875:     
image 2107:      
image 8015:   
image 6565:     
image 6174:      
image 6894:     
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.271222)
image 5159:     
image 1199:    
image 2456:     
image 3402:    
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.407990)
image 2599:     
image 822:    
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:    
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.507232)
image 4024:    
image 1894:     
image 7297:    
image 1796:    
image 7075:     
image 2258:    
image 5122:    
image 5586:   
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.237607)
image 1917:     
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:    
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.090735)
image 7143:    
image 6019:     
image 885:     
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:   
image 528:    
evaluating validation preformance... 250/1000 (2.484804)
image 3028:   
image 3141:    
image 7137:    
image 3444:    
image 2049:    
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.477038)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (2.985662)
image 833:    
image 5483:     
image 2476:     
image 5930:     
image 59:    
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:     
evaluating validation preformance... 280/1000 (2.517668)
image 2481:    
image 1860:    
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.363909)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:    
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.157497)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.711024)
image 3553:    
image 5971:     
image 122:    
image 3212:      
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:     
evaluating validation preformance... 320/1000 (2.281117)
image 489:      
image 5316:     
image 2613:    
image 7935:     
image 7768:     
image 7894:      
image 6267:     UNK
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.734196)
image 5179:    
image 3754:      
image 2911:     
image 6979:      
image 5449:     
image 2198:     
image 2535:     
image 2601:    
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.380038)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:     
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.452285)
image 6881:    
image 942:     
image 2775:   
image 3311:     
image 4587:      
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.031018)
image 2905:    
image 7814:      
image 56:    
image 5034:     
image 7946:     
image 3470:     
image 4655:     
image 818:    
image 6607:    
image 4866:      
evaluating validation preformance... 370/1000 (2.570266)
image 4351:      
image 1054:     
image 129:    
image 2849:     
image 725:   UNK
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.643246)
image 2458:     
image 1084:      
image 4835:    
image 867:    
image 723:    
image 6255:     
image 5255:     
image 3598:    
image 2997:     
image 60:    
evaluating validation preformance... 390/1000 (2.777799)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:     
image 1117:      
image 5817:     
image 1231:    
image 1630:     
image 6886:     
evaluating validation preformance... 400/1000 (2.229609)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.126668)
image 4359:     
image 2372:    
image 4472:      
image 6810:    
image 1592:     
image 7864:     
image 4286:    
image 6688:    
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.312771)
image 30:     
image 5540:     
image 2445:     
image 5896:      
image 7607:     
image 1426:    
image 6977:    
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.770715)
image 385:    
image 6938:       
image 2381:    
image 5796:     
image 4010:     
image 3452:    
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.924497)
image 1731:       
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:     
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.128483)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:      
image 2466:     
image 975:     
image 3818:    
image 6995:    
image 3682:    
evaluating validation preformance... 460/1000 (2.597121)
image 7979:    
image 1618:    UNK
image 7608:    
image 6393:    
image 5100:      
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.247498)
image 4503:    
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:      
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.861739)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:    UNK
image 1595:  UNK  
image 4757:    
image 205:     
evaluating validation preformance... 490/1000 (3.343704)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:       
image 1485:     
image 5744:    
evaluating validation preformance... 500/1000 (2.458201)
image 1797:    
image 4670:    
image 4846:    
image 5907:     
image 3321:    
image 1700:     
image 438:    
image 5980:     
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.921170)
image 3246:       
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:     UNK
evaluating validation preformance... 520/1000 (2.573606)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:     
image 3045:      
image 303:   
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.455270)
image 5619:     
image 4391:    
image 891:     
image 3072:    
image 7781:    
image 6163:      
image 7376:    
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.407398)
image 5292:    
image 2901:    
image 3568:    
image 690:      
image 3345:      
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.555474)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.516261)
image 6056:    
image 6419:    
image 275:     
image 7441:     
image 7893:    
image 3623:    
image 7232:     
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.554932)
image 7936:     
image 5433:    UNK
image 5691:    
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.604774)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.548066)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.420112)
image 353:     
image 1095:     
image 3583:     
image 3264:     UNK
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.646252)
image 69:    
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:     
image 359:       
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.370914)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.457140)
image 8074:      
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.437916)
image 5313:      
image 2377:      
image 6058:    
image 4661:    
image 2955:    
image 3333:    
image 7124:    
image 4278:    
image 953:     
image 4037:      
evaluating validation preformance... 650/1000 (2.538750)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.622518)
image 5701:    
image 1709:      
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:    
image 1972:   
evaluating validation preformance... 670/1000 (2.763221)
image 7877:    
image 6761:     
image 6880:   
image 4914:     
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722: UNK UNK  
image 7784:      
evaluating validation preformance... 680/1000 (2.966407)
image 1445:     UNK
image 6841:     
image 2896:     
image 6947:   
image 4782:    
image 7669:     
image 4382:     
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.784358)
image 6860:     
image 576:     
image 6580:      
image 1497:     
image 3360:     
image 4939:      
image 6225:     
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.957925)
image 5343:      
image 68:    UNK
image 3184:    
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK UNK
image 7801:    
image 1129:     
evaluating validation preformance... 710/1000 (2.428254)
image 7368:     
image 709:     
image 3197:    
image 5214:    
image 445:      
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.615146)
image 5729:     
image 6395:     
image 516:      
image 1026:    
image 2972:      
image 3005:     
image 1241:      
image 2743:      
image 3665:    
image 1290:      UNK
evaluating validation preformance... 730/1000 (2.308646)
image 2527:     
image 6266:     
image 4161:      
image 1139:    
image 3781:     
image 6081:     
image 997:    
image 5092:     
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.374068)
image 2239:     
image 120:       
image 4902:      
image 3796:    
image 3355:     
image 1787:    
image 5365:      
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.630666)
image 3279:    
image 6380:    
image 2663:     
image 3815:    
image 512:      
image 5899:      
image 6078:     
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.983155)
image 4582:    
image 5484:    
image 3049:      
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:    
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.104451)
image 6220:     
image 6238:     
image 4534:     
image 2732:     
image 7003:    
image 1739:     
image 5503:     
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.801205)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:     
image 6978:    
image 3450:     
image 3312:    
image 7824:      
image 2032:     
evaluating validation preformance... 790/1000 (3.067553)
image 5047:      
image 325:       
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:    
image 1728:     UNK
image 6725:     
evaluating validation preformance... 800/1000 (2.234325)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:      
image 290:      
image 159:      
image 4345:    
image 2217:    
image 3169:     
evaluating validation preformance... 810/1000 (2.410964)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.924240)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:    UNK
image 7147:      
image 6348:     
image 580:     
image 2531:    
evaluating validation preformance... 830/1000 (2.366713)
image 5107:     
image 3973:     
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.405606)
image 7592:     
image 1798:    
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.715010)
image 4404:    
image 5501:    
image 5765:     
image 1838:      
image 4354:    
image 336:    
image 3596:    
image 1921:     
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.761108)
image 4254:      
image 6842:    
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:      
image 3222:   
image 4002:     
evaluating validation preformance... 870/1000 (2.355231)
image 4934:    
image 6487:     
image 4217:    
image 6355:    
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:    
image 28:      
evaluating validation preformance... 880/1000 (2.583301)
image 5460:      
image 3671:      
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.915640)
image 7485:    
image 6102:    
image 1001:    
image 7167:     
image 4168:    
image 187:    
image 7798:     
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.562707)
image 5664:     
image 4985:    
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.194544)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.590596)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:       
image 7102:    
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.505805)
image 5636:      
image 7799:      
image 6025:     
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.692466)
image 5860:     UNK
image 3275:    
image 1935:    
image 3520:     
image 5452:    
image 2446:    
image 5984:   
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.909086)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:      
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:      
evaluating validation preformance... 960/1000 (2.682138)
image 4935:    
image 1930:      
image 6850:    
image 5310:     
image 177:     
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.268622)
image 5688:     
image 5448:     
image 5871:     
image 7516:     
image 3734:    
image 2921:     
image 7800:    UNK UNK
image 3999:    
image 6317:    
image 5931:      
evaluating validation preformance... 980/1000 (2.749206)
image 7352:     
image 5113:     
image 7822:     
image 4858:    
image 658:    
image 2982:     
image 5843:    
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.422024)
image 5789:      
image 5606:    
image 6107:    
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.311498)
average loss on validation: 2.570
model saved to ./log_Att2in_sc/model.pth
model saved to ./log_Att2in_sc/model-best.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.2876198291778564
Cider scores: 0.5412187747107939
Read data: 0.28719544410705566
Cider scores: 0.5775278272194782
Read data: 0.21956300735473633
Cider scores: 0.6948731850386429
Read data: 0.2770051956176758
Cider scores: 0.6372792710738582
Read data: 0.23199081420898438
Cider scores: 0.5691887274294223
Read data: 0.18317055702209473
Cider scores: 0.498089150414087
Read data: 0.1777172088623047
Cider scores: 0.5399161409141175
Read data: 0.20838046073913574
Cider scores: 0.6253842511063664
Read data: 0.18271183967590332
Cider scores: 0.5528174987211103
Read data: 0.18186521530151367
Cider scores: 0.7169311074630637
Read data: 0.19463825225830078
Cider scores: 0.5966146898522775
Read data: 0.2473280429840088
Cider scores: 0.6616826420588879
Read data: 0.18564248085021973
Cider scores: 0.5760227022320271
Read data: 0.19176411628723145
Cider scores: 0.6187712986276921
Read data: 0.1856691837310791
Cider scores: 0.5393220657560414
Read data: 0.17325043678283691
Cider scores: 0.6440422958074736
Read data: 0.16838884353637695
Cider scores: 0.43269305967717137
Read data: 0.16733002662658691
Cider scores: 0.6592764309653536
Read data: 0.16777324676513672
Cider scores: 0.6125887071279489
Read data: 0.1680464744567871
Cider scores: 0.7995872879572622
Average cider score on test set: 0.605
End calculating cider score on TEST data set
===============================================
Read data: 0.16704821586608887
iter 19000 (epoch 31), train_loss = 2.522, time/batch = 0.029
Read data: 0.00010800361633300781
iter 19001 (epoch 31), train_loss = 2.426, time/batch = 0.024
Read data: 0.00012063980102539062
iter 19002 (epoch 31), train_loss = 2.444, time/batch = 0.028
Read data: 0.0001552104949951172
iter 19003 (epoch 31), train_loss = 2.626, time/batch = 0.028
Read data: 0.00020766258239746094
iter 19004 (epoch 31), train_loss = 2.137, time/batch = 0.025
Read data: 0.00010919570922851562
iter 19005 (epoch 31), train_loss = 2.373, time/batch = 0.023
Read data: 0.00012540817260742188
iter 19006 (epoch 31), train_loss = 2.355, time/batch = 0.030
Read data: 0.00013685226440429688
iter 19007 (epoch 31), train_loss = 2.353, time/batch = 0.031
Read data: 0.0001461505889892578
iter 19008 (epoch 31), train_loss = 2.224, time/batch = 0.021
Read data: 7.987022399902344e-05
iter 19009 (epoch 31), train_loss = 2.824, time/batch = 0.024
Read data: 9.441375732421875e-05
iter 19010 (epoch 31), train_loss = 2.614, time/batch = 0.040
Read data: 9.250640869140625e-05
iter 19011 (epoch 31), train_loss = 2.661, time/batch = 0.030
Read data: 0.00014352798461914062
iter 19012 (epoch 31), train_loss = 2.094, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 19013 (epoch 31), train_loss = 2.495, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 19014 (epoch 31), train_loss = 2.497, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 19015 (epoch 31), train_loss = 2.509, time/batch = 0.025
Read data: 9.72747802734375e-05
iter 19016 (epoch 31), train_loss = 2.212, time/batch = 0.029
Read data: 9.608268737792969e-05
iter 19017 (epoch 31), train_loss = 2.441, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 19018 (epoch 31), train_loss = 2.844, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 19019 (epoch 31), train_loss = 2.070, time/batch = 0.024
Read data: 0.0001800060272216797
iter 19020 (epoch 31), train_loss = 2.193, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 19021 (epoch 31), train_loss = 2.319, time/batch = 0.022
Read data: 9.202957153320312e-05
iter 19022 (epoch 31), train_loss = 2.266, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 19023 (epoch 31), train_loss = 2.110, time/batch = 0.027
Read data: 0.0001270771026611328
iter 19024 (epoch 31), train_loss = 2.762, time/batch = 0.028
Read data: 0.0002574920654296875
iter 19025 (epoch 31), train_loss = 2.642, time/batch = 0.025
Read data: 0.00010943412780761719
iter 19026 (epoch 31), train_loss = 2.316, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 19027 (epoch 31), train_loss = 2.750, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 19028 (epoch 31), train_loss = 2.021, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 19029 (epoch 31), train_loss = 2.209, time/batch = 0.022
Read data: 9.012222290039062e-05
iter 19030 (epoch 31), train_loss = 2.445, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 19031 (epoch 31), train_loss = 2.239, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 19032 (epoch 31), train_loss = 2.551, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 19033 (epoch 31), train_loss = 2.307, time/batch = 0.026
Read data: 9.250640869140625e-05
iter 19034 (epoch 31), train_loss = 2.094, time/batch = 0.033
Read data: 7.915496826171875e-05
iter 19035 (epoch 31), train_loss = 2.621, time/batch = 0.026
Read data: 0.00013375282287597656
iter 19036 (epoch 31), train_loss = 2.022, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 19037 (epoch 31), train_loss = 2.565, time/batch = 0.022
Read data: 8.96453857421875e-05
iter 19038 (epoch 31), train_loss = 2.588, time/batch = 0.031
Read data: 7.915496826171875e-05
iter 19039 (epoch 31), train_loss = 2.425, time/batch = 0.030
Read data: 9.322166442871094e-05
iter 19040 (epoch 31), train_loss = 2.608, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 19041 (epoch 31), train_loss = 2.357, time/batch = 0.024
Read data: 7.82012939453125e-05
iter 19042 (epoch 31), train_loss = 2.705, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 19043 (epoch 31), train_loss = 1.928, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 19044 (epoch 31), train_loss = 1.992, time/batch = 0.032
Read data: 8.654594421386719e-05
iter 19045 (epoch 31), train_loss = 2.483, time/batch = 0.024
Read data: 9.179115295410156e-05
iter 19046 (epoch 31), train_loss = 2.121, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 19047 (epoch 31), train_loss = 2.418, time/batch = 0.027
Read data: 0.00012612342834472656
iter 19048 (epoch 31), train_loss = 2.612, time/batch = 0.023
Read data: 8.058547973632812e-05
iter 19049 (epoch 31), train_loss = 2.296, time/batch = 0.025
Read data: 0.00023317337036132812
iter 19050 (epoch 31), train_loss = 2.049, time/batch = 0.025
Read data: 9.751319885253906e-05
iter 19051 (epoch 31), train_loss = 2.885, time/batch = 0.034
Read data: 8.130073547363281e-05
iter 19052 (epoch 31), train_loss = 2.598, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19053 (epoch 31), train_loss = 2.331, time/batch = 0.025
Read data: 0.00011467933654785156
iter 19054 (epoch 31), train_loss = 2.532, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 19055 (epoch 31), train_loss = 2.831, time/batch = 0.028
Read data: 0.00013065338134765625
iter 19056 (epoch 31), train_loss = 2.532, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19057 (epoch 31), train_loss = 2.760, time/batch = 0.024
Read data: 0.00011301040649414062
iter 19058 (epoch 31), train_loss = 2.532, time/batch = 0.032
Read data: 7.82012939453125e-05
iter 19059 (epoch 31), train_loss = 2.396, time/batch = 0.027
Read data: 0.00013446807861328125
iter 19060 (epoch 31), train_loss = 1.862, time/batch = 0.021
Read data: 7.748603820800781e-05
iter 19061 (epoch 31), train_loss = 2.230, time/batch = 0.022
Read data: 8.606910705566406e-05
iter 19062 (epoch 31), train_loss = 2.355, time/batch = 0.036
Read data: 7.748603820800781e-05
iter 19063 (epoch 31), train_loss = 2.539, time/batch = 0.027
Read data: 0.00015473365783691406
iter 19064 (epoch 31), train_loss = 2.001, time/batch = 0.022
Read data: 7.891654968261719e-05
iter 19065 (epoch 31), train_loss = 2.332, time/batch = 0.025
Read data: 9.799003601074219e-05
iter 19066 (epoch 31), train_loss = 2.433, time/batch = 0.027
Read data: 0.00010013580322265625
iter 19067 (epoch 31), train_loss = 2.266, time/batch = 0.031
Read data: 9.846687316894531e-05
iter 19068 (epoch 31), train_loss = 2.574, time/batch = 0.031
Read data: 8.869171142578125e-05
iter 19069 (epoch 31), train_loss = 2.440, time/batch = 0.028
Read data: 9.942054748535156e-05
iter 19070 (epoch 31), train_loss = 2.387, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 19071 (epoch 31), train_loss = 2.224, time/batch = 0.031
Read data: 9.1552734375e-05
iter 19072 (epoch 31), train_loss = 3.207, time/batch = 0.037
Read data: 0.00011610984802246094
iter 19073 (epoch 31), train_loss = 2.102, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 19074 (epoch 31), train_loss = 1.860, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 19075 (epoch 31), train_loss = 2.375, time/batch = 0.036
Read data: 8.58306884765625e-05
iter 19076 (epoch 31), train_loss = 2.289, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 19077 (epoch 31), train_loss = 2.405, time/batch = 0.030
Read data: 0.00012993812561035156
iter 19078 (epoch 31), train_loss = 1.852, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 19079 (epoch 31), train_loss = 2.403, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 19080 (epoch 31), train_loss = 2.620, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 19081 (epoch 31), train_loss = 2.353, time/batch = 0.032
Read data: 8.726119995117188e-05
iter 19082 (epoch 31), train_loss = 2.319, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 19083 (epoch 31), train_loss = 2.249, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 19084 (epoch 31), train_loss = 2.322, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 19085 (epoch 31), train_loss = 2.347, time/batch = 0.025
Read data: 0.00011777877807617188
iter 19086 (epoch 31), train_loss = 2.310, time/batch = 0.028
Read data: 0.00013136863708496094
iter 19087 (epoch 31), train_loss = 1.961, time/batch = 0.021
Read data: 9.489059448242188e-05
iter 19088 (epoch 31), train_loss = 2.673, time/batch = 0.021
Read data: 9.322166442871094e-05
iter 19089 (epoch 31), train_loss = 2.419, time/batch = 0.027
Read data: 0.00012040138244628906
iter 19090 (epoch 31), train_loss = 2.309, time/batch = 0.030
Read data: 0.00014662742614746094
iter 19091 (epoch 31), train_loss = 2.496, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 19092 (epoch 31), train_loss = 2.266, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 19093 (epoch 31), train_loss = 2.007, time/batch = 0.023
Read data: 9.1552734375e-05
iter 19094 (epoch 31), train_loss = 2.355, time/batch = 0.027
Read data: 9.72747802734375e-05
iter 19095 (epoch 31), train_loss = 2.318, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 19096 (epoch 31), train_loss = 2.408, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 19097 (epoch 31), train_loss = 2.351, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 19098 (epoch 31), train_loss = 2.547, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 19099 (epoch 31), train_loss = 2.509, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 19100 (epoch 31), train_loss = 2.235, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 19101 (epoch 31), train_loss = 2.453, time/batch = 0.032
Read data: 8.368492126464844e-05
iter 19102 (epoch 31), train_loss = 2.009, time/batch = 0.021
Read data: 8.153915405273438e-05
iter 19103 (epoch 31), train_loss = 2.375, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 19104 (epoch 31), train_loss = 2.251, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 19105 (epoch 31), train_loss = 2.040, time/batch = 0.023
Read data: 0.00011801719665527344
iter 19106 (epoch 31), train_loss = 2.451, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 19107 (epoch 31), train_loss = 2.247, time/batch = 0.028
Read data: 9.870529174804688e-05
iter 19108 (epoch 31), train_loss = 2.490, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 19109 (epoch 31), train_loss = 2.404, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 19110 (epoch 31), train_loss = 2.445, time/batch = 0.027
Read data: 8.726119995117188e-05
iter 19111 (epoch 31), train_loss = 2.540, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 19112 (epoch 31), train_loss = 2.808, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 19113 (epoch 31), train_loss = 2.702, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 19114 (epoch 31), train_loss = 2.313, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 19115 (epoch 31), train_loss = 2.458, time/batch = 0.028
Read data: 0.0017616748809814453
iter 19116 (epoch 31), train_loss = 2.233, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 19117 (epoch 31), train_loss = 2.568, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 19118 (epoch 31), train_loss = 2.482, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19119 (epoch 31), train_loss = 2.475, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 19120 (epoch 31), train_loss = 2.176, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 19121 (epoch 31), train_loss = 2.301, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 19122 (epoch 31), train_loss = 2.444, time/batch = 0.023
Read data: 0.00013136863708496094
iter 19123 (epoch 31), train_loss = 2.506, time/batch = 0.026
Read data: 9.822845458984375e-05
iter 19124 (epoch 31), train_loss = 2.184, time/batch = 0.023
Read data: 0.00010371208190917969
iter 19125 (epoch 31), train_loss = 2.307, time/batch = 0.028
Read data: 7.891654968261719e-05
iter 19126 (epoch 31), train_loss = 2.982, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 19127 (epoch 31), train_loss = 2.530, time/batch = 0.024
Read data: 0.00010204315185546875
iter 19128 (epoch 31), train_loss = 2.370, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 19129 (epoch 31), train_loss = 2.286, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 19130 (epoch 31), train_loss = 1.989, time/batch = 0.025
Read data: 0.00010776519775390625
iter 19131 (epoch 31), train_loss = 2.504, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 19132 (epoch 31), train_loss = 2.604, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 19133 (epoch 31), train_loss = 2.454, time/batch = 0.021
Read data: 9.34600830078125e-05
iter 19134 (epoch 31), train_loss = 2.455, time/batch = 0.028
Read data: 0.00012183189392089844
iter 19135 (epoch 31), train_loss = 2.224, time/batch = 0.026
Read data: 9.107589721679688e-05
iter 19136 (epoch 31), train_loss = 2.160, time/batch = 0.023
Read data: 9.179115295410156e-05
iter 19137 (epoch 31), train_loss = 2.247, time/batch = 0.026
Read data: 9.560585021972656e-05
iter 19138 (epoch 31), train_loss = 2.444, time/batch = 0.024
Read data: 9.322166442871094e-05
iter 19139 (epoch 31), train_loss = 2.246, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 19140 (epoch 31), train_loss = 2.393, time/batch = 0.022
Read data: 9.655952453613281e-05
iter 19141 (epoch 31), train_loss = 2.367, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 19142 (epoch 31), train_loss = 2.406, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 19143 (epoch 31), train_loss = 2.346, time/batch = 0.026
Read data: 0.00010037422180175781
iter 19144 (epoch 31), train_loss = 2.290, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 19145 (epoch 31), train_loss = 2.546, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 19146 (epoch 31), train_loss = 2.283, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19147 (epoch 31), train_loss = 2.401, time/batch = 0.025
Read data: 0.00010085105895996094
iter 19148 (epoch 31), train_loss = 2.667, time/batch = 0.036
Read data: 8.273124694824219e-05
iter 19149 (epoch 31), train_loss = 2.440, time/batch = 0.029
Read data: 0.00023651123046875
iter 19150 (epoch 31), train_loss = 2.148, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 19151 (epoch 31), train_loss = 2.159, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 19152 (epoch 31), train_loss = 2.658, time/batch = 0.039
Read data: 8.869171142578125e-05
iter 19153 (epoch 31), train_loss = 2.662, time/batch = 0.025
Read data: 0.00016021728515625
iter 19154 (epoch 31), train_loss = 2.403, time/batch = 0.031
Read data: 8.893013000488281e-05
iter 19155 (epoch 31), train_loss = 2.063, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 19156 (epoch 31), train_loss = 1.985, time/batch = 0.027
Read data: 8.654594421386719e-05
iter 19157 (epoch 31), train_loss = 2.000, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 19158 (epoch 31), train_loss = 2.124, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 19159 (epoch 31), train_loss = 2.686, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 19160 (epoch 31), train_loss = 2.124, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 19161 (epoch 31), train_loss = 2.082, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 19162 (epoch 31), train_loss = 2.529, time/batch = 0.027
Read data: 0.00017213821411132812
iter 19163 (epoch 31), train_loss = 2.382, time/batch = 0.030
Read data: 0.0016646385192871094
iter 19164 (epoch 31), train_loss = 2.082, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 19165 (epoch 31), train_loss = 2.665, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 19166 (epoch 31), train_loss = 2.142, time/batch = 0.036
Read data: 8.869171142578125e-05
iter 19167 (epoch 31), train_loss = 2.500, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 19168 (epoch 31), train_loss = 2.618, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19169 (epoch 31), train_loss = 2.752, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 19170 (epoch 31), train_loss = 2.522, time/batch = 0.025
Read data: 0.0001399517059326172
iter 19171 (epoch 31), train_loss = 2.249, time/batch = 0.028
Read data: 0.00012183189392089844
iter 19172 (epoch 31), train_loss = 2.317, time/batch = 0.029
Read data: 0.00013113021850585938
iter 19173 (epoch 31), train_loss = 2.329, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 19174 (epoch 31), train_loss = 2.512, time/batch = 0.023
Read data: 0.00021409988403320312
iter 19175 (epoch 31), train_loss = 2.517, time/batch = 0.030
Read data: 8.392333984375e-05
iter 19176 (epoch 31), train_loss = 2.353, time/batch = 0.021
Read data: 8.869171142578125e-05
iter 19177 (epoch 31), train_loss = 2.435, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 19178 (epoch 31), train_loss = 2.516, time/batch = 0.029
Read data: 8.296966552734375e-05
iter 19179 (epoch 31), train_loss = 2.657, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 19180 (epoch 31), train_loss = 2.447, time/batch = 0.027
Read data: 0.00010156631469726562
iter 19181 (epoch 31), train_loss = 2.018, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 19182 (epoch 31), train_loss = 2.535, time/batch = 0.025
Read data: 0.00011849403381347656
iter 19183 (epoch 31), train_loss = 2.191, time/batch = 0.022
Read data: 9.703636169433594e-05
iter 19184 (epoch 31), train_loss = 2.621, time/batch = 0.030
Read data: 8.654594421386719e-05
iter 19185 (epoch 31), train_loss = 2.394, time/batch = 0.023
Read data: 8.726119995117188e-05
iter 19186 (epoch 31), train_loss = 2.266, time/batch = 0.023
Read data: 0.00010013580322265625
iter 19187 (epoch 31), train_loss = 2.591, time/batch = 0.026
Read data: 9.942054748535156e-05
iter 19188 (epoch 31), train_loss = 2.302, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 19189 (epoch 31), train_loss = 2.399, time/batch = 0.033
Read data: 8.344650268554688e-05
iter 19190 (epoch 31), train_loss = 2.233, time/batch = 0.025
Read data: 0.00011849403381347656
iter 19191 (epoch 31), train_loss = 2.070, time/batch = 0.032
Read data: 0.0009284019470214844
iter 19192 (epoch 31), train_loss = 2.568, time/batch = 0.024
Read data: 0.00011181831359863281
iter 19193 (epoch 31), train_loss = 2.213, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19194 (epoch 31), train_loss = 2.216, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 19195 (epoch 31), train_loss = 2.494, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19196 (epoch 31), train_loss = 2.390, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 19197 (epoch 31), train_loss = 2.249, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 19198 (epoch 31), train_loss = 2.402, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 19199 (epoch 31), train_loss = 2.669, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 19200 (epoch 31), train_loss = 2.451, time/batch = 0.024
Read data: 9.870529174804688e-05
iter 19201 (epoch 32), train_loss = 2.210, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 19202 (epoch 32), train_loss = 1.990, time/batch = 0.027
Read data: 0.00010156631469726562
iter 19203 (epoch 32), train_loss = 2.466, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 19204 (epoch 32), train_loss = 2.390, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 19205 (epoch 32), train_loss = 2.644, time/batch = 0.027
Read data: 0.0001285076141357422
iter 19206 (epoch 32), train_loss = 2.091, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 19207 (epoch 32), train_loss = 2.677, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19208 (epoch 32), train_loss = 1.960, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 19209 (epoch 32), train_loss = 2.141, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 19210 (epoch 32), train_loss = 2.683, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 19211 (epoch 32), train_loss = 2.028, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 19212 (epoch 32), train_loss = 2.111, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 19213 (epoch 32), train_loss = 2.082, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 19214 (epoch 32), train_loss = 2.183, time/batch = 0.034
Read data: 8.96453857421875e-05
iter 19215 (epoch 32), train_loss = 2.531, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 19216 (epoch 32), train_loss = 2.531, time/batch = 0.021
Read data: 8.821487426757812e-05
iter 19217 (epoch 32), train_loss = 2.179, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 19218 (epoch 32), train_loss = 2.507, time/batch = 0.023
Read data: 0.000141143798828125
iter 19219 (epoch 32), train_loss = 2.624, time/batch = 0.030
Read data: 8.0108642578125e-05
iter 19220 (epoch 32), train_loss = 2.393, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 19221 (epoch 32), train_loss = 2.570, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 19222 (epoch 32), train_loss = 2.525, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 19223 (epoch 32), train_loss = 2.462, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 19224 (epoch 32), train_loss = 2.432, time/batch = 0.035
Read data: 0.0002644062042236328
iter 19225 (epoch 32), train_loss = 2.375, time/batch = 0.031
Read data: 8.749961853027344e-05
iter 19226 (epoch 32), train_loss = 2.206, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 19227 (epoch 32), train_loss = 2.498, time/batch = 0.036
Read data: 9.822845458984375e-05
iter 19228 (epoch 32), train_loss = 2.105, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 19229 (epoch 32), train_loss = 2.421, time/batch = 0.033
Read data: 9.226799011230469e-05
iter 19230 (epoch 32), train_loss = 2.575, time/batch = 0.025
Read data: 8.487701416015625e-05
iter 19231 (epoch 32), train_loss = 2.330, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19232 (epoch 32), train_loss = 2.379, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 19233 (epoch 32), train_loss = 2.441, time/batch = 0.023
Read data: 8.940696716308594e-05
iter 19234 (epoch 32), train_loss = 2.080, time/batch = 0.026
Read data: 9.965896606445312e-05
iter 19235 (epoch 32), train_loss = 2.591, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 19236 (epoch 32), train_loss = 2.509, time/batch = 0.023
Read data: 9.72747802734375e-05
iter 19237 (epoch 32), train_loss = 2.295, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 19238 (epoch 32), train_loss = 2.418, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 19239 (epoch 32), train_loss = 2.185, time/batch = 0.036
Read data: 8.7738037109375e-05
iter 19240 (epoch 32), train_loss = 2.649, time/batch = 0.030
Read data: 0.00013208389282226562
iter 19241 (epoch 32), train_loss = 2.378, time/batch = 0.027
Read data: 9.322166442871094e-05
iter 19242 (epoch 32), train_loss = 2.125, time/batch = 0.024
Read data: 8.392333984375e-05
iter 19243 (epoch 32), train_loss = 2.667, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 19244 (epoch 32), train_loss = 2.427, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 19245 (epoch 32), train_loss = 2.314, time/batch = 0.023
Read data: 0.0017535686492919922
iter 19246 (epoch 32), train_loss = 2.045, time/batch = 0.021
Read data: 9.202957153320312e-05
iter 19247 (epoch 32), train_loss = 2.335, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 19248 (epoch 32), train_loss = 2.407, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 19249 (epoch 32), train_loss = 2.545, time/batch = 0.025
Read data: 0.000278472900390625
iter 19250 (epoch 32), train_loss = 2.450, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 19251 (epoch 32), train_loss = 2.289, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 19252 (epoch 32), train_loss = 2.340, time/batch = 0.028
Read data: 0.00010156631469726562
iter 19253 (epoch 32), train_loss = 2.832, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 19254 (epoch 32), train_loss = 2.069, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 19255 (epoch 32), train_loss = 2.314, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 19256 (epoch 32), train_loss = 2.663, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 19257 (epoch 32), train_loss = 1.888, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 19258 (epoch 32), train_loss = 2.166, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 19259 (epoch 32), train_loss = 2.256, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 19260 (epoch 32), train_loss = 2.333, time/batch = 0.025
Read data: 0.00010442733764648438
iter 19261 (epoch 32), train_loss = 2.034, time/batch = 0.025
Read data: 9.250640869140625e-05
iter 19262 (epoch 32), train_loss = 2.336, time/batch = 0.025
Read data: 0.00013971328735351562
iter 19263 (epoch 32), train_loss = 2.478, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 19264 (epoch 32), train_loss = 2.305, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 19265 (epoch 32), train_loss = 2.638, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 19266 (epoch 32), train_loss = 2.081, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 19267 (epoch 32), train_loss = 2.716, time/batch = 0.031
Read data: 8.177757263183594e-05
iter 19268 (epoch 32), train_loss = 2.071, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 19269 (epoch 32), train_loss = 2.661, time/batch = 0.023
Read data: 0.0001647472381591797
iter 19270 (epoch 32), train_loss = 2.617, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 19271 (epoch 32), train_loss = 2.515, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 19272 (epoch 32), train_loss = 2.287, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 19273 (epoch 32), train_loss = 2.466, time/batch = 0.026
Read data: 0.0001392364501953125
iter 19274 (epoch 32), train_loss = 2.327, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 19275 (epoch 32), train_loss = 2.114, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 19276 (epoch 32), train_loss = 2.617, time/batch = 0.032
Read data: 8.606910705566406e-05
iter 19277 (epoch 32), train_loss = 2.449, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 19278 (epoch 32), train_loss = 1.943, time/batch = 0.027
Read data: 8.392333984375e-05
iter 19279 (epoch 32), train_loss = 2.259, time/batch = 0.022
Read data: 8.249282836914062e-05
iter 19280 (epoch 32), train_loss = 2.300, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 19281 (epoch 32), train_loss = 2.345, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 19282 (epoch 32), train_loss = 2.564, time/batch = 0.031
Read data: 8.368492126464844e-05
iter 19283 (epoch 32), train_loss = 2.397, time/batch = 0.021
Read data: 8.368492126464844e-05
iter 19284 (epoch 32), train_loss = 2.580, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 19285 (epoch 32), train_loss = 2.287, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 19286 (epoch 32), train_loss = 1.936, time/batch = 0.021
Read data: 8.416175842285156e-05
iter 19287 (epoch 32), train_loss = 2.164, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 19288 (epoch 32), train_loss = 2.163, time/batch = 0.023
Read data: 8.821487426757812e-05
iter 19289 (epoch 32), train_loss = 1.968, time/batch = 0.024
Read data: 9.822845458984375e-05
iter 19290 (epoch 32), train_loss = 2.594, time/batch = 0.031
Read data: 0.00010323524475097656
iter 19291 (epoch 32), train_loss = 2.595, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 19292 (epoch 32), train_loss = 2.596, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 19293 (epoch 32), train_loss = 1.992, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 19294 (epoch 32), train_loss = 2.503, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 19295 (epoch 32), train_loss = 2.261, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 19296 (epoch 32), train_loss = 2.561, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 19297 (epoch 32), train_loss = 2.766, time/batch = 0.024
Read data: 9.799003601074219e-05
iter 19298 (epoch 32), train_loss = 2.605, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19299 (epoch 32), train_loss = 2.370, time/batch = 0.029
Read data: 8.7738037109375e-05
iter 19300 (epoch 32), train_loss = 2.202, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 19301 (epoch 32), train_loss = 2.414, time/batch = 0.026
Read data: 9.775161743164062e-05
iter 19302 (epoch 32), train_loss = 2.043, time/batch = 0.024
Read data: 0.00010061264038085938
iter 19303 (epoch 32), train_loss = 2.255, time/batch = 0.028
Read data: 9.965896606445312e-05
iter 19304 (epoch 32), train_loss = 2.727, time/batch = 0.034
Read data: 8.535385131835938e-05
iter 19305 (epoch 32), train_loss = 2.613, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 19306 (epoch 32), train_loss = 2.237, time/batch = 0.025
Read data: 0.00012183189392089844
iter 19307 (epoch 32), train_loss = 2.304, time/batch = 0.032
Read data: 0.00010037422180175781
iter 19308 (epoch 32), train_loss = 2.148, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 19309 (epoch 32), train_loss = 2.224, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 19310 (epoch 32), train_loss = 2.348, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 19311 (epoch 32), train_loss = 2.291, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 19312 (epoch 32), train_loss = 2.319, time/batch = 0.025
Read data: 0.00011181831359863281
iter 19313 (epoch 32), train_loss = 2.395, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 19314 (epoch 32), train_loss = 2.376, time/batch = 0.035
Read data: 8.130073547363281e-05
iter 19315 (epoch 32), train_loss = 2.321, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 19316 (epoch 32), train_loss = 2.482, time/batch = 0.027
Read data: 8.440017700195312e-05
iter 19317 (epoch 32), train_loss = 2.154, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 19318 (epoch 32), train_loss = 2.672, time/batch = 0.026
Read data: 0.00011515617370605469
iter 19319 (epoch 32), train_loss = 2.702, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 19320 (epoch 32), train_loss = 2.535, time/batch = 0.025
Read data: 8.58306884765625e-05
iter 19321 (epoch 32), train_loss = 2.254, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 19322 (epoch 32), train_loss = 2.287, time/batch = 0.025
Read data: 0.00010752677917480469
iter 19323 (epoch 32), train_loss = 2.185, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 19324 (epoch 32), train_loss = 2.333, time/batch = 0.026
Read data: 0.00021600723266601562
iter 19325 (epoch 32), train_loss = 2.294, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 19326 (epoch 32), train_loss = 2.201, time/batch = 0.023
Read data: 0.00012111663818359375
iter 19327 (epoch 32), train_loss = 2.505, time/batch = 0.026
Read data: 0.00010275840759277344
iter 19328 (epoch 32), train_loss = 2.010, time/batch = 0.026
Read data: 9.751319885253906e-05
iter 19329 (epoch 32), train_loss = 2.303, time/batch = 0.026
Read data: 0.000125885009765625
iter 19330 (epoch 32), train_loss = 2.288, time/batch = 0.023
Read data: 9.679794311523438e-05
iter 19331 (epoch 32), train_loss = 2.136, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 19332 (epoch 32), train_loss = 2.211, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 19333 (epoch 32), train_loss = 2.524, time/batch = 0.027
Read data: 8.940696716308594e-05
iter 19334 (epoch 32), train_loss = 2.933, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 19335 (epoch 32), train_loss = 2.544, time/batch = 0.027
Read data: 0.0001087188720703125
iter 19336 (epoch 32), train_loss = 2.272, time/batch = 0.033
Read data: 8.869171142578125e-05
iter 19337 (epoch 32), train_loss = 2.515, time/batch = 0.036
Read data: 8.893013000488281e-05
iter 19338 (epoch 32), train_loss = 2.626, time/batch = 0.024
Read data: 0.00014472007751464844
iter 19339 (epoch 32), train_loss = 2.335, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 19340 (epoch 32), train_loss = 2.367, time/batch = 0.026
Read data: 8.320808410644531e-05
iter 19341 (epoch 32), train_loss = 2.307, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 19342 (epoch 32), train_loss = 2.345, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 19343 (epoch 32), train_loss = 2.334, time/batch = 0.028
Read data: 0.000133514404296875
iter 19344 (epoch 32), train_loss = 2.023, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 19345 (epoch 32), train_loss = 2.248, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 19346 (epoch 32), train_loss = 2.206, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 19347 (epoch 32), train_loss = 2.455, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 19348 (epoch 32), train_loss = 2.232, time/batch = 0.027
Read data: 8.869171142578125e-05
iter 19349 (epoch 32), train_loss = 2.318, time/batch = 0.025
Read data: 0.0002384185791015625
iter 19350 (epoch 32), train_loss = 2.429, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 19351 (epoch 32), train_loss = 2.346, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 19352 (epoch 32), train_loss = 2.371, time/batch = 0.027
Read data: 8.678436279296875e-05
iter 19353 (epoch 32), train_loss = 1.967, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 19354 (epoch 32), train_loss = 2.458, time/batch = 0.035
Read data: 0.0001277923583984375
iter 19355 (epoch 32), train_loss = 2.246, time/batch = 0.027
Read data: 8.7738037109375e-05
iter 19356 (epoch 32), train_loss = 2.250, time/batch = 0.021
Read data: 8.273124694824219e-05
iter 19357 (epoch 32), train_loss = 2.179, time/batch = 0.037
Read data: 8.726119995117188e-05
iter 19358 (epoch 32), train_loss = 2.355, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19359 (epoch 32), train_loss = 2.145, time/batch = 0.024
Read data: 0.00020051002502441406
iter 19360 (epoch 32), train_loss = 1.873, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 19361 (epoch 32), train_loss = 2.716, time/batch = 0.027
Read data: 0.0001437664031982422
iter 19362 (epoch 32), train_loss = 2.598, time/batch = 0.028
Read data: 8.273124694824219e-05
iter 19363 (epoch 32), train_loss = 2.411, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 19364 (epoch 32), train_loss = 2.614, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 19365 (epoch 32), train_loss = 2.557, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 19366 (epoch 32), train_loss = 2.542, time/batch = 0.040
Read data: 0.00014209747314453125
iter 19367 (epoch 32), train_loss = 2.935, time/batch = 0.029
Read data: 8.654594421386719e-05
iter 19368 (epoch 32), train_loss = 2.365, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 19369 (epoch 32), train_loss = 2.294, time/batch = 0.032
Read data: 0.00014448165893554688
iter 19370 (epoch 32), train_loss = 2.314, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 19371 (epoch 32), train_loss = 2.224, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 19372 (epoch 32), train_loss = 2.050, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 19373 (epoch 32), train_loss = 1.935, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 19374 (epoch 32), train_loss = 2.389, time/batch = 0.033
Read data: 8.511543273925781e-05
iter 19375 (epoch 32), train_loss = 2.523, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 19376 (epoch 32), train_loss = 2.397, time/batch = 0.027
Read data: 9.369850158691406e-05
iter 19377 (epoch 32), train_loss = 2.467, time/batch = 0.037
Read data: 8.845329284667969e-05
iter 19378 (epoch 32), train_loss = 2.385, time/batch = 0.022
Read data: 8.463859558105469e-05
iter 19379 (epoch 32), train_loss = 2.220, time/batch = 0.029
Read data: 8.630752563476562e-05
iter 19380 (epoch 32), train_loss = 2.205, time/batch = 0.021
Read data: 8.082389831542969e-05
iter 19381 (epoch 32), train_loss = 2.179, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 19382 (epoch 32), train_loss = 2.297, time/batch = 0.027
Read data: 0.00010037422180175781
iter 19383 (epoch 32), train_loss = 2.256, time/batch = 0.029
Read data: 9.274482727050781e-05
iter 19384 (epoch 32), train_loss = 2.137, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 19385 (epoch 32), train_loss = 2.262, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 19386 (epoch 32), train_loss = 2.344, time/batch = 0.023
Read data: 0.0001506805419921875
iter 19387 (epoch 32), train_loss = 2.329, time/batch = 0.022
Read data: 9.608268737792969e-05
iter 19388 (epoch 32), train_loss = 2.431, time/batch = 0.027
Read data: 9.846687316894531e-05
iter 19389 (epoch 32), train_loss = 2.343, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 19390 (epoch 32), train_loss = 2.265, time/batch = 0.029
Read data: 0.00011897087097167969
iter 19391 (epoch 32), train_loss = 2.380, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 19392 (epoch 32), train_loss = 2.494, time/batch = 0.021
Read data: 8.940696716308594e-05
iter 19393 (epoch 32), train_loss = 2.796, time/batch = 0.033
Read data: 0.0001239776611328125
iter 19394 (epoch 32), train_loss = 2.402, time/batch = 0.028
Read data: 8.082389831542969e-05
iter 19395 (epoch 32), train_loss = 2.109, time/batch = 0.024
Read data: 8.320808410644531e-05
iter 19396 (epoch 32), train_loss = 2.568, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 19397 (epoch 32), train_loss = 2.314, time/batch = 0.025
Read data: 0.0001697540283203125
iter 19398 (epoch 32), train_loss = 2.265, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 19399 (epoch 32), train_loss = 2.315, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19400 (epoch 32), train_loss = 2.367, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 19401 (epoch 32), train_loss = 2.791, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 19402 (epoch 32), train_loss = 2.465, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 19403 (epoch 32), train_loss = 2.160, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 19404 (epoch 32), train_loss = 2.310, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 19405 (epoch 32), train_loss = 2.907, time/batch = 0.035
Read data: 8.869171142578125e-05
iter 19406 (epoch 32), train_loss = 2.251, time/batch = 0.029
Read data: 0.00012612342834472656
iter 19407 (epoch 32), train_loss = 2.495, time/batch = 0.031
Read data: 8.749961853027344e-05
iter 19408 (epoch 32), train_loss = 2.387, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 19409 (epoch 32), train_loss = 2.663, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 19410 (epoch 32), train_loss = 2.482, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 19411 (epoch 32), train_loss = 2.144, time/batch = 0.024
Read data: 9.584426879882812e-05
iter 19412 (epoch 32), train_loss = 2.557, time/batch = 0.030
Read data: 0.0001068115234375
iter 19413 (epoch 32), train_loss = 2.664, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 19414 (epoch 32), train_loss = 2.677, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 19415 (epoch 32), train_loss = 2.453, time/batch = 0.032
Read data: 8.893013000488281e-05
iter 19416 (epoch 32), train_loss = 2.369, time/batch = 0.030
Read data: 0.00010395050048828125
iter 19417 (epoch 32), train_loss = 2.239, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 19418 (epoch 32), train_loss = 2.495, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 19419 (epoch 32), train_loss = 2.630, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19420 (epoch 32), train_loss = 2.803, time/batch = 0.033
Read data: 8.320808410644531e-05
iter 19421 (epoch 32), train_loss = 2.038, time/batch = 0.023
Read data: 8.20159912109375e-05
iter 19422 (epoch 32), train_loss = 2.535, time/batch = 0.024
Read data: 9.703636169433594e-05
iter 19423 (epoch 32), train_loss = 2.160, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 19424 (epoch 32), train_loss = 2.740, time/batch = 0.025
Read data: 0.0003838539123535156
iter 19425 (epoch 32), train_loss = 2.502, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 19426 (epoch 32), train_loss = 1.967, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 19427 (epoch 32), train_loss = 2.346, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 19428 (epoch 32), train_loss = 2.823, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 19429 (epoch 32), train_loss = 2.227, time/batch = 0.024
Read data: 0.00016498565673828125
iter 19430 (epoch 32), train_loss = 2.090, time/batch = 0.025
Read data: 0.00012445449829101562
iter 19431 (epoch 32), train_loss = 2.225, time/batch = 0.024
Read data: 0.00010204315185546875
iter 19432 (epoch 32), train_loss = 2.526, time/batch = 0.027
Read data: 8.916854858398438e-05
iter 19433 (epoch 32), train_loss = 2.447, time/batch = 0.023
Read data: 0.0017023086547851562
iter 19434 (epoch 32), train_loss = 2.136, time/batch = 0.024
Read data: 0.00012493133544921875
iter 19435 (epoch 32), train_loss = 2.546, time/batch = 0.029
Read data: 0.00010228157043457031
iter 19436 (epoch 32), train_loss = 2.460, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 19437 (epoch 32), train_loss = 2.236, time/batch = 0.025
Read data: 0.00010657310485839844
iter 19438 (epoch 32), train_loss = 2.468, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 19439 (epoch 32), train_loss = 2.674, time/batch = 0.028
Read data: 8.487701416015625e-05
iter 19440 (epoch 32), train_loss = 2.653, time/batch = 0.021
Read data: 8.678436279296875e-05
iter 19441 (epoch 32), train_loss = 2.155, time/batch = 0.031
Read data: 7.867813110351562e-05
iter 19442 (epoch 32), train_loss = 2.341, time/batch = 0.021
Read data: 0.00010275840759277344
iter 19443 (epoch 32), train_loss = 2.265, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 19444 (epoch 32), train_loss = 2.004, time/batch = 0.028
Read data: 9.918212890625e-05
iter 19445 (epoch 32), train_loss = 2.364, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 19446 (epoch 32), train_loss = 1.999, time/batch = 0.022
Read data: 0.00012612342834472656
iter 19447 (epoch 32), train_loss = 2.241, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 19448 (epoch 32), train_loss = 2.650, time/batch = 0.021
Read data: 8.726119995117188e-05
iter 19449 (epoch 32), train_loss = 2.233, time/batch = 0.029
Read data: 0.0002999305725097656
iter 19450 (epoch 32), train_loss = 2.402, time/batch = 0.027
Read data: 9.083747863769531e-05
iter 19451 (epoch 32), train_loss = 2.293, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 19452 (epoch 32), train_loss = 2.047, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 19453 (epoch 32), train_loss = 2.276, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 19454 (epoch 32), train_loss = 2.418, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 19455 (epoch 32), train_loss = 2.183, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 19456 (epoch 32), train_loss = 2.801, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 19457 (epoch 32), train_loss = 2.454, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 19458 (epoch 32), train_loss = 2.402, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 19459 (epoch 32), train_loss = 2.870, time/batch = 0.030
Read data: 8.440017700195312e-05
iter 19460 (epoch 32), train_loss = 2.818, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 19461 (epoch 32), train_loss = 2.488, time/batch = 0.037
Read data: 9.298324584960938e-05
iter 19462 (epoch 32), train_loss = 2.700, time/batch = 0.033
Read data: 8.678436279296875e-05
iter 19463 (epoch 32), train_loss = 2.188, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 19464 (epoch 32), train_loss = 2.627, time/batch = 0.030
Read data: 0.00011038780212402344
iter 19465 (epoch 32), train_loss = 2.756, time/batch = 0.029
Read data: 0.0001437664031982422
iter 19466 (epoch 32), train_loss = 2.124, time/batch = 0.021
Read data: 8.416175842285156e-05
iter 19467 (epoch 32), train_loss = 2.129, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 19468 (epoch 32), train_loss = 2.270, time/batch = 0.021
Read data: 9.465217590332031e-05
iter 19469 (epoch 32), train_loss = 2.390, time/batch = 0.021
Read data: 8.678436279296875e-05
iter 19470 (epoch 32), train_loss = 2.260, time/batch = 0.024
Read data: 0.00014257431030273438
iter 19471 (epoch 32), train_loss = 2.278, time/batch = 0.028
Read data: 9.226799011230469e-05
iter 19472 (epoch 32), train_loss = 2.113, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 19473 (epoch 32), train_loss = 2.337, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 19474 (epoch 32), train_loss = 1.959, time/batch = 0.022
Read data: 0.0002186298370361328
iter 19475 (epoch 32), train_loss = 2.223, time/batch = 0.033
Read data: 8.392333984375e-05
iter 19476 (epoch 32), train_loss = 2.250, time/batch = 0.033
Read data: 8.535385131835938e-05
iter 19477 (epoch 32), train_loss = 2.280, time/batch = 0.038
Read data: 0.00010824203491210938
iter 19478 (epoch 32), train_loss = 2.223, time/batch = 0.032
Read data: 9.72747802734375e-05
iter 19479 (epoch 32), train_loss = 2.371, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 19480 (epoch 32), train_loss = 2.105, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 19481 (epoch 32), train_loss = 2.164, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 19482 (epoch 32), train_loss = 2.981, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 19483 (epoch 32), train_loss = 2.073, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 19484 (epoch 32), train_loss = 2.339, time/batch = 0.022
Read data: 9.775161743164062e-05
iter 19485 (epoch 32), train_loss = 2.530, time/batch = 0.028
Read data: 8.821487426757812e-05
iter 19486 (epoch 32), train_loss = 2.215, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 19487 (epoch 32), train_loss = 2.379, time/batch = 0.022
Read data: 9.369850158691406e-05
iter 19488 (epoch 32), train_loss = 2.093, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 19489 (epoch 32), train_loss = 1.940, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 19490 (epoch 32), train_loss = 2.149, time/batch = 0.024
Read data: 0.00010156631469726562
iter 19491 (epoch 32), train_loss = 2.540, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 19492 (epoch 32), train_loss = 2.571, time/batch = 0.032
Read data: 8.296966552734375e-05
iter 19493 (epoch 32), train_loss = 2.460, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 19494 (epoch 32), train_loss = 2.539, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 19495 (epoch 32), train_loss = 2.268, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 19496 (epoch 32), train_loss = 2.410, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19497 (epoch 32), train_loss = 2.336, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 19498 (epoch 32), train_loss = 2.396, time/batch = 0.024
Read data: 0.00010180473327636719
iter 19499 (epoch 32), train_loss = 2.421, time/batch = 0.029
Read data: 0.0001010894775390625
iter 19500 (epoch 32), train_loss = 2.538, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 19501 (epoch 32), train_loss = 2.768, time/batch = 0.035
Read data: 8.463859558105469e-05
iter 19502 (epoch 32), train_loss = 2.508, time/batch = 0.025
Read data: 0.00014901161193847656
iter 19503 (epoch 32), train_loss = 2.494, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 19504 (epoch 32), train_loss = 2.180, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 19505 (epoch 32), train_loss = 2.458, time/batch = 0.024
Read data: 0.00010228157043457031
iter 19506 (epoch 32), train_loss = 2.548, time/batch = 0.024
Read data: 0.00010156631469726562
iter 19507 (epoch 32), train_loss = 2.564, time/batch = 0.033
Read data: 8.249282836914062e-05
iter 19508 (epoch 32), train_loss = 2.434, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 19509 (epoch 32), train_loss = 2.594, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 19510 (epoch 32), train_loss = 2.343, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 19511 (epoch 32), train_loss = 2.025, time/batch = 0.028
Read data: 0.00011038780212402344
iter 19512 (epoch 32), train_loss = 2.708, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 19513 (epoch 32), train_loss = 2.120, time/batch = 0.023
Read data: 9.369850158691406e-05
iter 19514 (epoch 32), train_loss = 2.592, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 19515 (epoch 32), train_loss = 2.542, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 19516 (epoch 32), train_loss = 2.130, time/batch = 0.028
Read data: 9.608268737792969e-05
iter 19517 (epoch 32), train_loss = 2.204, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 19518 (epoch 32), train_loss = 2.363, time/batch = 0.023
Read data: 7.843971252441406e-05
iter 19519 (epoch 32), train_loss = 2.580, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 19520 (epoch 32), train_loss = 2.264, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 19521 (epoch 32), train_loss = 2.382, time/batch = 0.029
Read data: 8.96453857421875e-05
iter 19522 (epoch 32), train_loss = 2.092, time/batch = 0.027
Read data: 9.489059448242188e-05
iter 19523 (epoch 32), train_loss = 2.528, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 19524 (epoch 32), train_loss = 2.355, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 19525 (epoch 32), train_loss = 2.838, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 19526 (epoch 32), train_loss = 2.475, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 19527 (epoch 32), train_loss = 2.501, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 19528 (epoch 32), train_loss = 2.578, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 19529 (epoch 32), train_loss = 2.457, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 19530 (epoch 32), train_loss = 2.218, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 19531 (epoch 32), train_loss = 2.070, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 19532 (epoch 32), train_loss = 2.731, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 19533 (epoch 32), train_loss = 2.559, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 19534 (epoch 32), train_loss = 2.240, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 19535 (epoch 32), train_loss = 2.560, time/batch = 0.024
Read data: 9.942054748535156e-05
iter 19536 (epoch 32), train_loss = 2.394, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 19537 (epoch 32), train_loss = 2.411, time/batch = 0.025
Read data: 0.00010466575622558594
iter 19538 (epoch 32), train_loss = 2.229, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 19539 (epoch 32), train_loss = 2.833, time/batch = 0.031
Read data: 8.392333984375e-05
iter 19540 (epoch 32), train_loss = 2.031, time/batch = 0.023
Read data: 0.00010657310485839844
iter 19541 (epoch 32), train_loss = 2.920, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 19542 (epoch 32), train_loss = 1.924, time/batch = 0.022
Read data: 8.058547973632812e-05
iter 19543 (epoch 32), train_loss = 2.496, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 19544 (epoch 32), train_loss = 2.573, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 19545 (epoch 32), train_loss = 2.263, time/batch = 0.021
Read data: 8.893013000488281e-05
iter 19546 (epoch 32), train_loss = 2.376, time/batch = 0.025
Read data: 0.00014281272888183594
iter 19547 (epoch 32), train_loss = 2.249, time/batch = 0.030
Read data: 9.560585021972656e-05
iter 19548 (epoch 32), train_loss = 2.127, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 19549 (epoch 32), train_loss = 2.315, time/batch = 0.025
Read data: 0.0002491474151611328
iter 19550 (epoch 32), train_loss = 2.067, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 19551 (epoch 32), train_loss = 2.611, time/batch = 0.035
Read data: 8.535385131835938e-05
iter 19552 (epoch 32), train_loss = 2.078, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 19553 (epoch 32), train_loss = 2.612, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 19554 (epoch 32), train_loss = 2.531, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 19555 (epoch 32), train_loss = 2.188, time/batch = 0.024
Read data: 8.249282836914062e-05
iter 19556 (epoch 32), train_loss = 2.546, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 19557 (epoch 32), train_loss = 2.368, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 19558 (epoch 32), train_loss = 2.338, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 19559 (epoch 32), train_loss = 2.543, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 19560 (epoch 32), train_loss = 2.399, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 19561 (epoch 32), train_loss = 2.207, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 19562 (epoch 32), train_loss = 2.611, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 19563 (epoch 32), train_loss = 2.508, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 19564 (epoch 32), train_loss = 2.401, time/batch = 0.036
Read data: 8.130073547363281e-05
iter 19565 (epoch 32), train_loss = 2.429, time/batch = 0.027
Read data: 9.298324584960938e-05
iter 19566 (epoch 32), train_loss = 2.168, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 19567 (epoch 32), train_loss = 2.454, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 19568 (epoch 32), train_loss = 2.244, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 19569 (epoch 32), train_loss = 2.230, time/batch = 0.031
Read data: 8.082389831542969e-05
iter 19570 (epoch 32), train_loss = 2.448, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 19571 (epoch 32), train_loss = 2.609, time/batch = 0.027
Read data: 8.273124694824219e-05
iter 19572 (epoch 32), train_loss = 2.560, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 19573 (epoch 32), train_loss = 2.279, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 19574 (epoch 32), train_loss = 2.042, time/batch = 0.027
Read data: 0.0002644062042236328
iter 19575 (epoch 32), train_loss = 2.189, time/batch = 0.032
Read data: 8.440017700195312e-05
iter 19576 (epoch 32), train_loss = 1.930, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 19577 (epoch 32), train_loss = 2.553, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 19578 (epoch 32), train_loss = 2.837, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 19579 (epoch 32), train_loss = 2.427, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 19580 (epoch 32), train_loss = 2.496, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 19581 (epoch 32), train_loss = 2.221, time/batch = 0.021
Read data: 9.202957153320312e-05
iter 19582 (epoch 32), train_loss = 2.446, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 19583 (epoch 32), train_loss = 2.289, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 19584 (epoch 32), train_loss = 2.382, time/batch = 0.025
Read data: 0.0001049041748046875
iter 19585 (epoch 32), train_loss = 2.348, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 19586 (epoch 32), train_loss = 2.264, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 19587 (epoch 32), train_loss = 2.659, time/batch = 0.030
Read data: 0.0001010894775390625
iter 19588 (epoch 32), train_loss = 2.310, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 19589 (epoch 32), train_loss = 1.672, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 19590 (epoch 32), train_loss = 2.298, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 19591 (epoch 32), train_loss = 2.352, time/batch = 0.027
Read data: 0.00010156631469726562
iter 19592 (epoch 32), train_loss = 2.120, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 19593 (epoch 32), train_loss = 2.374, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19594 (epoch 32), train_loss = 2.567, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 19595 (epoch 32), train_loss = 2.598, time/batch = 0.030
Read data: 8.296966552734375e-05
iter 19596 (epoch 32), train_loss = 2.408, time/batch = 0.026
Read data: 9.679794311523438e-05
iter 19597 (epoch 32), train_loss = 2.408, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 19598 (epoch 32), train_loss = 2.154, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 19599 (epoch 32), train_loss = 2.025, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 19600 (epoch 32), train_loss = 2.658, time/batch = 0.029
Read data: 8.392333984375e-05
iter 19601 (epoch 32), train_loss = 2.308, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 19602 (epoch 32), train_loss = 2.114, time/batch = 0.021
Read data: 0.00010323524475097656
iter 19603 (epoch 32), train_loss = 2.618, time/batch = 0.026
Read data: 0.00010228157043457031
iter 19604 (epoch 32), train_loss = 2.264, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 19605 (epoch 32), train_loss = 2.216, time/batch = 0.027
Read data: 0.0001010894775390625
iter 19606 (epoch 32), train_loss = 2.211, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 19607 (epoch 32), train_loss = 2.144, time/batch = 0.024
Read data: 9.846687316894531e-05
iter 19608 (epoch 32), train_loss = 2.241, time/batch = 0.022
Read data: 0.0001068115234375
iter 19609 (epoch 32), train_loss = 2.529, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 19610 (epoch 32), train_loss = 2.410, time/batch = 0.024
Read data: 9.655952453613281e-05
iter 19611 (epoch 32), train_loss = 2.417, time/batch = 0.029
Read data: 9.417533874511719e-05
iter 19612 (epoch 32), train_loss = 2.187, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 19613 (epoch 32), train_loss = 2.444, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 19614 (epoch 32), train_loss = 2.316, time/batch = 0.024
Read data: 8.106231689453125e-05
iter 19615 (epoch 32), train_loss = 2.376, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 19616 (epoch 32), train_loss = 2.543, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 19617 (epoch 32), train_loss = 2.281, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 19618 (epoch 32), train_loss = 2.700, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 19619 (epoch 32), train_loss = 2.372, time/batch = 0.026
Read data: 0.00010228157043457031
iter 19620 (epoch 32), train_loss = 2.536, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 19621 (epoch 32), train_loss = 2.297, time/batch = 0.031
Read data: 9.751319885253906e-05
iter 19622 (epoch 32), train_loss = 2.326, time/batch = 0.027
Read data: 0.00013971328735351562
iter 19623 (epoch 32), train_loss = 2.562, time/batch = 0.040
Read data: 8.845329284667969e-05
iter 19624 (epoch 32), train_loss = 2.315, time/batch = 0.028
Read data: 0.0002579689025878906
iter 19625 (epoch 32), train_loss = 2.216, time/batch = 0.025
Read data: 8.869171142578125e-05
iter 19626 (epoch 32), train_loss = 2.492, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 19627 (epoch 32), train_loss = 2.225, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 19628 (epoch 32), train_loss = 2.317, time/batch = 0.024
Read data: 0.00010156631469726562
iter 19629 (epoch 32), train_loss = 1.988, time/batch = 0.025
Read data: 0.00010800361633300781
iter 19630 (epoch 32), train_loss = 2.324, time/batch = 0.034
Read data: 8.463859558105469e-05
iter 19631 (epoch 32), train_loss = 2.118, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 19632 (epoch 32), train_loss = 2.480, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 19633 (epoch 32), train_loss = 2.507, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 19634 (epoch 32), train_loss = 2.540, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19635 (epoch 32), train_loss = 2.551, time/batch = 0.040
Read data: 8.916854858398438e-05
iter 19636 (epoch 32), train_loss = 2.286, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 19637 (epoch 32), train_loss = 2.733, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 19638 (epoch 32), train_loss = 2.165, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 19639 (epoch 32), train_loss = 2.420, time/batch = 0.027
Read data: 7.700920104980469e-05
iter 19640 (epoch 32), train_loss = 2.350, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 19641 (epoch 32), train_loss = 2.714, time/batch = 0.029
Read data: 8.320808410644531e-05
iter 19642 (epoch 32), train_loss = 2.332, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 19643 (epoch 32), train_loss = 2.189, time/batch = 0.020
Read data: 9.560585021972656e-05
iter 19644 (epoch 32), train_loss = 2.438, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 19645 (epoch 32), train_loss = 2.406, time/batch = 0.034
Read data: 0.00010657310485839844
iter 19646 (epoch 32), train_loss = 2.644, time/batch = 0.026
Read data: 8.559226989746094e-05
iter 19647 (epoch 32), train_loss = 2.362, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 19648 (epoch 32), train_loss = 2.424, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 19649 (epoch 32), train_loss = 2.183, time/batch = 0.025
Read data: 0.0002071857452392578
iter 19650 (epoch 32), train_loss = 2.141, time/batch = 0.036
Read data: 8.535385131835938e-05
iter 19651 (epoch 32), train_loss = 2.577, time/batch = 0.028
Read data: 9.775161743164062e-05
iter 19652 (epoch 32), train_loss = 2.137, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 19653 (epoch 32), train_loss = 2.388, time/batch = 0.040
Read data: 8.869171142578125e-05
iter 19654 (epoch 32), train_loss = 2.499, time/batch = 0.039
Read data: 7.748603820800781e-05
iter 19655 (epoch 32), train_loss = 2.651, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 19656 (epoch 32), train_loss = 2.239, time/batch = 0.022
Read data: 8.845329284667969e-05
iter 19657 (epoch 32), train_loss = 2.366, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 19658 (epoch 32), train_loss = 2.509, time/batch = 0.023
Read data: 9.942054748535156e-05
iter 19659 (epoch 32), train_loss = 2.123, time/batch = 0.023
Read data: 8.893013000488281e-05
iter 19660 (epoch 32), train_loss = 2.336, time/batch = 0.029
Read data: 9.179115295410156e-05
iter 19661 (epoch 32), train_loss = 2.066, time/batch = 0.028
Read data: 0.00010848045349121094
iter 19662 (epoch 32), train_loss = 2.599, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 19663 (epoch 32), train_loss = 2.377, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 19664 (epoch 32), train_loss = 2.047, time/batch = 0.025
Read data: 0.00013709068298339844
iter 19665 (epoch 32), train_loss = 2.142, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 19666 (epoch 32), train_loss = 2.392, time/batch = 0.031
Read data: 0.0001327991485595703
iter 19667 (epoch 32), train_loss = 2.234, time/batch = 0.035
Read data: 9.512901306152344e-05
iter 19668 (epoch 32), train_loss = 2.719, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 19669 (epoch 32), train_loss = 2.504, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19670 (epoch 32), train_loss = 2.696, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 19671 (epoch 32), train_loss = 2.466, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 19672 (epoch 32), train_loss = 2.787, time/batch = 0.030
Read data: 8.082389831542969e-05
iter 19673 (epoch 32), train_loss = 2.194, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 19674 (epoch 32), train_loss = 2.643, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 19675 (epoch 32), train_loss = 2.710, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 19676 (epoch 32), train_loss = 2.423, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 19677 (epoch 32), train_loss = 2.192, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 19678 (epoch 32), train_loss = 2.340, time/batch = 0.032
Read data: 8.153915405273438e-05
iter 19679 (epoch 32), train_loss = 2.829, time/batch = 0.032
Read data: 8.368492126464844e-05
iter 19680 (epoch 32), train_loss = 2.190, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 19681 (epoch 32), train_loss = 2.440, time/batch = 0.026
Read data: 9.822845458984375e-05
iter 19682 (epoch 32), train_loss = 2.545, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 19683 (epoch 32), train_loss = 2.075, time/batch = 0.025
Read data: 8.034706115722656e-05
iter 19684 (epoch 32), train_loss = 2.344, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 19685 (epoch 32), train_loss = 2.110, time/batch = 0.026
Read data: 9.036064147949219e-05
iter 19686 (epoch 32), train_loss = 2.676, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 19687 (epoch 32), train_loss = 2.156, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 19688 (epoch 32), train_loss = 2.351, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 19689 (epoch 32), train_loss = 2.243, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 19690 (epoch 32), train_loss = 2.466, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 19691 (epoch 32), train_loss = 1.999, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 19692 (epoch 32), train_loss = 2.116, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19693 (epoch 32), train_loss = 2.207, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 19694 (epoch 32), train_loss = 2.204, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 19695 (epoch 32), train_loss = 1.985, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 19696 (epoch 32), train_loss = 2.806, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 19697 (epoch 32), train_loss = 2.341, time/batch = 0.032
Read data: 8.368492126464844e-05
iter 19698 (epoch 32), train_loss = 2.245, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 19699 (epoch 32), train_loss = 2.423, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 19700 (epoch 32), train_loss = 2.547, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 19701 (epoch 32), train_loss = 2.205, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 19702 (epoch 32), train_loss = 2.330, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 19703 (epoch 32), train_loss = 2.826, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 19704 (epoch 32), train_loss = 2.255, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 19705 (epoch 32), train_loss = 2.685, time/batch = 0.033
Read data: 8.869171142578125e-05
iter 19706 (epoch 32), train_loss = 2.584, time/batch = 0.028
Read data: 8.869171142578125e-05
iter 19707 (epoch 32), train_loss = 2.454, time/batch = 0.034
Read data: 8.726119995117188e-05
iter 19708 (epoch 32), train_loss = 2.371, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 19709 (epoch 32), train_loss = 2.366, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 19710 (epoch 32), train_loss = 2.298, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 19711 (epoch 32), train_loss = 2.071, time/batch = 0.023
Read data: 0.00011396408081054688
iter 19712 (epoch 32), train_loss = 2.595, time/batch = 0.034
Read data: 0.00010538101196289062
iter 19713 (epoch 32), train_loss = 2.399, time/batch = 0.038
Read data: 8.702278137207031e-05
iter 19714 (epoch 32), train_loss = 2.437, time/batch = 0.027
Read data: 9.894371032714844e-05
iter 19715 (epoch 32), train_loss = 2.254, time/batch = 0.020
Read data: 8.702278137207031e-05
iter 19716 (epoch 32), train_loss = 2.282, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 19717 (epoch 32), train_loss = 2.460, time/batch = 0.022
Read data: 9.775161743164062e-05
iter 19718 (epoch 32), train_loss = 2.565, time/batch = 0.028
Read data: 0.0001480579376220703
iter 19719 (epoch 32), train_loss = 2.320, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 19720 (epoch 32), train_loss = 2.342, time/batch = 0.030
Read data: 0.00010323524475097656
iter 19721 (epoch 32), train_loss = 2.310, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 19722 (epoch 32), train_loss = 2.594, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 19723 (epoch 32), train_loss = 2.942, time/batch = 0.025
Read data: 0.0001537799835205078
iter 19724 (epoch 32), train_loss = 2.396, time/batch = 0.021
Read data: 0.0002675056457519531
iter 19725 (epoch 32), train_loss = 2.568, time/batch = 0.031
Read data: 9.799003601074219e-05
iter 19726 (epoch 32), train_loss = 2.119, time/batch = 0.024
Read data: 0.00010085105895996094
iter 19727 (epoch 32), train_loss = 2.527, time/batch = 0.033
Read data: 8.96453857421875e-05
iter 19728 (epoch 32), train_loss = 1.914, time/batch = 0.022
Read data: 0.00014662742614746094
iter 19729 (epoch 32), train_loss = 2.589, time/batch = 0.027
Read data: 8.58306884765625e-05
iter 19730 (epoch 32), train_loss = 2.604, time/batch = 0.023
Read data: 8.392333984375e-05
iter 19731 (epoch 32), train_loss = 1.930, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 19732 (epoch 32), train_loss = 2.507, time/batch = 0.028
Read data: 9.202957153320312e-05
iter 19733 (epoch 32), train_loss = 2.579, time/batch = 0.033
Read data: 8.058547973632812e-05
iter 19734 (epoch 32), train_loss = 2.087, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 19735 (epoch 32), train_loss = 2.370, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 19736 (epoch 32), train_loss = 2.046, time/batch = 0.023
Read data: 8.249282836914062e-05
iter 19737 (epoch 32), train_loss = 2.784, time/batch = 0.023
Read data: 0.00010061264038085938
iter 19738 (epoch 32), train_loss = 2.259, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 19739 (epoch 32), train_loss = 2.156, time/batch = 0.025
Read data: 9.703636169433594e-05
iter 19740 (epoch 32), train_loss = 2.370, time/batch = 0.028
Read data: 0.00010204315185546875
iter 19741 (epoch 32), train_loss = 2.641, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 19742 (epoch 32), train_loss = 2.357, time/batch = 0.024
Read data: 0.00010728836059570312
iter 19743 (epoch 32), train_loss = 2.289, time/batch = 0.031
Read data: 0.00012063980102539062
iter 19744 (epoch 32), train_loss = 2.274, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 19745 (epoch 32), train_loss = 2.033, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 19746 (epoch 32), train_loss = 2.138, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 19747 (epoch 32), train_loss = 2.517, time/batch = 0.028
Read data: 0.00012612342834472656
iter 19748 (epoch 32), train_loss = 1.995, time/batch = 0.023
Read data: 8.368492126464844e-05
iter 19749 (epoch 32), train_loss = 2.242, time/batch = 0.029
Read data: 0.00021600723266601562
iter 19750 (epoch 32), train_loss = 2.334, time/batch = 0.037
Read data: 8.273124694824219e-05
iter 19751 (epoch 32), train_loss = 2.378, time/batch = 0.025
Read data: 0.00014281272888183594
iter 19752 (epoch 32), train_loss = 2.397, time/batch = 0.030
Read data: 9.012222290039062e-05
iter 19753 (epoch 32), train_loss = 2.226, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 19754 (epoch 32), train_loss = 2.304, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 19755 (epoch 32), train_loss = 2.707, time/batch = 0.023
Read data: 9.751319885253906e-05
iter 19756 (epoch 32), train_loss = 2.377, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 19757 (epoch 32), train_loss = 3.007, time/batch = 0.025
Read data: 0.0001270771026611328
iter 19758 (epoch 32), train_loss = 1.838, time/batch = 0.029
Read data: 8.940696716308594e-05
iter 19759 (epoch 32), train_loss = 1.753, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 19760 (epoch 32), train_loss = 2.513, time/batch = 0.023
Read data: 0.0001628398895263672
iter 19761 (epoch 32), train_loss = 2.534, time/batch = 0.024
Read data: 0.00010013580322265625
iter 19762 (epoch 32), train_loss = 2.523, time/batch = 0.026
Read data: 0.00010657310485839844
iter 19763 (epoch 32), train_loss = 2.559, time/batch = 0.027
Read data: 0.00010585784912109375
iter 19764 (epoch 32), train_loss = 2.821, time/batch = 0.029
Read data: 0.00012969970703125
iter 19765 (epoch 32), train_loss = 2.381, time/batch = 0.028
Read data: 0.0017399787902832031
iter 19766 (epoch 32), train_loss = 2.593, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 19767 (epoch 32), train_loss = 1.877, time/batch = 0.024
Read data: 0.0001304149627685547
iter 19768 (epoch 32), train_loss = 2.585, time/batch = 0.036
Read data: 0.00011157989501953125
iter 19769 (epoch 32), train_loss = 2.539, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 19770 (epoch 32), train_loss = 2.409, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 19771 (epoch 32), train_loss = 2.434, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 19772 (epoch 32), train_loss = 2.837, time/batch = 0.028
Read data: 0.00018906593322753906
iter 19773 (epoch 32), train_loss = 2.403, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 19774 (epoch 32), train_loss = 2.116, time/batch = 0.026
Read data: 0.0002200603485107422
iter 19775 (epoch 32), train_loss = 2.366, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 19776 (epoch 32), train_loss = 2.551, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 19777 (epoch 32), train_loss = 2.397, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19778 (epoch 32), train_loss = 2.180, time/batch = 0.033
Read data: 9.012222290039062e-05
iter 19779 (epoch 32), train_loss = 2.599, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 19780 (epoch 32), train_loss = 2.024, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 19781 (epoch 32), train_loss = 2.444, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 19782 (epoch 32), train_loss = 2.337, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 19783 (epoch 32), train_loss = 2.498, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 19784 (epoch 32), train_loss = 2.341, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19785 (epoch 32), train_loss = 2.497, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 19786 (epoch 32), train_loss = 2.457, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 19787 (epoch 32), train_loss = 2.655, time/batch = 0.021
Read data: 0.00010156631469726562
iter 19788 (epoch 32), train_loss = 2.568, time/batch = 0.030
Read data: 0.0001628398895263672
iter 19789 (epoch 32), train_loss = 2.350, time/batch = 0.025
Read data: 0.00013375282287597656
iter 19790 (epoch 32), train_loss = 1.909, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 19791 (epoch 32), train_loss = 2.588, time/batch = 0.025
Read data: 0.0017156600952148438
iter 19792 (epoch 32), train_loss = 2.247, time/batch = 0.027
Read data: 0.00020432472229003906
iter 19793 (epoch 32), train_loss = 2.242, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 19794 (epoch 32), train_loss = 2.423, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 19795 (epoch 32), train_loss = 2.142, time/batch = 0.025
Read data: 8.940696716308594e-05
iter 19796 (epoch 32), train_loss = 2.479, time/batch = 0.029
Read data: 8.916854858398438e-05
iter 19797 (epoch 32), train_loss = 2.381, time/batch = 0.032
Read data: 7.987022399902344e-05
iter 19798 (epoch 32), train_loss = 2.481, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19799 (epoch 32), train_loss = 2.622, time/batch = 0.024
Read data: 0.0001671314239501953
iter 19800 (epoch 32), train_loss = 2.524, time/batch = 0.023
Read data: 0.000179290771484375
iter 19801 (epoch 33), train_loss = 2.383, time/batch = 0.030
Read data: 0.00015044212341308594
iter 19802 (epoch 33), train_loss = 2.049, time/batch = 0.030
Read data: 8.678436279296875e-05
iter 19803 (epoch 33), train_loss = 1.958, time/batch = 0.022
Read data: 0.00011205673217773438
iter 19804 (epoch 33), train_loss = 2.108, time/batch = 0.022
Read data: 0.00015282630920410156
iter 19805 (epoch 33), train_loss = 2.169, time/batch = 0.025
Read data: 0.00010251998901367188
iter 19806 (epoch 33), train_loss = 2.426, time/batch = 0.029
Read data: 9.369850158691406e-05
iter 19807 (epoch 33), train_loss = 2.158, time/batch = 0.032
Read data: 7.939338684082031e-05
iter 19808 (epoch 33), train_loss = 2.302, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 19809 (epoch 33), train_loss = 2.414, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 19810 (epoch 33), train_loss = 2.494, time/batch = 0.025
Read data: 0.00012159347534179688
iter 19811 (epoch 33), train_loss = 2.610, time/batch = 0.021
Read data: 8.96453857421875e-05
iter 19812 (epoch 33), train_loss = 2.654, time/batch = 0.032
Read data: 0.00012969970703125
iter 19813 (epoch 33), train_loss = 2.320, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 19814 (epoch 33), train_loss = 2.162, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 19815 (epoch 33), train_loss = 2.389, time/batch = 0.030
Read data: 0.00012969970703125
iter 19816 (epoch 33), train_loss = 1.922, time/batch = 0.028
Read data: 8.511543273925781e-05
iter 19817 (epoch 33), train_loss = 2.521, time/batch = 0.031
Read data: 8.130073547363281e-05
iter 19818 (epoch 33), train_loss = 2.684, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 19819 (epoch 33), train_loss = 2.259, time/batch = 0.027
Read data: 0.0001220703125
iter 19820 (epoch 33), train_loss = 2.452, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 19821 (epoch 33), train_loss = 2.506, time/batch = 0.023
Read data: 0.00010085105895996094
iter 19822 (epoch 33), train_loss = 2.534, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 19823 (epoch 33), train_loss = 2.468, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 19824 (epoch 33), train_loss = 2.507, time/batch = 0.029
Read data: 0.00022935867309570312
iter 19825 (epoch 33), train_loss = 2.150, time/batch = 0.031
Read data: 8.225440979003906e-05
iter 19826 (epoch 33), train_loss = 2.118, time/batch = 0.023
Read data: 8.392333984375e-05
iter 19827 (epoch 33), train_loss = 2.347, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 19828 (epoch 33), train_loss = 2.535, time/batch = 0.025
Read data: 9.036064147949219e-05
iter 19829 (epoch 33), train_loss = 2.144, time/batch = 0.027
Read data: 9.5367431640625e-05
iter 19830 (epoch 33), train_loss = 2.251, time/batch = 0.034
Read data: 8.535385131835938e-05
iter 19831 (epoch 33), train_loss = 2.625, time/batch = 0.027
Read data: 9.679794311523438e-05
iter 19832 (epoch 33), train_loss = 2.577, time/batch = 0.029
Read data: 8.249282836914062e-05
iter 19833 (epoch 33), train_loss = 2.303, time/batch = 0.029
Read data: 8.487701416015625e-05
iter 19834 (epoch 33), train_loss = 2.538, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 19835 (epoch 33), train_loss = 2.190, time/batch = 0.025
Read data: 0.00013875961303710938
iter 19836 (epoch 33), train_loss = 2.152, time/batch = 0.025
Read data: 9.274482727050781e-05
iter 19837 (epoch 33), train_loss = 2.713, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 19838 (epoch 33), train_loss = 2.161, time/batch = 0.026
Read data: 8.511543273925781e-05
iter 19839 (epoch 33), train_loss = 2.192, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 19840 (epoch 33), train_loss = 2.448, time/batch = 0.021
Read data: 8.20159912109375e-05
iter 19841 (epoch 33), train_loss = 2.188, time/batch = 0.022
Read data: 9.226799011230469e-05
iter 19842 (epoch 33), train_loss = 2.560, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 19843 (epoch 33), train_loss = 2.000, time/batch = 0.024
Read data: 0.00013017654418945312
iter 19844 (epoch 33), train_loss = 1.851, time/batch = 0.023
Read data: 9.274482727050781e-05
iter 19845 (epoch 33), train_loss = 2.138, time/batch = 0.029
Read data: 9.202957153320312e-05
iter 19846 (epoch 33), train_loss = 2.243, time/batch = 0.021
Read data: 9.608268737792969e-05
iter 19847 (epoch 33), train_loss = 2.730, time/batch = 0.030
Read data: 8.58306884765625e-05
iter 19848 (epoch 33), train_loss = 2.595, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 19849 (epoch 33), train_loss = 2.485, time/batch = 0.037
Read data: 0.00023889541625976562
iter 19850 (epoch 33), train_loss = 2.046, time/batch = 0.023
Read data: 0.00010251998901367188
iter 19851 (epoch 33), train_loss = 2.657, time/batch = 0.023
Read data: 9.107589721679688e-05
iter 19852 (epoch 33), train_loss = 2.170, time/batch = 0.033
Read data: 8.225440979003906e-05
iter 19853 (epoch 33), train_loss = 2.429, time/batch = 0.025
Read data: 9.489059448242188e-05
iter 19854 (epoch 33), train_loss = 2.232, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 19855 (epoch 33), train_loss = 2.335, time/batch = 0.022
Read data: 9.775161743164062e-05
iter 19856 (epoch 33), train_loss = 2.517, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 19857 (epoch 33), train_loss = 2.582, time/batch = 0.038
Read data: 8.153915405273438e-05
iter 19858 (epoch 33), train_loss = 2.177, time/batch = 0.031
Read data: 9.012222290039062e-05
iter 19859 (epoch 33), train_loss = 2.403, time/batch = 0.024
Read data: 8.392333984375e-05
iter 19860 (epoch 33), train_loss = 2.355, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 19861 (epoch 33), train_loss = 2.225, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 19862 (epoch 33), train_loss = 2.573, time/batch = 0.022
Read data: 9.751319885253906e-05
iter 19863 (epoch 33), train_loss = 2.424, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 19864 (epoch 33), train_loss = 2.427, time/batch = 0.033
Read data: 0.00011110305786132812
iter 19865 (epoch 33), train_loss = 2.197, time/batch = 0.029
Read data: 8.20159912109375e-05
iter 19866 (epoch 33), train_loss = 2.069, time/batch = 0.024
Read data: 0.00010442733764648438
iter 19867 (epoch 33), train_loss = 2.390, time/batch = 0.029
Read data: 8.58306884765625e-05
iter 19868 (epoch 33), train_loss = 2.490, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 19869 (epoch 33), train_loss = 2.398, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 19870 (epoch 33), train_loss = 2.464, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 19871 (epoch 33), train_loss = 2.374, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 19872 (epoch 33), train_loss = 2.283, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 19873 (epoch 33), train_loss = 2.306, time/batch = 0.024
Read data: 9.202957153320312e-05
iter 19874 (epoch 33), train_loss = 2.188, time/batch = 0.029
Read data: 0.0002224445343017578
iter 19875 (epoch 33), train_loss = 2.244, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 19876 (epoch 33), train_loss = 2.551, time/batch = 0.029
Read data: 9.72747802734375e-05
iter 19877 (epoch 33), train_loss = 2.112, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 19878 (epoch 33), train_loss = 2.269, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 19879 (epoch 33), train_loss = 2.293, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 19880 (epoch 33), train_loss = 2.269, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 19881 (epoch 33), train_loss = 2.390, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 19882 (epoch 33), train_loss = 1.963, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 19883 (epoch 33), train_loss = 2.213, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 19884 (epoch 33), train_loss = 2.156, time/batch = 0.033
Read data: 0.00010132789611816406
iter 19885 (epoch 33), train_loss = 1.834, time/batch = 0.022
Read data: 0.00010418891906738281
iter 19886 (epoch 33), train_loss = 2.501, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 19887 (epoch 33), train_loss = 2.426, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 19888 (epoch 33), train_loss = 2.284, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 19889 (epoch 33), train_loss = 2.514, time/batch = 0.027
Read data: 9.107589721679688e-05
iter 19890 (epoch 33), train_loss = 2.193, time/batch = 0.030
Read data: 9.870529174804688e-05
iter 19891 (epoch 33), train_loss = 2.315, time/batch = 0.040
Read data: 8.749961853027344e-05
iter 19892 (epoch 33), train_loss = 2.586, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 19893 (epoch 33), train_loss = 2.296, time/batch = 0.031
Read data: 8.869171142578125e-05
iter 19894 (epoch 33), train_loss = 2.537, time/batch = 0.024
Read data: 8.463859558105469e-05
iter 19895 (epoch 33), train_loss = 2.172, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 19896 (epoch 33), train_loss = 2.268, time/batch = 0.030
Read data: 8.559226989746094e-05
iter 19897 (epoch 33), train_loss = 2.244, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 19898 (epoch 33), train_loss = 2.110, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 19899 (epoch 33), train_loss = 2.364, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 19900 (epoch 33), train_loss = 2.187, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 19901 (epoch 33), train_loss = 2.549, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 19902 (epoch 33), train_loss = 2.431, time/batch = 0.027
Read data: 0.0001049041748046875
iter 19903 (epoch 33), train_loss = 2.356, time/batch = 0.026
Read data: 0.00011491775512695312
iter 19904 (epoch 33), train_loss = 2.350, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 19905 (epoch 33), train_loss = 2.567, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 19906 (epoch 33), train_loss = 2.586, time/batch = 0.021
Read data: 0.0001068115234375
iter 19907 (epoch 33), train_loss = 2.536, time/batch = 0.025
Read data: 9.1552734375e-05
iter 19908 (epoch 33), train_loss = 2.751, time/batch = 0.034
Read data: 9.846687316894531e-05
iter 19909 (epoch 33), train_loss = 2.531, time/batch = 0.031
Read data: 8.487701416015625e-05
iter 19910 (epoch 33), train_loss = 2.182, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 19911 (epoch 33), train_loss = 2.481, time/batch = 0.024
Read data: 0.00011992454528808594
iter 19912 (epoch 33), train_loss = 2.292, time/batch = 0.023
Read data: 9.5367431640625e-05
iter 19913 (epoch 33), train_loss = 2.519, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 19914 (epoch 33), train_loss = 2.584, time/batch = 0.031
Read data: 9.322166442871094e-05
iter 19915 (epoch 33), train_loss = 2.223, time/batch = 0.024
Read data: 9.489059448242188e-05
iter 19916 (epoch 33), train_loss = 2.545, time/batch = 0.024
Read data: 0.00010085105895996094
iter 19917 (epoch 33), train_loss = 2.520, time/batch = 0.030
Read data: 0.00013184547424316406
iter 19918 (epoch 33), train_loss = 2.298, time/batch = 0.036
Read data: 9.083747863769531e-05
iter 19919 (epoch 33), train_loss = 1.972, time/batch = 0.021
Read data: 0.00015115737915039062
iter 19920 (epoch 33), train_loss = 2.562, time/batch = 0.031
Read data: 9.036064147949219e-05
iter 19921 (epoch 33), train_loss = 2.223, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 19922 (epoch 33), train_loss = 2.726, time/batch = 0.034
Read data: 0.00010943412780761719
iter 19923 (epoch 33), train_loss = 2.277, time/batch = 0.023
Read data: 0.00012111663818359375
iter 19924 (epoch 33), train_loss = 2.098, time/batch = 0.025
Read data: 0.00023937225341796875
iter 19925 (epoch 33), train_loss = 2.323, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 19926 (epoch 33), train_loss = 2.315, time/batch = 0.027
Read data: 9.751319885253906e-05
iter 19927 (epoch 33), train_loss = 2.517, time/batch = 0.035
Read data: 0.0001659393310546875
iter 19928 (epoch 33), train_loss = 2.388, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 19929 (epoch 33), train_loss = 2.768, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 19930 (epoch 33), train_loss = 2.229, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19931 (epoch 33), train_loss = 2.520, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 19932 (epoch 33), train_loss = 2.268, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 19933 (epoch 33), train_loss = 2.758, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 19934 (epoch 33), train_loss = 2.173, time/batch = 0.023
Read data: 0.000102996826171875
iter 19935 (epoch 33), train_loss = 2.195, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 19936 (epoch 33), train_loss = 2.149, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 19937 (epoch 33), train_loss = 2.327, time/batch = 0.029
Read data: 9.250640869140625e-05
iter 19938 (epoch 33), train_loss = 2.462, time/batch = 0.028
Read data: 9.894371032714844e-05
iter 19939 (epoch 33), train_loss = 2.327, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 19940 (epoch 33), train_loss = 2.440, time/batch = 0.037
Read data: 8.296966552734375e-05
iter 19941 (epoch 33), train_loss = 2.406, time/batch = 0.025
Read data: 8.797645568847656e-05
iter 19942 (epoch 33), train_loss = 2.059, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 19943 (epoch 33), train_loss = 2.449, time/batch = 0.025
Read data: 0.00012063980102539062
iter 19944 (epoch 33), train_loss = 2.013, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 19945 (epoch 33), train_loss = 2.178, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 19946 (epoch 33), train_loss = 2.324, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 19947 (epoch 33), train_loss = 2.430, time/batch = 0.039
Read data: 0.00012063980102539062
iter 19948 (epoch 33), train_loss = 2.304, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 19949 (epoch 33), train_loss = 2.718, time/batch = 0.026
Read data: 0.00021719932556152344
iter 19950 (epoch 33), train_loss = 2.126, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 19951 (epoch 33), train_loss = 2.384, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 19952 (epoch 33), train_loss = 2.216, time/batch = 0.025
Read data: 9.465217590332031e-05
iter 19953 (epoch 33), train_loss = 2.416, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 19954 (epoch 33), train_loss = 2.782, time/batch = 0.034
Read data: 8.130073547363281e-05
iter 19955 (epoch 33), train_loss = 2.416, time/batch = 0.026
Read data: 0.0001533031463623047
iter 19956 (epoch 33), train_loss = 2.550, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 19957 (epoch 33), train_loss = 2.541, time/batch = 0.022
Read data: 0.0001010894775390625
iter 19958 (epoch 33), train_loss = 2.414, time/batch = 0.022
Read data: 9.34600830078125e-05
iter 19959 (epoch 33), train_loss = 2.367, time/batch = 0.025
Read data: 9.059906005859375e-05
iter 19960 (epoch 33), train_loss = 2.120, time/batch = 0.031
Read data: 8.702278137207031e-05
iter 19961 (epoch 33), train_loss = 2.309, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 19962 (epoch 33), train_loss = 2.146, time/batch = 0.030
Read data: 8.392333984375e-05
iter 19963 (epoch 33), train_loss = 2.702, time/batch = 0.027
Read data: 0.00013637542724609375
iter 19964 (epoch 33), train_loss = 2.521, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 19965 (epoch 33), train_loss = 1.872, time/batch = 0.023
Read data: 8.654594421386719e-05
iter 19966 (epoch 33), train_loss = 2.567, time/batch = 0.027
Read data: 9.560585021972656e-05
iter 19967 (epoch 33), train_loss = 2.284, time/batch = 0.023
Read data: 9.1552734375e-05
iter 19968 (epoch 33), train_loss = 2.757, time/batch = 0.027
Read data: 9.250640869140625e-05
iter 19969 (epoch 33), train_loss = 2.183, time/batch = 0.026
Read data: 0.00010609626770019531
iter 19970 (epoch 33), train_loss = 1.936, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 19971 (epoch 33), train_loss = 2.404, time/batch = 0.031
Read data: 0.00015115737915039062
iter 19972 (epoch 33), train_loss = 2.551, time/batch = 0.023
Read data: 8.797645568847656e-05
iter 19973 (epoch 33), train_loss = 2.668, time/batch = 0.026
Read data: 0.00010347366333007812
iter 19974 (epoch 33), train_loss = 2.487, time/batch = 0.023
Read data: 0.0002415180206298828
iter 19975 (epoch 33), train_loss = 2.822, time/batch = 0.035
Read data: 0.00014925003051757812
iter 19976 (epoch 33), train_loss = 2.674, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 19977 (epoch 33), train_loss = 2.358, time/batch = 0.038
Read data: 8.940696716308594e-05
iter 19978 (epoch 33), train_loss = 2.339, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 19979 (epoch 33), train_loss = 2.086, time/batch = 0.021
Read data: 8.797645568847656e-05
iter 19980 (epoch 33), train_loss = 2.403, time/batch = 0.025
Read data: 0.00010204315185546875
iter 19981 (epoch 33), train_loss = 2.298, time/batch = 0.023
Read data: 9.059906005859375e-05
iter 19982 (epoch 33), train_loss = 2.426, time/batch = 0.024
Read data: 0.000133514404296875
iter 19983 (epoch 33), train_loss = 2.450, time/batch = 0.025
Read data: 0.00010347366333007812
iter 19984 (epoch 33), train_loss = 1.819, time/batch = 0.025
Read data: 9.322166442871094e-05
iter 19985 (epoch 33), train_loss = 2.591, time/batch = 0.035
Read data: 9.107589721679688e-05
iter 19986 (epoch 33), train_loss = 2.425, time/batch = 0.032
Read data: 8.225440979003906e-05
iter 19987 (epoch 33), train_loss = 2.266, time/batch = 0.029
Read data: 9.703636169433594e-05
iter 19988 (epoch 33), train_loss = 2.244, time/batch = 0.032
Read data: 8.487701416015625e-05
iter 19989 (epoch 33), train_loss = 2.012, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 19990 (epoch 33), train_loss = 2.377, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 19991 (epoch 33), train_loss = 2.555, time/batch = 0.028
Read data: 0.0001251697540283203
iter 19992 (epoch 33), train_loss = 2.502, time/batch = 0.029
Read data: 8.511543273925781e-05
iter 19993 (epoch 33), train_loss = 2.252, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 19994 (epoch 33), train_loss = 2.181, time/batch = 0.024
Read data: 8.058547973632812e-05
iter 19995 (epoch 33), train_loss = 2.770, time/batch = 0.025
Read data: 9.584426879882812e-05
iter 19996 (epoch 33), train_loss = 2.238, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 19997 (epoch 33), train_loss = 2.634, time/batch = 0.027
Read data: 9.393692016601562e-05
iter 19998 (epoch 33), train_loss = 2.447, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 19999 (epoch 33), train_loss = 2.320, time/batch = 0.024
image 976:     
image 5399:    
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:      
image 2375:    
image 2494:     
image 6381:     
evaluating validation preformance... 10/1000 (2.610420)
image 2798:     
image 5884:     
image 2067:     
image 3600:     
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:      
evaluating validation preformance... 20/1000 (2.175759)
image 6903:    
image 3301:    
image 2019:    
image 5535:     
image 7680:      
image 5527:      
image 2568:    
image 160:    
image 8085:      
image 7670:      
evaluating validation preformance... 30/1000 (2.509675)
image 4604:    
image 5745:     
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.061318)
image 2938:    UNK
image 5183:     
image 2380:     
image 6973:    
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.490603)
image 4940:      
image 4905:    UNK
image 469:     
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    
image 1729:    
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.797575)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:    
image 5641:     
evaluating validation preformance... 70/1000 (2.524803)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.571895)
image 3276:      
image 3812:    
image 1400:    
image 3443:     
image 5027:     
image 7251:     
image 7305:   
image 1480:      
image 4806:      
image 766:     
evaluating validation preformance... 90/1000 (2.074242)
image 6124:     
image 5415:     
image 369:     
image 5747:    
image 1003:    
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.879821)
image 2800:     
image 7249:     
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:     
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.790704)
image 1122:    
image 509:     
image 4091:    
image 5761:     
image 16:     
image 231:    
image 6505:    
image 1450:    
image 3979:      
image 5302:      
evaluating validation preformance... 120/1000 (2.377858)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:      
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.888563)
image 6214:     
image 429:    
image 7743:    
image 3657:      
image 4535:    
image 5542:     
image 8068:     
image 4450:     
image 1524:     
image 2867:    
evaluating validation preformance... 140/1000 (2.692437)
image 1738:     
image 1455:     
image 4198:      
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:     
evaluating validation preformance... 150/1000 (2.931812)
image 1865:     
image 3830:      
image 360:      
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:    
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.815688)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.545053)
image 7922:     
image 2353:    
image 4580:    
image 5905:    
image 6488:    
image 3000:    UNK
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.722606)
image 2313:    
image 6289:    
image 8084:    
image 2696:    
image 5830:     
image 6240:      
image 4541:     UNK
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.371289)
image 5372:     
image 7529:    UNK
image 875:    
image 2107:      
image 8015:   
image 6565:     
image 6174:     
image 6894:     
image 4164:     
image 7049:     
evaluating validation preformance... 200/1000 (2.269366)
image 5159:    
image 1199:    
image 2456:    
image 3402:     
image 7631:     
image 3562:    
image 405:    
image 2532:    
image 2844:     
image 4023:     
evaluating validation preformance... 210/1000 (2.427483)
image 2599:     
image 822:    
image 3926:     
image 6942:     
image 1942: UNK  
image 618:     
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.507903)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:     
image 2258:     
image 5122:    
image 5586:    
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.244095)
image 1917:   
image 5844:      
image 1661:     
image 1510:    
image 4630:      
image 6741:    
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.077717)
image 7143:    
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:   
image 528:    
evaluating validation preformance... 250/1000 (2.509241)
image 3028:     
image 3141:    
image 7137:    
image 3444:    
image 2049:    
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.466530)
image 492:    
image 5429:      
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:    
image 7380:      
evaluating validation preformance... 270/1000 (3.007177)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:    
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:     
evaluating validation preformance... 280/1000 (2.471857)
image 2481:    
image 1860:     
image 1464:     
image 4488:     
image 7299:     
image 5006:     
image 7828:     
image 7372:   
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.400199)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.170041)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:    
image 2148:     
image 1974:    
image 6050:    
image 6156:     
evaluating validation preformance... 310/1000 (2.668169)
image 3553:    
image 5971:     
image 122:     
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:     
image 6423:     
evaluating validation preformance... 320/1000 (2.276693)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:    
image 1159:      
evaluating validation preformance... 330/1000 (2.780907)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:     
image 2601:      
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.422367)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:     
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.441710)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:      
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.061275)
image 2905:     
image 7814:      
image 56:    
image 5034:     
image 7946:      
image 3470:      
image 4655:     
image 818:    
image 6607:    
image 4866:     
evaluating validation preformance... 370/1000 (2.596622)
image 4351:     
image 1054:     
image 129:     
image 2849:     
image 725:   UNK
image 2573:     
image 6766:     
image 5754:     
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.632133)
image 2458:     
image 1084:      
image 4835:    
image 867:    
image 723:    
image 6255:    
image 5255:    
image 3598:    
image 2997:     
image 60:    
evaluating validation preformance... 390/1000 (2.814872)
image 828:    
image 2733:    
image 791:    
image 5408:     
image 7842:    
image 1117:    
image 5817:      
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.190912)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:    
image 2105:      
image 3919:     
image 7980:     
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.146626)
image 4359:     
image 2372:     
image 4472:     
image 6810:    
image 1592:     
image 7864:    
image 4286:    
image 6688:    
image 5697:     
image 7020:     
evaluating validation preformance... 420/1000 (2.335055)
image 30:      
image 5540:     
image 2445:     
image 5896:      
image 7607:     
image 1426:      
image 6977:     
image 877:   
image 2408:    
image 7706:     
evaluating validation preformance... 430/1000 (2.752493)
image 385:    
image 6938:      
image 2381:    
image 5796:      
image 4010:    
image 3452:    
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.903290)
image 1731:       
image 978:      
image 6033:     
image 5080:     
image 7804:    
image 439:      
image 4790:     
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.142166)
image 2241:      
image 2651:    UNK
image 2315:     
image 4784:     
image 5160:      
image 2466:     
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.605709)
image 7979:    
image 1618:    
image 7608:    
image 6393:    
image 5100:      
image 4480:     
image 1440:    
image 5886:      
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.207213)
image 4503:    
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:    
evaluating validation preformance... 480/1000 (2.891562)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:    UNK
image 1595:     
image 4757:    
image 205:    
evaluating validation preformance... 490/1000 (3.338336)
image 2044:    
image 4349:    
image 3855:      
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:    
evaluating validation preformance... 500/1000 (2.429110)
image 1797:    
image 4670:     
image 4846:    
image 5907:     
image 3321:    
image 1700:     
image 438:    
image 5980:     
image 408:     
image 5403:      
evaluating validation preformance... 510/1000 (2.929238)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.572051)
image 6806:      
image 6464:    
image 1872:     
image 1575:    
image 3045:    
image 303:   
image 5552:      
image 4628:    
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.469598)
image 5619:     
image 4391:   
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:    
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.437755)
image 5292:    
image 2901:    
image 3568:    
image 690:     
image 3345:      
image 6234:     
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.556642)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.541741)
image 6056:    
image 6419:    
image 275:     
image 7441:    
image 7893:    
image 3623:    
image 7232:    
image 4778:     
image 1007:    
image 3387:     
evaluating validation preformance... 570/1000 (2.559927)
image 7936:     
image 5433:      
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:    UNK
image 3267:    
evaluating validation preformance... 580/1000 (2.638808)
image 2135:    
image 3865:     
image 7837:    
image 1172:     
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:     
evaluating validation preformance... 590/1000 (2.575480)
image 4420:    
image 1734:      
image 7239:     
image 7447:    
image 8009:    
image 4510:    
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.416561)
image 353:    
image 1095:     
image 3583:      
image 3264:    
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:    
image 4823:    
evaluating validation preformance... 610/1000 (2.623050)
image 69:     
image 3465:    
image 6179:     
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.350588)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:  UNK  
image 2847:      
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.504075)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:     
image 883:     
image 559:     
image 1120:     
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.438741)
image 5313:      
image 2377:      
image 6058:    
image 4661:    
image 2955:   
image 3333:    
image 7124:    
image 4278:      
image 953:      
image 4037:      
evaluating validation preformance... 650/1000 (2.527995)
image 8065:    UNK
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:     
evaluating validation preformance... 660/1000 (2.647812)
image 5701:    
image 1709:       
image 4811:    
image 622:    
image 5997:     
image 1608:    
image 4119:       
image 1619:      
image 5652:     
image 1972:     
evaluating validation preformance... 670/1000 (2.742558)
image 7877:    
image 6761:     
image 6880:   
image 4914:    UNK
image 4522:     
image 2311:    
image 7587:     
image 4848:     
image 6722: UNK UNK
image 7784:    
evaluating validation preformance... 680/1000 (2.967832)
image 1445:     UNK
image 6841:     
image 2896:    
image 6947:   
image 4782:    
image 7669:    
image 4382:    
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.777718)
image 6860:     
image 576:     
image 6580:      
image 1497:     
image 3360:     
image 4939:      
image 6225:    
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.938011)
image 5343:      
image 68:    
image 3184:     
image 5637:      
image 2041:     
image 650:     
image 4911:     
image 34:    UNK UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.490896)
image 7368:      
image 709:     
image 3197:    
image 5214:     
image 445:     
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:     
evaluating validation preformance... 720/1000 (2.588809)
image 5729:     
image 6395:     
image 516:      
image 1026:    
image 2972:      
image 3005:    
image 1241:     
image 2743:     
image 3665:    
image 1290:      
evaluating validation preformance... 730/1000 (2.284251)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:    
image 6081:      
image 997:    
image 5092:     
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.379951)
image 2239:     
image 120:       
image 4902:      
image 3796:      
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.614975)
image 3279:    
image 6380:    
image 2663:     
image 3815:     
image 512:     
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.985500)
image 4582:    
image 5484:    
image 3049:      
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.082544)
image 6220:     
image 6238:      
image 4534:    
image 2732:     
image 7003:    
image 1739:     
image 5503:     
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.820125)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:    
image 6978:    
image 3450:     
image 3312:     
image 7824:     
image 2032:     
evaluating validation preformance... 790/1000 (3.051991)
image 5047:      
image 325:      
image 7626:    
image 4552:     
image 983:     
image 8052:      
image 1585:      
image 4336:      
image 1728:     
image 6725:    
evaluating validation preformance... 800/1000 (2.224422)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:    
image 290:     
image 159:      UNK
image 4345:    
image 2217:     
image 3169:     
evaluating validation preformance... 810/1000 (2.427180)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060:    UNK
image 1317:     
image 3339:    
image 1052:      
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.915040)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:     
image 5514:     
image 7147:      
image 6348:     
image 580:     
image 2531:    
evaluating validation preformance... 830/1000 (2.352861)
image 5107:    
image 3973:     
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:      
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.404768)
image 7592:    
image 1798:   
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.702113)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:     
image 3596:      
image 1921:     
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.705756)
image 4254:     
image 6842:     
image 1644:    
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:     
evaluating validation preformance... 870/1000 (2.337493)
image 4934:    
image 6487:     
image 4217:     
image 6355:      
image 2793:     
image 7201:     
image 5681:    
image 1824:   
image 2098:     
image 28:      
evaluating validation preformance... 880/1000 (2.585400)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:     
image 2314:     
image 6244:     
image 4530:     
evaluating validation preformance... 890/1000 (2.910015)
image 7485:    
image 6102:     
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:    
image 4813:    
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.560933)
image 5664:     
image 4985:    
image 4082:      
image 6291:    
image 5573:     
image 1405:    
image 4431:    
image 2801:     
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.169934)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.599278)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:       
image 7102:    
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.475960)
image 5636:      
image 7799:      
image 6025:    
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.705008)
image 5860:  UNK  
image 3275:    
image 1935:    
image 3520:     
image 5452:    
image 2446:     
image 5984:   
image 5804:     
image 6691:      
image 6530:     
evaluating validation preformance... 950/1000 (2.909988)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:      
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:      
evaluating validation preformance... 960/1000 (2.734241)
image 4935:    
image 1930:      
image 6850:    
image 5310:     
image 177:    
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.274101)
image 5688:     
image 5448:    
image 5871:     
image 7516:      
image 3734:    
image 2921:      
image 7800:    UNK UNK
image 3999:    
image 6317:    
image 5931:      
evaluating validation preformance... 980/1000 (2.726763)
image 7352:     
image 5113:     
image 7822:    UNK
image 4858:    
image 658:    
image 2982:     
image 5843:    
image 1822:     
image 7813:     
image 5567:    
evaluating validation preformance... 990/1000 (2.403431)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:     
evaluating validation preformance... 1000/1000 (2.303834)
average loss on validation: 2.570
model saved to ./log_Att2in_sc/model.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3195478916168213
Cider scores: 0.5760537098454942
Read data: 0.3609035015106201
Cider scores: 0.6213187245587188
Read data: 0.33365345001220703
Cider scores: 0.5986438058834037
Read data: 0.23604607582092285
Cider scores: 0.5705279735423102
Read data: 0.2200772762298584
Cider scores: 0.48122747972997254
Read data: 0.20176148414611816
Cider scores: 0.542907134003465
Read data: 0.19110751152038574
Cider scores: 0.5356861716360969
Read data: 0.18175840377807617
Cider scores: 0.5991855638279691
Read data: 0.1785874366760254
Cider scores: 0.5813712232797935
Read data: 0.20173931121826172
Cider scores: 0.6577226488118538
Read data: 0.18372583389282227
Cider scores: 0.6822503315374334
Read data: 0.1770319938659668
Cider scores: 0.7174887639948675
Read data: 0.23360228538513184
Cider scores: 0.5704781634700802
Read data: 0.19695687294006348
Cider scores: 0.6222769273375471
Read data: 0.1893446445465088
Cider scores: 0.6343245528197664
Read data: 0.16863179206848145
Cider scores: 0.6925999866172164
Read data: 0.16605162620544434
Cider scores: 0.4580941757976552
Read data: 0.16298127174377441
Cider scores: 0.7163740368004138
Read data: 0.16612553596496582
Cider scores: 0.5115710308732154
Read data: 0.16859912872314453
Cider scores: 0.7808445323178523
Average cider score on test set: 0.608
End calculating cider score on TEST data set
===============================================
Read data: 0.16595172882080078
iter 20000 (epoch 33), train_loss = 2.553, time/batch = 0.020
Read data: 0.00010204315185546875
iter 20001 (epoch 33), train_loss = 2.336, time/batch = 0.025
Read data: 0.0001201629638671875
iter 20002 (epoch 33), train_loss = 2.518, time/batch = 0.023
Read data: 0.0001316070556640625
iter 20003 (epoch 33), train_loss = 2.261, time/batch = 0.030
Read data: 0.0001227855682373047
iter 20004 (epoch 33), train_loss = 2.502, time/batch = 0.030
Read data: 0.00010538101196289062
iter 20005 (epoch 33), train_loss = 2.583, time/batch = 0.029
Read data: 0.00012111663818359375
iter 20006 (epoch 33), train_loss = 2.384, time/batch = 0.029
Read data: 0.00012159347534179688
iter 20007 (epoch 33), train_loss = 2.698, time/batch = 0.027
Read data: 9.942054748535156e-05
iter 20008 (epoch 33), train_loss = 2.405, time/batch = 0.026
Read data: 0.00010132789611816406
iter 20009 (epoch 33), train_loss = 2.147, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 20010 (epoch 33), train_loss = 2.271, time/batch = 0.026
Read data: 8.487701416015625e-05
iter 20011 (epoch 33), train_loss = 2.113, time/batch = 0.024
Read data: 9.465217590332031e-05
iter 20012 (epoch 33), train_loss = 2.780, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 20013 (epoch 33), train_loss = 2.313, time/batch = 0.028
Read data: 0.00010061264038085938
iter 20014 (epoch 33), train_loss = 2.399, time/batch = 0.032
Read data: 0.00012946128845214844
iter 20015 (epoch 33), train_loss = 2.042, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 20016 (epoch 33), train_loss = 2.373, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 20017 (epoch 33), train_loss = 2.234, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 20018 (epoch 33), train_loss = 2.291, time/batch = 0.031
Read data: 0.00022935867309570312
iter 20019 (epoch 33), train_loss = 2.272, time/batch = 0.024
Read data: 8.559226989746094e-05
iter 20020 (epoch 33), train_loss = 2.041, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 20021 (epoch 33), train_loss = 2.345, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 20022 (epoch 33), train_loss = 2.429, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 20023 (epoch 33), train_loss = 2.717, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 20024 (epoch 33), train_loss = 2.162, time/batch = 0.027
Read data: 0.00021219253540039062
iter 20025 (epoch 33), train_loss = 2.590, time/batch = 0.030
Read data: 8.225440979003906e-05
iter 20026 (epoch 33), train_loss = 2.249, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20027 (epoch 33), train_loss = 2.669, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 20028 (epoch 33), train_loss = 2.571, time/batch = 0.029
Read data: 8.082389831542969e-05
iter 20029 (epoch 33), train_loss = 2.395, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 20030 (epoch 33), train_loss = 2.232, time/batch = 0.024
Read data: 9.894371032714844e-05
iter 20031 (epoch 33), train_loss = 2.372, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 20032 (epoch 33), train_loss = 2.536, time/batch = 0.025
Read data: 8.96453857421875e-05
iter 20033 (epoch 33), train_loss = 2.011, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 20034 (epoch 33), train_loss = 2.639, time/batch = 0.023
Read data: 0.00010371208190917969
iter 20035 (epoch 33), train_loss = 2.419, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 20036 (epoch 33), train_loss = 2.231, time/batch = 0.029
Read data: 0.00011658668518066406
iter 20037 (epoch 33), train_loss = 1.916, time/batch = 0.025
Read data: 0.00012111663818359375
iter 20038 (epoch 33), train_loss = 2.261, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 20039 (epoch 33), train_loss = 2.475, time/batch = 0.026
Read data: 0.00013589859008789062
iter 20040 (epoch 33), train_loss = 2.031, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 20041 (epoch 33), train_loss = 2.542, time/batch = 0.033
Read data: 9.489059448242188e-05
iter 20042 (epoch 33), train_loss = 2.023, time/batch = 0.032
Read data: 9.083747863769531e-05
iter 20043 (epoch 33), train_loss = 2.481, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 20044 (epoch 33), train_loss = 2.626, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 20045 (epoch 33), train_loss = 2.396, time/batch = 0.025
Read data: 0.00011134147644042969
iter 20046 (epoch 33), train_loss = 2.601, time/batch = 0.027
Read data: 0.00012040138244628906
iter 20047 (epoch 33), train_loss = 2.465, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 20048 (epoch 33), train_loss = 2.551, time/batch = 0.026
Read data: 0.00010514259338378906
iter 20049 (epoch 33), train_loss = 2.414, time/batch = 0.035
Read data: 0.0002703666687011719
iter 20050 (epoch 33), train_loss = 2.283, time/batch = 0.031
Read data: 8.916854858398438e-05
iter 20051 (epoch 33), train_loss = 2.406, time/batch = 0.024
Read data: 8.845329284667969e-05
iter 20052 (epoch 33), train_loss = 2.504, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 20053 (epoch 33), train_loss = 2.211, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 20054 (epoch 33), train_loss = 2.503, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 20055 (epoch 33), train_loss = 2.186, time/batch = 0.033
Read data: 0.00019025802612304688
iter 20056 (epoch 33), train_loss = 2.515, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 20057 (epoch 33), train_loss = 2.489, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 20058 (epoch 33), train_loss = 1.811, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20059 (epoch 33), train_loss = 1.988, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20060 (epoch 33), train_loss = 2.107, time/batch = 0.020
Read data: 9.393692016601562e-05
iter 20061 (epoch 33), train_loss = 2.290, time/batch = 0.027
Read data: 9.012222290039062e-05
iter 20062 (epoch 33), train_loss = 2.237, time/batch = 0.031
Read data: 7.796287536621094e-05
iter 20063 (epoch 33), train_loss = 2.545, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 20064 (epoch 33), train_loss = 2.262, time/batch = 0.022
Read data: 8.678436279296875e-05
iter 20065 (epoch 33), train_loss = 2.317, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 20066 (epoch 33), train_loss = 2.421, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 20067 (epoch 33), train_loss = 2.461, time/batch = 0.025
Read data: 9.679794311523438e-05
iter 20068 (epoch 33), train_loss = 2.415, time/batch = 0.034
Read data: 8.058547973632812e-05
iter 20069 (epoch 33), train_loss = 2.430, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 20070 (epoch 33), train_loss = 2.863, time/batch = 0.039
Read data: 9.751319885253906e-05
iter 20071 (epoch 33), train_loss = 2.343, time/batch = 0.034
Read data: 8.654594421386719e-05
iter 20072 (epoch 33), train_loss = 2.631, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 20073 (epoch 33), train_loss = 2.175, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 20074 (epoch 33), train_loss = 2.044, time/batch = 0.027
Read data: 0.00024628639221191406
iter 20075 (epoch 33), train_loss = 2.055, time/batch = 0.024
Read data: 8.296966552734375e-05
iter 20076 (epoch 33), train_loss = 2.514, time/batch = 0.025
Read data: 0.00010251998901367188
iter 20077 (epoch 33), train_loss = 2.057, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 20078 (epoch 33), train_loss = 2.624, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 20079 (epoch 33), train_loss = 2.175, time/batch = 0.027
Read data: 0.00014138221740722656
iter 20080 (epoch 33), train_loss = 2.286, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20081 (epoch 33), train_loss = 2.552, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 20082 (epoch 33), train_loss = 2.617, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20083 (epoch 33), train_loss = 2.411, time/batch = 0.025
Read data: 9.369850158691406e-05
iter 20084 (epoch 33), train_loss = 2.631, time/batch = 0.023
Read data: 0.00010633468627929688
iter 20085 (epoch 33), train_loss = 2.059, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 20086 (epoch 33), train_loss = 2.190, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20087 (epoch 33), train_loss = 2.164, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 20088 (epoch 33), train_loss = 2.459, time/batch = 0.032
Read data: 8.034706115722656e-05
iter 20089 (epoch 33), train_loss = 2.363, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 20090 (epoch 33), train_loss = 2.490, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 20091 (epoch 33), train_loss = 1.882, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 20092 (epoch 33), train_loss = 2.698, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 20093 (epoch 33), train_loss = 2.467, time/batch = 0.039
Read data: 0.0001380443572998047
iter 20094 (epoch 33), train_loss = 1.855, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 20095 (epoch 33), train_loss = 2.381, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 20096 (epoch 33), train_loss = 2.695, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 20097 (epoch 33), train_loss = 2.198, time/batch = 0.031
Read data: 0.00011134147644042969
iter 20098 (epoch 33), train_loss = 2.620, time/batch = 0.028
Read data: 8.869171142578125e-05
iter 20099 (epoch 33), train_loss = 2.436, time/batch = 0.028
Read data: 8.440017700195312e-05
iter 20100 (epoch 33), train_loss = 2.166, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 20101 (epoch 33), train_loss = 2.298, time/batch = 0.023
Read data: 9.298324584960938e-05
iter 20102 (epoch 33), train_loss = 2.450, time/batch = 0.030
Read data: 7.843971252441406e-05
iter 20103 (epoch 33), train_loss = 2.563, time/batch = 0.028
Read data: 8.535385131835938e-05
iter 20104 (epoch 33), train_loss = 2.154, time/batch = 0.019
Read data: 9.369850158691406e-05
iter 20105 (epoch 33), train_loss = 2.450, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 20106 (epoch 33), train_loss = 2.204, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 20107 (epoch 33), train_loss = 2.453, time/batch = 0.025
Read data: 0.00010991096496582031
iter 20108 (epoch 33), train_loss = 2.225, time/batch = 0.024
Read data: 0.00011944770812988281
iter 20109 (epoch 33), train_loss = 2.187, time/batch = 0.030
Read data: 9.417533874511719e-05
iter 20110 (epoch 33), train_loss = 2.419, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 20111 (epoch 33), train_loss = 2.167, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20112 (epoch 33), train_loss = 2.190, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 20113 (epoch 33), train_loss = 2.253, time/batch = 0.022
Read data: 0.0001010894775390625
iter 20114 (epoch 33), train_loss = 2.460, time/batch = 0.036
Read data: 8.130073547363281e-05
iter 20115 (epoch 33), train_loss = 2.713, time/batch = 0.024
Read data: 8.344650268554688e-05
iter 20116 (epoch 33), train_loss = 2.097, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 20117 (epoch 33), train_loss = 2.591, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 20118 (epoch 33), train_loss = 2.314, time/batch = 0.027
Read data: 0.00011324882507324219
iter 20119 (epoch 33), train_loss = 2.195, time/batch = 0.037
Read data: 9.489059448242188e-05
iter 20120 (epoch 33), train_loss = 2.543, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 20121 (epoch 33), train_loss = 2.114, time/batch = 0.025
Read data: 8.153915405273438e-05
iter 20122 (epoch 33), train_loss = 2.609, time/batch = 0.038
Read data: 8.58306884765625e-05
iter 20123 (epoch 33), train_loss = 2.535, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 20124 (epoch 33), train_loss = 2.220, time/batch = 0.026
Read data: 0.0002944469451904297
iter 20125 (epoch 33), train_loss = 2.074, time/batch = 0.024
Read data: 8.20159912109375e-05
iter 20126 (epoch 33), train_loss = 2.435, time/batch = 0.037
Read data: 8.654594421386719e-05
iter 20127 (epoch 33), train_loss = 2.392, time/batch = 0.028
Read data: 8.654594421386719e-05
iter 20128 (epoch 33), train_loss = 2.259, time/batch = 0.028
Read data: 8.845329284667969e-05
iter 20129 (epoch 33), train_loss = 2.062, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 20130 (epoch 33), train_loss = 2.221, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 20131 (epoch 33), train_loss = 2.461, time/batch = 0.029
Read data: 0.00011610984802246094
iter 20132 (epoch 33), train_loss = 2.345, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 20133 (epoch 33), train_loss = 2.325, time/batch = 0.021
Read data: 9.012222290039062e-05
iter 20134 (epoch 33), train_loss = 1.833, time/batch = 0.034
Read data: 7.891654968261719e-05
iter 20135 (epoch 33), train_loss = 2.644, time/batch = 0.030
Read data: 8.749961853027344e-05
iter 20136 (epoch 33), train_loss = 2.486, time/batch = 0.037
Read data: 8.988380432128906e-05
iter 20137 (epoch 33), train_loss = 2.607, time/batch = 0.025
Read data: 0.00011467933654785156
iter 20138 (epoch 33), train_loss = 2.822, time/batch = 0.033
Read data: 8.630752563476562e-05
iter 20139 (epoch 33), train_loss = 2.125, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20140 (epoch 33), train_loss = 2.038, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 20141 (epoch 33), train_loss = 2.342, time/batch = 0.028
Read data: 7.843971252441406e-05
iter 20142 (epoch 33), train_loss = 2.241, time/batch = 0.023
Read data: 9.894371032714844e-05
iter 20143 (epoch 33), train_loss = 2.410, time/batch = 0.031
Read data: 8.392333984375e-05
iter 20144 (epoch 33), train_loss = 2.351, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 20145 (epoch 33), train_loss = 2.286, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 20146 (epoch 33), train_loss = 2.506, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 20147 (epoch 33), train_loss = 2.301, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 20148 (epoch 33), train_loss = 2.593, time/batch = 0.025
Read data: 7.82012939453125e-05
iter 20149 (epoch 33), train_loss = 2.299, time/batch = 0.032
Read data: 0.0002090930938720703
iter 20150 (epoch 33), train_loss = 2.198, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 20151 (epoch 33), train_loss = 2.524, time/batch = 0.030
Read data: 9.250640869140625e-05
iter 20152 (epoch 33), train_loss = 2.424, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 20153 (epoch 33), train_loss = 2.217, time/batch = 0.028
Read data: 0.00013494491577148438
iter 20154 (epoch 33), train_loss = 2.492, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 20155 (epoch 33), train_loss = 2.540, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 20156 (epoch 33), train_loss = 2.328, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 20157 (epoch 33), train_loss = 2.716, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 20158 (epoch 33), train_loss = 2.294, time/batch = 0.023
Read data: 0.00011110305786132812
iter 20159 (epoch 33), train_loss = 2.388, time/batch = 0.031
Read data: 8.916854858398438e-05
iter 20160 (epoch 33), train_loss = 2.499, time/batch = 0.036
Read data: 0.000133514404296875
iter 20161 (epoch 33), train_loss = 2.474, time/batch = 0.027
Read data: 0.00011491775512695312
iter 20162 (epoch 33), train_loss = 2.246, time/batch = 0.029
Read data: 9.083747863769531e-05
iter 20163 (epoch 33), train_loss = 2.192, time/batch = 0.020
Read data: 0.0001251697540283203
iter 20164 (epoch 33), train_loss = 2.524, time/batch = 0.032
Read data: 7.748603820800781e-05
iter 20165 (epoch 33), train_loss = 2.244, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20166 (epoch 33), train_loss = 2.605, time/batch = 0.021
Read data: 0.00010013580322265625
iter 20167 (epoch 33), train_loss = 2.250, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 20168 (epoch 33), train_loss = 2.391, time/batch = 0.028
Read data: 7.867813110351562e-05
iter 20169 (epoch 33), train_loss = 2.700, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 20170 (epoch 33), train_loss = 2.239, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 20171 (epoch 33), train_loss = 2.245, time/batch = 0.025
Read data: 8.392333984375e-05
iter 20172 (epoch 33), train_loss = 2.369, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 20173 (epoch 33), train_loss = 2.457, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20174 (epoch 33), train_loss = 2.089, time/batch = 0.031
Read data: 0.00035691261291503906
iter 20175 (epoch 33), train_loss = 2.546, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 20176 (epoch 33), train_loss = 2.376, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 20177 (epoch 33), train_loss = 2.631, time/batch = 0.028
Read data: 9.083747863769531e-05
iter 20178 (epoch 33), train_loss = 2.358, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 20179 (epoch 33), train_loss = 2.437, time/batch = 0.030
Read data: 0.00010728836059570312
iter 20180 (epoch 33), train_loss = 2.031, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 20181 (epoch 33), train_loss = 2.194, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 20182 (epoch 33), train_loss = 2.130, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 20183 (epoch 33), train_loss = 1.975, time/batch = 0.026
Read data: 0.0001430511474609375
iter 20184 (epoch 33), train_loss = 2.311, time/batch = 0.024
Read data: 8.130073547363281e-05
iter 20185 (epoch 33), train_loss = 2.327, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 20186 (epoch 33), train_loss = 2.442, time/batch = 0.026
Read data: 8.392333984375e-05
iter 20187 (epoch 33), train_loss = 2.478, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 20188 (epoch 33), train_loss = 2.676, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 20189 (epoch 33), train_loss = 2.451, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 20190 (epoch 33), train_loss = 2.502, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 20191 (epoch 33), train_loss = 2.137, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 20192 (epoch 33), train_loss = 2.054, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 20193 (epoch 33), train_loss = 2.683, time/batch = 0.034
Read data: 0.00011920928955078125
iter 20194 (epoch 33), train_loss = 2.084, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 20195 (epoch 33), train_loss = 2.556, time/batch = 0.031
Read data: 0.00013136863708496094
iter 20196 (epoch 33), train_loss = 2.313, time/batch = 0.028
Read data: 8.20159912109375e-05
iter 20197 (epoch 33), train_loss = 2.001, time/batch = 0.030
Read data: 0.00011157989501953125
iter 20198 (epoch 33), train_loss = 2.271, time/batch = 0.031
Read data: 8.678436279296875e-05
iter 20199 (epoch 33), train_loss = 2.449, time/batch = 0.028
Read data: 8.392333984375e-05
iter 20200 (epoch 33), train_loss = 2.275, time/batch = 0.022
Read data: 8.153915405273438e-05
iter 20201 (epoch 33), train_loss = 2.391, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 20202 (epoch 33), train_loss = 2.409, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 20203 (epoch 33), train_loss = 1.896, time/batch = 0.020
Read data: 9.059906005859375e-05
iter 20204 (epoch 33), train_loss = 2.109, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 20205 (epoch 33), train_loss = 2.835, time/batch = 0.028
Read data: 0.0001010894775390625
iter 20206 (epoch 33), train_loss = 2.351, time/batch = 0.027
Read data: 0.00010204315185546875
iter 20207 (epoch 33), train_loss = 2.488, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 20208 (epoch 33), train_loss = 2.497, time/batch = 0.029
Read data: 8.106231689453125e-05
iter 20209 (epoch 33), train_loss = 2.359, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 20210 (epoch 33), train_loss = 2.036, time/batch = 0.029
Read data: 7.939338684082031e-05
iter 20211 (epoch 33), train_loss = 2.728, time/batch = 0.028
Read data: 8.559226989746094e-05
iter 20212 (epoch 33), train_loss = 2.329, time/batch = 0.027
Read data: 7.963180541992188e-05
iter 20213 (epoch 33), train_loss = 2.167, time/batch = 0.023
Read data: 8.0108642578125e-05
iter 20214 (epoch 33), train_loss = 2.380, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 20215 (epoch 33), train_loss = 2.343, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20216 (epoch 33), train_loss = 2.402, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 20217 (epoch 33), train_loss = 2.676, time/batch = 0.025
Read data: 0.00010228157043457031
iter 20218 (epoch 33), train_loss = 2.211, time/batch = 0.023
Read data: 0.00010395050048828125
iter 20219 (epoch 33), train_loss = 2.449, time/batch = 0.029
Read data: 9.679794311523438e-05
iter 20220 (epoch 33), train_loss = 2.733, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 20221 (epoch 33), train_loss = 2.618, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 20222 (epoch 33), train_loss = 2.417, time/batch = 0.027
Read data: 7.748603820800781e-05
iter 20223 (epoch 33), train_loss = 2.026, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 20224 (epoch 33), train_loss = 2.362, time/batch = 0.024
Read data: 0.00021338462829589844
iter 20225 (epoch 33), train_loss = 2.426, time/batch = 0.021
Read data: 0.00010228157043457031
iter 20226 (epoch 33), train_loss = 2.289, time/batch = 0.037
Read data: 8.058547973632812e-05
iter 20227 (epoch 33), train_loss = 2.661, time/batch = 0.025
Read data: 0.0001239776611328125
iter 20228 (epoch 33), train_loss = 2.160, time/batch = 0.037
Read data: 8.535385131835938e-05
iter 20229 (epoch 33), train_loss = 2.111, time/batch = 0.028
Read data: 0.00013828277587890625
iter 20230 (epoch 33), train_loss = 2.344, time/batch = 0.029
Read data: 9.393692016601562e-05
iter 20231 (epoch 33), train_loss = 2.580, time/batch = 0.032
Read data: 9.369850158691406e-05
iter 20232 (epoch 33), train_loss = 2.481, time/batch = 0.025
Read data: 0.0001068115234375
iter 20233 (epoch 33), train_loss = 2.434, time/batch = 0.026
Read data: 8.0108642578125e-05
iter 20234 (epoch 33), train_loss = 2.230, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 20235 (epoch 33), train_loss = 2.416, time/batch = 0.031
Read data: 0.0001380443572998047
iter 20236 (epoch 33), train_loss = 2.457, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20237 (epoch 33), train_loss = 2.159, time/batch = 0.024
Read data: 7.772445678710938e-05
iter 20238 (epoch 33), train_loss = 2.298, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 20239 (epoch 33), train_loss = 2.590, time/batch = 0.033
Read data: 8.296966552734375e-05
iter 20240 (epoch 33), train_loss = 2.973, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20241 (epoch 33), train_loss = 2.309, time/batch = 0.029
Read data: 7.700920104980469e-05
iter 20242 (epoch 33), train_loss = 2.203, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 20243 (epoch 33), train_loss = 2.086, time/batch = 0.028
Read data: 9.965896606445312e-05
iter 20244 (epoch 33), train_loss = 2.128, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 20245 (epoch 33), train_loss = 2.231, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20246 (epoch 33), train_loss = 2.365, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 20247 (epoch 33), train_loss = 2.511, time/batch = 0.031
Read data: 8.797645568847656e-05
iter 20248 (epoch 33), train_loss = 2.045, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 20249 (epoch 33), train_loss = 2.199, time/batch = 0.025
Read data: 0.0002105236053466797
iter 20250 (epoch 33), train_loss = 2.645, time/batch = 0.031
Read data: 8.034706115722656e-05
iter 20251 (epoch 33), train_loss = 2.202, time/batch = 0.025
Read data: 0.00013136863708496094
iter 20252 (epoch 33), train_loss = 2.617, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 20253 (epoch 33), train_loss = 2.596, time/batch = 0.026
Read data: 7.796287536621094e-05
iter 20254 (epoch 33), train_loss = 2.738, time/batch = 0.029
Read data: 8.130073547363281e-05
iter 20255 (epoch 33), train_loss = 2.176, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 20256 (epoch 33), train_loss = 2.180, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 20257 (epoch 33), train_loss = 2.714, time/batch = 0.033
Read data: 0.00012230873107910156
iter 20258 (epoch 33), train_loss = 2.468, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 20259 (epoch 33), train_loss = 2.461, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 20260 (epoch 33), train_loss = 2.439, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 20261 (epoch 33), train_loss = 2.405, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 20262 (epoch 33), train_loss = 2.473, time/batch = 0.033
Read data: 8.440017700195312e-05
iter 20263 (epoch 33), train_loss = 2.624, time/batch = 0.024
Read data: 0.0001232624053955078
iter 20264 (epoch 33), train_loss = 2.587, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 20265 (epoch 33), train_loss = 2.342, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 20266 (epoch 33), train_loss = 2.494, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 20267 (epoch 33), train_loss = 2.703, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 20268 (epoch 33), train_loss = 2.619, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20269 (epoch 33), train_loss = 2.059, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 20270 (epoch 33), train_loss = 2.091, time/batch = 0.026
Read data: 7.867813110351562e-05
iter 20271 (epoch 33), train_loss = 2.110, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 20272 (epoch 33), train_loss = 2.538, time/batch = 0.024
Read data: 7.677078247070312e-05
iter 20273 (epoch 33), train_loss = 2.287, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 20274 (epoch 33), train_loss = 2.057, time/batch = 0.031
Read data: 0.00021767616271972656
iter 20275 (epoch 33), train_loss = 2.231, time/batch = 0.025
Read data: 8.344650268554688e-05
iter 20276 (epoch 33), train_loss = 2.166, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 20277 (epoch 33), train_loss = 2.008, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 20278 (epoch 33), train_loss = 2.532, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 20279 (epoch 33), train_loss = 2.471, time/batch = 0.025
Read data: 0.0001456737518310547
iter 20280 (epoch 33), train_loss = 2.395, time/batch = 0.033
Read data: 8.0108642578125e-05
iter 20281 (epoch 33), train_loss = 2.398, time/batch = 0.025
Read data: 0.00010991096496582031
iter 20282 (epoch 33), train_loss = 2.265, time/batch = 0.031
Read data: 0.00011849403381347656
iter 20283 (epoch 33), train_loss = 2.101, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 20284 (epoch 33), train_loss = 2.701, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 20285 (epoch 33), train_loss = 2.761, time/batch = 0.019
Read data: 9.560585021972656e-05
iter 20286 (epoch 33), train_loss = 2.566, time/batch = 0.023
Read data: 0.00011730194091796875
iter 20287 (epoch 33), train_loss = 2.163, time/batch = 0.034
Read data: 8.273124694824219e-05
iter 20288 (epoch 33), train_loss = 2.419, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 20289 (epoch 33), train_loss = 2.221, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 20290 (epoch 33), train_loss = 2.051, time/batch = 0.028
Read data: 8.177757263183594e-05
iter 20291 (epoch 33), train_loss = 2.318, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20292 (epoch 33), train_loss = 2.267, time/batch = 0.023
Read data: 9.775161743164062e-05
iter 20293 (epoch 33), train_loss = 2.352, time/batch = 0.025
Read data: 8.654594421386719e-05
iter 20294 (epoch 33), train_loss = 2.552, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 20295 (epoch 33), train_loss = 2.759, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 20296 (epoch 33), train_loss = 2.003, time/batch = 0.021
Read data: 0.0001049041748046875
iter 20297 (epoch 33), train_loss = 2.244, time/batch = 0.021
Read data: 9.965896606445312e-05
iter 20298 (epoch 33), train_loss = 2.399, time/batch = 0.029
Read data: 0.00010347366333007812
iter 20299 (epoch 33), train_loss = 2.149, time/batch = 0.025
Read data: 8.368492126464844e-05
iter 20300 (epoch 33), train_loss = 1.919, time/batch = 0.023
Read data: 8.606910705566406e-05
iter 20301 (epoch 33), train_loss = 2.446, time/batch = 0.035
Read data: 8.0108642578125e-05
iter 20302 (epoch 33), train_loss = 2.339, time/batch = 0.034
Read data: 8.320808410644531e-05
iter 20303 (epoch 33), train_loss = 1.869, time/batch = 0.023
Read data: 9.083747863769531e-05
iter 20304 (epoch 33), train_loss = 2.436, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 20305 (epoch 33), train_loss = 2.015, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 20306 (epoch 33), train_loss = 2.288, time/batch = 0.026
Read data: 7.963180541992188e-05
iter 20307 (epoch 33), train_loss = 2.027, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 20308 (epoch 33), train_loss = 2.664, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 20309 (epoch 33), train_loss = 2.367, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 20310 (epoch 33), train_loss = 2.074, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 20311 (epoch 33), train_loss = 2.320, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 20312 (epoch 33), train_loss = 2.561, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 20313 (epoch 33), train_loss = 2.264, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20314 (epoch 33), train_loss = 2.258, time/batch = 0.032
Read data: 0.0001239776611328125
iter 20315 (epoch 33), train_loss = 2.708, time/batch = 0.030
Read data: 0.00019502639770507812
iter 20316 (epoch 33), train_loss = 2.488, time/batch = 0.027
Read data: 0.0001304149627685547
iter 20317 (epoch 33), train_loss = 2.426, time/batch = 0.028
Read data: 8.96453857421875e-05
iter 20318 (epoch 33), train_loss = 2.168, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 20319 (epoch 33), train_loss = 2.591, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 20320 (epoch 33), train_loss = 2.319, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 20321 (epoch 33), train_loss = 2.316, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 20322 (epoch 33), train_loss = 2.279, time/batch = 0.031
Read data: 8.511543273925781e-05
iter 20323 (epoch 33), train_loss = 2.458, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 20324 (epoch 33), train_loss = 2.381, time/batch = 0.029
Read data: 0.000217437744140625
iter 20325 (epoch 33), train_loss = 2.723, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 20326 (epoch 33), train_loss = 2.167, time/batch = 0.031
Read data: 0.00014472007751464844
iter 20327 (epoch 33), train_loss = 2.473, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 20328 (epoch 33), train_loss = 2.067, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 20329 (epoch 33), train_loss = 2.579, time/batch = 0.036
Read data: 8.177757263183594e-05
iter 20330 (epoch 33), train_loss = 2.533, time/batch = 0.034
Read data: 8.463859558105469e-05
iter 20331 (epoch 33), train_loss = 2.202, time/batch = 0.024
Read data: 0.00012969970703125
iter 20332 (epoch 33), train_loss = 2.420, time/batch = 0.024
Read data: 9.036064147949219e-05
iter 20333 (epoch 33), train_loss = 2.479, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 20334 (epoch 33), train_loss = 1.909, time/batch = 0.025
Read data: 0.00011801719665527344
iter 20335 (epoch 33), train_loss = 2.457, time/batch = 0.025
Read data: 0.00012874603271484375
iter 20336 (epoch 33), train_loss = 2.354, time/batch = 0.028
Read data: 0.00012421607971191406
iter 20337 (epoch 33), train_loss = 2.262, time/batch = 0.029
Read data: 7.748603820800781e-05
iter 20338 (epoch 33), train_loss = 2.580, time/batch = 0.026
Read data: 7.653236389160156e-05
iter 20339 (epoch 33), train_loss = 2.279, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 20340 (epoch 33), train_loss = 2.245, time/batch = 0.021
Read data: 9.822845458984375e-05
iter 20341 (epoch 33), train_loss = 2.538, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 20342 (epoch 33), train_loss = 2.142, time/batch = 0.023
Read data: 0.000102996826171875
iter 20343 (epoch 33), train_loss = 2.370, time/batch = 0.035
Read data: 9.560585021972656e-05
iter 20344 (epoch 33), train_loss = 2.318, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 20345 (epoch 33), train_loss = 2.342, time/batch = 0.029
Read data: 0.00011301040649414062
iter 20346 (epoch 33), train_loss = 2.146, time/batch = 0.023
Read data: 8.392333984375e-05
iter 20347 (epoch 33), train_loss = 2.111, time/batch = 0.025
Read data: 0.00010275840759277344
iter 20348 (epoch 33), train_loss = 2.444, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 20349 (epoch 33), train_loss = 2.280, time/batch = 0.022
Read data: 0.0002605915069580078
iter 20350 (epoch 33), train_loss = 2.316, time/batch = 0.028
Read data: 7.796287536621094e-05
iter 20351 (epoch 33), train_loss = 2.212, time/batch = 0.029
Read data: 8.702278137207031e-05
iter 20352 (epoch 33), train_loss = 2.331, time/batch = 0.022
Read data: 8.726119995117188e-05
iter 20353 (epoch 33), train_loss = 2.156, time/batch = 0.024
Read data: 8.654594421386719e-05
iter 20354 (epoch 33), train_loss = 2.326, time/batch = 0.029
Read data: 7.772445678710938e-05
iter 20355 (epoch 33), train_loss = 2.125, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 20356 (epoch 33), train_loss = 2.496, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 20357 (epoch 33), train_loss = 2.797, time/batch = 0.028
Read data: 0.00010251998901367188
iter 20358 (epoch 33), train_loss = 1.979, time/batch = 0.024
Read data: 9.751319885253906e-05
iter 20359 (epoch 33), train_loss = 2.027, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 20360 (epoch 33), train_loss = 1.959, time/batch = 0.023
Read data: 0.00010585784912109375
iter 20361 (epoch 33), train_loss = 2.392, time/batch = 0.025
Read data: 0.00010061264038085938
iter 20362 (epoch 33), train_loss = 2.429, time/batch = 0.023
Read data: 0.00011610984802246094
iter 20363 (epoch 33), train_loss = 2.816, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 20364 (epoch 33), train_loss = 2.375, time/batch = 0.033
Read data: 8.106231689453125e-05
iter 20365 (epoch 33), train_loss = 2.446, time/batch = 0.034
Read data: 0.00011348724365234375
iter 20366 (epoch 33), train_loss = 2.260, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 20367 (epoch 33), train_loss = 2.553, time/batch = 0.026
Read data: 8.702278137207031e-05
iter 20368 (epoch 33), train_loss = 2.371, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 20369 (epoch 33), train_loss = 2.445, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 20370 (epoch 33), train_loss = 2.471, time/batch = 0.035
Read data: 8.726119995117188e-05
iter 20371 (epoch 33), train_loss = 2.556, time/batch = 0.028
Read data: 0.0001742839813232422
iter 20372 (epoch 33), train_loss = 2.639, time/batch = 0.041
Read data: 7.605552673339844e-05
iter 20373 (epoch 33), train_loss = 2.374, time/batch = 0.028
Read data: 0.00012350082397460938
iter 20374 (epoch 33), train_loss = 2.313, time/batch = 0.031
Read data: 8.416175842285156e-05
iter 20375 (epoch 33), train_loss = 2.578, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 20376 (epoch 33), train_loss = 2.286, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 20377 (epoch 33), train_loss = 2.359, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 20378 (epoch 33), train_loss = 2.213, time/batch = 0.027
Read data: 7.557868957519531e-05
iter 20379 (epoch 33), train_loss = 2.194, time/batch = 0.025
Read data: 0.00013113021850585938
iter 20380 (epoch 33), train_loss = 2.062, time/batch = 0.021
Read data: 9.059906005859375e-05
iter 20381 (epoch 33), train_loss = 2.119, time/batch = 0.026
Read data: 8.821487426757812e-05
iter 20382 (epoch 33), train_loss = 2.222, time/batch = 0.027
Read data: 0.0001354217529296875
iter 20383 (epoch 33), train_loss = 2.571, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 20384 (epoch 33), train_loss = 2.437, time/batch = 0.022
Read data: 8.511543273925781e-05
iter 20385 (epoch 33), train_loss = 2.577, time/batch = 0.025
Read data: 8.893013000488281e-05
iter 20386 (epoch 33), train_loss = 2.080, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 20387 (epoch 33), train_loss = 2.454, time/batch = 0.026
Read data: 9.989738464355469e-05
iter 20388 (epoch 33), train_loss = 2.175, time/batch = 0.030
Read data: 0.0001277923583984375
iter 20389 (epoch 33), train_loss = 2.491, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 20390 (epoch 33), train_loss = 2.641, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 20391 (epoch 33), train_loss = 2.653, time/batch = 0.029
Read data: 0.0009181499481201172
iter 20392 (epoch 33), train_loss = 2.717, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 20393 (epoch 33), train_loss = 2.322, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 20394 (epoch 33), train_loss = 1.894, time/batch = 0.023
Read data: 9.393692016601562e-05
iter 20395 (epoch 33), train_loss = 2.304, time/batch = 0.022
Read data: 9.441375732421875e-05
iter 20396 (epoch 33), train_loss = 2.501, time/batch = 0.025
Read data: 9.107589721679688e-05
iter 20397 (epoch 33), train_loss = 2.309, time/batch = 0.034
Read data: 7.82012939453125e-05
iter 20398 (epoch 33), train_loss = 2.394, time/batch = 0.026
Read data: 8.344650268554688e-05
iter 20399 (epoch 33), train_loss = 2.551, time/batch = 0.023
Read data: 0.00018024444580078125
iter 20400 (epoch 33), train_loss = 2.434, time/batch = 0.020
Read data: 8.654594421386719e-05
iter 20401 (epoch 34), train_loss = 2.060, time/batch = 0.025
Read data: 8.630752563476562e-05
iter 20402 (epoch 34), train_loss = 2.272, time/batch = 0.033
Read data: 0.00010704994201660156
iter 20403 (epoch 34), train_loss = 1.892, time/batch = 0.027
Read data: 8.344650268554688e-05
iter 20404 (epoch 34), train_loss = 2.259, time/batch = 0.027
Read data: 8.392333984375e-05
iter 20405 (epoch 34), train_loss = 2.185, time/batch = 0.032
Read data: 8.249282836914062e-05
iter 20406 (epoch 34), train_loss = 2.225, time/batch = 0.031
Read data: 0.0001220703125
iter 20407 (epoch 34), train_loss = 2.562, time/batch = 0.034
Read data: 9.34600830078125e-05
iter 20408 (epoch 34), train_loss = 2.160, time/batch = 0.024
Read data: 0.00011849403381347656
iter 20409 (epoch 34), train_loss = 2.312, time/batch = 0.037
Read data: 8.869171142578125e-05
iter 20410 (epoch 34), train_loss = 2.244, time/batch = 0.023
Read data: 8.082389831542969e-05
iter 20411 (epoch 34), train_loss = 1.860, time/batch = 0.028
Read data: 0.00014328956604003906
iter 20412 (epoch 34), train_loss = 2.755, time/batch = 0.022
Read data: 7.796287536621094e-05
iter 20413 (epoch 34), train_loss = 2.028, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 20414 (epoch 34), train_loss = 2.438, time/batch = 0.027
Read data: 9.274482727050781e-05
iter 20415 (epoch 34), train_loss = 2.303, time/batch = 0.029
Read data: 8.225440979003906e-05
iter 20416 (epoch 34), train_loss = 2.413, time/batch = 0.028
Read data: 7.462501525878906e-05
iter 20417 (epoch 34), train_loss = 2.129, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 20418 (epoch 34), train_loss = 2.511, time/batch = 0.025
Read data: 7.581710815429688e-05
iter 20419 (epoch 34), train_loss = 1.954, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 20420 (epoch 34), train_loss = 2.240, time/batch = 0.023
Read data: 8.463859558105469e-05
iter 20421 (epoch 34), train_loss = 2.391, time/batch = 0.039
Read data: 7.915496826171875e-05
iter 20422 (epoch 34), train_loss = 2.269, time/batch = 0.029
Read data: 8.749961853027344e-05
iter 20423 (epoch 34), train_loss = 2.487, time/batch = 0.032
Read data: 0.0001468658447265625
iter 20424 (epoch 34), train_loss = 2.129, time/batch = 0.024
Read data: 0.0002167224884033203
iter 20425 (epoch 34), train_loss = 2.545, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 20426 (epoch 34), train_loss = 2.543, time/batch = 0.031
Read data: 8.0108642578125e-05
iter 20427 (epoch 34), train_loss = 2.668, time/batch = 0.028
Read data: 9.751319885253906e-05
iter 20428 (epoch 34), train_loss = 2.227, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 20429 (epoch 34), train_loss = 2.348, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 20430 (epoch 34), train_loss = 2.189, time/batch = 0.027
Read data: 8.034706115722656e-05
iter 20431 (epoch 34), train_loss = 2.404, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 20432 (epoch 34), train_loss = 2.378, time/batch = 0.029
Read data: 0.00015091896057128906
iter 20433 (epoch 34), train_loss = 2.202, time/batch = 0.026
Read data: 8.225440979003906e-05
iter 20434 (epoch 34), train_loss = 2.219, time/batch = 0.035
Read data: 8.678436279296875e-05
iter 20435 (epoch 34), train_loss = 2.212, time/batch = 0.024
Read data: 0.00012302398681640625
iter 20436 (epoch 34), train_loss = 2.388, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20437 (epoch 34), train_loss = 2.848, time/batch = 0.026
Read data: 8.106231689453125e-05
iter 20438 (epoch 34), train_loss = 2.400, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 20439 (epoch 34), train_loss = 2.385, time/batch = 0.023
Read data: 8.273124694824219e-05
iter 20440 (epoch 34), train_loss = 2.199, time/batch = 0.027
Read data: 7.677078247070312e-05
iter 20441 (epoch 34), train_loss = 2.375, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 20442 (epoch 34), train_loss = 2.469, time/batch = 0.025
Read data: 0.00010013580322265625
iter 20443 (epoch 34), train_loss = 2.258, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 20444 (epoch 34), train_loss = 2.594, time/batch = 0.025
Read data: 0.00010895729064941406
iter 20445 (epoch 34), train_loss = 2.323, time/batch = 0.038
Read data: 0.00013136863708496094
iter 20446 (epoch 34), train_loss = 2.428, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 20447 (epoch 34), train_loss = 2.566, time/batch = 0.024
Read data: 0.00019788742065429688
iter 20448 (epoch 34), train_loss = 1.924, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 20449 (epoch 34), train_loss = 2.147, time/batch = 0.027
Read data: 0.0002548694610595703
iter 20450 (epoch 34), train_loss = 2.539, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 20451 (epoch 34), train_loss = 2.484, time/batch = 0.030
Read data: 8.392333984375e-05
iter 20452 (epoch 34), train_loss = 2.393, time/batch = 0.034
Read data: 8.821487426757812e-05
iter 20453 (epoch 34), train_loss = 2.789, time/batch = 0.030
Read data: 0.00011587142944335938
iter 20454 (epoch 34), train_loss = 2.385, time/batch = 0.024
Read data: 8.440017700195312e-05
iter 20455 (epoch 34), train_loss = 2.563, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 20456 (epoch 34), train_loss = 2.649, time/batch = 0.032
Read data: 8.177757263183594e-05
iter 20457 (epoch 34), train_loss = 2.832, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 20458 (epoch 34), train_loss = 2.100, time/batch = 0.029
Read data: 8.058547973632812e-05
iter 20459 (epoch 34), train_loss = 2.292, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20460 (epoch 34), train_loss = 2.700, time/batch = 0.036
Read data: 8.487701416015625e-05
iter 20461 (epoch 34), train_loss = 2.466, time/batch = 0.022
Read data: 8.416175842285156e-05
iter 20462 (epoch 34), train_loss = 2.389, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 20463 (epoch 34), train_loss = 2.401, time/batch = 0.035
Read data: 8.678436279296875e-05
iter 20464 (epoch 34), train_loss = 2.519, time/batch = 0.030
Read data: 8.630752563476562e-05
iter 20465 (epoch 34), train_loss = 1.747, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 20466 (epoch 34), train_loss = 2.273, time/batch = 0.031
Read data: 8.20159912109375e-05
iter 20467 (epoch 34), train_loss = 2.198, time/batch = 0.025
Read data: 0.0001220703125
iter 20468 (epoch 34), train_loss = 2.189, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 20469 (epoch 34), train_loss = 2.471, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 20470 (epoch 34), train_loss = 2.029, time/batch = 0.026
Read data: 7.772445678710938e-05
iter 20471 (epoch 34), train_loss = 2.273, time/batch = 0.027
Read data: 8.20159912109375e-05
iter 20472 (epoch 34), train_loss = 2.304, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 20473 (epoch 34), train_loss = 2.318, time/batch = 0.023
Read data: 9.751319885253906e-05
iter 20474 (epoch 34), train_loss = 2.568, time/batch = 0.023
Read data: 0.0002384185791015625
iter 20475 (epoch 34), train_loss = 2.372, time/batch = 0.023
Read data: 0.00013685226440429688
iter 20476 (epoch 34), train_loss = 2.288, time/batch = 0.034
Read data: 8.249282836914062e-05
iter 20477 (epoch 34), train_loss = 2.429, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20478 (epoch 34), train_loss = 2.327, time/batch = 0.029
Read data: 8.0108642578125e-05
iter 20479 (epoch 34), train_loss = 2.508, time/batch = 0.024
Read data: 8.702278137207031e-05
iter 20480 (epoch 34), train_loss = 2.376, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 20481 (epoch 34), train_loss = 2.152, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 20482 (epoch 34), train_loss = 2.351, time/batch = 0.038
Read data: 8.678436279296875e-05
iter 20483 (epoch 34), train_loss = 2.300, time/batch = 0.024
Read data: 0.00014519691467285156
iter 20484 (epoch 34), train_loss = 2.236, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 20485 (epoch 34), train_loss = 2.124, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 20486 (epoch 34), train_loss = 2.148, time/batch = 0.022
Read data: 0.000141143798828125
iter 20487 (epoch 34), train_loss = 2.267, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 20488 (epoch 34), train_loss = 2.444, time/batch = 0.029
Read data: 7.891654968261719e-05
iter 20489 (epoch 34), train_loss = 2.143, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 20490 (epoch 34), train_loss = 2.018, time/batch = 0.028
Read data: 7.605552673339844e-05
iter 20491 (epoch 34), train_loss = 2.531, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 20492 (epoch 34), train_loss = 1.877, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 20493 (epoch 34), train_loss = 2.263, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 20494 (epoch 34), train_loss = 2.347, time/batch = 0.031
Read data: 8.440017700195312e-05
iter 20495 (epoch 34), train_loss = 2.684, time/batch = 0.034
Read data: 9.179115295410156e-05
iter 20496 (epoch 34), train_loss = 2.579, time/batch = 0.026
Read data: 0.00013256072998046875
iter 20497 (epoch 34), train_loss = 1.829, time/batch = 0.022
Read data: 8.082389831542969e-05
iter 20498 (epoch 34), train_loss = 2.361, time/batch = 0.034
Read data: 7.939338684082031e-05
iter 20499 (epoch 34), train_loss = 2.201, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20500 (epoch 34), train_loss = 2.007, time/batch = 0.027
Read data: 0.0001270771026611328
iter 20501 (epoch 34), train_loss = 2.261, time/batch = 0.030
Read data: 8.940696716308594e-05
iter 20502 (epoch 34), train_loss = 2.300, time/batch = 0.036
Read data: 9.632110595703125e-05
iter 20503 (epoch 34), train_loss = 2.410, time/batch = 0.036
Read data: 8.058547973632812e-05
iter 20504 (epoch 34), train_loss = 2.274, time/batch = 0.031
Read data: 7.605552673339844e-05
iter 20505 (epoch 34), train_loss = 2.487, time/batch = 0.024
Read data: 0.00011539459228515625
iter 20506 (epoch 34), train_loss = 2.740, time/batch = 0.026
Read data: 8.416175842285156e-05
iter 20507 (epoch 34), train_loss = 2.380, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 20508 (epoch 34), train_loss = 2.183, time/batch = 0.025
Read data: 0.0001049041748046875
iter 20509 (epoch 34), train_loss = 2.112, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 20510 (epoch 34), train_loss = 2.306, time/batch = 0.028
Read data: 8.034706115722656e-05
iter 20511 (epoch 34), train_loss = 2.464, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 20512 (epoch 34), train_loss = 2.458, time/batch = 0.022
Read data: 9.036064147949219e-05
iter 20513 (epoch 34), train_loss = 2.689, time/batch = 0.027
Read data: 0.00010061264038085938
iter 20514 (epoch 34), train_loss = 2.386, time/batch = 0.026
Read data: 0.00011873245239257812
iter 20515 (epoch 34), train_loss = 2.385, time/batch = 0.027
Read data: 8.463859558105469e-05
iter 20516 (epoch 34), train_loss = 2.004, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 20517 (epoch 34), train_loss = 2.314, time/batch = 0.030
Read data: 8.058547973632812e-05
iter 20518 (epoch 34), train_loss = 1.964, time/batch = 0.028
Read data: 7.772445678710938e-05
iter 20519 (epoch 34), train_loss = 2.137, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 20520 (epoch 34), train_loss = 2.378, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 20521 (epoch 34), train_loss = 2.225, time/batch = 0.034
Read data: 8.0108642578125e-05
iter 20522 (epoch 34), train_loss = 2.448, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 20523 (epoch 34), train_loss = 2.392, time/batch = 0.028
Read data: 8.893013000488281e-05
iter 20524 (epoch 34), train_loss = 2.416, time/batch = 0.024
Read data: 0.0002543926239013672
iter 20525 (epoch 34), train_loss = 2.385, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 20526 (epoch 34), train_loss = 2.258, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20527 (epoch 34), train_loss = 2.691, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 20528 (epoch 34), train_loss = 2.329, time/batch = 0.024
Read data: 9.083747863769531e-05
iter 20529 (epoch 34), train_loss = 2.524, time/batch = 0.025
Read data: 9.512901306152344e-05
iter 20530 (epoch 34), train_loss = 2.111, time/batch = 0.023
Read data: 0.00010514259338378906
iter 20531 (epoch 34), train_loss = 2.166, time/batch = 0.027
Read data: 0.00012874603271484375
iter 20532 (epoch 34), train_loss = 2.613, time/batch = 0.025
Read data: 9.393692016601562e-05
iter 20533 (epoch 34), train_loss = 1.765, time/batch = 0.037
Read data: 8.726119995117188e-05
iter 20534 (epoch 34), train_loss = 2.377, time/batch = 0.031
Read data: 8.654594421386719e-05
iter 20535 (epoch 34), train_loss = 2.344, time/batch = 0.026
Read data: 9.298324584960938e-05
iter 20536 (epoch 34), train_loss = 2.447, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 20537 (epoch 34), train_loss = 2.450, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 20538 (epoch 34), train_loss = 2.281, time/batch = 0.022
Read data: 9.965896606445312e-05
iter 20539 (epoch 34), train_loss = 2.410, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 20540 (epoch 34), train_loss = 2.560, time/batch = 0.030
Read data: 9.083747863769531e-05
iter 20541 (epoch 34), train_loss = 2.592, time/batch = 0.028
Read data: 0.00010585784912109375
iter 20542 (epoch 34), train_loss = 2.210, time/batch = 0.031
Read data: 9.465217590332031e-05
iter 20543 (epoch 34), train_loss = 2.353, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 20544 (epoch 34), train_loss = 2.415, time/batch = 0.039
Read data: 8.654594421386719e-05
iter 20545 (epoch 34), train_loss = 2.511, time/batch = 0.034
Read data: 9.226799011230469e-05
iter 20546 (epoch 34), train_loss = 2.398, time/batch = 0.022
Read data: 8.702278137207031e-05
iter 20547 (epoch 34), train_loss = 2.110, time/batch = 0.026
Read data: 0.0001285076141357422
iter 20548 (epoch 34), train_loss = 2.538, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 20549 (epoch 34), train_loss = 2.517, time/batch = 0.022
Read data: 0.0002663135528564453
iter 20550 (epoch 34), train_loss = 1.860, time/batch = 0.025
Read data: 0.00011610984802246094
iter 20551 (epoch 34), train_loss = 2.273, time/batch = 0.027
Read data: 9.131431579589844e-05
iter 20552 (epoch 34), train_loss = 2.661, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 20553 (epoch 34), train_loss = 1.979, time/batch = 0.021
Read data: 9.393692016601562e-05
iter 20554 (epoch 34), train_loss = 2.308, time/batch = 0.028
Read data: 7.62939453125e-05
iter 20555 (epoch 34), train_loss = 2.251, time/batch = 0.030
Read data: 0.00012612342834472656
iter 20556 (epoch 34), train_loss = 2.379, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 20557 (epoch 34), train_loss = 2.420, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 20558 (epoch 34), train_loss = 2.392, time/batch = 0.033
Read data: 0.00012993812561035156
iter 20559 (epoch 34), train_loss = 2.041, time/batch = 0.020
Read data: 8.225440979003906e-05
iter 20560 (epoch 34), train_loss = 2.268, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 20561 (epoch 34), train_loss = 2.366, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 20562 (epoch 34), train_loss = 2.341, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 20563 (epoch 34), train_loss = 2.195, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 20564 (epoch 34), train_loss = 2.313, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 20565 (epoch 34), train_loss = 2.111, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20566 (epoch 34), train_loss = 2.110, time/batch = 0.036
Read data: 0.00012636184692382812
iter 20567 (epoch 34), train_loss = 1.884, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 20568 (epoch 34), train_loss = 2.440, time/batch = 0.027
Read data: 0.00014352798461914062
iter 20569 (epoch 34), train_loss = 2.073, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 20570 (epoch 34), train_loss = 2.263, time/batch = 0.028
Read data: 7.82012939453125e-05
iter 20571 (epoch 34), train_loss = 2.279, time/batch = 0.027
Read data: 8.535385131835938e-05
iter 20572 (epoch 34), train_loss = 2.257, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 20573 (epoch 34), train_loss = 2.554, time/batch = 0.034
Read data: 0.00014090538024902344
iter 20574 (epoch 34), train_loss = 2.450, time/batch = 0.034
Read data: 8.0108642578125e-05
iter 20575 (epoch 34), train_loss = 2.148, time/batch = 0.028
Read data: 0.00013899803161621094
iter 20576 (epoch 34), train_loss = 2.247, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 20577 (epoch 34), train_loss = 2.441, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 20578 (epoch 34), train_loss = 2.294, time/batch = 0.026
Read data: 8.845329284667969e-05
iter 20579 (epoch 34), train_loss = 2.245, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 20580 (epoch 34), train_loss = 2.363, time/batch = 0.038
Read data: 0.00011420249938964844
iter 20581 (epoch 34), train_loss = 2.438, time/batch = 0.026
Read data: 8.7738037109375e-05
iter 20582 (epoch 34), train_loss = 2.438, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 20583 (epoch 34), train_loss = 2.393, time/batch = 0.028
Read data: 8.606910705566406e-05
iter 20584 (epoch 34), train_loss = 2.154, time/batch = 0.023
Read data: 8.487701416015625e-05
iter 20585 (epoch 34), train_loss = 2.477, time/batch = 0.024
Read data: 8.392333984375e-05
iter 20586 (epoch 34), train_loss = 2.427, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 20587 (epoch 34), train_loss = 2.551, time/batch = 0.030
Read data: 9.369850158691406e-05
iter 20588 (epoch 34), train_loss = 2.366, time/batch = 0.026
Read data: 7.843971252441406e-05
iter 20589 (epoch 34), train_loss = 2.752, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 20590 (epoch 34), train_loss = 1.916, time/batch = 0.023
Read data: 8.416175842285156e-05
iter 20591 (epoch 34), train_loss = 2.327, time/batch = 0.027
Read data: 0.00013518333435058594
iter 20592 (epoch 34), train_loss = 2.340, time/batch = 0.025
Read data: 9.441375732421875e-05
iter 20593 (epoch 34), train_loss = 2.262, time/batch = 0.025
Read data: 9.34600830078125e-05
iter 20594 (epoch 34), train_loss = 2.314, time/batch = 0.027
Read data: 0.00010037422180175781
iter 20595 (epoch 34), train_loss = 2.325, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 20596 (epoch 34), train_loss = 2.305, time/batch = 0.025
Read data: 8.821487426757812e-05
iter 20597 (epoch 34), train_loss = 2.526, time/batch = 0.039
Read data: 0.0001499652862548828
iter 20598 (epoch 34), train_loss = 2.255, time/batch = 0.027
Read data: 8.559226989746094e-05
iter 20599 (epoch 34), train_loss = 2.425, time/batch = 0.023
Read data: 8.58306884765625e-05
iter 20600 (epoch 34), train_loss = 2.470, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 20601 (epoch 34), train_loss = 2.602, time/batch = 0.026
Read data: 8.273124694824219e-05
iter 20602 (epoch 34), train_loss = 2.514, time/batch = 0.023
Read data: 0.00011658668518066406
iter 20603 (epoch 34), train_loss = 2.405, time/batch = 0.028
Read data: 8.988380432128906e-05
iter 20604 (epoch 34), train_loss = 2.284, time/batch = 0.028
Read data: 0.00010633468627929688
iter 20605 (epoch 34), train_loss = 2.439, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 20606 (epoch 34), train_loss = 2.091, time/batch = 0.021
Read data: 9.72747802734375e-05
iter 20607 (epoch 34), train_loss = 2.646, time/batch = 0.030
Read data: 8.273124694824219e-05
iter 20608 (epoch 34), train_loss = 2.363, time/batch = 0.024
Read data: 9.632110595703125e-05
iter 20609 (epoch 34), train_loss = 2.861, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 20610 (epoch 34), train_loss = 2.385, time/batch = 0.025
Read data: 7.62939453125e-05
iter 20611 (epoch 34), train_loss = 2.421, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 20612 (epoch 34), train_loss = 2.149, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 20613 (epoch 34), train_loss = 2.589, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 20614 (epoch 34), train_loss = 2.149, time/batch = 0.020
Read data: 9.799003601074219e-05
iter 20615 (epoch 34), train_loss = 2.080, time/batch = 0.026
Read data: 0.0001246929168701172
iter 20616 (epoch 34), train_loss = 1.851, time/batch = 0.026
Read data: 9.894371032714844e-05
iter 20617 (epoch 34), train_loss = 2.090, time/batch = 0.021
Read data: 0.00013327598571777344
iter 20618 (epoch 34), train_loss = 2.456, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 20619 (epoch 34), train_loss = 2.199, time/batch = 0.026
Read data: 8.630752563476562e-05
iter 20620 (epoch 34), train_loss = 1.983, time/batch = 0.029
Read data: 8.273124694824219e-05
iter 20621 (epoch 34), train_loss = 2.076, time/batch = 0.023
Read data: 9.965896606445312e-05
iter 20622 (epoch 34), train_loss = 2.320, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 20623 (epoch 34), train_loss = 2.480, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20624 (epoch 34), train_loss = 2.468, time/batch = 0.029
Read data: 0.00024437904357910156
iter 20625 (epoch 34), train_loss = 2.172, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 20626 (epoch 34), train_loss = 1.995, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 20627 (epoch 34), train_loss = 2.373, time/batch = 0.031
Read data: 7.891654968261719e-05
iter 20628 (epoch 34), train_loss = 2.373, time/batch = 0.024
Read data: 9.131431579589844e-05
iter 20629 (epoch 34), train_loss = 2.365, time/batch = 0.029
Read data: 7.987022399902344e-05
iter 20630 (epoch 34), train_loss = 2.029, time/batch = 0.030
Read data: 8.177757263183594e-05
iter 20631 (epoch 34), train_loss = 2.729, time/batch = 0.025
Read data: 8.0108642578125e-05
iter 20632 (epoch 34), train_loss = 2.329, time/batch = 0.027
Read data: 7.843971252441406e-05
iter 20633 (epoch 34), train_loss = 2.744, time/batch = 0.032
Read data: 8.082389831542969e-05
iter 20634 (epoch 34), train_loss = 2.468, time/batch = 0.023
Read data: 7.987022399902344e-05
iter 20635 (epoch 34), train_loss = 2.204, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 20636 (epoch 34), train_loss = 2.085, time/batch = 0.028
Read data: 9.942054748535156e-05
iter 20637 (epoch 34), train_loss = 2.162, time/batch = 0.029
Read data: 7.963180541992188e-05
iter 20638 (epoch 34), train_loss = 2.305, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 20639 (epoch 34), train_loss = 2.243, time/batch = 0.024
Read data: 7.987022399902344e-05
iter 20640 (epoch 34), train_loss = 2.511, time/batch = 0.028
Read data: 7.987022399902344e-05
iter 20641 (epoch 34), train_loss = 2.045, time/batch = 0.023
Read data: 0.00010132789611816406
iter 20642 (epoch 34), train_loss = 1.923, time/batch = 0.025
Read data: 9.608268737792969e-05
iter 20643 (epoch 34), train_loss = 2.299, time/batch = 0.024
Read data: 0.00013303756713867188
iter 20644 (epoch 34), train_loss = 2.245, time/batch = 0.023
Read data: 9.036064147949219e-05
iter 20645 (epoch 34), train_loss = 2.541, time/batch = 0.034
Read data: 7.724761962890625e-05
iter 20646 (epoch 34), train_loss = 2.466, time/batch = 0.025
Read data: 7.843971252441406e-05
iter 20647 (epoch 34), train_loss = 2.229, time/batch = 0.031
Read data: 8.320808410644531e-05
iter 20648 (epoch 34), train_loss = 2.462, time/batch = 0.032
Read data: 9.250640869140625e-05
iter 20649 (epoch 34), train_loss = 2.172, time/batch = 0.026
Read data: 0.00022459030151367188
iter 20650 (epoch 34), train_loss = 2.482, time/batch = 0.026
Read data: 9.059906005859375e-05
iter 20651 (epoch 34), train_loss = 2.503, time/batch = 0.023
Read data: 8.344650268554688e-05
iter 20652 (epoch 34), train_loss = 2.111, time/batch = 0.030
Read data: 9.226799011230469e-05
iter 20653 (epoch 34), train_loss = 2.580, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 20654 (epoch 34), train_loss = 1.982, time/batch = 0.024
Read data: 7.867813110351562e-05
iter 20655 (epoch 34), train_loss = 2.426, time/batch = 0.036
Read data: 8.058547973632812e-05
iter 20656 (epoch 34), train_loss = 2.379, time/batch = 0.031
Read data: 0.0001404285430908203
iter 20657 (epoch 34), train_loss = 2.282, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 20658 (epoch 34), train_loss = 2.562, time/batch = 0.033
Read data: 8.082389831542969e-05
iter 20659 (epoch 34), train_loss = 2.425, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20660 (epoch 34), train_loss = 3.029, time/batch = 0.030
Read data: 8.20159912109375e-05
iter 20661 (epoch 34), train_loss = 3.035, time/batch = 0.030
Read data: 8.487701416015625e-05
iter 20662 (epoch 34), train_loss = 2.632, time/batch = 0.031
Read data: 8.463859558105469e-05
iter 20663 (epoch 34), train_loss = 2.514, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 20664 (epoch 34), train_loss = 2.351, time/batch = 0.025
Read data: 8.130073547363281e-05
iter 20665 (epoch 34), train_loss = 1.943, time/batch = 0.021
Read data: 0.00010418891906738281
iter 20666 (epoch 34), train_loss = 2.526, time/batch = 0.023
Read data: 8.869171142578125e-05
iter 20667 (epoch 34), train_loss = 1.797, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20668 (epoch 34), train_loss = 2.393, time/batch = 0.022
Read data: 9.393692016601562e-05
iter 20669 (epoch 34), train_loss = 2.428, time/batch = 0.028
Read data: 9.179115295410156e-05
iter 20670 (epoch 34), train_loss = 2.108, time/batch = 0.026
Read data: 9.34600830078125e-05
iter 20671 (epoch 34), train_loss = 2.123, time/batch = 0.023
Read data: 8.749961853027344e-05
iter 20672 (epoch 34), train_loss = 2.715, time/batch = 0.026
Read data: 0.0001232624053955078
iter 20673 (epoch 34), train_loss = 2.408, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 20674 (epoch 34), train_loss = 2.685, time/batch = 0.030
Read data: 0.0002391338348388672
iter 20675 (epoch 34), train_loss = 2.057, time/batch = 0.021
Read data: 8.702278137207031e-05
iter 20676 (epoch 34), train_loss = 2.684, time/batch = 0.027
Read data: 8.797645568847656e-05
iter 20677 (epoch 34), train_loss = 2.329, time/batch = 0.027
Read data: 7.82012939453125e-05
iter 20678 (epoch 34), train_loss = 2.416, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 20679 (epoch 34), train_loss = 2.129, time/batch = 0.027
Read data: 8.511543273925781e-05
iter 20680 (epoch 34), train_loss = 2.191, time/batch = 0.026
Read data: 9.703636169433594e-05
iter 20681 (epoch 34), train_loss = 2.298, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 20682 (epoch 34), train_loss = 2.320, time/batch = 0.025
Read data: 8.058547973632812e-05
iter 20683 (epoch 34), train_loss = 2.301, time/batch = 0.019
Read data: 9.465217590332031e-05
iter 20684 (epoch 34), train_loss = 2.266, time/batch = 0.028
Read data: 9.822845458984375e-05
iter 20685 (epoch 34), train_loss = 2.495, time/batch = 0.025
Read data: 8.702278137207031e-05
iter 20686 (epoch 34), train_loss = 2.067, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 20687 (epoch 34), train_loss = 2.055, time/batch = 0.027
Read data: 0.00014543533325195312
iter 20688 (epoch 34), train_loss = 1.956, time/batch = 0.020
Read data: 8.654594421386719e-05
iter 20689 (epoch 34), train_loss = 2.380, time/batch = 0.025
Read data: 8.7738037109375e-05
iter 20690 (epoch 34), train_loss = 2.348, time/batch = 0.025
Read data: 0.00014090538024902344
iter 20691 (epoch 34), train_loss = 2.442, time/batch = 0.022
Read data: 9.1552734375e-05
iter 20692 (epoch 34), train_loss = 2.258, time/batch = 0.028
Read data: 8.392333984375e-05
iter 20693 (epoch 34), train_loss = 2.387, time/batch = 0.025
Read data: 8.606910705566406e-05
iter 20694 (epoch 34), train_loss = 2.316, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 20695 (epoch 34), train_loss = 2.081, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 20696 (epoch 34), train_loss = 2.049, time/batch = 0.020
Read data: 0.00013780593872070312
iter 20697 (epoch 34), train_loss = 2.696, time/batch = 0.029
Read data: 0.000102996826171875
iter 20698 (epoch 34), train_loss = 2.402, time/batch = 0.021
Read data: 9.036064147949219e-05
iter 20699 (epoch 34), train_loss = 2.381, time/batch = 0.025
Read data: 8.559226989746094e-05
iter 20700 (epoch 34), train_loss = 2.418, time/batch = 0.029
Read data: 9.751319885253906e-05
iter 20701 (epoch 34), train_loss = 1.996, time/batch = 0.027
Read data: 7.915496826171875e-05
iter 20702 (epoch 34), train_loss = 2.281, time/batch = 0.026
Read data: 8.130073547363281e-05
iter 20703 (epoch 34), train_loss = 2.248, time/batch = 0.023
Read data: 9.703636169433594e-05
iter 20704 (epoch 34), train_loss = 2.522, time/batch = 0.031
Read data: 0.00010347366333007812
iter 20705 (epoch 34), train_loss = 2.419, time/batch = 0.024
Read data: 7.486343383789062e-05
iter 20706 (epoch 34), train_loss = 2.592, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 20707 (epoch 34), train_loss = 2.388, time/batch = 0.028
Read data: 8.58306884765625e-05
iter 20708 (epoch 34), train_loss = 2.155, time/batch = 0.023
Read data: 0.00010061264038085938
iter 20709 (epoch 34), train_loss = 2.276, time/batch = 0.021
Read data: 0.00010800361633300781
iter 20710 (epoch 34), train_loss = 2.238, time/batch = 0.026
Read data: 8.916854858398438e-05
iter 20711 (epoch 34), train_loss = 2.286, time/batch = 0.031
Read data: 8.559226989746094e-05
iter 20712 (epoch 34), train_loss = 2.442, time/batch = 0.029
Read data: 7.82012939453125e-05
iter 20713 (epoch 34), train_loss = 2.516, time/batch = 0.025
Read data: 8.20159912109375e-05
iter 20714 (epoch 34), train_loss = 2.273, time/batch = 0.021
Read data: 0.0001010894775390625
iter 20715 (epoch 34), train_loss = 2.318, time/batch = 0.020
Read data: 9.012222290039062e-05
iter 20716 (epoch 34), train_loss = 2.555, time/batch = 0.022
Read data: 8.296966552734375e-05
iter 20717 (epoch 34), train_loss = 2.366, time/batch = 0.033
Read data: 0.00010037422180175781
iter 20718 (epoch 34), train_loss = 2.617, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 20719 (epoch 34), train_loss = 2.687, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 20720 (epoch 34), train_loss = 2.276, time/batch = 0.029
Read data: 8.368492126464844e-05
iter 20721 (epoch 34), train_loss = 2.072, time/batch = 0.023
Read data: 7.963180541992188e-05
iter 20722 (epoch 34), train_loss = 1.981, time/batch = 0.025
Read data: 8.916854858398438e-05
iter 20723 (epoch 34), train_loss = 2.276, time/batch = 0.025
Read data: 8.845329284667969e-05
iter 20724 (epoch 34), train_loss = 2.026, time/batch = 0.026
Read data: 0.00022411346435546875
iter 20725 (epoch 34), train_loss = 2.559, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 20726 (epoch 34), train_loss = 2.163, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 20727 (epoch 34), train_loss = 1.996, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 20728 (epoch 34), train_loss = 2.315, time/batch = 0.028
Read data: 9.489059448242188e-05
iter 20729 (epoch 34), train_loss = 2.248, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 20730 (epoch 34), train_loss = 2.405, time/batch = 0.025
Read data: 8.225440979003906e-05
iter 20731 (epoch 34), train_loss = 2.642, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 20732 (epoch 34), train_loss = 2.173, time/batch = 0.031
Read data: 8.249282836914062e-05
iter 20733 (epoch 34), train_loss = 2.398, time/batch = 0.021
Read data: 9.679794311523438e-05
iter 20734 (epoch 34), train_loss = 2.067, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 20735 (epoch 34), train_loss = 2.497, time/batch = 0.021
Read data: 8.916854858398438e-05
iter 20736 (epoch 34), train_loss = 2.096, time/batch = 0.024
Read data: 8.988380432128906e-05
iter 20737 (epoch 34), train_loss = 2.449, time/batch = 0.034
Read data: 8.106231689453125e-05
iter 20738 (epoch 34), train_loss = 2.443, time/batch = 0.023
Read data: 0.00010180473327636719
iter 20739 (epoch 34), train_loss = 2.309, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 20740 (epoch 34), train_loss = 2.172, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 20741 (epoch 34), train_loss = 2.516, time/batch = 0.027
Read data: 8.821487426757812e-05
iter 20742 (epoch 34), train_loss = 2.228, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 20743 (epoch 34), train_loss = 2.400, time/batch = 0.036
Read data: 8.082389831542969e-05
iter 20744 (epoch 34), train_loss = 2.112, time/batch = 0.023
Read data: 8.034706115722656e-05
iter 20745 (epoch 34), train_loss = 2.335, time/batch = 0.031
Read data: 0.0001227855682373047
iter 20746 (epoch 34), train_loss = 2.621, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 20747 (epoch 34), train_loss = 2.507, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20748 (epoch 34), train_loss = 2.305, time/batch = 0.027
Read data: 8.249282836914062e-05
iter 20749 (epoch 34), train_loss = 2.269, time/batch = 0.026
Read data: 0.00025534629821777344
iter 20750 (epoch 34), train_loss = 2.386, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 20751 (epoch 34), train_loss = 2.563, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 20752 (epoch 34), train_loss = 2.230, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 20753 (epoch 34), train_loss = 2.503, time/batch = 0.033
Read data: 9.679794311523438e-05
iter 20754 (epoch 34), train_loss = 2.220, time/batch = 0.028
Read data: 0.00011301040649414062
iter 20755 (epoch 34), train_loss = 2.562, time/batch = 0.028
Read data: 8.749961853027344e-05
iter 20756 (epoch 34), train_loss = 2.672, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 20757 (epoch 34), train_loss = 2.701, time/batch = 0.024
Read data: 7.796287536621094e-05
iter 20758 (epoch 34), train_loss = 2.292, time/batch = 0.027
Read data: 9.179115295410156e-05
iter 20759 (epoch 34), train_loss = 2.427, time/batch = 0.030
Read data: 8.106231689453125e-05
iter 20760 (epoch 34), train_loss = 2.450, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 20761 (epoch 34), train_loss = 2.571, time/batch = 0.019
Read data: 9.679794311523438e-05
iter 20762 (epoch 34), train_loss = 2.426, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 20763 (epoch 34), train_loss = 2.257, time/batch = 0.021
Read data: 9.107589721679688e-05
iter 20764 (epoch 34), train_loss = 1.967, time/batch = 0.027
Read data: 9.918212890625e-05
iter 20765 (epoch 34), train_loss = 2.130, time/batch = 0.026
Read data: 9.799003601074219e-05
iter 20766 (epoch 34), train_loss = 2.067, time/batch = 0.024
Read data: 8.821487426757812e-05
iter 20767 (epoch 34), train_loss = 2.668, time/batch = 0.029
Read data: 8.416175842285156e-05
iter 20768 (epoch 34), train_loss = 2.122, time/batch = 0.026
Read data: 9.131431579589844e-05
iter 20769 (epoch 34), train_loss = 2.571, time/batch = 0.025
Read data: 8.177757263183594e-05
iter 20770 (epoch 34), train_loss = 2.344, time/batch = 0.025
Read data: 9.632110595703125e-05
iter 20771 (epoch 34), train_loss = 2.358, time/batch = 0.026
Read data: 8.177757263183594e-05
iter 20772 (epoch 34), train_loss = 2.474, time/batch = 0.022
Read data: 9.083747863769531e-05
iter 20773 (epoch 34), train_loss = 2.397, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 20774 (epoch 34), train_loss = 2.361, time/batch = 0.025
Read data: 0.00024437904357910156
iter 20775 (epoch 34), train_loss = 2.226, time/batch = 0.030
Read data: 8.034706115722656e-05
iter 20776 (epoch 34), train_loss = 2.054, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 20777 (epoch 34), train_loss = 2.276, time/batch = 0.027
Read data: 8.296966552734375e-05
iter 20778 (epoch 34), train_loss = 2.643, time/batch = 0.023
Read data: 7.796287536621094e-05
iter 20779 (epoch 34), train_loss = 2.409, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 20780 (epoch 34), train_loss = 2.444, time/batch = 0.029
Read data: 8.034706115722656e-05
iter 20781 (epoch 34), train_loss = 2.044, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 20782 (epoch 34), train_loss = 2.873, time/batch = 0.025
Read data: 7.939338684082031e-05
iter 20783 (epoch 34), train_loss = 2.192, time/batch = 0.022
Read data: 8.869171142578125e-05
iter 20784 (epoch 34), train_loss = 2.150, time/batch = 0.036
Read data: 7.724761962890625e-05
iter 20785 (epoch 34), train_loss = 2.343, time/batch = 0.027
Read data: 0.00013828277587890625
iter 20786 (epoch 34), train_loss = 2.116, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 20787 (epoch 34), train_loss = 2.250, time/batch = 0.025
Read data: 8.416175842285156e-05
iter 20788 (epoch 34), train_loss = 2.647, time/batch = 0.027
Read data: 0.00014638900756835938
iter 20789 (epoch 34), train_loss = 2.340, time/batch = 0.027
Read data: 9.202957153320312e-05
iter 20790 (epoch 34), train_loss = 2.388, time/batch = 0.032
Read data: 0.00014209747314453125
iter 20791 (epoch 34), train_loss = 2.374, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 20792 (epoch 34), train_loss = 2.499, time/batch = 0.041
Read data: 7.772445678710938e-05
iter 20793 (epoch 34), train_loss = 2.444, time/batch = 0.024
Read data: 0.0001239776611328125
iter 20794 (epoch 34), train_loss = 2.253, time/batch = 0.034
Read data: 8.797645568847656e-05
iter 20795 (epoch 34), train_loss = 2.181, time/batch = 0.024
Read data: 8.368492126464844e-05
iter 20796 (epoch 34), train_loss = 2.166, time/batch = 0.031
Read data: 8.606910705566406e-05
iter 20797 (epoch 34), train_loss = 2.023, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 20798 (epoch 34), train_loss = 2.386, time/batch = 0.030
Read data: 7.939338684082031e-05
iter 20799 (epoch 34), train_loss = 2.660, time/batch = 0.025
Read data: 7.867813110351562e-05
iter 20800 (epoch 34), train_loss = 2.245, time/batch = 0.029
Read data: 7.915496826171875e-05
iter 20801 (epoch 34), train_loss = 2.383, time/batch = 0.030
Read data: 8.249282836914062e-05
iter 20802 (epoch 34), train_loss = 2.234, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 20803 (epoch 34), train_loss = 2.461, time/batch = 0.032
Read data: 8.7738037109375e-05
iter 20804 (epoch 34), train_loss = 2.489, time/batch = 0.028
Read data: 0.00011539459228515625
iter 20805 (epoch 34), train_loss = 2.277, time/batch = 0.024
Read data: 0.0001723766326904297
iter 20806 (epoch 34), train_loss = 2.660, time/batch = 0.034
Read data: 8.225440979003906e-05
iter 20807 (epoch 34), train_loss = 2.329, time/batch = 0.028
Read data: 8.940696716308594e-05
iter 20808 (epoch 34), train_loss = 2.624, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 20809 (epoch 34), train_loss = 2.463, time/batch = 0.028
Read data: 8.225440979003906e-05
iter 20810 (epoch 34), train_loss = 2.200, time/batch = 0.024
Read data: 8.0108642578125e-05
iter 20811 (epoch 34), train_loss = 2.377, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 20812 (epoch 34), train_loss = 2.643, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 20813 (epoch 34), train_loss = 2.249, time/batch = 0.022
Read data: 8.559226989746094e-05
iter 20814 (epoch 34), train_loss = 2.414, time/batch = 0.030
Read data: 8.320808410644531e-05
iter 20815 (epoch 34), train_loss = 2.363, time/batch = 0.025
Read data: 7.700920104980469e-05
iter 20816 (epoch 34), train_loss = 2.444, time/batch = 0.025
Read data: 9.918212890625e-05
iter 20817 (epoch 34), train_loss = 2.017, time/batch = 0.023
Read data: 9.632110595703125e-05
iter 20818 (epoch 34), train_loss = 2.812, time/batch = 0.030
Read data: 7.891654968261719e-05
iter 20819 (epoch 34), train_loss = 2.300, time/batch = 0.023
Read data: 9.608268737792969e-05
iter 20820 (epoch 34), train_loss = 2.168, time/batch = 0.022
Read data: 8.7738037109375e-05
iter 20821 (epoch 34), train_loss = 2.520, time/batch = 0.027
Read data: 7.867813110351562e-05
iter 20822 (epoch 34), train_loss = 2.160, time/batch = 0.022
Read data: 9.942054748535156e-05
iter 20823 (epoch 34), train_loss = 2.100, time/batch = 0.023
Read data: 9.441375732421875e-05
iter 20824 (epoch 34), train_loss = 2.599, time/batch = 0.023
Read data: 0.00023627281188964844
iter 20825 (epoch 34), train_loss = 2.719, time/batch = 0.025
Read data: 8.726119995117188e-05
iter 20826 (epoch 34), train_loss = 2.199, time/batch = 0.022
Read data: 8.487701416015625e-05
iter 20827 (epoch 34), train_loss = 2.091, time/batch = 0.025
Read data: 0.00013709068298339844
iter 20828 (epoch 34), train_loss = 2.510, time/batch = 0.028
Read data: 9.870529174804688e-05
iter 20829 (epoch 34), train_loss = 1.879, time/batch = 0.023
Read data: 9.131431579589844e-05
iter 20830 (epoch 34), train_loss = 2.487, time/batch = 0.023
Read data: 8.106231689453125e-05
iter 20831 (epoch 34), train_loss = 2.702, time/batch = 0.028
Read data: 0.00010251998901367188
iter 20832 (epoch 34), train_loss = 2.316, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 20833 (epoch 34), train_loss = 2.292, time/batch = 0.025
Read data: 9.083747863769531e-05
iter 20834 (epoch 34), train_loss = 2.392, time/batch = 0.026
Read data: 8.726119995117188e-05
iter 20835 (epoch 34), train_loss = 2.136, time/batch = 0.030
Read data: 7.653236389160156e-05
iter 20836 (epoch 34), train_loss = 2.505, time/batch = 0.029
Read data: 8.678436279296875e-05
iter 20837 (epoch 34), train_loss = 2.139, time/batch = 0.025
Read data: 0.000125885009765625
iter 20838 (epoch 34), train_loss = 2.480, time/batch = 0.021
Read data: 0.0001289844512939453
iter 20839 (epoch 34), train_loss = 2.229, time/batch = 0.025
Read data: 9.202957153320312e-05
iter 20840 (epoch 34), train_loss = 2.443, time/batch = 0.026
Read data: 9.918212890625e-05
iter 20841 (epoch 34), train_loss = 2.414, time/batch = 0.023
Read data: 9.560585021972656e-05
iter 20842 (epoch 34), train_loss = 2.738, time/batch = 0.025
Read data: 8.511543273925781e-05
iter 20843 (epoch 34), train_loss = 2.427, time/batch = 0.027
Read data: 8.416175842285156e-05
iter 20844 (epoch 34), train_loss = 2.421, time/batch = 0.030
Read data: 9.202957153320312e-05
iter 20845 (epoch 34), train_loss = 2.122, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 20846 (epoch 34), train_loss = 2.500, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 20847 (epoch 34), train_loss = 2.258, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 20848 (epoch 34), train_loss = 2.333, time/batch = 0.029
Read data: 8.177757263183594e-05
iter 20849 (epoch 34), train_loss = 2.346, time/batch = 0.027
Read data: 0.00021266937255859375
iter 20850 (epoch 34), train_loss = 2.220, time/batch = 0.027
Read data: 7.987022399902344e-05
iter 20851 (epoch 34), train_loss = 2.434, time/batch = 0.024
Read data: 7.700920104980469e-05
iter 20852 (epoch 34), train_loss = 2.050, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 20853 (epoch 34), train_loss = 2.475, time/batch = 0.022
Read data: 8.797645568847656e-05
iter 20854 (epoch 34), train_loss = 2.317, time/batch = 0.029
Read data: 0.00010037422180175781
iter 20855 (epoch 34), train_loss = 2.200, time/batch = 0.021
Read data: 9.012222290039062e-05
iter 20856 (epoch 34), train_loss = 2.283, time/batch = 0.036
Read data: 7.963180541992188e-05
iter 20857 (epoch 34), train_loss = 2.303, time/batch = 0.027
Read data: 0.00012922286987304688
iter 20858 (epoch 34), train_loss = 2.355, time/batch = 0.026
Read data: 8.153915405273438e-05
iter 20859 (epoch 34), train_loss = 2.142, time/batch = 0.032
Read data: 8.416175842285156e-05
iter 20860 (epoch 34), train_loss = 1.946, time/batch = 0.025
Read data: 7.987022399902344e-05
iter 20861 (epoch 34), train_loss = 2.260, time/batch = 0.025
Read data: 8.273124694824219e-05
iter 20862 (epoch 34), train_loss = 2.322, time/batch = 0.031
Read data: 8.344650268554688e-05
iter 20863 (epoch 34), train_loss = 1.975, time/batch = 0.022
Read data: 9.822845458984375e-05
iter 20864 (epoch 34), train_loss = 2.456, time/batch = 0.021
Read data: 9.131431579589844e-05
iter 20865 (epoch 34), train_loss = 2.290, time/batch = 0.032
Read data: 0.00012969970703125
iter 20866 (epoch 34), train_loss = 2.640, time/batch = 0.030
Read data: 7.748603820800781e-05
iter 20867 (epoch 34), train_loss = 2.132, time/batch = 0.029
Read data: 8.726119995117188e-05
iter 20868 (epoch 34), train_loss = 2.442, time/batch = 0.023
Read data: 7.867813110351562e-05
iter 20869 (epoch 34), train_loss = 2.398, time/batch = 0.024
Read data: 8.034706115722656e-05
iter 20870 (epoch 34), train_loss = 2.148, time/batch = 0.021
Read data: 0.00017786026000976562
iter 20871 (epoch 34), train_loss = 2.396, time/batch = 0.024
Read data: 0.00016164779663085938
iter 20872 (epoch 34), train_loss = 2.125, time/batch = 0.022
Read data: 0.0001609325408935547
iter 20873 (epoch 34), train_loss = 2.240, time/batch = 0.029
Read data: 9.083747863769531e-05
iter 20874 (epoch 34), train_loss = 2.186, time/batch = 0.029
Read data: 0.0002155303955078125
iter 20875 (epoch 34), train_loss = 2.688, time/batch = 0.022
Read data: 0.00013303756713867188
iter 20876 (epoch 34), train_loss = 2.688, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 20877 (epoch 34), train_loss = 2.222, time/batch = 0.026
Read data: 9.489059448242188e-05
iter 20878 (epoch 34), train_loss = 2.384, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 20879 (epoch 34), train_loss = 2.417, time/batch = 0.030
Read data: 8.463859558105469e-05
iter 20880 (epoch 34), train_loss = 2.169, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 20881 (epoch 34), train_loss = 2.074, time/batch = 0.021
Read data: 9.632110595703125e-05
iter 20882 (epoch 34), train_loss = 2.307, time/batch = 0.023
Read data: 9.799003601074219e-05
iter 20883 (epoch 34), train_loss = 2.397, time/batch = 0.023
Read data: 0.00013399124145507812
iter 20884 (epoch 34), train_loss = 2.457, time/batch = 0.035
Read data: 9.775161743164062e-05
iter 20885 (epoch 34), train_loss = 2.509, time/batch = 0.027
Read data: 0.0001323223114013672
iter 20886 (epoch 34), train_loss = 2.096, time/batch = 0.021
Read data: 9.584426879882812e-05
iter 20887 (epoch 34), train_loss = 2.587, time/batch = 0.024
Read data: 9.72747802734375e-05
iter 20888 (epoch 34), train_loss = 2.293, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 20889 (epoch 34), train_loss = 2.246, time/batch = 0.025
Read data: 9.012222290039062e-05
iter 20890 (epoch 34), train_loss = 2.324, time/batch = 0.026
Read data: 9.655952453613281e-05
iter 20891 (epoch 34), train_loss = 2.556, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 20892 (epoch 34), train_loss = 2.397, time/batch = 0.025
Read data: 0.00010156631469726562
iter 20893 (epoch 34), train_loss = 2.604, time/batch = 0.024
Read data: 8.916854858398438e-05
iter 20894 (epoch 34), train_loss = 2.338, time/batch = 0.026
Read data: 9.369850158691406e-05
iter 20895 (epoch 34), train_loss = 2.264, time/batch = 0.025
Read data: 8.749961853027344e-05
iter 20896 (epoch 34), train_loss = 2.246, time/batch = 0.028
Read data: 9.369850158691406e-05
iter 20897 (epoch 34), train_loss = 2.285, time/batch = 0.024
Read data: 0.00010061264038085938
iter 20898 (epoch 34), train_loss = 2.453, time/batch = 0.027
Read data: 8.845329284667969e-05
iter 20899 (epoch 34), train_loss = 2.650, time/batch = 0.023
Read data: 0.0002155303955078125
iter 20900 (epoch 34), train_loss = 2.616, time/batch = 0.033
Read data: 8.177757263183594e-05
iter 20901 (epoch 34), train_loss = 2.310, time/batch = 0.028
Read data: 0.00013208389282226562
iter 20902 (epoch 34), train_loss = 2.629, time/batch = 0.027
Read data: 8.606910705566406e-05
iter 20903 (epoch 34), train_loss = 2.227, time/batch = 0.025
Read data: 7.677078247070312e-05
iter 20904 (epoch 34), train_loss = 2.345, time/batch = 0.024
Read data: 7.963180541992188e-05
iter 20905 (epoch 34), train_loss = 2.497, time/batch = 0.023
Read data: 8.916854858398438e-05
iter 20906 (epoch 34), train_loss = 2.039, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 20907 (epoch 34), train_loss = 2.570, time/batch = 0.023
Read data: 0.00013589859008789062
iter 20908 (epoch 34), train_loss = 2.373, time/batch = 0.029
Read data: 8.821487426757812e-05
iter 20909 (epoch 34), train_loss = 1.953, time/batch = 0.027
Read data: 9.059906005859375e-05
iter 20910 (epoch 34), train_loss = 2.513, time/batch = 0.039
Read data: 8.058547973632812e-05
iter 20911 (epoch 34), train_loss = 2.332, time/batch = 0.039
Read data: 9.131431579589844e-05
iter 20912 (epoch 34), train_loss = 2.358, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 20913 (epoch 34), train_loss = 2.246, time/batch = 0.029
Read data: 9.799003601074219e-05
iter 20914 (epoch 34), train_loss = 2.412, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 20915 (epoch 34), train_loss = 2.210, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 20916 (epoch 34), train_loss = 2.071, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 20917 (epoch 34), train_loss = 2.350, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 20918 (epoch 34), train_loss = 2.324, time/batch = 0.028
Read data: 8.344650268554688e-05
iter 20919 (epoch 34), train_loss = 2.406, time/batch = 0.023
Read data: 0.00010371208190917969
iter 20920 (epoch 34), train_loss = 2.369, time/batch = 0.030
Read data: 7.867813110351562e-05
iter 20921 (epoch 34), train_loss = 2.058, time/batch = 0.026
Read data: 8.082389831542969e-05
iter 20922 (epoch 34), train_loss = 2.481, time/batch = 0.024
Read data: 8.416175842285156e-05
iter 20923 (epoch 34), train_loss = 2.700, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 20924 (epoch 34), train_loss = 2.369, time/batch = 0.026
Read data: 0.00022482872009277344
iter 20925 (epoch 34), train_loss = 2.587, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 20926 (epoch 34), train_loss = 2.234, time/batch = 0.025
Read data: 0.00010061264038085938
iter 20927 (epoch 34), train_loss = 2.122, time/batch = 0.023
Read data: 9.202957153320312e-05
iter 20928 (epoch 34), train_loss = 2.817, time/batch = 0.025
Read data: 9.894371032714844e-05
iter 20929 (epoch 34), train_loss = 2.651, time/batch = 0.028
Read data: 9.5367431640625e-05
iter 20930 (epoch 34), train_loss = 1.840, time/batch = 0.024
Read data: 9.679794311523438e-05
iter 20931 (epoch 34), train_loss = 2.132, time/batch = 0.025
Read data: 9.775161743164062e-05
iter 20932 (epoch 34), train_loss = 2.260, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 20933 (epoch 34), train_loss = 2.369, time/batch = 0.030
Read data: 8.96453857421875e-05
iter 20934 (epoch 34), train_loss = 2.665, time/batch = 0.028
Read data: 9.393692016601562e-05
iter 20935 (epoch 34), train_loss = 2.088, time/batch = 0.027
Read data: 8.058547973632812e-05
iter 20936 (epoch 34), train_loss = 2.288, time/batch = 0.021
Read data: 7.915496826171875e-05
iter 20937 (epoch 34), train_loss = 2.628, time/batch = 0.027
Read data: 0.0001342296600341797
iter 20938 (epoch 34), train_loss = 1.969, time/batch = 0.036
Read data: 0.00012421607971191406
iter 20939 (epoch 34), train_loss = 2.638, time/batch = 0.035
Read data: 8.988380432128906e-05
iter 20940 (epoch 34), train_loss = 2.192, time/batch = 0.025
Read data: 0.00011944770812988281
iter 20941 (epoch 34), train_loss = 2.566, time/batch = 0.028
Read data: 0.00014448165893554688
iter 20942 (epoch 34), train_loss = 2.310, time/batch = 0.026
Read data: 8.296966552734375e-05
iter 20943 (epoch 34), train_loss = 2.069, time/batch = 0.022
Read data: 0.00011181831359863281
iter 20944 (epoch 34), train_loss = 1.994, time/batch = 0.024
Read data: 8.96453857421875e-05
iter 20945 (epoch 34), train_loss = 2.646, time/batch = 0.028
Read data: 9.107589721679688e-05
iter 20946 (epoch 34), train_loss = 2.581, time/batch = 0.037
Read data: 8.511543273925781e-05
iter 20947 (epoch 34), train_loss = 1.803, time/batch = 0.022
Read data: 8.106231689453125e-05
iter 20948 (epoch 34), train_loss = 2.909, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 20949 (epoch 34), train_loss = 2.294, time/batch = 0.024
Read data: 0.00021767616271972656
iter 20950 (epoch 34), train_loss = 2.252, time/batch = 0.023
Read data: 8.7738037109375e-05
iter 20951 (epoch 34), train_loss = 2.329, time/batch = 0.027
Read data: 7.62939453125e-05
iter 20952 (epoch 34), train_loss = 2.102, time/batch = 0.024
Read data: 9.012222290039062e-05
iter 20953 (epoch 34), train_loss = 2.406, time/batch = 0.026
Read data: 9.608268737792969e-05
iter 20954 (epoch 34), train_loss = 2.087, time/batch = 0.024
Read data: 0.0001342296600341797
iter 20955 (epoch 34), train_loss = 2.426, time/batch = 0.029
Read data: 9.655952453613281e-05
iter 20956 (epoch 34), train_loss = 2.486, time/batch = 0.024
Read data: 8.893013000488281e-05
iter 20957 (epoch 34), train_loss = 2.631, time/batch = 0.025
Read data: 0.00010251998901367188
iter 20958 (epoch 34), train_loss = 2.102, time/batch = 0.023
Read data: 9.34600830078125e-05
iter 20959 (epoch 34), train_loss = 2.286, time/batch = 0.029
Read data: 9.131431579589844e-05
iter 20960 (epoch 34), train_loss = 2.354, time/batch = 0.029
Read data: 9.5367431640625e-05
iter 20961 (epoch 34), train_loss = 2.319, time/batch = 0.028
Read data: 0.000133514404296875
iter 20962 (epoch 34), train_loss = 2.069, time/batch = 0.025
Read data: 7.915496826171875e-05
iter 20963 (epoch 34), train_loss = 2.254, time/batch = 0.028
Read data: 8.916854858398438e-05
iter 20964 (epoch 34), train_loss = 2.227, time/batch = 0.025
Read data: 7.772445678710938e-05
iter 20965 (epoch 34), train_loss = 2.156, time/batch = 0.029
Read data: 0.00010085105895996094
iter 20966 (epoch 34), train_loss = 2.225, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 20967 (epoch 34), train_loss = 2.066, time/batch = 0.024
Read data: 8.082389831542969e-05
iter 20968 (epoch 34), train_loss = 2.310, time/batch = 0.021
Read data: 8.749961853027344e-05
iter 20969 (epoch 34), train_loss = 2.238, time/batch = 0.027
Read data: 8.749961853027344e-05
iter 20970 (epoch 34), train_loss = 2.415, time/batch = 0.023
Read data: 9.465217590332031e-05
iter 20971 (epoch 34), train_loss = 2.490, time/batch = 0.031
Read data: 0.0001404285430908203
iter 20972 (epoch 34), train_loss = 2.454, time/batch = 0.032
Read data: 7.963180541992188e-05
iter 20973 (epoch 34), train_loss = 2.354, time/batch = 0.021
Read data: 8.0108642578125e-05
iter 20974 (epoch 34), train_loss = 2.190, time/batch = 0.025
Read data: 0.0002455711364746094
iter 20975 (epoch 34), train_loss = 2.335, time/batch = 0.029
Read data: 7.843971252441406e-05
iter 20976 (epoch 34), train_loss = 2.158, time/batch = 0.022
Read data: 8.988380432128906e-05
iter 20977 (epoch 34), train_loss = 1.989, time/batch = 0.037
Read data: 0.000232696533203125
iter 20978 (epoch 34), train_loss = 2.204, time/batch = 0.029
Read data: 8.654594421386719e-05
iter 20979 (epoch 34), train_loss = 2.393, time/batch = 0.031
Read data: 0.00010085105895996094
iter 20980 (epoch 34), train_loss = 1.979, time/batch = 0.027
Read data: 8.630752563476562e-05
iter 20981 (epoch 34), train_loss = 2.368, time/batch = 0.021
Read data: 0.0001690387725830078
iter 20982 (epoch 34), train_loss = 2.226, time/batch = 0.023
Read data: 8.988380432128906e-05
iter 20983 (epoch 34), train_loss = 2.477, time/batch = 0.025
Read data: 8.988380432128906e-05
iter 20984 (epoch 34), train_loss = 2.767, time/batch = 0.028
Read data: 9.131431579589844e-05
iter 20985 (epoch 34), train_loss = 2.435, time/batch = 0.032
Read data: 8.273124694824219e-05
iter 20986 (epoch 34), train_loss = 2.024, time/batch = 0.021
Read data: 7.891654968261719e-05
iter 20987 (epoch 34), train_loss = 2.504, time/batch = 0.025
Read data: 0.00011157989501953125
iter 20988 (epoch 34), train_loss = 2.327, time/batch = 0.028
Read data: 7.915496826171875e-05
iter 20989 (epoch 34), train_loss = 2.378, time/batch = 0.034
Read data: 7.82012939453125e-05
iter 20990 (epoch 34), train_loss = 1.708, time/batch = 0.027
Read data: 7.891654968261719e-05
iter 20991 (epoch 34), train_loss = 2.511, time/batch = 0.030
Read data: 0.0011730194091796875
iter 20992 (epoch 34), train_loss = 2.511, time/batch = 0.029
Read data: 8.440017700195312e-05
iter 20993 (epoch 34), train_loss = 2.339, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 20994 (epoch 34), train_loss = 2.543, time/batch = 0.028
Read data: 7.748603820800781e-05
iter 20995 (epoch 34), train_loss = 2.037, time/batch = 0.027
Read data: 8.153915405273438e-05
iter 20996 (epoch 34), train_loss = 2.446, time/batch = 0.022
Read data: 7.534027099609375e-05
iter 20997 (epoch 34), train_loss = 2.209, time/batch = 0.020
Read data: 9.131431579589844e-05
iter 20998 (epoch 34), train_loss = 2.820, time/batch = 0.034
Read data: 8.130073547363281e-05
iter 20999 (epoch 34), train_loss = 2.364, time/batch = 0.025
image 976:     
image 5399:     
image 6910:    
image 660:    
image 6372:    
image 616:    
image 2678:      
image 2375:    
image 2494:    
image 6381:    
evaluating validation preformance... 10/1000 (2.596883)
image 2798:     
image 5884:     
image 2067:   
image 3600:     
image 3617:     
image 1697:    
image 6767:    
image 6023:     
image 6550:     
image 6718:     
evaluating validation preformance... 20/1000 (2.178362)
image 6903:    
image 3301:  UNK  
image 2019:    
image 5535:     
image 7680:      
image 5527:      
image 2568:     
image 160:      
image 8085:     
image 7670:      
evaluating validation preformance... 30/1000 (2.496695)
image 4604:    
image 5745:    
image 5288:   
image 1562:     
image 7807:    
image 3572:    
image 6763:     
image 4318:    
image 1744:    
image 1684:     
evaluating validation preformance... 40/1000 (3.109685)
image 2938:    UNK
image 5183:     
image 2380:    
image 6973:    
image 5629:    
image 7130:     
image 1679:    
image 7194:     
image 2022:      
image 2850:     
evaluating validation preformance... 50/1000 (2.525662)
image 4940:      
image 4905:      
image 469:     
image 102:    
image 6009:    UNK
image 4271:   
image 6329:    UNK
image 1729:    
image 4444:     
image 6070:     
evaluating validation preformance... 60/1000 (2.841511)
image 4389:     
image 4281:     
image 4504:     
image 6146:     
image 5767:     
image 3160:     
image 7146:    
image 4433:    
image 2973:  
image 5641:   
evaluating validation preformance... 70/1000 (2.598922)
image 3258:     
image 6895:      
image 5296:     
image 4623:      
image 2588:     
image 4656:     
image 663:    
image 2322:    
image 2260:    
image 2242:     
evaluating validation preformance... 80/1000 (2.557408)
image 3276:      
image 3812:    
image 1400:    
image 3443:     
image 5027:     
image 7251:     
image 7305:   
image 1480:      
image 4806:      
image 766:      
evaluating validation preformance... 90/1000 (2.078968)
image 6124:     
image 5415:     
image 369:    
image 5747:    
image 1003:     
image 6612:     
image 7701:     
image 7379:     
image 1165:    
image 6553:     
evaluating validation preformance... 100/1000 (2.902918)
image 2800:     
image 7249:     
image 3211:    
image 686:    
image 3986:     
image 2518:     
image 7399:      
image 1832:     
image 3666:    
image 150:      
evaluating validation preformance... 110/1000 (2.773377)
image 1122:    
image 509:     
image 4091:    
image 5761:     
image 16:     
image 231:    
image 6505:    
image 1450:    
image 3979:      
image 5302:     
evaluating validation preformance... 120/1000 (2.359717)
image 3477:     
image 1212:      
image 3809:    UNK
image 4329:    
image 3500:     
image 4913:      
image 4589:    
image 5863:     
image 1642:     
image 6166:    
evaluating validation preformance... 130/1000 (2.875492)
image 6214:     
image 429:    
image 7743:    
image 3657:    
image 4535:     
image 5542:     
image 8068:     
image 4450:    
image 1524:     
image 2867:    
evaluating validation preformance... 140/1000 (2.663517)
image 1738:     
image 1455:     
image 4198:     
image 2180:    
image 4436:    
image 197:     
image 519:     
image 8070:     
image 4287:    
image 1266:    
evaluating validation preformance... 150/1000 (2.895020)
image 1865:     
image 3830:    
image 360:     
image 5097:     
image 4455:     
image 1153:    
image 1248:     
image 7688:    
image 820:    
image 7993:      
evaluating validation preformance... 160/1000 (2.832429)
image 4297:    
image 3315:     
image 1107:    
image 2051:    
image 4713:    
image 8036:    
image 5662:     
image 2095:     
image 3679:     
image 3426:    
evaluating validation preformance... 170/1000 (2.543010)
image 7922:     
image 2353:    
image 4580:    
image 5905:    
image 6488:    
image 3000:    
image 1806:      
image 7761:    
image 3014:    
image 3687:    
evaluating validation preformance... 180/1000 (2.726906)
image 2313:    
image 6289:    
image 8084:      
image 2696:    
image 5830:     
image 6240:     
image 4541:     
image 2813:      
image 2145:     
image 6106:     
evaluating validation preformance... 190/1000 (2.347393)
image 5372:     
image 7529:  UNK  
image 875:    
image 2107:      
image 8015:   
image 6565:     
image 6174:      
image 6894:     
image 4164:     
image 7049:    
evaluating validation preformance... 200/1000 (2.296024)
image 5159:     
image 1199:    
image 2456:    
image 3402:    
image 7631:     
image 3562:    
image 405:   
image 2532:    
image 2844:      
image 4023:     
evaluating validation preformance... 210/1000 (2.451924)
image 2599:     
image 822:     
image 3926:     
image 6942:     
image 1942: UNK  
image 618:    
image 1725:     
image 1089:      
image 864:    
image 7345:     
evaluating validation preformance... 220/1000 (2.531462)
image 4024:    
image 1894:     
image 7297:      
image 1796:    
image 7075:    
image 2258:    
image 5122:    
image 5586:   
image 4483:    
image 6582:     
evaluating validation preformance... 230/1000 (2.261254)
image 1917:     
image 5844:      
image 1661:     
image 1510:    
image 4630:    
image 6741:     
image 1020:    
image 5967:    
image 8014:    
image 5594:      
evaluating validation preformance... 240/1000 (2.093445)
image 7143:    
image 6019:     
image 885:    
image 2802:    
image 2214:    
image 4704:     
image 890:     
image 778:    
image 1724:   
image 528:    
evaluating validation preformance... 250/1000 (2.502793)
image 3028:    
image 3141:    
image 7137:    
image 3444:     UNK
image 2049:    
image 550:     
image 3367:     
image 4907:     
image 6173:     
image 3082:     
evaluating validation preformance... 260/1000 (2.492097)
image 492:    
image 5429:     
image 6968:      
image 2672:     
image 6920:     
image 6211:    
image 3326:    
image 1870:    
image 4511:     
image 7380:      
evaluating validation preformance... 270/1000 (3.036376)
image 833:    
image 5483:    
image 2476:     
image 5930:     
image 59:    
image 5007:    
image 2884:    UNK
image 486:     
image 7629:      
image 2054:      
evaluating validation preformance... 280/1000 (2.506436)
image 2481:    
image 1860:    
image 1464:     
image 4488:    
image 7299:     
image 5006:     
image 7828:     
image 7372:    
image 2058:      
image 2130:     
evaluating validation preformance... 290/1000 (2.337437)
image 6835:     
image 4698:      
image 7212:    
image 5933:     
image 2431:    
image 7277:      
image 2088:      
image 3340:     
image 3579:    
image 6928:     
evaluating validation preformance... 300/1000 (2.168842)
image 2805:    
image 4374:     
image 25:     
image 7702:    
image 256:     
image 7362:     
image 2148:     
image 1974:    
image 6050:     
image 6156:     
evaluating validation preformance... 310/1000 (2.674736)
image 3553:    
image 5971:     
image 122:    
image 3212:    
image 7223:     
image 7007:     
image 6064:    UNK
image 7358:      
image 5096:      
image 6423:    
evaluating validation preformance... 320/1000 (2.276194)
image 489:      
image 5316:     
image 2613:      
image 7935:     
image 7768:     
image 7894:      
image 6267:    
image 2203:     
image 5727:     
image 1159:      
evaluating validation preformance... 330/1000 (2.768676)
image 5179:    
image 3754:      
image 2911:     
image 6979:     
image 5449:     
image 2198:     
image 2535:      
image 2601:    
image 4524:     
image 3972:     
evaluating validation preformance... 340/1000 (2.401017)
image 4542:      
image 1878:      
image 5329:       
image 4139:    
image 6018:    
image 1206:      
image 5385:    
image 2794:      
image 7785:    
image 2085:    
evaluating validation preformance... 350/1000 (2.445399)
image 6881:    
image 942:    
image 2775:   
image 3311:     
image 4587:     
image 1215:    
image 5241:    
image 6606:    
image 2387:     
image 3342:    
evaluating validation preformance... 360/1000 (2.014597)
image 2905:     
image 7814:      
image 56:    
image 5034:     
image 7946:      
image 3470:      
image 4655:     
image 818:    
image 6607:    
image 4866:     
evaluating validation preformance... 370/1000 (2.619259)
image 4351:      
image 1054:     
image 129:     
image 2849:     
image 725:   UNK
image 2573:     
image 6766:     
image 5754:    
image 1955:     
image 7569:     
evaluating validation preformance... 380/1000 (2.640712)
image 2458:     
image 1084:    
image 4835:    
image 867:    
image 723:     
image 6255:    
image 5255:    
image 3598:    
image 2997:    
image 60:    
evaluating validation preformance... 390/1000 (2.831578)
image 828:     
image 2733:    
image 791:    
image 5408:  UNK  
image 7842:    
image 1117:    
image 5817:     
image 1231:    
image 1630:    
image 6886:     
evaluating validation preformance... 400/1000 (2.240820)
image 2627:    UNK
image 7172:    
image 1991:    
image 7413:    
image 2105:     
image 3919:     
image 7980:    
image 670:    
image 2325:    
image 7546:      
evaluating validation preformance... 410/1000 (2.089252)
image 4359:     
image 2372:     
image 4472:      
image 6810:    
image 1592:     
image 7864:     
image 4286:    
image 6688:    
image 5697:    
image 7020:     
evaluating validation preformance... 420/1000 (2.344353)
image 30:      
image 5540:     
image 2445:    
image 5896:      
image 7607:     
image 1426:    
image 6977:     
image 877:   
image 2408:    UNK
image 7706:     
evaluating validation preformance... 430/1000 (2.780290)
image 385:    
image 6938:      
image 2381:    
image 5796:    
image 4010:    
image 3452:     
image 2023:     
image 3052:    
image 6215:    
image 4092:    
evaluating validation preformance... 440/1000 (2.895634)
image 1731:       
image 978:      
image 6033:     
image 5080:    
image 7804:    
image 439:      
image 4790:     
image 5855:     
image 4245:      
image 973:   
evaluating validation preformance... 450/1000 (2.111238)
image 2241:     
image 2651:     
image 2315:     
image 4784:     
image 5160:      
image 2466:     
image 975:     
image 3818:    
image 6995:     
image 3682:    
evaluating validation preformance... 460/1000 (2.614069)
image 7979:     
image 1618:    UNK
image 7608:    
image 6393:     
image 5100:    
image 4480:     
image 1440:    
image 5886:    
image 5995:     
image 1900:    
evaluating validation preformance... 470/1000 (3.258098)
image 4503:    
image 7112:     
image 3480:     
image 7533:    
image 5050:    
image 6862:     
image 7450:     
image 841:     
image 1118:    
image 6114:      
evaluating validation preformance... 480/1000 (2.896839)
image 358:      
image 4663:    
image 5541:     
image 4485:    
image 2727:    
image 1040:    
image 3823:     
image 1595:  UNK  
image 4757:     
image 205:    
evaluating validation preformance... 490/1000 (3.393022)
image 2044:    
image 4349:    
image 3855:     
image 1846:    
image 3724:     
image 606:      
image 6577:      
image 6820:     
image 1485:     
image 5744:    
evaluating validation preformance... 500/1000 (2.457011)
image 1797:    
image 4670:    
image 4846:    
image 5907:     
image 3321:      
image 1700:     
image 438:      
image 5980:    
image 408:     
image 5403:     
evaluating validation preformance... 510/1000 (2.930010)
image 3246:     
image 4424:     
image 41:     
image 459:     
image 1072:      
image 5650:     
image 2597:    UNK
image 5416:    
image 2744:     
image 5979:    
evaluating validation preformance... 520/1000 (2.594898)
image 6806:     UNK
image 6464:    
image 1872:     
image 1575:    
image 3045:      
image 303:   
image 5552:      
image 4628:    UNK
image 1314:    
image 6335:    
evaluating validation preformance... 530/1000 (2.459138)
image 5619:     
image 4391:  
image 891:     
image 3072:    
image 7781:     
image 6163:      
image 7376:    
image 6034:     
image 6062:    
image 3170:     
evaluating validation preformance... 540/1000 (2.461797)
image 5292:    
image 2901:    
image 3568:    
image 690:     
image 3345:    
image 6234:    
image 5074:    
image 4696:    
image 1183:      
image 1961:    
evaluating validation preformance... 550/1000 (2.552126)
image 5439:     
image 7981:    
image 6012:     
image 4732:     
image 6630:    
image 994:      
image 5079:     
image 6169:    
image 4340:    
image 2134:    
evaluating validation preformance... 560/1000 (2.522203)
image 6056:    
image 6419:    
image 275:     
image 7441:     
image 7893:    
image 3623:    
image 7232:     
image 4778:    
image 1007:     
image 3387:     
evaluating validation preformance... 570/1000 (2.573990)
image 7936:     
image 5433:    UNK
image 5691:      
image 1628:    
image 4501:    
image 1247:    
image 315:    
image 317:     
image 329:     
image 3267:    
evaluating validation preformance... 580/1000 (2.625262)
image 2135:    
image 3865:     
image 7837:    
image 1172:      
image 4651:     
image 73:     
image 1500:     
image 5094:    
image 5778:    
image 6422:    
evaluating validation preformance... 590/1000 (2.545631)
image 4420:    
image 1734:      
image 7239:     
image 7447:     
image 8009:    
image 4510:    UNK
image 7495:    
image 2530:     
image 4597:      
image 3381:     
evaluating validation preformance... 600/1000 (2.431136)
image 353:     
image 1095:     
image 3583:      
image 3264:    UNK
image 5668:     
image 7189:     
image 6573:     
image 3253:   
image 1773:     
image 4823:    
evaluating validation preformance... 610/1000 (2.637826)
image 69:    
image 3465:    
image 6179:    
image 552:     
image 511:    
image 761:    
image 5742:    
image 359:     
image 4170:    
image 7915:    
evaluating validation preformance... 620/1000 (2.364335)
image 6575:      
image 5695:    
image 7418:     
image 1948:    
image 4012:     
image 6981:     
image 989:    
image 2847:     
image 4456:     
image 2351:    
evaluating validation preformance... 630/1000 (2.491754)
image 8074:    
image 1904:     
image 7917:     
image 2394:     
image 4406:    
image 883:      
image 559:     
image 1120:    
image 5124:    
image 4680:     
evaluating validation preformance... 640/1000 (2.451342)
image 5313:      
image 2377:     
image 6058:    
image 4661:    
image 2955:   
image 3333:    
image 7124:     
image 4278:      
image 953:     
image 4037:    
evaluating validation preformance... 650/1000 (2.536704)
image 8065:    
image 3577:    
image 3254:     
image 4562:    
image 5462:     
image 2824:    
image 1639:    
image 1475:    
image 3991:    
image 1023:    
evaluating validation preformance... 660/1000 (2.654861)
image 5701:    
image 1709:     
image 4811:      
image 622:    
image 5997:     
image 1608:    
image 4119:      
image 1619:      
image 5652:     
image 1972:   
evaluating validation preformance... 670/1000 (2.759093)
image 7877:    
image 6761:     
image 6880:    
image 4914:    UNK
image 4522:     
image 2311:     
image 7587:     
image 4848:     
image 6722:  UNK  
image 7784:    
evaluating validation preformance... 680/1000 (2.997422)
image 1445:     
image 6841:     
image 2896:     
image 6947:   
image 4782:    
image 7669:     
image 4382:    UNK
image 1257:    
image 6405:    
image 6504:    
evaluating validation preformance... 690/1000 (2.810988)
image 6860:     
image 576:     
image 6580:      
image 1497:     
image 3360:     
image 4939:    
image 6225:    
image 3669:     
image 980:    
image 5362:    
evaluating validation preformance... 700/1000 (2.999224)
image 5343:      
image 68:    
image 3184:    
image 5637:      
image 2041:     
image 650:     
image 4911:    
image 34:    UNK UNK
image 7801:    
image 1129:    
evaluating validation preformance... 710/1000 (2.445195)
image 7368:    
image 709:     
image 3197:    
image 5214:    
image 445:      
image 3428:     
image 268:     
image 2328:    
image 4627:    
image 1586:      
evaluating validation preformance... 720/1000 (2.591790)
image 5729:     
image 6395:     
image 516:      
image 1026:    
image 2972:      
image 3005:    
image 1241:      
image 2743:      
image 3665:     
image 1290:    
evaluating validation preformance... 730/1000 (2.270199)
image 2527:     
image 6266:     
image 4161:    
image 1139:    
image 3781:     
image 6081:      
image 997:    
image 5092:      
image 7789:      
image 2504:      
evaluating validation preformance... 740/1000 (2.362875)
image 2239:     
image 120:     
image 4902:      
image 3796:  UNK  
image 3355:     
image 1787:    
image 5365:    
image 2674:      
image 4735:     
image 6197:     
evaluating validation preformance... 750/1000 (2.604981)
image 3279:    
image 6380:    
image 2663:     
image 3815:    
image 512:     
image 5899:     
image 6078:    
image 4808:    
image 3780:     
image 7174:    
evaluating validation preformance... 760/1000 (2.972790)
image 4582:    
image 5484:    
image 3049:    
image 4641:      
image 8028:    
image 4739:    
image 2452:    
image 5400:     
image 1357:     
image 3449:     
evaluating validation preformance... 770/1000 (2.087524)
image 6220:    
image 6238:      
image 4534:    
image 2732:     
image 7003:    
image 1739:     
image 5503:     
image 2329:    
image 1201:     
image 5956:     
evaluating validation preformance... 780/1000 (2.841994)
image 6867:    
image 5525:     
image 4746:    
image 5531:     
image 5425:    
image 6978:    
image 3450:     
image 3312:    
image 7824:     
image 2032:     
evaluating validation preformance... 790/1000 (3.074635)
image 5047:      
image 325:       
image 7626:    
image 4552:     
image 983:    
image 8052:      
image 1585:      
image 4336:    
image 1728:     
image 6725:     
evaluating validation preformance... 800/1000 (2.220087)
image 7288:      
image 7302:      
image 3055:     
image 5250:     
image 1158:    
image 290:     
image 159:     
image 4345:    
image 2217:    
image 3169:     
evaluating validation preformance... 810/1000 (2.408703)
image 614:    
image 7295:    
image 4110:    
image 5402:    
image 3060: UNK  
image 1317:     
image 3339:    
image 1052:     
image 3701:    
image 4194:    
evaluating validation preformance... 820/1000 (1.929949)
image 7204:      
image 4428:      
image 7825:      
image 5890:      
image 4334:    
image 5514:     
image 7147:    
image 6348:      
image 580:     UNK
image 2531:    
evaluating validation preformance... 830/1000 (2.371438)
image 5107:    
image 3973:  UNK   
image 4233:     
image 3593:      
image 5872:     
image 2074:     
image 5805:    UNK
image 5683:     
image 1489:    
image 6117:    
evaluating validation preformance... 840/1000 (2.431551)
image 7592:     
image 1798:   UNK
image 3567:     
image 5090:     
image 6440:     
image 4214:    
image 2093:    
image 1712:    
image 3313:    
image 5534:    
evaluating validation preformance... 850/1000 (2.698014)
image 4404:    
image 5501:    
image 5765:    
image 1838:      
image 4354:    
image 336:    
image 3596:      
image 1921:     
image 6261:    
image 2166:       
evaluating validation preformance... 860/1000 (2.695792)
image 4254:      
image 6842:     
image 1644:   
image 7371:    
image 4638:     
image 4031:     
image 2702:    
image 4927:     
image 3222:   
image 4002:     
evaluating validation preformance... 870/1000 (2.340315)
image 4934:    
image 6487:    
image 4217:    
image 6355:    
image 2793:     
image 7201:      
image 5681:    
image 1824:   
image 2098:    
image 28:      
evaluating validation preformance... 880/1000 (2.593861)
image 5460:      
image 3671:     
image 3602:     
image 3473:     
image 2048:     
image 1379:    
image 419:    
image 2314:    
image 6244:     
image 4530:    
evaluating validation preformance... 890/1000 (2.889939)
image 7485:    
image 6102:     
image 1001:    
image 7167:    
image 4168:    
image 187:    
image 7798:    
image 4813:     
image 7753:     
image 210:    
evaluating validation preformance... 900/1000 (3.588616)
image 5664:     
image 4985:    
image 4082:      
image 6291:    
image 5573:     
image 1405:      
image 4431:    
image 2801:    
image 2398:   
image 7205:     
evaluating validation preformance... 910/1000 (2.200962)
image 1368:     
image 1925:    
image 5870:    
image 4915:     
image 3879:     
image 1002:     
image 4605:     
image 6475:     
image 3748:    
image 844:     
evaluating validation preformance... 920/1000 (2.589672)
image 7152:    
image 4559:      
image 7233:    
image 1341:    
image 5337:     
image 3189:     
image 6274:       
image 7102:    
image 5532:    
image 2516:     
evaluating validation preformance... 930/1000 (2.505026)
image 5636:      
image 7799:      
image 6025:     
image 6907:    
image 2507:    
image 7014:     
image 5566:      
image 5161:     
image 652:     
image 4412:    
evaluating validation preformance... 940/1000 (2.702340)
image 5860:     
image 3275:    
image 1935:    
image 3520:    
image 5452:    
image 2446:    
image 5984:   
image 5804:     
image 6691:     
image 6530:     
evaluating validation preformance... 950/1000 (2.934888)
image 1081:    
image 1179:     
image 4316:     
image 3588:    
image 1085:        
image 3923:    
image 4229:     
image 3336:    
image 2915:    
image 1550:      
evaluating validation preformance... 960/1000 (2.720236)
image 4935:    
image 1930:      
image 6850:    
image 5310:     
image 177:    
image 94:    
image 529:    
image 4632:      
image 3766:    
image 374:      
evaluating validation preformance... 970/1000 (2.279180)
image 5688:     
image 5448:    
image 5871:     
image 7516:      
image 3734:    
image 2921:      
image 7800:  UNK  
image 3999:    
image 6317:    
image 5931:      
evaluating validation preformance... 980/1000 (2.729393)
image 7352:     
image 5113:     
image 7822:     
image 4858:     
image 658:    
image 2982:     
image 5843:    
image 1822:     
image 7813:     
image 5567:     
evaluating validation preformance... 990/1000 (2.418306)
image 5789:      
image 5606:    
image 6107:     
image 7976:    
image 3890:     
image 5901:     
image 1163:    
image 2483:    
image 2591:    
image 7615:    
evaluating validation preformance... 1000/1000 (2.310043)
average loss on validation: 2.575
model saved to ./log_Att2in_sc/model.pth
===============================================
Begin calculating cider score on TEST data set
DataLoader loading json file:  data/f8ktalk2.json
vocab size is  2485
DataLoader loading h5 file:  data/cocotalk_fc data/f8ktalk_att data/cocotalk_box data/f8ktalk2_label.h5
max sequence length in data is 16
read 8000 image features
assigned 6000 images to split train
assigned 1000 images to split val
assigned 1000 images to split test
Read data: 1.3910479545593262
Cider scores: 0.6172858408204038
Read data: 0.33394646644592285
Cider scores: 0.6433365353037614
Read data: 0.23608160018920898
Cider scores: 0.5907723625867798
Read data: 0.23923873901367188
Cider scores: 0.5635593382496986
Read data: 0.2447977066040039
Cider scores: 0.5754726545636073
Read data: 0.19743561744689941
Cider scores: 0.5203888564799073
Read data: 0.20039582252502441
Cider scores: 0.541823065212496
Read data: 0.187042236328125
Cider scores: 0.6293788517707765
Read data: 0.17733240127563477
Cider scores: 0.5578466768187933
Read data: 0.2048196792602539
Cider scores: 0.7085255957984266
Read data: 0.18344402313232422
Cider scores: 0.6329251567937458
Read data: 0.1819469928741455
Cider scores: 0.7302485708030487
Read data: 0.2395646572113037
Cider scores: 0.6722693668180523
Read data: 0.20111966133117676
Cider scores: 0.637604726748637
Read data: 0.18608736991882324
Cider scores: 0.6301119840885665
Read data: 0.17012453079223633
Cider scores: 0.7587399105071995
Read data: 0.16428923606872559
Cider scores: 0.5138635318805378
Read data: 0.16342377662658691
Cider scores: 0.6622935323567477
Read data: 0.1655871868133545
Cider scores: 0.6014998148033593
Read data: 0.16677141189575195
Cider scores: 0.8081100486177002
Average cider score on test set: 0.630
End calculating cider score on TEST data set
===============================================
Read data: 0.1659858226776123
iter 21000 (epoch 34), train_loss = 2.299, time/batch = 0.027
Read data: 0.00011086463928222656
iter 21001 (epoch 35), train_loss = 2.482, time/batch = 0.020
Read data: 0.00012159347534179688
iter 21002 (epoch 35), train_loss = 2.269, time/batch = 0.021
Read data: 0.00011420249938964844
iter 21003 (epoch 35), train_loss = 2.548, time/batch = 0.033
Read data: 0.00010228157043457031
iter 21004 (epoch 35), train_loss = 2.343, time/batch = 0.030
Read data: 0.00011014938354492188
iter 21005 (epoch 35), train_loss = 2.324, time/batch = 0.023
Read data: 9.655952453613281e-05
iter 21006 (epoch 35), train_loss = 2.407, time/batch = 0.027
Read data: 0.00018787384033203125
iter 21007 (epoch 35), train_loss = 2.249, time/batch = 0.027
Read data: 0.00010442733764648438
iter 21008 (epoch 35), train_loss = 2.282, time/batch = 0.023
Read data: 0.00011682510375976562
iter 21009 (epoch 35), train_loss = 2.185, time/batch = 0.023
Read data: 7.772445678710938e-05
iter 21010 (epoch 35), train_loss = 2.116, time/batch = 0.034
Read data: 8.487701416015625e-05
iter 21011 (epoch 35), train_loss = 2.225, time/batch = 0.027
Read data: 8.893013000488281e-05
iter 21012 (epoch 35), train_loss = 2.274, time/batch = 0.022
Read data: 9.512901306152344e-05
iter 21013 (epoch 35), train_loss = 2.484, time/batch = 0.025
Read data: 7.653236389160156e-05
iter 21014 (epoch 35), train_loss = 2.239, time/batch = 0.023
Read data: 0.0001888275146484375
iter 21015 (epoch 35), train_loss = 2.542, time/batch = 0.023
Read data: 9.918212890625e-05
iter 21016 (epoch 35), train_loss = 2.209, time/batch = 0.026
Read data: 0.00010395050048828125
iter 21017 (epoch 35), train_loss = 2.424, time/batch = 0.035
Read data: 8.296966552734375e-05
iter 21018 (epoch 35), train_loss = 2.037, time/batch = 0.031
Read data: 8.96453857421875e-05
iter 21019 (epoch 35), train_loss = 2.430, time/batch = 0.030
Read data: 0.00012922286987304688
iter 21020 (epoch 35), train_loss = 2.252, time/batch = 0.030
Read data: 9.894371032714844e-05
iter 21021 (epoch 35), train_loss = 2.287, time/batch = 0.028
Read data: 0.00011348724365234375
iter 21022 (epoch 35), train_loss = 2.271, time/batch = 0.024
Read data: 8.535385131835938e-05
iter 21023 (epoch 35), train_loss = 2.634, time/batch = 0.036
Read data: 0.00013756752014160156
iter 21024 (epoch 35), train_loss = 2.124, time/batch = 0.026
Read data: 8.368492126464844e-05
iter 21025 (epoch 35), train_loss = 2.166, time/batch = 0.026
Read data: 0.00011396408081054688
iter 21026 (epoch 35), train_loss = 1.976, time/batch = 0.031
Read data: 8.869171142578125e-05
iter 21027 (epoch 35), train_loss = 2.560, time/batch = 0.027
Read data: 9.226799011230469e-05
iter 21028 (epoch 35), train_loss = 1.881, time/batch = 0.025
Read data: 8.320808410644531e-05
iter 21029 (epoch 35), train_loss = 2.063, time/batch = 0.025
Read data: 7.963180541992188e-05
iter 21030 (epoch 35), train_loss = 2.708, time/batch = 0.025
Read data: 0.00013256072998046875
iter 21031 (epoch 35), train_loss = 2.245, time/batch = 0.022
Read data: 0.00013709068298339844
iter 21032 (epoch 35), train_loss = 2.121, time/batch = 0.033
Read data: 0.00010251998901367188
iter 21033 (epoch 35), train_loss = 2.296, time/batch = 0.029
Read data: 8.344650268554688e-05
iter 21034 (epoch 35), train_loss = 2.695, time/batch = 0.033
Read data: 0.00016069412231445312
iter 21035 (epoch 35), train_loss = 2.208, time/batch = 0.028
Read data: 0.00012826919555664062
iter 21036 (epoch 35), train_loss = 1.959, time/batch = 0.022
Read data: 8.535385131835938e-05
iter 21037 (epoch 35), train_loss = 2.342, time/batch = 0.034
Read data: 7.963180541992188e-05
iter 21038 (epoch 35), train_loss = 2.115, time/batch = 0.029
Read data: 0.00016117095947265625
iter 21039 (epoch 35), train_loss = 2.813, time/batch = 0.023
Read data: 8.320808410644531e-05
iter 21040 (epoch 35), train_loss = 2.119, time/batch = 0.025
Read data: 8.440017700195312e-05
iter 21041 (epoch 35), train_loss = 2.196, time/batch = 0.027
Read data: 8.225440979003906e-05
iter 21042 (epoch 35), train_loss = 2.595, time/batch = 0.029
Read data: 7.653236389160156e-05
iter 21043 (epoch 35), train_loss = 2.222, time/batch = 0.029
Read data: 8.535385131835938e-05
iter 21044 (epoch 35), train_loss = 2.440, time/batch = 0.021
Read data: 8.654594421386719e-05
iter 21045 (epoch 35), train_loss = 2.117, time/batch = 0.025
Read data: 7.891654968261719e-05
iter 21046 (epoch 35), train_loss = 2.165, time/batch = 0.023
Read data: 0.0001723766326904297
iter 21047 (epoch 35), train_loss = 2.092, time/batch = 0.025
Read data: 9.989738464355469e-05
iter 21048 (epoch 35), train_loss = 2.515, time/batch = 0.033
Read data: 8.20159912109375e-05
iter 21049 (epoch 35), train_loss = 2.256, time/batch = 0.025
Read data: 0.00016689300537109375
iter 21050 (epoch 35), train_loss = 2.730, time/batch = 0.028
Read data: 8.106231689453125e-05
iter 21051 (epoch 35), train_loss = 2.433, time/batch = 0.022
Read data: 8.821487426757812e-05
iter 21052 (epoch 35), train_loss = 2.362, time/batch = 0.023
Read data: 0.00010609626770019531
iter 21053 (epoch 35), train_loss = 2.129, time/batch = 0.022
Read data: 9.703636169433594e-05
iter 21054 (epoch 35), train_loss = 2.206, time/batch = 0.028
Read data: 0.00011944770812988281
iter 21055 (epoch 35), train_loss = 2.452, time/batch = 0.026
Read data: 0.0001316070556640625
iter 21056 (epoch 35), train_loss = 2.308, time/batch = 0.023
Read data: 0.0001442432403564453
iter 21057 (epoch 35), train_loss = 1.877, time/batch = 0.036
Read data: 8.392333984375e-05
iter 21058 (epoch 35), train_loss = 2.279, time/batch = 0.032
Read data: 8.58306884765625e-05
iter 21059 (epoch 35), train_loss = 2.427, time/batch = 0.030
Read data: 8.797645568847656e-05
iter 21060 (epoch 35), train_loss = 2.237, time/batch = 0.033
Read data: 9.107589721679688e-05
iter 21061 (epoch 35), train_loss = 2.201, time/batch = 0.022
Read data: 8.344650268554688e-05
iter 21062 (epoch 35), train_loss = 2.225, time/batch = 0.027
Read data: 8.130073547363281e-05
iter 21063 (epoch 35), train_loss = 2.520, time/batch = 0.025
Read data: 8.463859558105469e-05
iter 21064 (epoch 35), train_loss = 2.365, time/batch = 0.030
Read data: 0.00012302398681640625
iter 21065 (epoch 35), train_loss = 2.405, time/batch = 0.027
Read data: 8.177757263183594e-05
iter 21066 (epoch 35), train_loss = 2.481, time/batch = 0.027
Read data: 8.988380432128906e-05
iter 21067 (epoch 35), train_loss = 2.699, time/batch = 0.028
Read data: 0.00012445449829101562
iter 21068 (epoch 35), train_loss = 2.027, time/batch = 0.028
Read data: 8.416175842285156e-05
iter 21069 (epoch 35), train_loss = 2.189, time/batch = 0.024
Read data: 7.891654968261719e-05
iter 21070 (epoch 35), train_loss = 2.551, time/batch = 0.025
Read data: 0.00015878677368164062
iter 21071 (epoch 35), train_loss = 2.325, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 21072 (epoch 35), train_loss = 2.281, time/batch = 0.027
Read data: 8.368492126464844e-05
iter 21073 (epoch 35), train_loss = 2.770, time/batch = 0.028
Read data: 8.320808410644531e-05
iter 21074 (epoch 35), train_loss = 2.701, time/batch = 0.033
Read data: 0.00021219253540039062
iter 21075 (epoch 35), train_loss = 2.510, time/batch = 0.024
Read data: 8.7738037109375e-05
iter 21076 (epoch 35), train_loss = 2.061, time/batch = 0.025
Read data: 0.00012230873107910156
iter 21077 (epoch 35), train_loss = 2.649, time/batch = 0.027
Read data: 8.106231689453125e-05
iter 21078 (epoch 35), train_loss = 2.400, time/batch = 0.023
Read data: 0.00013899803161621094
iter 21079 (epoch 35), train_loss = 2.509, time/batch = 0.025
Read data: 0.00012946128845214844
iter 21080 (epoch 35), train_loss = 2.019, time/batch = 0.028
Read data: 8.058547973632812e-05
iter 21081 (epoch 35), train_loss = 2.306, time/batch = 0.026
Read data: 7.891654968261719e-05
iter 21082 (epoch 35), train_loss = 2.112, time/batch = 0.023
Read data: 9.846687316894531e-05
iter 21083 (epoch 35), train_loss = 2.196, time/batch = 0.028
Read data: 0.00012183189392089844
iter 21084 (epoch 35), train_loss = 2.205, time/batch = 0.028
Read data: 8.797645568847656e-05
iter 21085 (epoch 35), train_loss = 2.248, time/batch = 0.027
Read data: 8.487701416015625e-05
iter 21086 (epoch 35), train_loss = 2.283, time/batch = 0.025
Read data: 0.000152587890625
iter 21087 (epoch 35), train_loss = 2.212, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 21088 (epoch 35), train_loss = 2.575, time/batch = 0.029
Read data: 0.00011563301086425781
iter 21089 (epoch 35), train_loss = 2.715, time/batch = 0.027
Read data: 7.939338684082031e-05
iter 21090 (epoch 35), train_loss = 2.127, time/batch = 0.027
Read data: 0.00015783309936523438
iter 21091 (epoch 35), train_loss = 2.587, time/batch = 0.036
Read data: 9.202957153320312e-05
iter 21092 (epoch 35), train_loss = 2.045, time/batch = 0.024
Read data: 8.940696716308594e-05
iter 21093 (epoch 35), train_loss = 2.899, time/batch = 0.033
Read data: 0.0001125335693359375
iter 21094 (epoch 35), train_loss = 2.373, time/batch = 0.026
Read data: 8.249282836914062e-05
iter 21095 (epoch 35), train_loss = 2.281, time/batch = 0.024
Read data: 8.392333984375e-05
iter 21096 (epoch 35), train_loss = 2.033, time/batch = 0.023
Read data: 8.630752563476562e-05
iter 21097 (epoch 35), train_loss = 2.138, time/batch = 0.024
Read data: 0.00010561943054199219
iter 21098 (epoch 35), train_loss = 2.532, time/batch = 0.029
Read data: 7.796287536621094e-05
iter 21099 (epoch 35), train_loss = 2.601, time/batch = 0.025
Read data: 0.0017657279968261719
iter 21100 (epoch 35), train_loss = 2.350, time/batch = 0.026
Read data: 8.678436279296875e-05
iter 21101 (epoch 35), train_loss = 2.615, time/batch = 0.027
Read data: 8.320808410644531e-05
iter 21102 (epoch 35), train_loss = 2.425, time/batch = 0.026
Read data: 8.797645568847656e-05
iter 21103 (epoch 35), train_loss = 2.022, time/batch = 0.022
Read data: 8.177757263183594e-05
iter 21104 (epoch 35), train_loss = 2.161, time/batch = 0.028
Read data: 8.249282836914062e-05
iter 21105 (epoch 35), train_loss = 2.255, time/batch = 0.026
Read data: 8.058547973632812e-05
iter 21106 (epoch 35), train_loss = 2.425, time/batch = 0.026
Read data: 0.00017571449279785156
iter 21107 (epoch 35), train_loss = 2.181, time/batch = 0.026
Read data: 0.00012350082397460938
iter 21108 (epoch 35), train_loss = 2.282, time/batch = 0.030
Read data: 0.00012445449829101562
iter 21109 (epoch 35), train_loss = 2.453, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 21110 (epoch 35), train_loss = 1.980, time/batch = 0.023
Read data: 7.891654968261719e-05
iter 21111 (epoch 35), train_loss = 2.604, time/batch = 0.026
Read data: 0.00012230873107910156
iter 21112 (epoch 35), train_loss = 2.089, time/batch = 0.023
Read data: 0.00011205673217773438
iter 21113 (epoch 35), train_loss = 2.237, time/batch = 0.039
Read data: 8.058547973632812e-05
iter 21114 (epoch 35), train_loss = 2.311, time/batch = 0.028
Read data: 0.00011682510375976562
iter 21115 (epoch 35), train_loss = 2.210, time/batch = 0.036
Read data: 7.939338684082031e-05
iter 21116 (epoch 35), train_loss = 2.357, time/batch = 0.024
Read data: 0.00012874603271484375
iter 21117 (epoch 35), train_loss = 2.636, time/batch = 0.026
Read data: 8.749961853027344e-05
iter 21118 (epoch 35), train_loss = 2.281, time/batch = 0.024
Read data: 0.0001308917999267578
iter 21119 (epoch 35), train_loss = 2.331, time/batch = 0.030
Read data: 8.344650268554688e-05
iter 21120 (epoch 35), train_loss = 2.159, time/batch = 0.028
Read data: 8.368492126464844e-05
iter 21121 (epoch 35), train_loss = 2.647, time/batch = 0.026
Read data: 7.748603820800781e-05
iter 21122 (epoch 35), train_loss = 2.238, time/batch = 0.027
Read data: 0.00012874603271484375
iter 21123 (epoch 35), train_loss = 2.114, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 21124 (epoch 35), train_loss = 1.956, time/batch = 0.022
Read data: 8.630752563476562e-05
iter 21125 (epoch 35), train_loss = 2.011, time/batch = 0.027
Read data: 9.870529174804688e-05
iter 21126 (epoch 35), train_loss = 2.198, time/batch = 0.023
Read data: 0.00014925003051757812
iter 21127 (epoch 35), train_loss = 1.923, time/batch = 0.025
Read data: 9.870529174804688e-05
iter 21128 (epoch 35), train_loss = 2.490, time/batch = 0.025
Read data: 9.918212890625e-05
iter 21129 (epoch 35), train_loss = 2.326, time/batch = 0.023
Read data: 9.322166442871094e-05
iter 21130 (epoch 35), train_loss = 2.515, time/batch = 0.026
Read data: 0.00017905235290527344
iter 21131 (epoch 35), train_loss = 2.057, time/batch = 0.024
Read data: 0.00013494491577148438
iter 21132 (epoch 35), train_loss = 2.483, time/batch = 0.030
Read data: 9.059906005859375e-05
iter 21133 (epoch 35), train_loss = 2.007, time/batch = 0.026
Read data: 7.82012939453125e-05
iter 21134 (epoch 35), train_loss = 2.142, time/batch = 0.029
Read data: 7.867813110351562e-05
iter 21135 (epoch 35), train_loss = 2.612, time/batch = 0.025
Read data: 8.678436279296875e-05
iter 21136 (epoch 35), train_loss = 2.493, time/batch = 0.023
Read data: 8.392333984375e-05
iter 21137 (epoch 35), train_loss = 2.097, time/batch = 0.025
Read data: 7.748603820800781e-05
iter 21138 (epoch 35), train_loss = 2.340, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 21139 (epoch 35), train_loss = 2.537, time/batch = 0.028
Read data: 8.463859558105469e-05
iter 21140 (epoch 35), train_loss = 2.469, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 21141 (epoch 35), train_loss = 2.428, time/batch = 0.024
Read data: 9.226799011230469e-05
iter 21142 (epoch 35), train_loss = 2.151, time/batch = 0.024
Read data: 0.00012230873107910156
iter 21143 (epoch 35), train_loss = 2.520, time/batch = 0.032
Read data: 8.463859558105469e-05
iter 21144 (epoch 35), train_loss = 2.177, time/batch = 0.020
Read data: 0.00011038780212402344
iter 21145 (epoch 35), train_loss = 2.076, time/batch = 0.024
Read data: 9.250640869140625e-05
iter 21146 (epoch 35), train_loss = 2.438, time/batch = 0.028
Read data: 8.153915405273438e-05
iter 21147 (epoch 35), train_loss = 2.501, time/batch = 0.031
Read data: 8.153915405273438e-05
iter 21148 (epoch 35), train_loss = 2.143, time/batch = 0.024
Read data: 8.58306884765625e-05
iter 21149 (epoch 35), train_loss = 2.250, time/batch = 0.021
Read data: 7.581710815429688e-05
iter 21150 (epoch 35), train_loss = 2.462, time/batch = 0.025
Read data: 0.0017848014831542969
iter 21151 (epoch 35), train_loss = 2.219, time/batch = 0.025
Read data: 0.00014495849609375
iter 21152 (epoch 35), train_loss = 1.892, time/batch = 0.022
Read data: 9.131431579589844e-05
iter 21153 (epoch 35), train_loss = 2.572, time/batch = 0.030
Read data: 7.772445678710938e-05
iter 21154 (epoch 35), train_loss = 2.252, time/batch = 0.029
Read data: 0.00015997886657714844
iter 21155 (epoch 35), train_loss = 2.578, time/batch = 0.025
Read data: 8.249282836914062e-05
iter 21156 (epoch 35), train_loss = 2.050, time/batch = 0.021
Read data: 0.0001361370086669922
iter 21157 (epoch 35), train_loss = 2.022, time/batch = 0.029
Read data: 9.441375732421875e-05
iter 21158 (epoch 35), train_loss = 2.392, time/batch = 0.030
Read data: 0.00015020370483398438
iter 21159 (epoch 35), train_loss = 2.370, time/batch = 0.028
Read data: 8.7738037109375e-05
iter 21160 (epoch 35), train_loss = 2.082, time/batch = 0.025
Read data: 0.00012636184692382812
iter 21161 (epoch 35), train_loss = 2.142, time/batch = 0.023
Read data: 8.225440979003906e-05
iter 21162 (epoch 35), train_loss = 2.168, time/batch = 0.023
Read data: 0.00013589859008789062
iter 21163 (epoch 35), train_loss = 1.880, time/batch = 0.026
Read data: 9.322166442871094e-05
iter 21164 (epoch 35), train_loss = 2.184, time/batch = 0.023
Read data: 0.00013566017150878906
iter 21165 (epoch 35), train_loss = 2.272, time/batch = 0.026
Read data: 9.012222290039062e-05
iter 21166 (epoch 35), train_loss = 2.312, time/batch = 0.027
Read data: 9.441375732421875e-05
iter 21167 (epoch 35), train_loss = 2.525, time/batch = 0.030
Read data: 8.416175842285156e-05
iter 21168 (epoch 35), train_loss = 2.158, time/batch = 0.026
Read data: 8.20159912109375e-05
iter 21169 (epoch 35), train_loss = 2.252, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 21170 (epoch 35), train_loss = 2.558, time/batch = 0.027
Read data: 7.796287536621094e-05
iter 21171 (epoch 35), train_loss = 2.116, time/batch = 0.025
Read data: 0.0001049041748046875
iter 21172 (epoch 35), train_loss = 2.119, time/batch = 0.026
Read data: 8.440017700195312e-05
iter 21173 (epoch 35), train_loss = 2.056, time/batch = 0.022
Read data: 9.250640869140625e-05
iter 21174 (epoch 35), train_loss = 2.488, time/batch = 0.037
Read data: 0.0001251697540283203
iter 21175 (epoch 35), train_loss = 2.642, time/batch = 0.023
Read data: 8.177757263183594e-05
iter 21176 (epoch 35), train_loss = 2.496, time/batch = 0.025
Read data: 8.082389831542969e-05
iter 21177 (epoch 35), train_loss = 2.467, time/batch = 0.027
Read data: 8.082389831542969e-05
iter 21178 (epoch 35), train_loss = 2.646, time/batch = 0.031
Read data: 8.058547973632812e-05
iter 21179 (epoch 35), train_loss = 2.471, time/batch = 0.024
Read data: 8.225440979003906e-05
iter 21180 (epoch 35), train_loss = 2.430, time/batch = 0.024
Read data: 0.00011920928955078125
iter 21181 (epoch 35), train_loss = 2.333, time/batch = 0.025
Read data: 7.796287536621094e-05
iter 21182 (epoch 35), train_loss = 2.444, time/batch = 0.031
Read data: 0.00012755393981933594
iter 21183 (epoch 35), train_loss = 2.214, time/batch = 0.029
Read data: 8.463859558105469e-05
iter 21184 (epoch 35), train_loss = 2.245, time/batch = 0.036
Read data: 9.417533874511719e-05
iter 21185 (epoch 35), train_loss = 2.371, time/batch = 0.034
Read data: 9.274482727050781e-05
iter 21186 (epoch 35), train_loss = 2.220, time/batch = 0.024
Read data: 8.869171142578125e-05
iter 21187 (epoch 35), train_loss = 1.936, time/batch = 0.024
Read data: 8.630752563476562e-05
iter 21188 (epoch 35), train_loss = 2.375, time/batch = 0.021
Read data: 0.000125885009765625
iter 21189 (epoch 35), train_loss = 2.194, time/batch = 0.024
Read data: 9.059906005859375e-05
iter 21190 (epoch 35), train_loss = 2.248, time/batch = 0.027
Read data: 0.0001785755157470703
iter 21191 (epoch 35), train_loss = 1.962, time/batch = 0.027
Read data: 9.632110595703125e-05
iter 21192 (epoch 35), train_loss = 2.369, time/batch = 0.028
Read data: 8.130073547363281e-05
iter 21193 (epoch 35), train_loss = 2.368, time/batch = 0.025
Read data: 7.557868957519531e-05
iter 21194 (epoch 35), train_loss = 2.573, time/batch = 0.024
Read data: 8.153915405273438e-05
iter 21195 (epoch 35), train_loss = 2.322, time/batch = 0.024
Read data: 0.00015616416931152344
iter 21196 (epoch 35), train_loss = 2.102, time/batch = 0.024
Read data: 8.606910705566406e-05
iter 21197 (epoch 35), train_loss = 2.145, time/batch = 0.023
Read data: 8.511543273925781e-05
iter 21198 (epoch 35), train_loss = 2.184, time/batch = 0.030
Read data: 7.915496826171875e-05
iter 21199 (epoch 35), train_loss = 2.150, time/batch = 0.028
Read data: 0.0001652240753173828
iter 21200 (epoch 35), train_loss = 2.318, time/batch = 0.023
Read data: 7.82012939453125e-05
iter 21201 (epoch 35), train_loss = 2.400, time/batch = 0.026
Read data: 7.581710815429688e-05
iter 21202 (epoch 35), train_loss = 2.176, time/batch = 0.028
Read data: 8.296966552734375e-05
iter 21203 (epoch 35), train_loss = 2.177, time/batch = 0.026
Read data: 0.00015783309936523438
iter 21204 (epoch 35), train_loss = 2.338, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 21205 (epoch 35), train_loss = 2.300, time/batch = 0.030
Read data: 7.700920104980469e-05
iter 21206 (epoch 35), train_loss = 2.260, time/batch = 0.024
Read data: 0.00016069412231445312
iter 21207 (epoch 35), train_loss = 1.872, time/batch = 0.027
Read data: 8.0108642578125e-05
iter 21208 (epoch 35), train_loss = 2.221, time/batch = 0.024
Read data: 0.00015234947204589844
iter 21209 (epoch 35), train_loss = 2.436, time/batch = 0.021
Read data: 9.322166442871094e-05
iter 21210 (epoch 35), train_loss = 2.427, time/batch = 0.028
Read data: 0.0001475811004638672
iter 21211 (epoch 35), train_loss = 2.254, time/batch = 0.031
Read data: 7.963180541992188e-05
iter 21212 (epoch 35), train_loss = 2.324, time/batch = 0.025
Read data: 8.535385131835938e-05
iter 21213 (epoch 35), train_loss = 2.316, time/batch = 0.030
Read data: 7.987022399902344e-05
iter 21214 (epoch 35), train_loss = 2.326, time/batch = 0.026
Read data: 0.00012874603271484375
iter 21215 (epoch 35), train_loss = 2.397, time/batch = 0.033
Read data: 8.463859558105469e-05
iter 21216 (epoch 35), train_loss = 2.430, time/batch = 0.029
Read data: 8.153915405273438e-05
iter 21217 (epoch 35), train_loss = 2.151, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 21218 (epoch 35), train_loss = 2.241, time/batch = 0.026
Read data: 7.939338684082031e-05
iter 21219 (epoch 35), train_loss = 2.457, time/batch = 0.022
Read data: 8.58306884765625e-05
iter 21220 (epoch 35), train_loss = 2.386, time/batch = 0.030
Read data: 0.00015783309936523438
iter 21221 (epoch 35), train_loss = 2.264, time/batch = 0.025
Read data: 0.00014591217041015625
iter 21222 (epoch 35), train_loss = 1.976, time/batch = 0.027
Read data: 7.772445678710938e-05
iter 21223 (epoch 35), train_loss = 2.780, time/batch = 0.025
Read data: 8.106231689453125e-05
iter 21224 (epoch 35), train_loss = 2.629, time/batch = 0.028
Read data: 0.0002028942108154297
iter 21225 (epoch 35), train_loss = 2.376, time/batch = 0.024
Read data: 8.177757263183594e-05
iter 21226 (epoch 35), train_loss = 2.035, time/batch = 0.028
Read data: 0.00012683868408203125
iter 21227 (epoch 35), train_loss = 2.027, time/batch = 0.022
Read data: 8.225440979003906e-05
iter 21228 (epoch 35), train_loss = 2.570, time/batch = 0.021
Read data: 0.00011777877807617188
iter 21229 (epoch 35), train_loss = 2.136, time/batch = 0.030
Read data: 9.417533874511719e-05
iter 21230 (epoch 35), train_loss = 2.231, time/batch = 0.021
Read data: 8.7738037109375e-05
iter 21231 (epoch 35), train_loss = 2.314, time/batch = 0.029
Read data: 0.00010347366333007812
iter 21232 (epoch 35), train_loss = 2.041, time/batch = 0.023
Read data: 8.96453857421875e-05
iter 21233 (epoch 35), train_loss = 2.417, time/batch = 0.031
Read data: 7.987022399902344e-05
iter 21234 (epoch 35), train_loss = 2.226, time/batch = 0.021
Read data: 0.00013017654418945312
iter 21235 (epoch 35), train_loss = 2.457, time/batch = 0.025
Read data: 9.942054748535156e-05
iter 21236 (epoch 35), train_loss = 2.485, time/batch = 0.024
Read data: 0.00011944770812988281
iter 21237 (epoch 35), train_loss = 2.095, time/batch = 0.026
Read data: 8.940696716308594e-05
iter 21238 (epoch 35), train_loss = 2.414, time/batch = 0.039
Read data: 0.00016379356384277344
iter 21239 (epoch 35), train_loss = 2.453, time/batch = 0.027
Read data: 0.00011134147644042969
iter 21240 (epoch 35), train_loss = 2.435, time/batch = 0.027
Read data: 0.00010895729064941406
iter 21241 (epoch 35), train_loss = 2.778, time/batch = 0.022
Read data: 8.130073547363281e-05
iter 21242 (epoch 35), train_loss = 2.633, time/batch = 0.028
Read data: 7.748603820800781e-05
