{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('labusr': conda)"
  },
  "interpreter": {
   "hash": "f3033dbcbae6bb642ed57e4081e4d44f6ee06ab71c363517056fcbe5febdb814"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "x = np.load(\"../data/cocotalk_fc/112114.npy\")\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, array\n",
    "import numpy as np\n",
    "\n",
    "class BigFile:\n",
    "\n",
    "    def __init__(self, datadir):\n",
    "        self.nr_of_images, self.ndims = map(int, open(os.path.join(datadir,'shape.txt')).readline().split())\n",
    "        id_file = os.path.join(datadir, \"id.txt\")\n",
    "        self.names = open(id_file).read().strip().split()\n",
    "        assert(len(self.names) == self.nr_of_images)\n",
    "        self.name2index = dict(zip(self.names, range(self.nr_of_images)))\n",
    "        self.binary_file = os.path.join(datadir, \"feature.bin\")\n",
    "        print (\"[%s] %dx%d instances loaded from %s\" % (self.__class__.__name__, self.nr_of_images, self.ndims, datadir))\n",
    "\n",
    "\n",
    "    def read(self, requested, isname=True):\n",
    "        requested = set(requested)\n",
    "        if isname:\n",
    "            index_name_array = [(self.name2index[x], x) for x in requested if x in self.name2index]\n",
    "        else:\n",
    "            assert(min(requested)>=0)\n",
    "            assert(max(requested)<len(self.names))\n",
    "            index_name_array = [(x, self.names[x]) for x in requested]\n",
    "        if len(index_name_array) == 0:\n",
    "            return [], []\n",
    "       \n",
    "        index_name_array.sort(key=lambda v:v[0])\n",
    "        sorted_index = [x[0] for x in index_name_array]\n",
    "\n",
    "        nr_of_images = len(index_name_array)\n",
    "        vecs = [None] * nr_of_images\n",
    "        offset = np.float32(1).nbytes * self.ndims\n",
    "        \n",
    "        res = array.array('f')\n",
    "        fr = open(self.binary_file, 'rb')\n",
    "        fr.seek(index_name_array[0][0] * offset)\n",
    "        res.fromfile(fr, self.ndims)\n",
    "        previous = index_name_array[0][0]\n",
    " \n",
    "        for next in sorted_index[1:]:\n",
    "            move = (next-1-previous) * offset\n",
    "            #print next, move\n",
    "            fr.seek(move, 1)\n",
    "            res.fromfile(fr, self.ndims)\n",
    "            previous = next\n",
    "\n",
    "        fr.close()\n",
    "\n",
    "        return [x[1] for x in index_name_array], [ res[i*self.ndims:(i+1)*self.ndims].tolist() for i in range(nr_of_images) ]\n",
    "\n",
    "\n",
    "    def read_one(self, name):\n",
    "        renamed, vectors = self.read([name])\n",
    "        return vectors[0]    \n",
    "\n",
    "    def shape(self):\n",
    "        return [self.nr_of_images, self.ndims]\n",
    "\n",
    "\n",
    "class StreamFile:\n",
    "\n",
    "    def __init__(self, datadir):\n",
    "        self.feat_dir = datadir\n",
    "        self.nr_of_images, self.ndims = map(int, open(os.path.join(datadir,'shape.txt')).readline().split())\n",
    "        id_file = os.path.join(datadir, \"id.txt\")\n",
    "        self.names = open(id_file).read().strip().split()\n",
    "        assert(len(self.names) == self.nr_of_images)\n",
    "        self.name2index = dict(zip(self.names, range(self.nr_of_images)))\n",
    "        self.binary_file = os.path.join(datadir, \"feature.bin\")\n",
    "        print (\"[%s] %dx%d instances loaded from %s\" % (self.__class__.__name__, self.nr_of_images, self.ndims, datadir))\n",
    "        self.fr = None\n",
    "        self.current = 0\n",
    "    \n",
    "\n",
    "    def open(self):\n",
    "        self.fr = open(os.path.join(self.feat_dir,'feature.bin'), 'rb')\n",
    "        self.current = 0\n",
    "\n",
    "    def close(self):\n",
    "        if self.fr:\n",
    "            self.fr.close()\n",
    "            self.fr = None\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "        \n",
    "    def next(self):\n",
    "        if self.current >= self.nr_of_images:\n",
    "            self.close()\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            res = array.array('f')\n",
    "            res.fromfile(self.fr, self.ndims)\n",
    "            _id = self.names[self.current]\n",
    "            self.current += 1\n",
    "            return _id, res.tolist() \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[BigFile] 8091x1024 instances loaded from ../data\n"
     ]
    }
   ],
   "source": [
    "bigfile = BigFile('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "imset = str.split('1000268201_693b08cb0e')\n",
    "renamed, vectors = bigfile.read(imset)\n",
    "\n",
    "for name,vec in zip(renamed, vectors):\n",
    "    print(name, vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '../data'\n",
    "nr_of_images, ndims = map(int, open(os.path.join(datadir,'shape.txt')).readline().split())\n",
    "id_file = os.path.join(datadir, \"id.txt\")\n",
    "names = open(id_file).read().strip().split()\n",
    "assert(len(names) == nr_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['1000268201_693b08cb0e', '1001773457_577c3a7d70', '1002674143_1b742ab4b8']"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "names[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "len(vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "name2index_file = open(\"../data/name2index.pkl\", \"rb\")\n",
    "name2index = pickle.load(name2index_file)\n",
    "\n",
    "index2name = {index:name for name,index in name2index.items()}\n",
    "\n",
    "with open('../data/flickr8ktrain.txt') as f:\n",
    "    train_names = f.readlines()   \n",
    "with open('../data/flickr8kval.txt') as f:\n",
    "    val_names = f.readlines()   \n",
    "with open('../data/flickr8ktest.txt') as f:\n",
    "    test_names = f.readlines()   \n",
    "\n",
    "train_id = [name2index[w[0:-1]] for w in train_names]\n",
    "val_id = [name2index[w[0:-1]] for w in val_names]\n",
    "test_id = [name2index[w[0:-1]] for w in test_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "len(val_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}